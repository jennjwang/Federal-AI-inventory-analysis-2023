{
  "theme_content": [
    {
      "theme": "security",
      "emoji": "\ud83d\udd12",
      "real_responses": [
        "The Barcode Scanner is a project developed by the DHS HSI Innovation Lab / RAVEn to scan and populate information from MRZ and PDF417 barcodes into text fields on the RAVEn GO's Encounter Card. This project supports ICE's mission to enforce and investigate violations of U.S. laws and allows for the analysis of trends and criminal patterns. For more information, refer to the DHS/ICE/PIA-055 Privacy Impact Assessment.",
        "The Identity Match Option (IMO) is a process used by USCIS to determine a single identity for each applicant or beneficiary across multiple systems. This process combines data from various systems to create comprehensive immigration histories for individuals, allowing for analysis, fraud detection, and resolution of data quality issues.",
        "The Cyber Threat Intelligence Feed Correlation utilizes AI to quickly correlate information from multiple feeds, enhancing the quality of externally shared information. The AI algorithm can learn and improve its efficiency in performing the task, and customized algorithms can be developed for continuous monitoring of threat actors' tactics, techniques, and procedures (TTPs).",
        "HSI uses Artificial Intelligence to normalize and correct data entry errors, identify purposeful misidentification, and connect information across datasets. This streamlines the process of investigations and reduces the number of resource hours needed. The services provided include normalizing addresses, inferring ID types, categorizing name parts, and validating phone numbers. These services are part of the Repository for Analytics in a Virtualized Environment (RAVEn), which supports ICE's mission to enforce and investigate violations of U.S. laws."
      ],
      "description": "AI is used in various projects to scan and populate information from barcodes, provide automated phone responses, enhance maritime detection, determine identities across systems, generate synthetic data for anomaly detection, improve document workflow, identify cases of overpayments, correlate cyber threat intelligence, classify service desk tickets, scan documents for privileged information, predict pest detection, manage video surveillance, analyze email data, normalize and correct data entry errors, assist in duplicate identification, improve malware reverse engineering, identify high-risk claims, develop a digital twin for chemical separations, and support secure spectrum sharing for 5G.",
      "actionable_steps": [
        "Conduct a comprehensive assessment of the organization's current processes and systems to identify potential areas where AI can be implemented effectively.",
        "Prioritize the projects based on their potential impact and feasibility, considering factors such as resource availability, technical requirements, and alignment with business goals.",
        "Develop and implement a clear roadmap for each AI project, including timelines, milestones, and key stakeholders, to ensure successful implementation and integration into existing workflows."
      ],
      "total_observations": 455,
      "positive_observations": 90
    },
    {
      "theme": "infrastructure",
      "emoji": "\ud83c\udfd7\ufe0f",
      "real_responses": [
        "The project involves using gridded meteorologic forcing data and daily streamflow data to build random forest and neural network models. The project is being developed on AWS and in cooperation with CHS, and the USGS HPC systems are also being utilized.",
        "The Water Mission Area Drought Prediction Project aims to create a method for predicting daily hydrologic drought by using machine learning models calibrated on streamflow and meteorological data. The models will be developed for specific locations and then applied to similar ungaged basins through a \"donor model\" approach. The project will utilize the USGS HPC systems for model development and running.",
        "The main goal of the project is to develop a machine learning-based system that can detect attacks in the fifth generation (5G) cellular network. This system aims to enhance security for mission-critical applications such as automated vehicles, drones, connected health, and emergency response operations that rely on the 5G network.",
        "The Autonomous Maritime Awareness system utilizes surveillance towers, ocean data solutions, unmanned autonomous surface vehicles (ASV), and AI to detect, identify, and track objects of interest in a maritime environment. The system uses low-cost surveillance towers equipped with radars and cameras, as well as ruggedized ASVs powered by wind, solar, or onboard engines. Both systems employ AI/ML to autonomously detect and track objects, and can send alerts to monitoring agencies for potential interdictions or intelligence collection."
      ],
      "description": "AI is used in these projects to develop and apply machine learning models for various purposes, such as predicting hydrologic drought, improving document workflows, detecting attacks on 5G networks, enhancing maritime awareness, analyzing data from rotating machines, monitoring and managing power grids, analyzing satellite imagery, detecting anomalies in critical infrastructure networks, mapping cracks on infrastructure, documenting war crimes, and automating anomaly detection for industrial control systems.",
      "actionable_steps": [
        "Establish a dedicated AI team: Bring together a team of experts in machine learning and AI technologies to focus on developing and applying machine learning models for various purposes mentioned. This team should consist of data scientists, engineers, and subject matter experts from relevant domains.",
        "Prioritize AI projects: Identify the most critical and impactful areas where AI can be applied within the organization. Prioritize projects that have the potential to deliver tangible results and provide significant value to the organization. This can be done through a thorough assessment of the potential benefits and risks associated with each project.",
        "Invest in infrastructure and data management: Ensure that the organization has the necessary infrastructure and data management capabilities to support AI projects. This includes investing in high-performance computing resources, data storage and processing systems, and robust data governance practices. Additionally, establish protocols for data collection, data quality assurance, and data sharing to ensure reliable and accurate inputs for AI models."
      ],
      "total_observations": 455,
      "positive_observations": 72
    },
    {
      "theme": "environmental",
      "emoji": "\ud83c\udf0d",
      "real_responses": [
        "The Coast Train Coast Train dataset is a collection of orthomosaic and satellite images of coastal, estuarine, and wetland environments along with corresponding thematic label masks. The dataset includes spatial and time-series data and contains over 1.2 billion labelled pixels, representing more than 3.6 million hectares.",
        "The Water Mission Area Drought Prediction Project aims to create a method for predicting daily hydrologic drought by using machine learning models calibrated on streamflow and meteorological data. The models will be developed for specific locations and then applied to similar ungaged basins through a \"donor model\" approach. The project will utilize the USGS HPC systems for model development and running.",
        "NOAA Coral Reef Watch has been using remote sensing, modeling, and in situ data to operate a Decision Support System to help resource managers, researchers, decision makers, and stakeholders prepare for and respond to coral reef ecosystem stressors caused by climate change and warming oceans. They offer the world's only global early-warning system for coral reef ecosystem changes and provide information, early warnings, and outlooks of stressful environmental conditions at targeted reef locations worldwide. Their products primarily focus on sea surface temperature but also incorporate other variables such as light and ocean color."
      ],
      "description": "AI is used in these projects to analyze large datasets, predict droughts, estimate water flow in streams, monitor coral reef ecosystems, detect and track objects in maritime environments, classify climate change-related projects, annotate marine imagery, detect illegal rhino horn smuggling, process aerial images of marine birds and mammals, replace wave models with AI models, detect volcanic events, enhance environmental regulation enforcement, predict flood flow metrics, classify marine mammal species using acoustic recordings, monitor citrus orchard health, analyze sub-surface drainage using satellite imagery, predict harmful algae blooms, and estimate chemical intake rates.",
      "actionable_steps": [
        "Identify specific projects or initiatives within the organization where AI can be implemented to analyze large datasets, predict events, or enhance monitoring capabilities. This could be done through consultation with experts in the respective fields or conducting a thorough assessment of existing processes and identifying areas where AI can add value.",
        "Invest in the necessary infrastructure and resources to support AI implementation. This may include acquiring or developing AI models, algorithms, and tools, as well as ensuring the availability of computing power and storage capabilities to process and analyze large datasets.",
        "Train and educate staff members on AI technologies and their applications in the organization's projects. This can be achieved through workshops, training programs, or partnering with external experts in AI to provide guidance and support in implementing and using AI effectively."
      ],
      "total_observations": 455,
      "positive_observations": 66
    },
    {
      "theme": "spatial",
      "emoji": "\ud83c\udf0d",
      "real_responses": [
        "The main goal of this project is to develop and test machine learning models for predicting and forecasting daily hydrologic drought in the Colorado River Basin. The project involves using gridded meteorologic forcing data and daily streamflow data to build random forest and neural network models. The project is being developed on AWS and in cooperation with CHS, and the USGS HPC systems are also being utilized.",
        "The Ecosystem Management Decision Support System (EMDS) is a spatial decision support system that operates within ArcGIS and QGIS. It allows users to create applications tailored to their specific needs using various AI engines, including logic processing, multi-criteria decision analysis, Bayesian networks, and Prolog-based decision trees.",
        "The main idea of the response is that machine learning models are being used to map and monitor forest mortality and defoliation across the United States. These models use training data from various sources and can process the output into vector polygons."
      ],
      "description": "AI is used in these projects to create prospectivity maps for mineral deposits, predict hydrologic drought, extract spot elevations from historical maps, streamline raster analysis, support spatial decision making, identify wildfire damage and defensible space, classify crop types, identify green sea turtles, detect volcanic events, map forest mortality, detect citrus tree infections, identify airframes and marine vessels, monitor citrus orchard health, predict ground shaking during earthquakes, analyze cracks on Reclamation facilities, map sub-surface drainage, model fish distribution, and classify land cover.",
      "actionable_steps": [
        "Develop a comprehensive plan to identify and prioritize the projects that would benefit the most from AI implementation. This can involve conducting a thorough analysis of the potential impact and feasibility of each project.",
        "Invest in the necessary infrastructure and resources to support AI implementation, such as acquiring high-performance computing systems and hiring data scientists or AI experts.",
        "Collaborate with external partners, such as universities or research institutions, to leverage their expertise in AI and gain access to cutting-edge technologies and methodologies."
      ],
      "total_observations": 455,
      "positive_observations": 63
    },
    {
      "theme": "healthcare",
      "emoji": "\ud83c\udfe5",
      "real_responses": [
        "The Medicare Part D Subsidy Model utilizes machine learning to identify and highlight cases that may have incorrect Medicare Part D subsidies. These flagged cases are then reviewed by technicians for further assessment.",
        "A machine learning model is being used to evaluate treatment policies for patients with hepatitis C virus. The model is focused on predicting disease progression among veterans with this virus.",
        "The study aimed to predict the likelihood of achieving corticosteroid-free remission with Vedolizumab in ulcerative colitis patients. The researchers used random forest modeling on a group of 594 patients and found that baseline data or data through week 6 of therapy could be used to construct predictive models.",
        "This response states that a tool can predict health outcomes such as suicide death, opioid overdose, and decompensated outcomes of chronic diseases by using electronic health records as inputs. The tool can analyze both structured and unstructured data to generate deep phenotypes and predictions of these outcomes."
      ],
      "description": "AI is used in these projects to identify incorrect Medicare subsidies, predict disease progression in patients with hepatitis C, construct predictive models for achieving remission in ulcerative colitis patients, generate predictions of health outcomes using electronic health records, assist radiologists in analyzing X-ray properties, enhance treatment for peripheral artery disease, detect suicidal thoughts among veterans, track medication adherence, find colon polyps, assess lung function, identify duplicate reports in the FDA system, determine causal language in physician's notes, improve diagnostic error detection, evaluate risk factors for opioid use disorder and overdose, extract family medical history data, optimize hospital performance, identify social determinants of health, analyze claim submission patterns, track mental health in veterans, enhance clinical management of colorectal polyps, match cause of death descriptions, and predict response to treatment for irritable bowel disease.",
      "actionable_steps": [
        "Establish a cross-functional team: Form a dedicated team consisting of data scientists, clinicians, and IT professionals to oversee the implementation of AI projects in healthcare. This team should work collaboratively to identify priorities, allocate resources, and ensure effective communication and coordination across different departments.",
        "Develop data governance framework: Implement a comprehensive data governance framework that ensures the availability, quality, and privacy of healthcare data. This should include protocols for data collection, storage, and sharing, as well as mechanisms to protect patient privacy and comply with relevant regulations such as HIPAA.",
        "Invest in AI infrastructure and tools: Allocate resources to build the necessary infrastructure and acquire AI tools and technologies that support the organization's AI initiatives. This may involve investing in cloud computing capabilities, data storage solutions, machine learning algorithms, and AI platforms that enable efficient data analysis and model development.",
        "Foster partnerships and collaborations: Establish partnerships with academic institutions, technology vendors, and other healthcare organizations to leverage external expertise and resources. Collaborations can help in accessing large and diverse datasets, conducting joint research, and sharing best practices in AI implementation, ultimately enhancing the organization's AI capabilities."
      ],
      "total_observations": 455,
      "positive_observations": 55
    },
    {
      "theme": "cyber intelligence",
      "emoji": "\ud83d\udd0d",
      "real_responses": [
        "The research aims to develop methods and technologies that will allow existing cybersecurity tools to defend industrial control systems (ICS) networks and enable cybersecurity analysts to detect compromise before any harm can be done. The focus is on analyzing captured communication signals to determine the protocol being used, and machine learning will be employed to identify unknown protocols. The findings will be used to create a prototype device.",
        "The Cyber Threat Intelligence Feed Correlation utilizes AI to quickly correlate information from multiple feeds, enhancing the quality of externally shared information. The AI algorithm can learn and improve its efficiency in performing the task, and customized algorithms can be developed for continuous monitoring of threat actors' tactics, techniques, and procedures (TTPs).",
        "The AI Security and Robustness Frameworks, processes, and testing tools have been developed to govern the acquisition, development, deployment, and maintenance of AI technologies. These tools, which use Machine Learning and Natural Language Processing, help ensure the trustworthy, robust, and secure operation of AI systems by speeding up data processing and enhancing the assessment of AI technology within the agency.",
        "The Cyber Sentry program monitors critical infrastructure networks and uses advanced anomaly detection and machine learning to analyze cyber-physical data from IT and OT networks, including ICS/SCADA. The Critical Infrastructure Anomaly Alerting model assists threat hunting analysts by providing AI-assisted processing of this information."
      ],
      "description": "AI is used in these projects to defend industrial control systems, analyze text in procurement descriptions, correlate cyber threat intelligence feeds, improve malware reverse engineering, govern the acquisition and operation of AI systems, monitor critical infrastructure networks, detect vulnerabilities in system design, safeguard industrial internet of things devices, predict events and develop digital twins, assist in understanding operational activities, process and aggregate data for vulnerability analysis, detect 5G attacks, and detect network attacks using mathematical and probabilistic models.",
      "actionable_steps": [
        "Conduct a comprehensive assessment of the organization's current infrastructure and identify areas where AI can be effectively implemented for defense and analysis purposes.",
        "Develop a strategic plan outlining the specific projects and initiatives where AI will be utilized, including the goals, objectives, and desired outcomes.",
        "Invest in AI technologies, tools, and resources that are specifically designed to address the identified needs and requirements, ensuring compatibility with existing systems and networks."
      ],
      "total_observations": 455,
      "positive_observations": 25
    },
    {
      "theme": "power systems",
      "emoji": "\ud83d\udd0c",
      "real_responses": [
        "The research aims to use deep learning technology and internal voltage sensors to diagnose and predict failure in solid-state ceramic membrane reactors under harsh conditions.",
        "The response discusses the application of big data, artificial intelligence, and machine learning to analyze phasor measurement unit (PMU) data.",
        "The Autonomous Maritime Awareness system utilizes surveillance towers, ocean data solutions, unmanned autonomous surface vehicles (ASV), and AI to detect, identify, and track objects of interest in a maritime environment.",
        "The project aims to develop a deep reinforcement learning approach that can effectively manage distributed or tightly coupled multi-agent systems in energy systems."
      ],
      "description": "AI is used in these projects to analyze data and make predictions for various applications such as diagnosing and predicting failure in reactors, enhancing grid operation and management, detecting and tracking objects in a maritime environment, improving power system resilience, monitoring critical infrastructure networks for anomalies, automating training of anomaly detection systems, and detecting and tracking items of interest without human intervention.",
      "actionable_steps": [
        "Create a dedicated AI team: Establish a team of experts in artificial intelligence and data analysis to handle the implementation of AI projects. This team should consist of data scientists, engineers, and domain experts who can collaborate effectively to develop and deploy AI models for various applications mentioned.",
        "Develop a robust data infrastructure: Implement a scalable and secure data infrastructure that can handle the large volumes of data generated by the projects. This infrastructure should include data storage, processing, and analytics capabilities to support the AI algorithms and models. It should also prioritize data quality and reliability to ensure accurate predictions and analysis.",
        "Invest in continuous learning and improvement: Foster a culture of continuous learning and improvement within the organization. Encourage the AI team to stay updated with the latest advancements in the field and provide them with resources and training opportunities. Regularly evaluate the performance of AI models and iterate on them to enhance their accuracy and efficiency."
      ],
      "total_observations": 455,
      "positive_observations": 24
    },
    {
      "theme": "customer service or engagement",
      "emoji": "\ud83e\udd1d",
      "real_responses": [
        "The Service Desk Virtual Agent, known as Curie, is a chatbot that utilizes machine learning to offer predictive responses during chats. This virtual assistant is designed to enhance the customer service experience for employees seeking IT support by providing relevant information from knowledge-based articles.",
        "IRM's BMP Systems is looking to integrate ServiceNow's Virtual Agent into their applications to facilitate support and data requests for users. This AI-powered chatbot will be provided by ServiceNow's Platform as a Service.",
        "ILMS has created an automated support desk assistant using ServiceNow Virtual Agent in order to make interactions with the support desk easier for customers and to reduce the workload of support desk agents by resolving simple issues. This system aims to streamline support desk operations and minimize costs."
      ],
      "description": "AI is used in these projects to enhance customer service experiences, predict eligibility for naturalization, facilitate support and data requests, analyze customer text input and provide relevant knowledge, automate support desk tasks, automate data entry and reminders, streamline customer experience and automate answering questions, and gather insights to simplify user interactions and reduce task completion time.",
      "actionable_steps": [
        "Conduct an assessment to identify the specific areas in the organization where AI can be implemented to enhance customer service experiences, automate tasks, and gather insights.",
        "Develop a comprehensive AI strategy that outlines the goals, objectives, and key performance indicators for each project mentioned.",
        "Allocate resources and budget to support the implementation of AI technologies, including the necessary hardware, software, and skilled personnel."
      ],
      "total_observations": 455,
      "positive_observations": 18
    },
    {
      "theme": "maritime",
      "emoji": "\ud83c\udf0a",
      "real_responses": [
        "The Autonomous Maritime Awareness system utilizes surveillance towers, ocean data solutions, unmanned autonomous surface vehicles (ASV), and AI to detect, identify, and track objects of interest in a maritime environment. The system uses low-cost surveillance towers equipped with radars and cameras, as well as ruggedized ASVs powered by wind, solar, or onboard engines. Both systems employ AI/ML to autonomously detect and track objects, and can send alerts to monitoring agencies for potential interdictions or intelligence collection.",
        "The Seabird Studies Team at the Western Ecological Research Center conducted aerial surveys of the ocean off central and southern California to count and classify marine birds and mammals. To process the large volume of images, they used machine learning techniques and created a labeled training dataset. They are currently reviewing the model's output and will generate maps of species distribution and abundance to inform planning for offshore wind energy development.",
        "The Fisheries Electronic Monitoring Library (FEML) is a centralized database that stores electronic monitoring (EM) data pertaining to marine life. It serves as a repository for this information.",
        "The EcoCast is an operational tool that uses boosted regression trees to model the distribution of swordfish and bycatch species in the California Current. It is designed to reduce bycatch and support sustainable fisheries by providing dynamic ocean management."
      ],
      "description": "AI is used in these projects to enhance maritime detection and tracking, detect and track objects of interest in a maritime environment, process large volumes of images to classify marine birds and mammals, store electronic monitoring data, classify species identity of toothed whales and dolphins using acoustic recordings, model the distribution of swordfish and bycatch species, and identify consistent wave systems.",
      "actionable_steps": [
        "Invest in advanced AI technologies and infrastructure: The organization should allocate resources to acquire state-of-the-art AI technologies and infrastructure that can handle large volumes of data and perform complex algorithms. This will enable efficient processing of images, acoustic recordings, and other data for maritime detection, tracking, and classification tasks.",
        "Collaborate with research institutions and experts: To ensure accurate and reliable results, the organization should collaborate with research institutions and experts in the field of marine biology, acoustics, and oceanography. This collaboration will help in developing robust AI models and algorithms for species identification, distribution modeling, and wave system identification.",
        "Implement a comprehensive data management system: Given the large volumes of data involved in these projects, it is crucial to implement a comprehensive data management system. This system should include efficient storage and retrieval mechanisms for electronic monitoring data, as well as provide tools for data annotation and labeling to train AI models. Additionally, the system should comply with data privacy and security regulations to protect sensitive information."
      ],
      "total_observations": 455,
      "positive_observations": 13
    },
    {
      "theme": "fraud",
      "emoji": "\ud83d\udd75\ufe0f\u200d\u2642\ufe0f",
      "real_responses": [
        "The Retailer Receipt Analysis is a Proof of Concept that uses artificial intelligence to automate the manual process of reviewing FNS receipts and invoices. It aims to save staff time, ensure accuracy, and detect difficult patterns. The goal is to develop a review system that has an automated workflow, learns from analyst feedback, and can detect and visualize fraud patterns on retailer invoices and receipts.",
        "The main idea is that the use of technology, specifically Artificial Intelligence and mobile device cameras, is being utilized in the CBP One app to detect proof of life or \"Liveness Detection.\" This technology is important for reducing fraudulent activity and ensuring that the submitted data is from the actual person in front of the camera.",
        "The SSI Redetermination Model utilizes machine learning to pinpoint cases of supplemental security income that are likely to have significant overpayments due to alterations in financial eligibility. These cases are then flagged for review by technicians.",
        "A/LM plans to develop AI/ML models to detect potential fraud or malfeasance in their Integrated Logistics Management System (ILMS). These models will focus on key supply chain functions like Asset Management, Procure-to-Pay, and Fleet Management to enhance existing risk analytics."
      ],
      "description": "Artificial intelligence is used in various projects to automate manual processes, detect fraud patterns, reduce fraudulent activity, prioritize alerts, pinpoint overpayments, enhance risk analytics, and detect false data injection in physical processes.",
      "actionable_steps": [
        "Conduct a comprehensive assessment of the organization's processes and identify areas where artificial intelligence can be implemented to automate manual tasks and improve efficiency.",
        "Invest in and acquire advanced AI tools and technologies that are specifically designed for fraud detection, risk analytics, and data analysis.",
        "Train and upskill employees on AI technologies and provide them with the necessary knowledge and skills to leverage AI in their day-to-day operations."
      ],
      "total_observations": 455,
      "positive_observations": 11
    },
    {
      "theme": "wildfire",
      "emoji": "\ud83d\udd25",
      "real_responses": [
        "The goal of this study is to use machine learning and image classification techniques to identify buildings, building loss, and defensible space in wildland-urban interface areas affected by a wildfire.",
        "This study seeks to provide a proof-of-concept for mapping wildfire damage and evaluating the effectiveness of defensible space measures using machine learning and object-based image classification.",
        "By utilizing machine learning and image classification techniques, this research aims to assess the impact of a wildfire on buildings, building loss, and defensible space in wildland-urban interface areas.",
        "The primary objective of this study is to explore the application of machine learning and object-based image classification in order to identify wildfire damage and evaluate the effectiveness of defensible space measures."
      ],
      "description": "This project utilizes AI, specifically machine learning and object-based image classification techniques, to identify buildings, building loss, and defensible space in wildland-urban interface areas before and after a wildfire, serving as a proof-of-concept for mapping wildfire damage and evaluating defensible space measures.",
      "actionable_steps": [
        "Invest in training and resources: The organization should allocate resources to train staff members in machine learning and object-based image classification techniques. This can be accomplished through workshops, seminars, or hiring experts in the field. By providing the necessary training, the organization can build a skilled team capable of implementing the AI project effectively.",
        "Gather and analyze relevant data: To implement this project, the organization needs to collect and analyze relevant data, such as satellite imagery or aerial photographs, both before and after a wildfire event. This data will serve as the basis for training the machine learning models and identifying buildings, building loss, and defensible space. The organization should establish partnerships with agencies or companies that can provide access to such data or consider acquiring it through other means.",
        "Develop and test the AI model: Once the necessary data is gathered, the organization should focus on developing and testing the AI model for identifying buildings, building loss, and defensible space. This involves refining the machine learning algorithms, training the model using the collected data, and evaluating its performance. The organization should allocate time and resources for continuous testing and improvement to ensure the model's accuracy and reliability in mapping wildfire damage and evaluating defensible space measures."
      ],
      "total_observations": 455,
      "positive_observations": 1
    }
  ],
  "record_content": {
    "Department": {
      "296": "Interior",
      "333": "SSA",
      "411": "USAID",
      "82": "Commerce",
      "230": "Homeland Security",
      "150": "HHS",
      "15": "Agriculture",
      "195": "HHS",
      "297": "Interior",
      "311": "Labor",
      "159": "HHS",
      "427": "VA",
      "363": "State",
      "397": "Treasury",
      "266": "Interior",
      "365": "State",
      "238": "Homeland Security",
      "257": "Interior",
      "102": "Energy",
      "449": "VA",
      "71": "Commerce",
      "121": "Energy",
      "55": "Commerce",
      "143": "GSA",
      "191": "HHS",
      "374": "State",
      "314": "Labor",
      "211": "Homeland Security",
      "163": "HHS",
      "273": "Interior",
      "237": "Homeland Security",
      "364": "State",
      "256": "Interior",
      "20": "Agriculture",
      "183": "HHS",
      "60": "Commerce",
      "353": "State",
      "62": "Commerce",
      "117": "Energy",
      "260": "Interior",
      "447": "VA",
      "284": "Interior",
      "179": "HHS",
      "234": "Homeland Security",
      "417": "USAID",
      "356": "State",
      "327": "SSA",
      "96": "Energy",
      "210": "Homeland Security",
      "199": "Homeland Security",
      "229": "Homeland Security",
      "310": "Labor",
      "235": "Homeland Security",
      "182": "HHS",
      "340": "SSA",
      "442": "VA",
      "401": "Treasury",
      "139": "GSA",
      "17": "Agriculture",
      "166": "HHS",
      "147": "GSA",
      "157": "HHS",
      "27": "Agriculture",
      "67": "Commerce",
      "208": "Homeland Security",
      "354": "State",
      "120": "Energy",
      "140": "GSA",
      "431": "VA",
      "332": "SSA",
      "35": "Agriculture",
      "322": "Labor",
      "358": "State",
      "64": "Commerce",
      "127": "Energy",
      "59": "Commerce",
      "126": "Energy",
      "12": "Agriculture",
      "103": "Energy",
      "105": "Energy",
      "334": "SSA",
      "410": "USAID",
      "335": "SSA",
      "219": "Homeland Security",
      "18": "Agriculture",
      "203": "Homeland Security",
      "142": "GSA",
      "393": "Treasury",
      "440": "VA",
      "125": "Energy",
      "369": "State",
      "443": "VA",
      "407": "USAID",
      "308": "Justice",
      "44": "Commerce",
      "29": "Agriculture",
      "98": "Energy",
      "390": "Transportation",
      "438": "VA",
      "329": "SSA",
      "3": "Agriculture",
      "375": "State",
      "50": "Commerce",
      "246": "Interior",
      "41": "Commerce",
      "72": "Commerce",
      "413": "USAID",
      "349": "State",
      "380": "Transportation",
      "420": "VA",
      "94": "Energy",
      "30": "Agriculture",
      "0": "Agriculture",
      "130": "Energy",
      "446": "VA",
      "454": "VA",
      "249": "Interior",
      "247": "Interior",
      "196": "HHS",
      "38": "Agriculture",
      "352": "State",
      "69": "Commerce",
      "261": "Interior",
      "409": "USAID",
      "228": "Homeland Security",
      "36": "Agriculture",
      "423": "VA",
      "422": "VA",
      "223": "Homeland Security",
      "226": "Homeland Security",
      "22": "Agriculture",
      "312": "Labor",
      "165": "HHS",
      "26": "Agriculture",
      "372": "State",
      "267": "Interior",
      "448": "VA",
      "170": "HHS",
      "437": "VA",
      "119": "Energy",
      "337": "SSA",
      "355": "State",
      "74": "Commerce",
      "338": "SSA",
      "78": "Commerce",
      "180": "HHS",
      "138": "GSA",
      "389": "Transportation",
      "45": "Commerce",
      "93": "Energy",
      "193": "HHS",
      "263": "Interior",
      "68": "Commerce",
      "350": "State",
      "24": "Agriculture",
      "395": "Treasury",
      "436": "VA",
      "362": "State",
      "136": "EPA",
      "270": "Interior",
      "221": "Homeland Security",
      "6": "Agriculture",
      "244": "Interior",
      "1": "Agriculture",
      "285": "Interior",
      "357": "State",
      "114": "Energy",
      "328": "SSA",
      "313": "Labor",
      "13": "Agriculture",
      "214": "Homeland Security",
      "131": "Energy",
      "233": "Homeland Security",
      "56": "Commerce",
      "90": "Energy",
      "421": "VA",
      "323": "Labor",
      "65": "Commerce",
      "176": "HHS",
      "289": "Interior",
      "428": "VA",
      "11": "Agriculture",
      "258": "Interior",
      "97": "Energy",
      "265": "Interior",
      "113": "Energy",
      "207": "Homeland Security",
      "315": "Labor",
      "231": "Homeland Security",
      "239": "Homeland Security",
      "396": "Treasury",
      "47": "Commerce",
      "10": "Agriculture",
      "371": "State",
      "288": "Interior",
      "251": "Interior",
      "370": "State",
      "149": "HHS",
      "75": "Commerce",
      "76": "Commerce",
      "122": "Energy",
      "101": "Energy",
      "394": "Treasury",
      "400": "Treasury",
      "133": "Energy",
      "37": "Agriculture",
      "205": "Homeland Security",
      "302": "Interior",
      "48": "Commerce",
      "2": "Agriculture",
      "115": "Energy",
      "152": "HHS",
      "359": "State",
      "319": "Labor",
      "190": "HHS",
      "301": "Interior",
      "57": "Commerce",
      "217": "Homeland Security",
      "242": "Interior",
      "25": "Agriculture",
      "53": "Commerce",
      "245": "Interior",
      "110": "Energy",
      "412": "USAID",
      "435": "VA",
      "177": "HHS",
      "453": "VA",
      "325": "Labor",
      "88": "Education",
      "218": "Homeland Security",
      "8": "Agriculture",
      "128": "Energy",
      "286": "Interior",
      "185": "HHS",
      "141": "GSA",
      "271": "Interior",
      "351": "State",
      "112": "Energy",
      "236": "Homeland Security",
      "404": "USAID",
      "92": "Energy",
      "111": "Energy",
      "54": "Commerce",
      "167": "HHS",
      "66": "Commerce",
      "124": "Energy",
      "178": "HHS",
      "160": "HHS",
      "426": "VA",
      "452": "VA",
      "378": "Transportation",
      "129": "Energy",
      "318": "Labor",
      "100": "Energy",
      "416": "USAID",
      "457": "VA",
      "295": "Interior",
      "215": "Homeland Security",
      "134": "EPA",
      "19": "Agriculture",
      "344": "State",
      "399": "Treasury",
      "254": "Interior",
      "294": "Interior",
      "342": "State",
      "339": "SSA",
      "385": "Transportation",
      "189": "HHS",
      "9": "Agriculture",
      "39": "Commerce",
      "155": "HHS",
      "243": "Interior",
      "224": "Homeland Security",
      "31": "Agriculture",
      "433": "VA",
      "415": "USAID",
      "168": "HHS",
      "309": "Labor",
      "153": "HHS",
      "107": "Energy",
      "80": "Commerce",
      "275": "Interior",
      "43": "Commerce",
      "293": "Interior",
      "406": "USAID",
      "116": "Energy",
      "137": "GSA",
      "248": "Interior",
      "154": "HHS",
      "109": "Energy",
      "321": "Labor",
      "95": "Energy",
      "382": "Transportation",
      "425": "VA",
      "184": "HHS",
      "429": "VA",
      "173": "HHS",
      "222": "Homeland Security",
      "253": "Interior",
      "188": "HHS",
      "77": "Commerce",
      "268": "Interior",
      "278": "Interior",
      "241": "Interior",
      "46": "Commerce",
      "336": "SSA",
      "201": "Homeland Security",
      "79": "Commerce",
      "386": "Transportation",
      "162": "HHS",
      "299": "Interior",
      "161": "HHS",
      "23": "Agriculture",
      "300": "Interior",
      "282": "Interior",
      "276": "Interior",
      "451": "VA",
      "360": "State",
      "403": "Treasury",
      "148": "GSA",
      "158": "HHS",
      "346": "State",
      "33": "Agriculture",
      "306": "Justice",
      "81": "Commerce",
      "220": "Homeland Security",
      "290": "Interior",
      "42": "Commerce",
      "51": "Commerce",
      "345": "State",
      "86": "Commerce",
      "391": "Transportation",
      "197": "HHS",
      "424": "VA",
      "200": "Homeland Security",
      "225": "Homeland Security",
      "123": "Energy",
      "388": "Transportation",
      "348": "State",
      "274": "Interior",
      "91": "Energy",
      "164": "HHS",
      "151": "HHS",
      "156": "HHS",
      "384": "Transportation",
      "212": "Homeland Security",
      "281": "Interior",
      "87": "Commerce",
      "171": "HHS",
      "455": "VA",
      "326": "Labor",
      "174": "HHS",
      "4": "Agriculture",
      "445": "VA",
      "441": "VA",
      "192": "HHS",
      "264": "Interior",
      "269": "Interior",
      "5": "Agriculture",
      "209": "Homeland Security",
      "287": "Interior",
      "63": "Commerce",
      "206": "Homeland Security",
      "108": "Energy",
      "272": "Interior",
      "144": "GSA",
      "198": "HHS",
      "49": "Commerce",
      "298": "Interior",
      "398": "Treasury",
      "402": "Treasury",
      "40": "Commerce",
      "85": "Commerce",
      "83": "Commerce",
      "14": "Agriculture",
      "341": "State",
      "430": "VA",
      "444": "VA",
      "172": "HHS",
      "381": "Transportation",
      "262": "Interior",
      "392": "Treasury",
      "280": "Interior",
      "70": "Commerce",
      "439": "VA",
      "387": "Transportation",
      "279": "Interior",
      "146": "GSA",
      "52": "Commerce",
      "106": "Energy",
      "450": "VA",
      "405": "USAID",
      "99": "Energy",
      "61": "Commerce",
      "7": "Agriculture",
      "186": "HHS",
      "283": "Interior",
      "330": "SSA",
      "232": "Homeland Security",
      "21": "Agriculture",
      "213": "Homeland Security",
      "408": "USAID",
      "250": "Interior",
      "118": "Energy",
      "169": "HHS",
      "259": "Interior",
      "181": "HHS",
      "104": "Energy",
      "303": "Interior",
      "84": "Commerce",
      "317": "Labor",
      "135": "EPA",
      "419": "VA",
      "28": "Agriculture",
      "304": "Interior",
      "418": "VA",
      "73": "Commerce",
      "368": "State",
      "316": "Labor",
      "202": "Homeland Security",
      "32": "Agriculture",
      "175": "HHS",
      "252": "Interior",
      "216": "Homeland Security",
      "204": "Homeland Security",
      "432": "VA",
      "240": "Interior",
      "292": "Interior",
      "132": "Energy",
      "373": "State",
      "227": "Homeland Security",
      "194": "HHS",
      "331": "SSA",
      "34": "Agriculture",
      "367": "State",
      "89": "Energy",
      "379": "Transportation",
      "434": "VA",
      "383": "Transportation",
      "291": "Interior",
      "456": "VA",
      "343": "State",
      "414": "USAID",
      "366": "State",
      "347": "State",
      "187": "HHS",
      "145": "GSA",
      "307": "Justice",
      "16": "Agriculture",
      "58": "Commerce",
      "277": "Interior",
      "305": "Justice",
      "255": "Interior",
      "320": "Labor",
      "324": "Labor"
    },
    "Agency": {
      "296": "USGS",
      "333": "SSA",
      "411": "USAID",
      "82": "National Telecommunications and \nInformation Administration (NTIA)",
      "230": "Immigration and Customs Enforcement",
      "150": "AHRQ",
      "15": "USDA",
      "195": "NIH",
      "297": "USGS",
      "311": null,
      "159": "CMS",
      "427": null,
      "363": null,
      "397": null,
      "266": "USGS",
      "365": null,
      "238": "United States Citizenship and Immigration Services",
      "257": "USGS",
      "102": null,
      "449": null,
      "71": "National Oceanic and \nAtmospheric Administration \n(NOAA)",
      "121": null,
      "55": "National Oceanic and \nAtmospheric Administration \n(NOAA)",
      "143": "GSA",
      "191": "NIH",
      "374": null,
      "314": null,
      "211": "Customs and Border Protection",
      "163": "CMS",
      "273": "USGS",
      "237": "United States Citizenship and Immigration Services",
      "364": null,
      "256": "USGS",
      "20": "USDA",
      "183": "NIH",
      "60": "National Oceanic and \nAtmospheric Administration \n(NOAA)",
      "353": null,
      "62": "National Oceanic and \nAtmospheric Administration \n(NOAA)",
      "117": null,
      "260": "USGS",
      "447": null,
      "284": "USGS",
      "179": "NIH",
      "234": "United States Citizenship and Immigration Services",
      "417": "USAID",
      "356": null,
      "327": "SSA",
      "96": null,
      "210": "Customs and Border Protection",
      "199": "Customs and Border Protection",
      "229": "Immigration and Customs Enforcement",
      "310": null,
      "235": "United States Citizenship and Immigration Services",
      "182": "NIH",
      "340": "SSA",
      "442": null,
      "401": null,
      "139": "GSA",
      "17": "USDA",
      "166": "CMS",
      "147": "GSA",
      "157": "CDC",
      "27": "USDA",
      "67": "National Oceanic and \nAtmospheric Administration \n(NOAA)",
      "208": "Customs and Border Protection",
      "354": null,
      "120": null,
      "140": "GSA",
      "431": null,
      "332": "SSA",
      "35": "USDA",
      "322": null,
      "358": null,
      "64": "National Oceanic and \nAtmospheric Administration \n(NOAA)",
      "127": null,
      "59": "National Oceanic and \nAtmospheric Administration \n(NOAA)",
      "126": null,
      "12": "USDA",
      "103": null,
      "105": null,
      "334": "SSA",
      "410": "USAID",
      "335": "SSA",
      "219": "Cybersecurity and Infrastructure Security Agency",
      "18": "USDA",
      "203": "Customs and Border Protection",
      "142": "GSA",
      "393": null,
      "440": null,
      "125": null,
      "369": null,
      "443": null,
      "407": "USAID",
      "308": "Tax Division",
      "44": "Minority Business Development \nAdministration (MBDA)",
      "29": "USDA",
      "98": null,
      "390": "National Highway Traffic Safety Administration",
      "438": null,
      "329": "SSA",
      "3": "USDA",
      "375": null,
      "50": "National Oceanic and \nAtmospheric Administration \n(NOAA)",
      "246": "BOR",
      "41": "International Trade \nAdministration (ITA)",
      "72": "National Oceanic and \nAtmospheric Administration \n(NOAA)",
      "413": "USAID",
      "349": null,
      "380": "Federal Aviation Administration",
      "420": null,
      "94": null,
      "30": "USDA",
      "0": "USDA",
      "130": null,
      "446": null,
      "454": null,
      "249": "BSEE",
      "247": "BSEE",
      "196": "NIH",
      "38": "USDA",
      "352": null,
      "69": "National Oceanic and \nAtmospheric Administration \n(NOAA)",
      "261": "USGS",
      "409": "USAID",
      "228": "Immigration and Customs Enforcement",
      "36": "USDA",
      "423": null,
      "422": null,
      "223": "Cybersecurity and Infrastructure Security Agency",
      "226": "Immigration and Customs Enforcement",
      "22": "USDA",
      "312": null,
      "165": "CMS",
      "26": "USDA",
      "372": null,
      "267": "USGS",
      "448": null,
      "170": "FDA",
      "437": null,
      "119": null,
      "337": "SSA",
      "355": null,
      "74": "National Oceanic and \nAtmospheric Administration \n(NOAA)",
      "338": "SSA",
      "78": "National Oceanic and \nAtmospheric Administration \n(NOAA)",
      "180": "NIH",
      "138": "GSA",
      "389": "National Highway Traffic Safety Administration",
      "45": "National Oceanic and \nAtmospheric Administration \n(NOAA)",
      "93": null,
      "193": "NIH",
      "263": "USGS",
      "68": "National Oceanic and \nAtmospheric Administration \n(NOAA)",
      "350": null,
      "24": "USDA",
      "395": null,
      "436": null,
      "362": null,
      "136": null,
      "270": "USGS",
      "221": "Cybersecurity and Infrastructure Security Agency",
      "6": "USDA",
      "244": "BOR",
      "1": "USDA",
      "285": "USGS",
      "357": null,
      "114": null,
      "328": "SSA",
      "313": null,
      "13": "USDA",
      "214": "Cybersecurity and Infrastructure Security Agency",
      "131": null,
      "233": "United States Citizenship and Immigration Services",
      "56": "National Oceanic and \nAtmospheric Administration \n(NOAA)",
      "90": null,
      "421": null,
      "323": null,
      "65": "National Oceanic and \nAtmospheric Administration \n(NOAA)",
      "176": "NIH",
      "289": "USGS",
      "428": null,
      "11": "USDA",
      "258": "USGS",
      "97": null,
      "265": "USGS",
      "113": null,
      "207": "Customs and Border Protection",
      "315": null,
      "231": "Immigration and Customs Enforcement",
      "239": "United States Citizenship and Immigration Services",
      "396": null,
      "47": "National Oceanic and \nAtmospheric Administration \n(NOAA)",
      "10": "USDA",
      "371": null,
      "288": "USGS",
      "251": "USGS",
      "370": null,
      "149": "AHRQ",
      "75": "National Oceanic and \nAtmospheric Administration \n(NOAA)",
      "76": "National Oceanic and \nAtmospheric Administration \n(NOAA)",
      "122": null,
      "101": null,
      "394": null,
      "400": null,
      "133": null,
      "37": "USDA",
      "205": "Customs and Border Protection",
      "302": "USGS",
      "48": "National Oceanic and \nAtmospheric Administration \n(NOAA)",
      "2": "USDA",
      "115": null,
      "152": "AHRQ",
      "359": null,
      "319": null,
      "190": "NIH",
      "301": "USGS",
      "57": "National Oceanic and \nAtmospheric Administration \n(NOAA)",
      "217": "Cybersecurity and Infrastructure Security Agency",
      "242": "BOR",
      "25": "USDA",
      "53": "National Oceanic and \nAtmospheric Administration \n(NOAA)",
      "245": "BOR",
      "110": null,
      "412": "USAID",
      "435": null,
      "177": "NIH",
      "453": null,
      "325": null,
      "88": "Education",
      "218": "Cybersecurity and Infrastructure Security Agency",
      "8": "USDA",
      "128": null,
      "286": "USGS",
      "185": "NIH",
      "141": "GSA",
      "271": "USGS",
      "351": null,
      "112": null,
      "236": "United States Citizenship and Immigration Services",
      "404": "USAID",
      "92": null,
      "111": null,
      "54": "National Oceanic and \nAtmospheric Administration \n(NOAA)",
      "167": "CMS",
      "66": "National Oceanic and \nAtmospheric Administration \n(NOAA)",
      "124": null,
      "178": "NIH",
      "160": "CMS",
      "426": null,
      "452": null,
      "378": "Federal Aviation Administration",
      "129": null,
      "318": null,
      "100": null,
      "416": "USAID",
      "457": null,
      "295": "USGS",
      "215": "Cybersecurity and Infrastructure Security Agency",
      "134": null,
      "19": "USDA",
      "344": null,
      "399": null,
      "254": "USGS",
      "294": "USGS",
      "342": null,
      "339": "SSA",
      "385": "Federal Railroad Administration",
      "189": "NIH",
      "9": "USDA",
      "39": "International Trade \nAdministration (ITA)",
      "155": "AHRQ",
      "243": "BOR",
      "224": "HQ",
      "31": "USDA",
      "433": null,
      "415": "USAID",
      "168": "CMS",
      "309": null,
      "153": "AHRQ",
      "107": null,
      "80": "National Oceanic and \nAtmospheric Administration \n(NOAA)",
      "275": "USGS",
      "43": "International Trade \nAdministration (ITA)",
      "293": "USGS",
      "406": "USAID",
      "116": null,
      "137": "GSA",
      "248": "BSEE",
      "154": "AHRQ",
      "109": null,
      "321": null,
      "95": null,
      "382": "Federal Aviation Administration",
      "425": null,
      "184": "NIH",
      "429": null,
      "173": "HRSA",
      "222": "Cybersecurity and Infrastructure Security Agency",
      "253": "USGS",
      "188": "NIH",
      "77": "National Oceanic and \nAtmospheric Administration \n(NOAA)",
      "268": "USGS",
      "278": "USGS",
      "241": "BOR",
      "46": "National Oceanic and \nAtmospheric Administration \n(NOAA)",
      "336": "SSA",
      "201": "Customs and Border Protection",
      "79": "National Oceanic and \nAtmospheric Administration \n(NOAA)",
      "386": "Federal Railroad Administration",
      "162": "CMS",
      "299": "USGS",
      "161": "CMS",
      "23": "USDA",
      "300": "USGS",
      "282": "USGS",
      "276": "USGS",
      "451": null,
      "360": null,
      "403": null,
      "148": "GSA",
      "158": "CDC",
      "346": null,
      "33": "USDA",
      "306": "Federal Bureau of Investigation",
      "81": "National Telecommunications and \nInformation Administration (NTIA)",
      "220": "Cybersecurity and Infrastructure Security Agency",
      "290": "USGS",
      "42": "International Trade \nAdministration (ITA)",
      "51": "National Oceanic and \nAtmospheric Administration \n(NOAA)",
      "345": null,
      "86": "United States Patent and Trade \nOffice (USPTO)",
      "391": "Pipeline and Hazardous Materials Safety Administration (PHMSA",
      "197": "NIH",
      "424": null,
      "200": "Customs and Border Protection",
      "225": "HQ Enforcement, Intelligence and Analysis, Science and Technology",
      "123": null,
      "388": "Federal Transportation Administration",
      "348": null,
      "274": "USGS",
      "91": null,
      "164": "CMS",
      "151": "AHRQ",
      "156": "CDC",
      "384": "Federal Aviation Administration",
      "212": "Cybersecurity and Infrastructure Security Agency",
      "281": "USGS",
      "87": "United States Patent and Trade \nOffice (USPTO)",
      "171": "FDA",
      "455": null,
      "326": null,
      "174": "NIH",
      "4": "USDA",
      "445": null,
      "441": null,
      "192": "NIH",
      "264": "USGS",
      "269": "USGS",
      "5": "USDA",
      "209": "Customs and Border Protection",
      "287": "USGS",
      "63": "National Oceanic and \nAtmospheric Administration \n(NOAA)",
      "206": "Customs and Border Protection",
      "108": null,
      "272": "USGS",
      "144": "GSA",
      "198": "NIH",
      "49": "National Oceanic and \nAtmospheric Administration \n(NOAA)",
      "298": "USGS",
      "398": null,
      "402": null,
      "40": "International Trade \nAdministration (ITA)",
      "85": "United States Patent and Trade \nOffice (USPTO)",
      "83": "United States Patent and Trade \nOffice (USPTO)",
      "14": "USDA",
      "341": null,
      "430": null,
      "444": null,
      "172": "HRSA",
      "381": "Federal Aviation Administration",
      "262": "USGS",
      "392": null,
      "280": "USGS",
      "70": "National Oceanic and \nAtmospheric Administration \n(NOAA)",
      "439": null,
      "387": "Federal Railroad Administration",
      "279": "USGS",
      "146": "GSA",
      "52": "National Oceanic and \nAtmospheric Administration \n(NOAA)",
      "106": null,
      "450": null,
      "405": "USAID",
      "99": null,
      "61": "National Oceanic and \nAtmospheric Administration \n(NOAA)",
      "7": "USDA",
      "186": "NIH",
      "283": "USGS",
      "330": "SSA",
      "232": "United States Citizenship and Immigration Services",
      "21": "USDA",
      "213": "Cybersecurity and Infrastructure Security Agency",
      "408": "USAID",
      "250": "USGS",
      "118": null,
      "169": "FDA",
      "259": "USGS",
      "181": "NIH",
      "104": null,
      "303": "USGS",
      "84": "United States Patent and Trade \nOffice (USPTO)",
      "317": null,
      "135": null,
      "419": null,
      "28": "USDA",
      "304": "USGS",
      "418": null,
      "73": "National Oceanic and \nAtmospheric Administration \n(NOAA)",
      "368": null,
      "316": null,
      "202": "Customs and Border Protection",
      "32": "USDA",
      "175": "NIH",
      "252": "USGS",
      "216": "Cybersecurity and Infrastructure Security Agency",
      "204": "Customs and Border Protection",
      "432": null,
      "240": "BLM",
      "292": "USGS",
      "132": null,
      "373": null,
      "227": "Immigration and Customs Enforcement",
      "194": "NIH",
      "331": "SSA",
      "34": "USDA",
      "367": null,
      "89": null,
      "379": "Federal Aviation Administration",
      "434": null,
      "383": "Federal Aviation Administration",
      "291": "USGS",
      "456": null,
      "343": null,
      "414": "USAID",
      "366": null,
      "347": null,
      "187": "NIH",
      "145": "GSA",
      "307": "Justice Management Division",
      "16": "USDA",
      "58": "National Oceanic and \nAtmospheric Administration \n(NOAA)",
      "277": "USGS",
      "305": "Drug Enforcement Administration",
      "255": "USGS",
      "320": null,
      "324": null
    },
    "Office": {
      "296": null,
      "333": "Office of Analytics, Review, and Oversight ",
      "411": "USAID/Bureau for Global Health (GH)",
      "82": null,
      "230": null,
      "150": null,
      "15": "FNS",
      "195": "OIG",
      "297": null,
      "311": null,
      "159": null,
      "427": null,
      "363": "IRM",
      "397": null,
      "266": null,
      "365": "PM",
      "238": null,
      "257": null,
      "102": "Idaho National Laboratory",
      "449": null,
      "71": null,
      "121": "Idaho National Laboratory",
      "55": null,
      "143": null,
      "191": "OER",
      "374": "R",
      "314": null,
      "211": null,
      "163": null,
      "273": null,
      "237": null,
      "364": "M/SS",
      "256": null,
      "20": "Forest Service",
      "183": "NLM",
      "60": null,
      "353": "CSO",
      "62": null,
      "117": "Idaho National Laboratory",
      "260": null,
      "447": null,
      "284": null,
      "179": "NIGMS",
      "234": null,
      "417": "USAID/Bureau for Latin America and the Caribbean",
      "356": "GPA",
      "327": "Office of Analytics, Review, and Oversight ",
      "96": "Idaho National Laboratory",
      "210": null,
      "199": null,
      "229": null,
      "310": null,
      "235": null,
      "182": "NLM",
      "340": "Office of Systems",
      "442": null,
      "401": null,
      "139": null,
      "17": "Forest Service",
      "166": null,
      "147": null,
      "157": "NCHS",
      "27": "NASS",
      "67": null,
      "208": null,
      "354": "F",
      "120": "Idaho National Laboratory",
      "140": null,
      "431": null,
      "332": "Office of Analytics, Review, and Oversight ",
      "35": "OCIO",
      "322": null,
      "358": "GPA",
      "64": null,
      "127": "Office of Electricity",
      "59": null,
      "126": "Office of Electricity",
      "12": "ERS",
      "103": "Idaho National Laboratory",
      "105": "Idaho National Laboratory",
      "334": "Office of Analytics, Review, and Oversight ",
      "410": "USAID/Bureau for Global Health (GH)",
      "335": "Office of Analytics, Review, and Oversight; Office of Hearing Operations, Office of Disability Systems",
      "219": null,
      "18": "Forest Service",
      "203": null,
      "142": null,
      "393": null,
      "440": null,
      "125": "Office of Electricity",
      "369": "R",
      "443": null,
      "407": "USAID/Bureau for Development, Democracy, and Innovation (DDI)",
      "308": null,
      "44": null,
      "29": "NIFA",
      "98": "Idaho National Laboratory",
      "390": "NSR Human Injury Research Division",
      "438": null,
      "329": "Office of Analytics, Review, and Oversight ",
      "3": "APHIS",
      "375": "R",
      "50": null,
      "246": null,
      "41": null,
      "72": null,
      "413": "USAID/Bureau for Global Health (GH)",
      "349": "CGFS",
      "380": "ATO",
      "420": null,
      "94": "Idaho National Laboratory",
      "30": "NRCS",
      "0": "APHIS",
      "130": "Office of Electricity",
      "446": null,
      "454": null,
      "249": null,
      "247": null,
      "196": "OPA",
      "38": "OSSP",
      "352": "CSO",
      "69": null,
      "261": null,
      "409": "USAID/Bureau for Development, Democracy, and Innovation (DDI)",
      "228": null,
      "36": "OCIO",
      "423": null,
      "422": null,
      "223": null,
      "226": null,
      "22": "Forest Service",
      "312": null,
      "165": null,
      "26": "NASS",
      "372": "R",
      "267": null,
      "448": null,
      "170": null,
      "437": null,
      "119": "Idaho National Laboratory",
      "337": "Office of Disability Information Systems,  Office of Hearing Operations, Office of Appellate Operations",
      "355": "FSI",
      "74": null,
      "338": "Office of Disability Information Systems,  Office of Hearing Operations, Office of Appellate Operations",
      "78": null,
      "180": "NLM",
      "138": null,
      "389": "NSR Human Injury Research Division",
      "45": null,
      "93": "Idaho National Laboratory",
      "193": "OER",
      "263": null,
      "68": null,
      "350": "CSO",
      "24": "Forest Service",
      "395": null,
      "436": null,
      "362": "IRM",
      "136": null,
      "270": null,
      "221": null,
      "6": "APHIS",
      "244": null,
      "1": "APHIS",
      "285": null,
      "357": "GPA",
      "114": "Idaho National Laboratory",
      "328": "Office of Analytics, Review, and Oversight ",
      "313": null,
      "13": "ERS",
      "214": null,
      "131": "Office of Electricity",
      "233": null,
      "56": null,
      "90": "Idaho National Laboratory",
      "421": null,
      "323": null,
      "65": null,
      "176": "NIEHS",
      "289": null,
      "428": null,
      "11": "ARS",
      "258": null,
      "97": "Idaho National Laboratory",
      "265": null,
      "113": "Idaho National Laboratory",
      "207": null,
      "315": null,
      "231": null,
      "239": null,
      "396": null,
      "47": null,
      "10": "ARS",
      "371": "R",
      "288": null,
      "251": null,
      "370": "R",
      "149": null,
      "75": null,
      "76": null,
      "122": "Idaho National Laboratory",
      "101": "Idaho National Laboratory",
      "394": null,
      "400": null,
      "133": "Office of Electricity",
      "37": "OCIO",
      "205": null,
      "302": null,
      "48": null,
      "2": "APHIS",
      "115": "Idaho National Laboratory",
      "152": null,
      "359": "GPA",
      "319": null,
      "190": "OER",
      "301": null,
      "57": null,
      "217": null,
      "242": null,
      "25": "FPAC",
      "53": null,
      "245": null,
      "110": "Idaho National Laboratory",
      "412": "USAID/Bureau for Global Health (GH)",
      "435": null,
      "177": "NIEHS",
      "453": null,
      "325": null,
      "88": "Office of Federal Student Aid (FSA)",
      "218": null,
      "8": "APHIS",
      "128": "Office of Electricity",
      "286": null,
      "185": "NLM",
      "141": null,
      "271": null,
      "351": "CSO",
      "112": "Idaho National Laboratory",
      "236": null,
      "404": "USAID/Bureau for Development, Democracy, and Innovation (DDI)",
      "92": "Idaho National Laboratory",
      "111": "Idaho National Laboratory",
      "54": null,
      "167": null,
      "66": null,
      "124": "Office of Electricity",
      "178": "NIGMS",
      "160": null,
      "426": null,
      "452": null,
      "378": "ANG",
      "129": "Office of Electricity",
      "318": null,
      "100": "Idaho National Laboratory",
      "416": "USAID/Bureau for Latin America and the Caribbean",
      "457": null,
      "295": null,
      "215": null,
      "134": null,
      "19": "Forest Service",
      "344": "A",
      "399": null,
      "254": null,
      "294": null,
      "342": "A",
      "339": "Office of Retirement of Disability Programs ",
      "385": "Office of Research, Development and Technology",
      "189": "OER",
      "9": "ARS",
      "39": null,
      "155": null,
      "243": null,
      "224": null,
      "31": "NRCS",
      "433": null,
      "415": "USAID/Bureau for Latin America and the Caribbean",
      "168": null,
      "309": null,
      "153": null,
      "107": "Idaho National Laboratory",
      "80": null,
      "275": null,
      "43": null,
      "293": null,
      "406": "USAID/Bureau for Development, Democracy, and Innovation (DDI)",
      "116": "Idaho National Laboratory",
      "137": null,
      "248": null,
      "154": null,
      "109": "Idaho National Laboratory",
      "321": null,
      "95": "Idaho National Laboratory",
      "382": "AVS",
      "425": null,
      "184": "NLM",
      "429": null,
      "173": null,
      "222": null,
      "253": null,
      "188": "NLM",
      "77": null,
      "268": null,
      "278": null,
      "241": null,
      "46": null,
      "336": "Office of Disability Determinations, Office of Disability Information Systems",
      "201": null,
      "79": null,
      "386": "Office of Research, Development and Technology",
      "162": null,
      "299": null,
      "161": null,
      "23": "Forest Service",
      "300": null,
      "282": null,
      "276": null,
      "451": null,
      "360": "IRM",
      "403": null,
      "148": null,
      "158": "NCHS",
      "346": "A",
      "33": "NRCS",
      "306": null,
      "81": null,
      "220": null,
      "290": null,
      "42": null,
      "51": null,
      "345": "A",
      "86": null,
      "391": "PHMSA Office of Chief Counsel (PHC)",
      "197": "OPA",
      "424": null,
      "200": null,
      "225": null,
      "123": "Idaho National Laboratory",
      "388": "ATO",
      "348": "A",
      "274": null,
      "91": "Idaho National Laboratory",
      "164": null,
      "151": null,
      "156": "NCHS",
      "384": "NextGen (ANG)",
      "212": null,
      "281": null,
      "87": null,
      "171": null,
      "455": null,
      "326": null,
      "174": "NHLBI",
      "4": "APHIS",
      "445": null,
      "441": null,
      "192": "OER",
      "264": null,
      "269": null,
      "5": "APHIS",
      "209": null,
      "287": null,
      "63": null,
      "206": null,
      "108": "Idaho National Laboratory",
      "272": null,
      "144": null,
      "198": "OPA",
      "49": null,
      "298": null,
      "398": null,
      "402": null,
      "40": null,
      "85": null,
      "83": null,
      "14": "Federal CDO Council",
      "341": "A",
      "430": null,
      "444": null,
      "172": null,
      "381": "Aviation Safety (AVS)",
      "262": null,
      "392": null,
      "280": null,
      "70": null,
      "439": null,
      "387": "Office of Research, Development and Technology",
      "279": null,
      "146": null,
      "52": null,
      "106": "Idaho National Laboratory",
      "450": null,
      "405": "USAID/Bureau for Development, Democracy, and Innovation (DDI)",
      "99": "Idaho National Laboratory",
      "61": null,
      "7": "APHIS",
      "186": "NLM",
      "283": null,
      "330": "Office of Analytics, Review, and Oversight ",
      "232": null,
      "21": "Forest Service",
      "213": null,
      "408": "USAID/Bureau for Development, Democracy, and Innovation (DDI)",
      "250": null,
      "118": "Idaho National Laboratory",
      "169": null,
      "259": null,
      "181": "NLM",
      "104": "Idaho National Laboratory",
      "303": null,
      "84": null,
      "317": null,
      "135": null,
      "419": null,
      "28": "NASS",
      "304": null,
      "418": null,
      "73": null,
      "368": "R",
      "316": null,
      "202": null,
      "32": "NRCS",
      "175": "NIEHS",
      "252": null,
      "216": null,
      "204": null,
      "432": null,
      "240": null,
      "292": null,
      "132": "Office of Electricity",
      "373": "R",
      "227": null,
      "194": "OIG",
      "331": "Office of Analytics, Review, and Oversight ",
      "34": "OASCR",
      "367": "R",
      "89": "Brookhaven National Laboratory",
      "379": "ANG",
      "434": null,
      "383": "AVS",
      "291": null,
      "456": null,
      "343": "A",
      "414": "USAID/Bureau for Global Health (GH)",
      "366": "PM",
      "347": "A",
      "187": "NLM",
      "145": null,
      "307": null,
      "16": "FNS",
      "58": null,
      "277": null,
      "305": null,
      "255": null,
      "320": null,
      "324": null
    },
    "Title": {
      "296": "Data\u2013driven prospectivity modelling of sediment\u2013hosted Zn\u2013Pb mineral systems and their critical raw materials",
      "333": "Medicare Part D Subsidy Model",
      "411": "Breakthrough RESEARCH\u2019s Social Media Listening",
      "82": "WAWENETS",
      "230": "Barcode Scanner ",
      "150": "Auto-generation Synonyms",
      "15": "Retailer Receipt Analysis",
      "195": "Text Analytics Portal",
      "297": "Updating Real-time Earthquake Shaking, Ground Failure, and Impact products with remote sensing and ground truth observations",
      "311": "Audio Transcription",
      "159": "Chatbot \u2013 Voice",
      "427": "Disentangling dementia patterns using artificial intelligence on brain imaging and electrophysiological data",
      "363": "Behavioral Analytics for Online Surveys Test (Makor Analytics)",
      "397": "Large Corporate \nCompliance",
      "266": "Coast Train",
      "365": "NLP to pull key information from unstructured text",
      "238": "Sentiment Analysis - Surveys",
      "257": "Water Mission Area Regional Drought Early Warning System",
      "102": "Protocol Analytics to enable Forensics \nof Industrial Control Systems",
      "449": "Reinforcement learning evaluation of treatment policies for patients with hepatitis C virus",
      "71": "ProbSR (probability of subfreezing \nroads",
      "121": "Data-driven failure diagnosis and \nprognosis of solid-state ceramic \nmembrane reactor under harsh \nconditions using deep learning \ntechnology with internal voltage sensors",
      "55": "Coastal Change Analysis Program \n(C-CAP)",
      "143": "Service Desk Virtual Agent (Curie)",
      "191": "Query View Report (QVR) LIKE",
      "374": "Image Clustering",
      "314": "Website Chatbot Assistant",
      "211": "Vessel Detection",
      "163": "Reasonable Accommodation RPA Bot",
      "273": "Spot Elevation OCR from historical topo maps",
      "237": "Predicted to Naturalize",
      "364": "Crisis Campaign Cable Analytics",
      "256": "Water Mission Area Drought Prediction Project",
      "20": "RMRS Raster Utility",
      "183": "MetaMap to identity potential terms for indexing MEDLINE articles",
      "60": "Robotic microscopes and machine \nlearning algorithms remotely and \nautonomously track lower trophic \nlevels for improved ecosystem \nmonitoring and assessment",
      "353": "Apptio",
      "62": "Ice seal detection and species \nclassification in multispectral \naerial imagery",
      "117": "Evaluating thermal properties of \nadvanced materials",
      "260": "Estimating stream flow from images in headwaters",
      "447": "Predicting corticosteroid free endoscopic remission with Vedolizumab in ulcerative colitis",
      "284": "Forecasting Water Temperature in the Delaware River Basin ",
      "179": "Leveraging AI for Business Process Automation",
      "234": "Identity Match Option (IMO) Process with DBIS Data Marts",
      "417": "NASA SERVIR - Mapping urban vulnerability using AI techniques",
      "356": "Facebook Ad Test Optimization System",
      "327": "Modernized Development Worksheet (MDW)",
      "96": "Artificial Intelligence Enhanced \nAdvanced Post Irradiation Examination",
      "210": "Use of technology to identify proof of life",
      "199": "AI Curated Synthetic Data",
      "229": "Mobile Device Analytics",
      "310": "Language Translation",
      "235": "Person-Centric Identity Services A-Number Management Model",
      "182": "Determining selection for indexing MEDLINE articles using Neural Network Architecture with a Convolutional Neural Network (CNN)",
      "340": "Mobile Wage Reporting (MOBWR) ",
      "442": "Prediction of health outcomes, including suicide death, opioid overdose, and decompensated outcomes of chronic diseases.",
      "401": "NRP Redesign",
      "139": "City Pairs Program Ticket Forecast and Scenario Analysis Tools",
      "17": "Ecosystem Management Decision Support System (EMDS)",
      "166": "Priority Score Model - ranks providers within the Fraud Prevention System using logistic regression based on program integrity guidelines.",
      "147": "Document Workflow / Intelligent Data Capture and Extraction",
      "157": "Item Nonresponse Detection in Open-text\nResponse Data",
      "27": "List Frame Deadwood Identification",
      "67": "The Development of ProbSevere \nv3 - An improved nowcasting \nmodel in support of severe \nweather warning operations",
      "208": "Integrated Digital Environment",
      "354": "NLP for Foreign Assistance Appropriations Analysis",
      "120": "Machine Learning Interatomic \nPotentials for Radiation Damage and \nPhysical Properties in Model Fluorite \nSystems",
      "140": "Category Taxonomy Refinement Using NLP",
      "431": "Nediser reports QA",
      "332": "SSI Redetermination Model",
      "35": "Acquisition Approval Request Compliance Tool",
      "322": "Automatic Data Processing Workflow with Form Recognizer",
      "358": "Machine-Learning Assisted Measurement and Evaluation of Public Outreach",
      "64": "First Guess Excessive Rainfall \nOutlook",
      "127": "Combinatorial Evaluation of Physical \nFeature Engineering and Deep \nTemporal Modeling  for Synchrophasor \nData at Scale",
      "59": "Coral Reef Watch",
      "126": "Big Data Synchrophasor Monitoring and \nAnalytics for Resiliency Tracking \n(BDSMART)",
      "12": "Democratizing Data",
      "103": "Automated Type and Data Structure \nResolution",
      "105": "Advanced Machine Learning-based \nFifth Generation Network Attack \nDetection System",
      "334": "PATH Model",
      "410": "Using ML for predicting treatment interruption among PLHIV in Nigeria",
      "335": "Insight",
      "219": "Cyber Threat Intelligence Feed Correlation",
      "18": "Wildland Urban Interface - Mapping Wildfire Loss",
      "203": "Autonomous Maritime Awareness",
      "142": "Service Desk Generic Ticket Classification",
      "393": "Inventory Item \nReplenishment MLR \nModeling POC - Phase 2",
      "440": "Gait signatures in patients with peripheral artery disease",
      "125": "Open-Source High-Fidelity Aggregate \nComposite Load Models of Emerging \nLoad Behaviors for Large-Scale \nAnalysis (GMLC 0064)",
      "369": "forecasting",
      "443": "VA-DoE Suicide Exemplar Project",
      "407": "Long-term impacts of land-use/land-cover dynamics on surface water quality in Botswana\u2019s reservoirs using satellite data and artificial intelligence methods: Case study of the Botswana\u2019s Limpopo River Basin (1984-2019)",
      "308": "Privileged Material Identification",
      "44": "Azure Chatbot",
      "29": "Climate Change Classification NLP",
      "98": "Artificial Intelligence Based Process \nControl and Optimization for Advanced \nManufacturing",
      "390": "Machine Learning for Occupant Safety Research",
      "438": "SoKat Suicidial Ideation Detection Engine",
      "329": "Pre-Effectuation Review / Targeted Denial Review Models",
      "3": "Detection of aquatic weeds",
      "375": "Louvain Community Detection",
      "50": "A Hybrid Statistical-Dynamical \nSystem for the Seamless \nPrediction of Daily Extremes and \nSubseasonal to Seasonal Climate \nVariability",
      "246": "Improved Processing and Analysis of Test and Operating Data from Rotating Machines",
      "41": "Consolidated Screening List",
      "72": "VIAME: Video and Image Analysis \nfor the Marine Environment \nSoftware Toolkit",
      "413": "Mali: AI predictions for the optimization of the allocation of the distribution of COVID-19 vaccines  ",
      "349": "Automatic Detection of Authentic Material",
      "380": "Surface Report Classifiier (SCM/Auto-Class)",
      "420": "AI Cure",
      "94": "Accelerating deployment of nuclear \nfuels through reduced-order thermo-\nphysical property models and machine \nlearning",
      "30": "Operational water supply forecasting for western US rivers",
      "0": "Predictive modeling of invasive pest species and category at the port of entry using machine learning algorithms",
      "130": "A Robust Event Diagnostic Platform: \nIntegrating Tensor Analytics and \nMachine Learning Into Real-time Grid \nMonitoring",
      "446": "Predicting hospitalization and corticosteroid use as a surrogate for IBD flares\u00a0",
      "454": "VA /IRB approved research study for finding colon polyps",
      "249": "Well Activity Report Classification",
      "247": "Sustained Casing Pressure Identification",
      "196": "Machine learning system to predict translational progress in biomedical research",
      "38": "Video Surveillance System",
      "352": "ServiceNow AI-Powered Virtual Agent (Chatbot)",
      "69": "SUVI Thematic Maps",
      "261": "Economic valuation of fisheries in the Delaware River",
      "409": "Project Vikela",
      "228": "Email Analytics ",
      "36": "Intelligent Ticket Routing",
      "423": "Automated eye movement analysis and diagnostic prediction of neurological disease",
      "422": "Assessing lung function in health and disease",
      "223": "Security Information and Event Management (SIEM) Alerting Models",
      "226": "Normalization Services",
      "22": "Landscape Change Monitoring System (LCMS)",
      "312": "Text to Speech Conversion",
      "165": "Data Lake/Load-Extract-Load-Transform (L-ETL)",
      "26": "Cropland Data Layer",
      "372": "TOPIQ",
      "267": "Seabird and Marine Mammal Surveys Near Potential Renewable Energy Sites Offshore Central and Southern California",
      "448": "Use of machine learning to predict surgery in Crohn\u2019s disease",
      "170": "Artificial Intelligence-based Deduplication\nAlgoirthm for Classfication of Duplicate Reports\nin the FDA Adverse Event Reports (FAERS)",
      "437": "Seizure detection from EEG and video",
      "119": "Passive Strain Measurements for \nExperiments in Radiation Environments",
      "337": "Duplicate Identification Process (DIP)",
      "355": "eRecords M/L Metadata Enrichment",
      "74": "Using community-sourced \nunderwater photography and \nimage recognition software to \nstudy green sea turtle distribution \nand ecology in southern California",
      "338": "Handwriting recognition from forms",
      "78": "Replacing unstructured WW3 in \nthe Great Lakes with a Recurrent \nneural network and a boosted \nensemble decision tree",
      "180": "Pangolin lineage classifications to support\naccessing and analysis of SARS-CoV-2 sequence\nData.",
      "138": "Acquisition Analytics",
      "389": "Machine Learning for Occupant Safety Research",
      "45": "Fisheries Electronic Monitoring \nImage Library",
      "93": "Accelerating and Improving the \nReliability of Low Failure Probability \nComputations to Support the Efficient \nSafety Evaluation and Deployment of \nAdvanced Reactor Technologies",
      "193": "NIH Grants Virtual Assistant",
      "263": "Deep Learning for Automated Detection and Classification of Waterfowl, Seabirds, and other Wildlife from Digital Aerial Imagery",
      "68": "The VOLcanic Cloud Analysis \nToolkit (VOLCAT): An application \nsystem for detecting, tracking, \ncharacterizing, and forecasting \nhazardous volcanic events",
      "350": "Automated Burning Detection",
      "24": "Forest Health Detection Monitoring",
      "395": "Collection Voice Bot",
      "436": "Provider directory data accuracy and system of record alignment",
      "362": "Fast Text Word Builder",
      "136": "Enforcement Targeting",
      "270": "Mapping benthic algae along the Buffalo National River from remotely sensed data",
      "221": "Malware Reverse Engineering",
      "6": "Approximate string or fuzzy matching, used to automate matching similar, but not identical, text in administrative documents",
      "244": "Improving UAS-derived photogrammetric data and analysis accuracy and confidence for high-resolution data sets using artificial intelligence and machine learning",
      "1": "Detection of pre-symptomatic HLB infected citrus",
      "285": "Prediction of Flood Flow Metrics for Minimally Altered Catchments",
      "357": "Global Audience Segmentation Framework",
      "114": "Nuclear-Renewable-Storage Digital \nTwin: Enhancing Design, Dispatch, and \nCyber Response of Integrated Energy \nSystems",
      "328": "Anomalous iClaim Predictive Model",
      "313": "Claims Document Processing",
      "13": "Westat",
      "214": "AI Security and Robustness",
      "131": "Discovery of Signatures, Anomalies, \nand Precursors in Synchrophasor Data \nwith Matrix Profile and Deep Recurrent \nNeural Networks",
      "233": "I-539 approval prediction",
      "56": "Deep learning algorithms to \nautomate right whale photo id",
      "90": "Advances in Nuclear Fuel Cycle \nNonproliferation, Safeguards, and \nSecurity Using an Integrated Data \nScience Approach",
      "421": "Acute kidney injury (AKI)",
      "323": "Case Recording summarization",
      "65": "CoralNet: Ongoing operational \nuse, improvement, and \ndevelopment, of machine vision \npoint classification",
      "176": "Splunk IT System Monitoring Software",
      "289": "Multi-task deep learning for daily streamflow and water temperature",
      "428": "Machine learning (ML) for enhanced diagnostic error detection and ML classification of protein electrophoresis text",
      "11": "NAL Automated indexing",
      "258": "AI system to recognize individual fish and disease",
      "97": "Secure Millimeter Wave Spectrum \nSharing with Autonomous Beam \nScheduling",
      "265": "ML-Mondays course on applications of deep learning to image analysis",
      "113": "Deep Reinforcement Learning and \nDecision Analytics for Integrated \nEnergy Systems",
      "207": "Geospatial imagery utilizing annotation",
      "315": "Data Ingestion of Payroll Forms",
      "231": "Facial Recognition Service ",
      "239": "Topic Modeling  on Request For Evidence data sets",
      "396": "Evaluate Multilingual BERT \nfor Software Translation \nUse Case Evaluations",
      "47": "AI-based automation of acoustic \ndetection of marine mammals",
      "10": "ARS Project Mapping",
      "371": "SentiBERTIQ",
      "288": "Process-Guided Deep Learning for Dissolved Oxygen Predictions on Stream Networks",
      "251": "Walrus Haulout Camera Trap Image Classification",
      "370": "Deepfake Detector",
      "149": "Relevancy Tailoring",
      "75": "An Interactive Machine Learning Signals in Passive Acoustic  Recordings\nToolkit for Classifying Species \nIdentity of Cetacean Echolocation",
      "76": "Steller sea lion automated count \nprogram",
      "122": "Tailoring the Properties of Multiphase \nMaterials Through the Use of \nCorrelative Microscopy and Machine \nLearning",
      "101": "Infrastructure eXpression",
      "394": "Collection Chat Bot",
      "400": "Line Anomaly \nRecommender",
      "133": "Robust Learning of Dynamic \nInteractions for Enhancing Power \nSystem Resilience",
      "37": "Predictive Maintenance Impacts",
      "205": "Data and Entity Resolution",
      "302": "A machine learning approach to developing ground motion models from simulated ground motions",
      "48": "Developing automation to \ndetermine species and count \nusing optical survey data in the \nGulf of Mexico",
      "2": "High throughput phenotyping in citrus orchards",
      "115": "Automated Infrastructure & Dependency \nDetection via Satellite Imagery and \nDependency Profiles",
      "152": "Suggested Related Content",
      "359": "GPATools and GPAIX",
      "319": "Electronic Records Management",
      "190": "Research, Condition, and Disease Categorization (RCDC)",
      "301": "Application of machine learning to  ground motion-based earthquake early warning",
      "57": "NN Radiation",
      "217": "Critical Infrastructure Anomaly Alerting",
      "242": "Data Driven Streamflow Forecasting",
      "25": "Land Change Analysis Tool (LCAT)",
      "53": "Drought outlooks by using ML \ntechniques",
      "245": "Photogrammetric Data Set Crack Mapping Technology Search ",
      "110": "Interdependent Infrastructure Systems \nResilience Analysis for Enhanced \nMicroreactor Power Grid Penetration",
      "412": "Serbia: AI predictions for the utilization of hospital beds ",
      "435": "Predictor profiles of OUD and overdose",
      "177": "COVID-19 Pandemic Vulnerability Index\nDashboard",
      "453": "Extraction of family medical history from patient records",
      "325": "Scanner Data Product Classification",
      "88": "Aidan",
      "218": "Cyber Incident Reporting",
      "8": "Artificial Intelligence for correlative statistical analysis",
      "128": "MindSynchro",
      "286": "Process-Guided Deep Learning Predictions of Lake Water Temperature",
      "185": "SingleCite: Improving single citation search in\nPubMed",
      "141": "Key KPI Forecasts for GWCM",
      "271": "Characterization of Sub-surface drainage (tile drains) from satellite imagery",
      "351": "Automated Damage Assessments",
      "112": "Support Vector Analysis for \nComputational Risk Assessment, \nDecision-Making, and Vulnerability \nDiscovery in Complex Systems",
      "236": "Person-Centric Identity Services Deduplication Model",
      "404": "Media Early Warning System (MEWS)",
      "92": "Scalable Framework of Hybrid Modeling \nwith Anticipatory Control Strategy for \nAutonomous Operation of Modular and \nMicroreactors",
      "111": "Adaptive Fingerprinting of Control \nSystem Devices through Generative \nAdversarial Networks",
      "54": "EcoCast: A dynamic ocean \nmanagement tool to reduce \nbycatch and support sustainable \nfisheries",
      "167": "Priority Score Timeliness - forecast the time needed to work on an alert produced by Fraud Prevention System (Random Forest, Decision Tree, Gradient Boost, Generalized Linear Regression)",
      "66": "Automated detection of \nhazardous low clouds in support \nof safe and efficient \ntransportation",
      "124": "The Grid Resilience and Intelligence \nPlatform (GRIP)",
      "178": "National Institute of General Medical Sciences\n(NIGMS) AI Supported Searches, Information\nSystems and Tools\nSystem Acronym: NIGMS ASSIST)",
      "160": "Chatbot \u2013 Text",
      "426": "Digital command center",
      "452": "GI Genius (Medtronic)",
      "378": "Determining Surface Winds with Machine Learning Software",
      "129": "PMU-Based Data Analytics Using \nDigital Twin Phasor Analytics Software",
      "318": "Official Document Validation",
      "100": "Resilient Attack Interceptor for \nIntelligent Devices",
      "416": "NASA SERVIR - Using artificial intelligence to forecast harmful algae blooms in Lake Atitl\u00e1n, Guatemala",
      "457": "Social determinants of health extractor",
      "295": "Where\u2019s the Rock: Using Neural Networks to Improve Land Cover Classification",
      "215": "AIS Scoring and Feedback",
      "134": "Use of random forest model to predict exposure pathways",
      "19": "CLT Knowledge Database",
      "344": "Supply Chain Fraud and Risk Models",
      "399": "LB&I Text Analytics \n(including Appeals Case \nManagement)",
      "254": "Walrus Object Detection in Drone/Satelite Imagery",
      "294": "AI applications to mapping surface water",
      "342": "Product Service Code Automation ML Model",
      "339": "Quick Disability Determinations Process",
      "385": "Automatic Track Change Detection Demonstration and Analysis",
      "189": "Program Class Code (Area of Science) Referral for NIAID",
      "9": "4% Repair Dashboard",
      "39": "B2B Matchmaking",
      "155": "Chatbot",
      "243": "Seasonal/Temporary Wetland/Floodplain Delineation using Remote Sensing and Deep Learning",
      "224": "Text Analytics for Survey Responses (TASR)",
      "31": "Ecological Site Descriptions (machine learning)",
      "433": "Prediction of Veterans' Suicidal Ideation following Transition from Military Service",
      "415": "NASA SERVIR - Bias Correcting Historical GEOGloWS ECMWF Streamflow Service (GESS) data using Machine Learning (ML) Techniques",
      "168": "Provider Education 90 Day - reviews claims for provider before and after education for statistical change in their claim submission patterns",
      "309": "Form Recognizer for Benefits Forms",
      "153": "Auto Tagging",
      "107": "Unattended Operation through Digital \nTwin Innovations",
      "80": "Picky",
      "275": "The National Landcover database",
      "43": "Market Diversification Toolkit",
      "293": "Explainable AI and interpretable machine learning",
      "406": "Machine Learning for Peace",
      "116": "Accelerated Nuclear Materials and Fuel \nQualification by Adopting a First to \nFailure Approach",
      "137": "Solicitation Review Tool (SRT)",
      "248": "Level 1 Report Corrosion Level Classification",
      "154": "Did you mean",
      "109": "Automated Malware Analysis Via \nDynamic Sandboxes",
      "321": "Automatic Document Processing",
      "95": "Promoting Optimal Sparse Sensing and \nSparse Learning for Nuclear Digital \nTwins",
      "382": "JASC Code classification in Safety Difficulty Reports (SDR)",
      "425": "CuraPatient",
      "184": "Best Match: New relevance search for PubMed",
      "429": "Behavidence",
      "173": "BHW Community Need Analysis Platform",
      "222": "Operational Activities Explorer",
      "253": "Individual Mountain Lion ID from Camera Data",
      "188": "National Library of Medicine NLM-Chem: towards automatic chemical indexing in PubMed articles",
      "77": "Steller sea lion brand sighting",
      "268": "Fouling Identification Neural Network (FINN)",
      "278": "Fish and Climate Change Database (FiCli)",
      "241": "Data Driven Sub-Seasonal Forecasting of Temperature and Precipitation ",
      "46": "Passive acoustic analysis using ML \nin Cook Inlet, AK",
      "336": "Intelligent Medical Language Analysis Generation (IMAGEN)",
      "201": "Automated Item of Interest Detection - ICAD",
      "79": "Using k-means clustering to \nidentify spatially and temporally \nconsistent wave systems",
      "386": "Crushed Aggregate Gradation Evaluation System",
      "162": "Predictive Intelligence - Incident Assignment for Quality Service Center (QSC).",
      "299": "Leveraging Deep Learning to Improve Earthquake Monitoring",
      "161": "Feedback Analysis Solution (FAS)",
      "23": "Geospatial and Remote Sensing Training Courses",
      "300": "Using Gradient Boosting Method and Feature Selection to Reduce Aleatory Uncertainty of Earthquake Ground-Motion Models",
      "282": "Prediction of Salt Front Location in the Delaware River Estuary",
      "276": "Artificial Intelligence for Environment & Sustainability (ARIES)",
      "451": "Computer-aided detection and classification of colorectal polyps",
      "360": "AI Capabilities Embedded in SMART",
      "403": "SBSE Issue Recommender",
      "148": "IAE FSD CCAI Virtual Agent",
      "158": "Sequential Coverage Algorithm (SCA) in Record\nLinkage",
      "346": "Within Grade Increase Automation",
      "33": "Digital Imagery (no-change) for NRI program",
      "306": "Complaint Lead Value Probability",
      "81": "Data Science: Clutter",
      "220": "Cyber Vulnerability Reporting",
      "290": "Predicting Water Temperature Dynamics of Unmonitored Lakes With Meta\u2010Transfer Learning",
      "42": "AD/CVD Self Initiation",
      "51": "FathomNet",
      "345": "Tailored Integration Logistics Management System (ILMS) Automated User Support Bot",
      "86": "Enriched Citation",
      "391": "PHMSA Rule Making",
      "197": "Semantic analysis of scientific documents\n(word2vec OPA )",
      "424": "Automatic speech transcription engines to aid scoring neuropsychological tests.",
      "200": "AI for Autonomous Situational Awareness",
      "225": "RelativityOne",
      "123": "Microstructurally-driven Framework for \nOptimization of In-core Materials",
      "388": "Automated Delay detection using voice processing",
      "348": "Conflict Forecasting",
      "274": "TerrainFeatures detection and recognition",
      "91": "Development of a multi-sensor data \nscience system used for signature \ndevelopment on solvent extraction \nprocesses conducted within Beartooth \nfacility",
      "164": "Rapid Authority to Operate (ATO)",
      "151": "Automated Suggestions",
      "156": "ICD-10 Coding of Cause of Death reported on\nDeath Certificates (MedCoder)",
      "384": "Offshore Precipitation Capability (OPC)",
      "212": "Advanced Analytic Enabled Forensic Investigation",
      "281": "Prediction of Inland Salinity in the Delaware River Basin",
      "87": "Inventor Search Assistant (iSAT)",
      "171": "Opioid Data Warehouse Term Identification Novel Synthetic Opioid Detection and Evaluation Analytics",
      "455": "Interpretation/triage of eye images",
      "326": "Expenditure Classification Autocoder",
      "174": "Leveraging AI/ML for classification and\ncategorization of scientific concepts",
      "4": "Automated Detection & Mapping of Host Plants from Ground Level Imagery",
      "445": "Prediction of biologic response to thiopurines",
      "441": "Medication Safety (MedSafe) Clinical Decision Support (CDS)",
      "192": "Internal Referral Module (IRM) NLP",
      "264": "Prediction of Regolith Thickness in the Delaware River Basin",
      "269": "Mapping river bathymetry from remotely sensed data ",
      "5": "Standardization of cut flower business names for message set data",
      "209": "RVSS Legacy Overhauled System Project (INVNT)",
      "287": "Prediction of Lake Water Temperature using Lake Attributes",
      "63": "First Guess Excessive Rainfall \nOutlook",
      "206": "Entity Resolution",
      "108": "Secure and Resilient Machine Learning \nSystem for Detecting Fifth Generation \n(5G) Attacks including Zero-Day Attacks",
      "272": "Waterfowl Lifehistory and Behavior Classification",
      "144": "Contract Acquisition Lifecycle Intelligence (CALI)",
      "198": "Person-level disambiguation for PubMed authors and NIH grant applicants",
      "49": "Fast tracking the use of VIAME for \nautomated identification of reef \nfish",
      "298": "Using Artificial Neural Networks to Improve Earthquake Ground-Motion Models",
      "398": "Large Partnership \nCompliance",
      "402": "Projected Contract Award \nDate Web App",
      "40": "Chatbot Pilot",
      "85": "AI retrieval for TM design coding \nand Image search",
      "83": "AI retrieval for patent search",
      "14": "OCIO/CDO Council Comment Analysis Tool",
      "341": "Federal Procurement Data System (FPDS) Auto-Populate Bot",
      "430": "Machine learning tools to predict outcomes of hospitalized VA patients",
      "444": "Machine learning models to predict disease progression among veterans with hepatitis C virus",
      "172": "Electronic Handbooks (EHBs) AI Chatbot ",
      "381": "Course Deviation Identification for Multiple Airport Route Separation (MARS)",
      "262": "Stream physical habitat characterization in the Chesapeake Bay Watershed",
      "392": "Inventory Item \nReplenishment MLR \nModeling POC - Phase 1",
      "280": "Fluvial Fish Native Distributions for the Conterminous United States using the NHDPlusV2.1 and Boosted Regression Tree (BRT) Models",
      "70": "BANTER, a machine learning \nacoustic event classifier",
      "439": "Using machine learning to predict perfusionists\u2019 critical decision-making during cardiac surgery",
      "387": "Development of Predictive Analytics Using Autonomous Track Geometry Measurement System (ATGMS) Data",
      "279": "Evaluating fish movement in restored coastal wetlands using imaging sonar and machine learning models",
      "146": "Chatbot for Federal Acquisition Community",
      "52": "ANN to improve CFS T and P \noutlooks",
      "106": "Red Teaming Artificial Intelligence",
      "450": "Predicting hepatocellular carcinoma in patients with hepatitis C",
      "405": "Gender differentiated credit scoring",
      "99": "Smart Contingency Analysis Neural \nNetwork for in-depth Power Grid \nVulnerability Analyses",
      "61": "Edge AI survey payload \ndevelopment",
      "7": "Training machine learning models to automatically read file attachments and save information into a more convenient Excel format. ",
      "186": "Computed Author: author name disambiguation National Institutes of Health (NIH) NLM\nfor PubMed",
      "283": "Prediction of Water Temperature in the Delaware River Basin",
      "330": "Rep Payee Misuse Model",
      "232": "I-485 Family Matching",
      "21": "TreeMap 2016",
      "213": "Advanced Network Anomaly Alerting",
      "408": "Morogoro youth empowerment through establishment of social innovation (YEESI) lab for problem-centered training in machine vision",
      "250": "Wildlife Underpass Camera Trap Image Classification, San Diego CA",
      "118": "Spectral Observation Convolutional \nNeural Network",
      "169": "Advanced Semantic Search and Indexing of Text for Tobacco Applications (ASSIST4Tobacco)",
      "259": "River Image SEnsing",
      "181": "Providing MeSH Check Tag of NLM\u2019s Medical\nText Indexer (MTI) ons using Support Vector\nMachines (SVM)",
      "104": "Signal Decomposition for Intrusion \nDetection in Reliability Assessment in \nCyber Resilience",
      "303": "Integrating machine learning phase pickers into the Southern California Seismic Network earthquake catalog",
      "84": "AI use for CPC classification",
      "317": "DOL Intranet Website Chatbot Assistant",
      "135": "Records Categorization",
      "419": "Artificial intelligence coach in cardiac surgery",
      "28": "Census of Agricuilture Response Propensity Scores",
      "304": "Understanding the 2020-2021 Puerto Rico Earthquake sequence with deep learning approaches",
      "418": "Artificial Intelligence physical therapy app",
      "73": "ENSO Outlooks using \nobserved/analyzed fields",
      "368": "Topic Modeling",
      "316": "Hololens",
      "202": "Autonomous Aerostat",
      "32": "Conservation Effects Assessment Project",
      "175": "Grant Application Subject-Matter Classification\nTool",
      "252": "ARMI Amphibian Species ID from Acoustic Data",
      "216": "Automated Indicator Sharing (AIS) Automated PII Detection",
      "204": "Autonomous Surveillance Towers (Anduril)",
      "432": "Precision medicine PTSD and suicidality diagnostic and predictive tool",
      "240": "Land Use Plan Document and Data Mining and Analysis R&D",
      "292": "Process guidance for learning groundwater influence on stream temperature predictions",
      "132": "Machine Learning Guided Operational \nIntelligence",
      "373": "Text Similarity",
      "227": "Machine Translation\n(Previously Language Translator)",
      "194": "Grants Analytics Portal",
      "331": "CDR Model",
      "34": "Artificial Intelligence SPAM Mitigation Project",
      "367": "Optical Character Recognition \u2013 text extraction",
      "89": "Objective-Driven Data Reduction for \nScientific Workflows",
      "379": "Remote Oceanic Meteorological Information Operations (ROMIO)",
      "434": "PredictMod",
      "383": "Regulatory Compliance Mapping Tool",
      "291": "Process-guided deep learning for predicting stream temperature in out-of-bound conditions",
      "456": "Screening for esophageal adenocarcinoma",
      "343": "Tailored Integration Logistics Management System (ILMS) User Analytics",
      "414": "Indonesia: AI predictions for improving forecasts for TB drugs",
      "366": "K-Means clustering into tiers",
      "347": "Verified Imagery Pilot Project",
      "187": "National Library of Medicine NLM-Gene: towards automatic gene indexing in PubMed articles",
      "145": "Classifying Qualitative Data",
      "307": "Intelligent Records Consolidation Tool",
      "16": "Nutrition Education & Local Access Dashboard",
      "58": "NN training software for the new \ngeneration of NCEP models",
      "277": "Global Inland Fisheries Risk Index",
      "305": "Drug Signature Program Algorithms",
      "255": "PRObability of Streamflow PERmanence",
      "320": "Call Recording Analysis",
      "324": "OEWS Occupation Autocoder"
    },
    "Summary": {
      "296": "Regional data (magnetics and their derivatives, gravity and their derivatives, black shales, terrane boundaries, LAB depths, permissive geology, paleo-latitude etc.) is loaded into Uber's H3 cube. Clastic Dominated (CD) and  Mississippi Valley Type (MVT) deposits are used to train a Weights of Evidence model and two different Gradient-Boosting Machine models. After training occured the result was a prospecticvity map for CD and MVT deposits in the three countries. ",
      "333": "This model uses machine learning to identify cases most likely to have incorrect Medicare Part D subsidies and flag them for technician review.",
      "411": "Social media listening draws on machine learning to synthesize and organize the vast quantities of data shared over social media platforms. Breakthrough RESEARCH carried out social listening on 12,301 social media posts in Nigeria to explore how gender-related online conversations manifest themselves and whether they have changed in the last five years. Using Crimson Hexagon\u2019s machine learning algorithm, \u201cBrightview,\u201d publicly available social media content originating in the countries of interest was scraped by the algorithm, for posts relevant to RH/FP and youth. The resulting social media posts were then classified by topic, using language detected in the content. This provided a dataset categorizing conversations into overarching topics, allowing analyses to uncover key trends in topic specific conversation volume, insights about misinformation, attitudes and social norms, and more. The machine learning algorithm was able to identify relevant social media content. The 12,301 social media posts were qualitatively assessed and categorized, allowing researchers to monitor and track social media conversations far more expansively than allowed by research methods more traditionally used in public health and SBC programs.",
      "82": "The algorithm produces estimates of telecommunications speech quality and speech \nintelligibility.  The input is a recording of speech from a telecommunications system in \ndigital file format.  The output is a single number that indicates speech quality (typically \non a 1 to 5 scale) or speech intelligibility (typically on a 0 to 1 scale).",
      "230": "The Barcode Scanner has been developed to scan and populate detected information into corresponding text fields within the RAVEn GO's Encounter Card. The barcode scanner currently supports\u00a0MRZ and PDF417 barcode types, frequently found on travel documents (Passport and Passport cards) and US Driver's Licenses.\u00a0\n\nThis is a DHS HSI Innovation Lab / RAVEn project. The Repository for Analytics in a Virtualized Environment (RAVEn) facilitates large, complex analytical projects to support ICE\u2019s mission to enforce and investigate violations of U.S. criminal, civil, and administrative laws. RAVEn also enables tools used to analyze trends and isolate criminal patterns as HSI mission needs arise. For more information, please read the DHS/ICE/PIA-055 - Privacy Impact Assessment 055 for RAVEn.",
      "150": "Behind the scenes, adding synonyms to search queries to improve search results",
      "15": "The Retailer Receipt Analysis is a Proof of Concept (POC) that uses Optical Character Recognition (OCR), an application of artificial intelligence on a sample (no more than 1000) of FNS receipt and invoice data. Consultants will use this data to demonstrate how the existing manual process can be automated, saving staff time, ensuring accurate review, and detecting difficult patterns. The goal of this POC will pave the way for a review system that (1) has an automated workflow and learns from analyst feedback (2) can incorporate know SNAP fraud patterns, look for new patterns, and visualize alerts on these patterns on retailer invoices and receipts.",
      "195": "The text analytics portal allows personnel without an analytics background to quickly examine text documents through a\nrelated set of search, topic modeling and entity recognition technologies",
      "297": "A breakthrough for rapid post-earthquake ground failure (GF) and loss modeling and reporting has been achieved with initial Bayesian updating of our global loss and GF models with ground-truth observations. Empirical models suffer from limited performance due to the complex, event-specific causal effects underlying the cascading processes of earthquake-triggered hazards and impacts. In contrast, satellite imagery-based impact assessments (e.g., NASA\u2019s Damage Proxy Maps, or DPMs), while spatially accurate, lack the specificity as to what physical process caused those image changes. We present the first rapid seismic multi-hazard and damage updating framework based on variational Bayesian causal inference and remotely sensed DPMs. This machine learning framework enables accurate and high-resolution multi-hazard and damage estimates by jointly inferring shaking and secondary hazards and resulting building damage and quantifying their causal dependencies from imagery and prior loss and GF models. The underlying physical causal dependencies are modeled using a multi-layer causal Bayesian network. Initial results are impressive, showing that our framework significantly improves the GF prediction abilities. It also reveals the event-specific causal dependencies among ground shaking, GF, building damage, and other environmental factors. We expect improved PAGER products to more rapidly evolve to accurate and thus more actionable images, maps, and products. ",
      "311": "Transcription of speech to text for records keeping using natural language processing models.",
      "159": "CMS/OSFLO: To assist the CMS Badging Help Desk, this Chatbot (voice) is an automated phone response for general\nbadging questions allowing help desk personnel to assist employees and contractors with more detailed/larger issues.",
      "427": "This collaborative effort focuses on developing a deep learning framework to predict the various patterns of dementia seen on MRI and EEG and explore the use of these imaging modalities as biomarkers for various dementias and epilepsy disorders.\u00a0 The VA is performing retrospective chart review to achieve this.",
      "363": "GEC executes a Technology Testbed to rapidly test emerging technology applications against foreign disinformation and propaganda challenges. GEC works with interagency and foreign partners to understand operational threats they\u2019re facing and identifies technological countermeasures to apply against the operational challenge via short-duration tests of promising technologies. Makor Analytics is an AI quantitative research company that helps clients understand their audience\u2019s perceptions and feelings helping to mitigate some of the limitations in traditional survey research. Makor Analytics\u2019 proprietary behavioral analytics technology was developed to uncover true convictions and subtle emotions adding additional insights into traditional online survey results. The desired outcome of the pilot is a report analyzing the survey responses using behavioral analytics to provide target audience sentiment insights and subsequent recommendations. By leveraging AI behavioral analytics, the pilot aims to provide additional information beyond self-reported data that reflects sentiment analysis in the country of interest.",
      "397": "Large Corporate Compliance is a machine learning model for classifying \ncorporate taxes.",
      "266": "Coast Train is a multi-labeler ML-ready dataset of orthomosaic and satellite images of coastal, estuarine, and wetland environments and corresponding thematic label masks. The data consist of spatial and time-series, and contains 1.2 billion labelled pixels, representing over 3.6 million hectares.",
      "365": "Use NLP to extract information such as country names and agreement dates from dozens of pages of unstructured pdf document",
      "238": "The Sentiment Analysis - Surveys system provides a statistical analysis of quantitative results from survey results and then uses Natural Language Processing (NLP) modeling software to assign \"sentiments\" to categories ranging from strongly positive to strongly negative. This allows survey administrators to glean valuable information from employee satisfaction surveys from both quantitative and qualitative data. This capability is currently available on demand.",
      "257": "The goal of this project is to build and test multiple ML models for predicting and forecasting daily hydrologic drought in the Colorado River Basin (CRB). Similar to the project listed in line 9, we use gridded meteorologic forcing data and daily streamflow data in the CRB to build random forest and neural networks (long-short term memory) to determine the best approach to predicting and forecasting hydrologic drought. The project is being developed on AWS and in cooperation with CHS. We are also using the USGS HPC systems.",
      "102": "The goal of this research is to discover methods and technologies to bridge gaps \nbetween the various industrial control systems (ICS) communication protocols and \nstandard Ethernet to enable existing cybersecurity tools defend ICS networks and \nempower cybersecurity analysts to detect compromise before threat actors can \ndisrupt infrastructure, damage property, and inflict harm. Research focuses on \nelectronic signal analysis of captured communication to determine the protocol, using \nuse machine learning to identify unknown protocols. Findings will be incorporated into \na prototype device.",
      "449": "A machine learning model is used to predict disease progression among veterans with hepatitis C virus.",
      "71": "A machine-learned algorithm that provides a 0-100% probability roads are subfreezing",
      "121": "This research will investigate in situ the effects of different components on the \ndegradation behavior in a solid-state ceramic membrane reactor by embedding \nsensors that will collect current and impedance data during operation. Artificial \nintelligence will be used to understand the large amounts of data and predict reactor \nfailure under harsh operating conditions.",
      "55": "Beginning in 2015, C-CAP embarked on operational high resolution land cover \ndevelopment effort that utilized geographic object-based image analysis and ML \nalgorithms such as Random Forest to classify coastal land cover from 1m multispectral \nimagery. More recently, C-CAP has been relying on a CNN approach for the deriving the \nimpervious surface component of their land cover products. The majority of the work is \naccomplished through external contracts. Prior to the high-res effort, C-CAP focused on \ndeveloping Landsat based moderate resolution multi-date land cover for the coastal U.S. \nIn 2002, C-CAP adopted a methodology that employed Classification and Regression Trees \nfor land cover data development.",
      "143": "Virtual agent that uses ML to provide predictive results for chat entries. A natural language chatbot (virtual assistant), we named Curie, as part of a multi-model customer service experience for employee's IT service requests leveraging knowledge-based articles.",
      "191": "The LIKE feature in QVR makes use of the NIH Research, Condition and Disease Categorization (RCDC) indexing results to\ncompare scientific terms associated with a project, person or publication and find scientifically similar projects, persons\nor publications.",
      "374": "Uses a pretrained deep learning model to generate image embeddings, then uses hierarchical clustering to identify similar images.",
      "314": "The chatbot helps the end user with basic information about the program, information on who to contact, or seeking petition case status.",
      "211": "Integrated technologies and analytics enhance maritime detection and the sensor network. Machine-assisted and AI-enhanced detection and tracking allows for improved illicit vessel detection in areas with high volumes of legitimate trade and recreational water vessel traffic by increasing situational awareness and responsiveness to threats.\n\nVessel Detection allows an agent to set a search area with criteria (e.g., people, drones, vehicles) and transmit that criteria to the sensors.  Images detected by the sensors are auto-recognized using Artificial Intelligence. The AI algorithms filter, detect, and recognize objects and divides them into Items of Interest (IoI) and \"other\" objects. \n\nDetections of IoI are shared with other detection systems while detections of other objects (e.g., animals) are not shared. IoIs can be tracked and maintained across multiple sensors seamlessly.",
      "163": "The Bot pulls HR data related to staffing changes, e.g. promotions, reassignments, change in supervisor, and generates\ninformation for action by Reasonable Accommodation staff to ensure disability reasonable accommodations follow the\nEmployee.",
      "273": "The goal of this project is to create a database of summit spot elevations from the HTMC labeled for summits in CONUS.",
      "237": "The Predicted to Naturalize model predicts when Legal Permanent Residents would be eligible to naturalize, and attempts to provide a current address. This model could potentially be used to send correspondence to USCIS customers of their resident status, and notify others of potential USCIS benefits.",
      "364": "Use optical character recognition and natural language processing on Department cables in order to evaluate gaps and trends in crisis training and bolster post preparedness for crisis events.",
      "256": "The goal of this project is to develop a method for predicting daily hydrologic drought using machine learning models calibrated on streamflow data (response) and meteorological forcing data. Models will be built at individual gages across CONUS, then transferred to ungaged basins using a 'donor model' approach that identifies which gages are most similar to the ungaged basin and combines the models from those gages for the final prediction. Models will be developed and run on the USGS HPC systems. ",
      "20": "RMRS Raster Utility is a .NET object oriented library that simplifies data acquisition, raster sampling, and statistical and spatial modeling while reducing the processing time and storage space associated with raster analysis. It includes machine learning techniques.",
      "183": "MetaMap is a widely available program providing access from biomedical text to the concepts in the unified medical\nlanguage system (UMLS) Metathesaurus. MetaMap uses NLP to provide a link between the text of biomedical literature\nand the knowledge, including synonymy relationships, embedded in the Metathesaurus. The flexible architecture in\nwhich to explore mapping strategies and their application are made available. MTI uses the MetaMap to generate\npotential indexing terms.",
      "60": "Phytoplankton are the foundation of marine food webs supporting fisheries and coastal \ncommunities. They respond rapidly to physical and chemical oceanography, and changes \nin phytoplankton communities can impact the structure and functioning of food webs. We \nuse a robotic microscope called an Imaging Flow Cytobot (IFCB) to continuously collect \nimages of phytoplankton from seawater. Automated taxonomic identification of imaged \nphytoplankton uses a supervised machine learning approach (random forest algorithm). \nWe deploy the IFCB on fixed (docks) and roving (aboard survey ships) platforms to \nautonomously monitor phytoplankton communities in aquaculture areas in Puget Sound \nand in the California Current System. We map the distribution and abundance of \nphytoplankton functional groups and their relative food value to support fisheries and \naquaculture and describe their changes in relation to ocean and climate variability and \nchange.",
      "353": "Working Capital Fund (IRM/WCF) uses Apptio to bill bureaus for consolidated services run from the WCF. Cost models are built in Apptio so bureaus can budget for the service costs in future FYs. Apptio has the capability to extrapolate future values using several available formulas.",
      "62": "Refine and improve detection and classification pipelines with the goal of reducing false \npositive rates (to < 50%) while maintaining > 90% accuracy and significantly reducing or \neliminating the labor intensive, post survey review process.",
      "117": "The standard thermal diffusivity measurement technique laser flash is enhanced by \nmodifying the traditional experimental set up and analyzing results with a machine \nlearning based tool that includes a finite element model, a least-squares fitting \nalgorithm and experimental data treatment algorithms. This tool helps elucidate thermo-\nphysical properties of a material from a single laser flash measurement.",
      "260": "The goals of this project are to 1) measure how much water flows in small, ungaged stream networks using timelapse images captured by inexpensive and off-the-shelf cameras and 2) provide a web-based platform for making the images, associated climate and other related data as well as the model itself easy to access and explore. Data for training come from user-uploaded imagery and flow data (when available). Database is available for uploading and image viewing here: https://www.usgs.gov/apps/ecosheds/fpe/",
      "447": "This work uses random forest modeling on a cohort of 594 patients with Vedolizumab to predict the outcome of corticosteroid-free biologic remission at week 52 on the testing cohort. Models were constructed using baseline data or data through week 6 of VDZ therapy.",
      "284": "We developed a process-guided deep learning and data assimilation approach to operationally produce 7-day forecasts of daily maximum stream water temperature downstream of drinking water reservoirs in support of water management decisions. Our process-guided deep learning model was pretrained on output from an integrated stream-reservoir process-based model and used an autoregressive technique and data assimilation to ingest real-time observations of stream temperature to improve near-term forecasts. Our modeling system produced forecasts of daily maximum water temperature with an average root mean squared error (RMSE) from 1.1 to 1.4\u00b0C for 1-day-ahead and 1.4 to 1.9\u00b0C for 7-day-ahead forecasts across all sites. ",
      "179": "NIGMS has developed a method to automate the initial referral of grant applications to the proper scientific expertise\nwithin the Institute using Natural Language Processing and Machine Learning. NIGMS IRMB and DIMA are currently using\nthis NLP/ML algorithm developed in R statistical software to parse grant applications and to determine Project Officer\ncandidates for grant assignment. This process was previously fully manual and required a substantial person hour effort.\nNIGMS has collaborated with the Electronic Records Administration group to incorporate this technique into the Internal\nReferral Module, and the tool is now available to be adapted for broader use across the NIH.",
      "234": "The Identity Match Option (IMO) is used to derive a single identity across multiple systems for each applicant or beneficiary who interacts with USCIS. The IMO aims to aid in person-centric research and analytics. \n\nUSCIS maintains a variety of systems to track specific interactions with individuals \u2013 benefits case management, appointment scheduling, background check validation, and customer service inquiries.  Each system captures its own person-centric data attributes (e.g. SSN, A-number, Name, DOB, address, etc.) related to individuals interacting with the agency. The identity derivation process uses standard entity matching algorithms included as part of the IMO product to leverage these individual instances of person-centric data attributes to derive identities. The system is able to account for a variety of data formats and potential data quality issues in the source data. The resulting identities are linked back to the original source records, allowing analysts to see an individual\u2019s comprehensive immigration history with the agency, perform fraud detection, and identify data quality issues requiring resolution.",
      "417": "This activity will improve urban vulnerability assessment in key population centers, particularly by co-creating replicable methods to use satellite imagery to map informal settlements. ",
      "356": "GPA\u2019s production media collection and analysis system that pulls data from half a dozen different open and commercial media clips services to give an up-to-date global picture of media coverage around the world.",
      "327": "This process uses AI to review textual data that is part of claim development tasks so it can be categorized into workload topics using natural language processing to facilitate faster technician review.",
      "96": "This project uses post irradiation examination of uranium-10wt.% zirconium (UZr) \nmetallic fuel as a case study to show how artificial intelligence (AI)-based technology \ncan facilitate and accelerate nuclear fuel development. The approach will 1) revisit the \nmicrostructural image and local thermal conductivity data collected from UZr, 2) build a \nbenchmark dataset for the microstructural patterns of irradiated UZr, and 3) train the \nmachine learning and deep learning models to uncover the relationships between \nmicro/nanoscale structure, zirconium phase redistribution, local thermal conductivity, \nand engineering scale fuel properties.",
      "210": "The Use of technology to identify proof of life, or \"Liveness Detection,\" uses Artificial Intelligence to reduce fraudulent activity, primarily for use within the CBP One app.\n\nThe CBP One app is designed to provide the public with a single portal to a variety of CBP services. It includes different functionality for travelers, importers, brokers, carriers, International Organizations, and other entities under a single consolidated log-in, and uses guided questions to help users determine the correct services, forms, or applications needed.\n\nThe Liveness Detection component used by the authentication system for the CBP One app uses the user's mobile device camera in addition to Artificial Intelligence algorithms to determine if the face presented to the app is the person in front of the camera at the time of capture and not a photo, mask, or other spoofing mechanism. Being able to accept submitted data with confidence that the submitting individual is who and where they claim to be is critical to the functionality of the app within the agency environment. ",
      "199": "AI Curated Synthetic Data creates synthetic data for computer vision to enable more capable and ethical AI when detecting anomalies in complex environments.\n\nSpecifically, it creates an emulated X-ray sensor that can produce visually realistic synthetic X-ray scan images similar to real X-ray scan images, and virtual 3D Assets of vehicles and narcotics containers. These images will be used to enhance the development of Anomaly Detection Algorithms for Non-Intrusive Inspection, incorporating AI/ML for the detection of narcotics and other contraband in conveyances and cargo.",
      "229": "Mobile Device Analytics (MDA) has been developed to meet the demand on investigators to view and analyze massive amounts of data resulting from court ordered mobile device extractions.  The overarching goal of MDA is to improve the efficacy of agents and analysts in identifying pertinent evidence, relationships, and criminal networks from data extracted from cellular phones. Machine Learning is being developed for object detection (such as firearms, drugs, money, etc.) in photos and videos contained in the data.\n\nThis is a DHS HSI Innovation Lab / RAVEn project. The Repository for Analytics in a Virtualized Environment (RAVEn) facilitates large, complex analytical projects to support ICE\u2019s mission to enforce and investigate violations of U.S. criminal, civil, and administrative laws. RAVEn also enables tools used to analyze trends and isolate criminal patterns as HSI mission needs arise. For more information, please read the DHS/ICE/PIA-055 - Privacy Impact Assessment 055 for RAVEn.",
      "310": "Language translation of published documents and website using natural language processing models.",
      "235": "The vision of Person-Centric Identity Services (PCIS) is to be the authoritative source of trusted biographical and biometric information that provides real-time, two-way visibility between services into an individual's comprehensive immigration history and status. The A-Number Management model ingests person-centric datasets from various source systems for model training and evaluation purposes. The dataset includes biographic information (name, date of birth, Alien #, Social Security #, passport #, etc.) as well as biographic information (fingerprint IDs, eye color, hair color, height, weight, etc.) for model training and matching purposes. \n\nThe A-Number Management identifies which records from within our identity database best match search criteria. The model uses machine learning to ensure that search results presented to authorized external partners for external integrations and servicing have a high degree of confidence with the search criteria so that trust in the PCIS entity resolution remains high.\n\nThe A-Number Management model plays a critical role in the entity resolution and surfacing of a person and all their associated records. The machine learning models are more capable of resolving \"fuzzy\" matches, and deal with the reality of different data quality.",
      "182": "Using the article title, abstract, journal, publication year, and indexing year of indexed and non-indexed articles that were\nsubmitted to MEDLINE in 2018, methods to automate the selection of indexed articles was researched. A classifier was\ndeveloped that combines the predictions of many traditional machine learning algorithms and a Convolutional Neural\nNetwork (CNN). The final classification layer uses a sigmoid activation function to generate a single output value between\nzero and one, which can be interpreted as the probability of an article being in-scope for MEDLINE.",
      "340": "Mobile Wage Reporting uses AI to extract text/data from scanned images/documents represeting pay stubs or payroll information to enable faster processing.",
      "442": "Using electronic health records (EHR) (both structured and unstructured data) as\u00a0 inputs, this tool outputs deep phenotypes and predictions of health outcomes including suicide death, opioid overdose, and decompensated outcomes of chronic diseases.",
      "401": "Deploy innovative active learning methods to provide a lower opportunity \ncost method of estimating a compliance baseline to support tax gap \nestimation, improper papyments reporting, development and validation of \nworkload identfication and selection models, and inform policy analysis.  \nSystem inputs require existing NRP data which provide an acceptable level \nof precision and quality for an acceptable level of data quality output.",
      "139": "Takes segment-level City Pair Program air travel purchase data and creates near-term forecasts for the current and upcoming fiscal year by month and at various levels of granularity including DOD vs Civilian, Agency, and Region.",
      "17": "EMDS is a spatial decision support system for landscape analysis and planning that runs as a component of ArcGIS and QGIS. Users develop applications for their specific problem that may use any combination of four AI engines for 1) logic processing, 2) multi-criteria decision analysis, 3) Bayesian networks, and Prolog-based decision trees.",
      "166": "Inputs - Medicare Claims data, Targeted Probe and Educate (TPE) Data, Jurisdiction information\nOutput - ranks providers within the FPS system using logistic regression based on program integrity guidelines.",
      "147": "GSA is driving towards a more accurate and scalable document workflow platform. GSA seeks to intelligently capture, classify, and transfer critical data from unstructured and structured documents, namely PDF files, to the right process, workflow, or decision engine.",
      "157": "NCHS is developing an item nonresponse detection model, to identify cases of item nonresponse (e.g., gibberish,\nuncertain/don\u2019t know, refusals, or high-risk) among open-text responses to help improve survey data and question and\nQuestionnaire design. The system is a Natural Language Processing (NLP) model pre-trained using Contrastive Learning\nand fine-tuned on a custom dataset from survey responses.",
      "27": "The deadwood model leverages boosted regression trees with inputs such as  administrative linkage data, frame data, and historical response information as inputs, to produce a propensity score representing a relative likelihood of a farm operation being out of business.  Common tree splits were identified using the model and combined with expert knowledge to develop a recurring process for deadwood clean up.",
      "67": "ProbSevere is a ML model that utilizes NWP, satellite, radar, and lightning data to nowcast \nsevere wind, severe hail, and tornadoes. ProbSevere, which was transitioned to NWS \noperations in October 2020, is a proven tool that enhances operational severe weather \nwarnings. This project aims to develop the next version of ProbSevere, ProbSevere v3. \nProbSevere v3 utilizes additional data sets and improved machine learning techniques to \nimprove upon the operational version of ProbSevere. ProbSevere v3 was successfully \ndemonstrated in the 2021 Hazardous Weather Testbed and a JTTI proposal was recently \nsubmitted to facilitate an operational update. The development is funded by GOES-R.",
      "208": "The Integrated Digital Environment provides managers with a better understanding of end user workflows, most and least used applications, and opportunities for improvement. \n\nThe AI/ML model applies to end user activity data (e.g., use of applications, flow between applications) to help CBP identify opportunities for more efficient or effective configuration of interfaces, use of resources, or development and deployment of CBP\u2019s applications.  It tailors analytics and insight generation to allow metrics gathering, usage recording/observation, dashboarding, and workflow experimentations/suggestions to support analysts utilizing the entire suite of agency and open-source data systems. It also customizes existing capabilities to allow the exact automations needed for agency applications and systems, creating an integrated digital environment for greater connectivity and security between applications, and better ability for CBP administrators to manage and optimize use of applications by end users.",
      "354": "Natural language processing application for F/RA to streamline the extraction of earmarks and directives from the annual appropriations bill. Before NLP this was an entirely manual process.",
      "120": "This project will use machine learning interatomic potentials to study the influence of \nradiation damage on physical properties of calcium fluoride and uranium dioxide. \nElectron irradiation experiments and thermal conductivity measurements will be \nperformed to validate the effectiveness of the developed potentials. The high \nthroughput capability of this method will become an important combinatorial materials \nscience tool for developing and qualifying new nuclear fuels.",
      "140": "Uses token extraction from product descriptions more accurately shape intended markets for Product Service Codes (PSCs).",
      "431": "Nediser is a continuously trained artificial intelligence \u201cradiology resident\u201d that assists radiologists in confirming the X-ray properties in their radiology reports.\u00a0 Nediser can select normal templates, detect hardware, evaluate patella alignment and leg length and angle discrepancy, and measure Cobb angles.",
      "332": "This model uses machine learning to identify supplemental security income cases with highest expected overpayments due to changes in financial eligibility and flag them for technician review.  ",
      "35": "A natural language processing (NLP) model was developed to utilize the text in procurement header and line descriptions within USDA's Integrated Acquisition System (IAS) to determine the likelihood that an award is IT-related, and therefore might require an AAR. The model uses the text characteristics for awards that have an AAR number entered into IAS and then calculates the probability of being IT-related for those procurements that did not have an AAR Number entered in IAS.",
      "322": "Automatic processing of current complex worflow to extract required data.",
      "358": "GPA\u2019s production system for collecting, analyzing, and summarizing the global digital content footprint of the Department.",
      "64": "Machine Learning Product that is a first guess for the WPC Excessive Rainfall Outlook - It is \nlearned from the ERO with atmospheric variables. It is for the Day 1, 2, 3 products",
      "127": "Explore the use of big data, artificial intelligence (AI), and machine learning technology \nand tools on phasor measurement unit (PMU) data to identify and improve existing \nknowledge, and to discover new insights and tools for better grid operation and \nmanagement.",
      "59": "For more than 20 years, NOAA Coral Reef Watch (CRW) has been using remote sensing, \nmodeled, and in situ data to operate a Decision Support System (DSS) to help resource \nmanagers (our target audience), researchers, decision makers, and other stakeholders \naround the world prepare for and respond to coral reef ecosystem stressors, \npredominantly resulting from climate change and warming of the Earth's oceans. Offering \nthe world's only global early-warning system of coral reef ecosystem physical \nenvironmental changes, CRW remotely monitors conditions that can cause coral \nbleaching, disease, and death; delivers information and early warnings in near real-time to \nour user community; and uses operational climate forecasts to provide outlooks of \nstressful environmental conditions at targeted reef locations worldwide. CRW products \nare primarily sea surface temperature (SST)-based but also incorporate light and ocean \ncolor, among other variables.",
      "126": "Explore the use of big data, artificial intelligence (AI), and machine learning technology \nand tools on phasor measurement unit (PMU) data to identify and improve existing \nknowledge, and to discover new insights and tools for better grid operation and \nmanagement.",
      "12": "The purpose of this project is to use AI tools, machine learning and natural language processing to understand how publicly-funded data and evidence are used to serve science and society.",
      "103": "This research identified and labeled type and structure data in an automated and \nscalable way such that the information can be used in other tools and other Reverse \nEngineering at Scale research areas such as symbolic execution. This was done \ninitially by utilizing heuristic methods and then scaled by adopting a machine learning \napproach.",
      "105": "The project goal is to prove that enhancing attack detection via innovative machine \nlearning and artificial intelligence techniques into the fifth generation (5G) cellular \nnetwork can help to secure mission-critical applications, such as automated vehicles \nand drones, connected health, emergency response operations, and other mission-\ncritical devices that either are or will be connected to the 5G cellular network.",
      "334": "This model uses machine learning to identify cases likely to receive an allowance at the hearing level and refer them to administrative law judges or senior adjudicators for prioritized review.",
      "410": "Using data from USAID funded Strengthening Integrated Delivery of HIV/AIDS Services (SIDHAS) project in Nigeria we trained and tested an algorithm that can be used for predicting the probability that someone newly initiated on ART will interrupt treatment. The algorithm has been successfully integrated into the Lafiya Management Information System (LAMIS), the individual-level client level electronic medical record system. Each week the outputs, for each new patient is shared with staff at the health facilities and those at high risk are provided with more intensive follow up support to reduce the risk of treatment interruption. We also conducted a qualitative assessment among to health care workers at the facilities to determine their perception of ML and determine what additional support are required for institutionalizing ML into their routine work.   ",
      "335": "Insight is decision support software used by hearings and appeals-level Disability Program adjudicators to help maximize the quality, speed, and consistency of their decision making.  Insight analyzes the free text of disability decisions and other case data to offer adjudicators real-time alerts on potential quality issues and case-specific reference information within a web application.  It also offers adjudicators a series of interactive tools to help streamline their work.  Adjudicators can leverage these features to speed their work and fix issues before the case moves forward (e.g. to another reviewing employee or to the claimant).  Insight\ufffds features are powered by several natural language processing and artificial intelligence packages and techniques.",
      "219": "Cyber Threat Intelligence Feed Correlation uses AI enabled capabilities to provide accelerated correlation across multiple incoming information feeds. This enables more timely enrichment to improve the externally shared information feeds. AI allows the algorithm to use the information items and results to learn most efficient ways to perform the task. Additionally, tailored algorithms could be created to provided sustained surveillance of threat actor TTPs.\n",
      "18": "This is a proof-of-concept study to investigate the use of machine learning (deep learning / convolutional neural networks) and object-based image classification techniques to identify buildings, building loss, and defensible space around buildings before and after a wildfire event in wildland-urban interface settings.",
      "203": "The Autonomous Maritime Awareness system combines surveillance towers, ocean data solutions, unmanned autonomous surface vehicles (ASV), and AI to autonomously detect, identify, and track items of interest in a maritime environment.\n\nThe towers are low-cost, customizable, and relocatable surveillance systems. They are equipped with a suite of radars and day/night camera sensors. The ASVs have been ruggedized for the open ocean and are powered by wind, solar, and/or onboard engine as required, allowing them to operate in an area of responsibility (AOR) for up to 12 months. Their sensor suite includes cameras and radar. \n\nBoth systems use AI/ML to detect and identify objects, determine items of interest (IoI) and autonomously track those items using their sensor suites. Once identified, these systems can send alerts to monitoring agencies for at-sea interdictions of potential targets and/or intel collections.",
      "142": "We are building a model to take generic Service Desk tickets and classify them so that they can be automatically re-routed to the correct team that handles these types of tickets. The process of re-routing generic tickets is currently done manually, so the model will allow us to automate it. The initial model will target the top 5 most common ticket types.",
      "393": "Built and evaluate a multiple linear regression model to predict to \ndetermine if the replenishment of an inventory item would receive by the \nstandard Need By time of 128 days set for all inventory items.",
      "440": "Machine learning is used to improve treatment of functional problems in patients with peripheral artery disease (PAD). Previously collected biomechanics data is used to identify representative gait signatures of PAD to 1) determine the gait signatures of patients with PAD and 2) the ability of limb acceleration measurements to identify and model the meaningful biomechanics measures from PAD data.",
      "125": "1. Machine learning methods such as cross-correlation, random forest, regression \ntree and transfer learning are used to estimate the load composition data and motor \nprotection profiles for different climante regions in the Western US\n2. Deep learning algorithm is appplied to calibrate the parameters of WECC \ncomposite load model to match the responses with detailed feeder model",
      "369": "using statistical models, projecting expected outcome into the future; this has been applied to COVID cases as well as violent events in relation to tweets",
      "443": "The VA-DoE Suicide Exemplar project is currently utilizing artificial intelligence to improve VA's ability to identify Veterans at risk for suicide through three closely related projects that all involve collaborations with the Department of Energy.",
      "407": "For water supply, semi-arid Botswana relies on the reservoirs within the Botswana\u2019s LRB. Reservoirs are particularly susceptible to the negative impacts of land-use and land-cover (LULC) activities and runoff because of their complex dynamics, relatively longer water residence times, and their role as an integrating sink for pollutants from their drainage basins. Despite these interrelationships and significance in regional and global economic stability, land and water (L-W) are often treated in \u201csilos\u201d. To understand the complex L-W nexus within the LRB, this study will use data-driven artificial intelligence for quantitative determination of the relationships between LULC change, together with socioeconomic development indicators and climate change, and their impacts on water quality and availability within the basin, both for 1984-2019 and to predict future scenarios (2020-2050). To advance data acquisition for LULC analysis and climate change, the study utilizes optical Earth-observation and meteorological satellite data. To provide near real-time and cost-effective approach for continuous monitoring of reservoir water quality within the basin, the study will develop empirical models for water quality estimation and water quality index mapping using 35-years of in-situ water quality measurements and water spectral observations using drone-borne spectrometer and optical satellite imagery through regression modeling and geospatial methods.",
      "308": "The application scans documents and \nlooks for attorney/client privileged \ninformation. It does this based on \nkeyword input by the system \noperator.",
      "44": "Azure Chatbot is being leveraged to automate and streamline the user response to \npotential questions for MBDA users while interacting with the external facing MBDA \nwebsite. The solution leverages AI based chatbot response coupled with Machine \nLearning and Natural Language Processing capabilities.",
      "29": "The model classifies NIFA funded projects as climate change related or not climate related through natural language processing techniques. The model input features include text fields containing the project's title, non-technical summary, objectives and keywords. The target is a dummy variable classification of projects as climate change related or not climate change related.",
      "98": "This project will develop the capability to intelligently control and optimize advanced \nmanufacturing processes instead of the existing trial and error approach. To achieve \nthis goal, artificial intelligence (AI) based control algorithms will be developed by \nemploying deep reinforcement learning. To reduce the computational expense with \nadvanced manufacturing models, physics-informed reduced order models (ROMs) will \nbe developed. The AI-based control algorithms will employ the ROMs\u2019 predictions to \nadaptively inform processing decisions in a simulation environment.",
      "390": "Description: Utilize deep learning for predicting crash parameters, Delta-V (change in velocity) and PDOF (principal direction of force), directly from real-world crash images. Delta-V and PDOF are two most important parameters affecting injury outcome. Deep learning models can help predict both Delta-V and PDOF, without the need to run WinSmash software for Delta-V computation, and without requiring estimations by crash examiners.  Moreover, with deep learning models, the Delta-V and PDOF can be obtained within milliseconds, providing rapid results for improved efficiency\"\nInput:  Real world crash images\nOutput:  Delta-V & PDOF",
      "438": "The SoKat Suicide Ideation Engine (SSIE) uses natural language processing (NLP) to improve identification of Veteran suicide ideation (SI) from survey data collected by the Office of Mental Health (OMH) Veteran Crisis Line (VCL) support team (VSignals).",
      "329": "These review models use machine learning to identify cases with greatest likelihood of disability eligibility determination error and refer them for quality review checks.  ",
      "3": "Identify and locate aquatic weeds",
      "375": "Takes in a social network and clusters nodes together into \u201ccommunities\u201d (i.e., similar nodes are grouped together)",
      "50": "Demonstrate the skill and suitability for operations of a statistical- dynamical prediction \nsystem that yields seamless probabilistic forecasts of daily extremes and sub seasonal-to-\nseasonal temperature and precipitation. We recently demonstrated a Bayesian statistical \nmethod for post-processing seasonal forecasts of mean temperature and precipitation \nfrom the North American Multi-Model Ensemble (NMME). We now seek to test the utility \nof an updated hybrid statistical-dynamical prediction system that facilitates seamless sub \nseasonal and seasonal forecasting. Importantly, this method allows for the representation \nof daily extremes consistent with climate conditions. This project explores the use of \nmachine learning.",
      "246": "This project is exploring a better method to analyze DC ramp test data from rotating machines. Previous DC ramp test analysis requires engineering expertise to recognize characteristic curves from DC ramp test plots. DC ramp tests produce a plot of voltage vs current for a ramping voltage applied to a rotating machine. By using machine learning/AI tools, such as linear regression, the ramp test plots can be analyzed by computer software, rather than manual engineering analysis, to recognize characteristic curves. The anticipated result will be faster and more reliable analysis of field-performed DC ramp testing.",
      "41": "The Consolidated Screening List (CSL) is a list of parties for which the United States \nGovernment maintains restrictions on certain exports, reexports, or transfers of items. It \nconsists of the consolidation of 13 export screening lists of the Departments of \nCommerce, State, and Treasury.  The CSL search engine has \u201cFuzzy Name Search\u201d \ncapabilities, allowing a search without knowing the exact spelling of an entity\u2019s name. In \nFuzzy Name mode, the CSL returns a \u201cscore\u201d for results that exactly or nearly match the \nsearched name. This is particularly helpful when searching on CSL for names that have \nbeen translated into English from non-Latin alphabet languages.",
      "72": "The Video and Image Analysis for the Marine Environment Software Toolkit, commonly \nknown as VIAME, is an open-source, modular software toolkit that allows users to employ \nhigh-level, deep-learning algorithms for automated annotation of imagery using a low \ncode/no code graphical user interface. VIAME is available free of charge to all NOAA \nusers.  The NOAA Fisheries Office of Science and Technology supports an annual \nmaintenance contract covering technical and customer support by the developer, routine \nsoftware updates, bug fixes, and development efforts that support broad, cross center \napplication needs.",
      "413": "AI technology was used to develop a pandemic preparedness AI model to support allocation of COVID-19 vaccines based on a multi-tiered strategy for target populations: 1) hotspots for COVID-19 positive cases and 2) pregnant/breastfeeding women using DHIS2 data. This was a proof-of-concept model.",
      "349": "The Foreign Service Institute School of Language Studies is developing a tool for automated discovery of authentic native language texts classified for both topic and Interagency Language Roundtable (ILR) proficiency level to support foreign language curriculum and language testing kit development.",
      "380": "SCM classifies surface incident reports by event type, such as Runway Incursion, Runway Excursion, Taxiway Incursion/Excursion and categorizes runway incursions further by severity type (Category A, B, C, D, E)",
      "420": "AICURE is a phone app that monitors adherence to orally prescribed medications during clinical or pharmaceutical sponsor\u00a0 drug studies.",
      "94": "This project will develop a novel physics-based tool that combines 1) reduced-order \nmodels, 2) machine learning algorithms, 3) fuel performance methods, and 4) state-of-\nthe-art thermal property characterization equipment and irradiated nuclear fuel data \nsets to accelerate nuclear fuel discovery, development, and deployment. The models \nwill describe thermal conductivity, specific heat, thermal expansion, and self-diffusion \ncoefficients as a function of temperature and irradiation.",
      "30": "Western US water management is underpinned by forecasts of spring-summer river flow volumes made using operational hydrologic models. The USDA Natural Resources Conservation Service (NRCS) National Water and Climate Center operates the largest such forecast system regionally, carrying on a nearly century-old tradition. The NWCC recently developed a next-generation prototype for generating such operational water supply forecasts (WSFs), the multi-model machine-learning metasystem (M4), which integrates a variety of AI and other data-science technologies carefully chosen or developed to satisfy specific user needs. Required inputs are data around snow and precipitation from the NRCS Snow Survey and Water Supply Forecast program SNOTEL environmental monitoring network, but are flexible.  In hindcasting test-cases spanning diverse environments across the western US and Alaska, out-of-sample accuracy improved markedly over current benchmarks. Various technical design elements, including multi-model ensemble modeling, autonomous machine learning (AutoML), hyperparameter pre-calibration, and theory-guided data science, collectively permitted automated training and operation.  Live operational testing at a subset of sites additionally demonstrated logistical feasibility of workflows, as well as geophysical explainability of results in terms of known hydroclimatic processes, belying the black-box reputation of machine learning and enabling relatable forecast storylines for NRCS customers.",
      "0": "Macine learning algorithms are used to develop with inspection data and improve prediction ability of detecting invasive/quarantine significant pests at the port of entry.",
      "130": "Explore the use of big data, artificial intelligence (AI), and machine learning technology \nand tools on phasor measurement unit (PMU) data to identify and improve existing \nknowledge, and to discover new insights and tools for better grid operation and \nmanagement.",
      "446": "This work examines data from 20,368 Veterans Health Administration (VHA) patients with an irritable bowel disease (IBD) diagnosis between 2002 and 2009. Longitudinal labs and associated predictors were used in random forest models to predict hospitalizations and steroid usage as a surrogate for IBD Flares.",
      "454": "This IRB approved research study uses\u00a0 a randomized trial for finding colon polyps with artifical intelligence.",
      "249": "Researching use of self-supervised deep neural networks to identify classification systems for significant well event using data from well Activity Reports",
      "247": "Well casing pressure requests are submitted to BSEE to determine whether a well platform is experiencing a sustained casing pressure (SCP) problem. SCP is usually caused by gas migration from a high-pressured subsurface formation through the leaking cement sheath in one of the well\u2019s casing annuli, but SCP can also be caused by defects in tube connections, downhole accessories, or seals. Because SCP can lead to major safety issues, quickly identifying wells with SCP could greatly mitigate accidents on the well platforms",
      "196": "Fundamental scientific advances can take decades to translate into improvements in human health. Shortening this\ninterval would increase the rate at which scientific discoveries lead to successful treatment of human disease. One way to\naccomplish this would be to identify which advances in knowledge are most likely to translate into clinical research.\nToward that end, the NIH Office of Portfolio Analysis built a machine learning system that detects whether a paper is\nlikely to be cited by a future clinical trial or guideline. Despite the noisiness of citation dynamics, as little as 2 years of\npostpublication data yield accurate predictions about a paper\u2019s eventual citation by a clinical article (accuracy = 84%, F1\nscore = 0.56; compared to 19% accuracy by chance). We found that distinct knowledge flow trajectories are linked to\npapers that either succeed or fail to influence clinical research. Translational progress in biomedicine can therefore be\nassessed and predicted in real time based on information conveyed by the scientific community\u2019s early reaction to a\npaper. For more information see the publication describing this system: Hutchins et al 2019\n(https://journals.plos.org/plosbiology/article?id=10.1371/journal.pbio.3000416)",
      "38": "The Video Surveillance System: the VSS system design will include a video management system, NVRs, DVRs, encoders, fixed cameras, Pan and Tilt cameras, network switches, routers, IP cables, equipment racks and mounting hardware. The Video Surveillance System (VSS)- shall control multiple sources of video surveillance subsystems to collect, manage, and present video clearly and concisely. VMS shall integrate the capabilities of each subsystem across single or multiple sites, allowing video management of any compatible analog or digital video device through a unified configuration platform and viewer. Disparate video systems are normalized and funneled through a shared video experience. Drag and drop cameras from the Security Management System hardware tree into VMS views and leverage Security Management System alarm integration and advanced features that help the operator track a target through a set of sequential cameras with a simplified method to select a new central camera and surrounding camera views.",
      "352": "IRM\u2019s BMP Systems is planning to incorporate ServiceNow\u2019s Virtual Agent into our existing applications to connect users with support and data requests. The Artificial Intelligence (AI) is provided by ServiceNow as part of their Platform as a Service (PaaS).",
      "69": "The GOES-16 Solar Ultraviolet Imager (SUVI) is NOAA's operational solar extreme-\nultraviolet imager. The SUVI Level 2 Thematic Map files in these directories are produced \nby NOAA's National Centers for Environmental Information in Boulder, Colorado. These \ndata have been processed from Level 2 High Dynamic Range (HDR) composite SUVI \nimages. The FITS file headers are populated with metadata to facilitate interpretation by \nusers of these observations. Please note that these files are considered to be \nexperimental and thus will be improved in future releases. Users requiring assistance with \nthese files can contact the NCEI SUVI team by emailing goesr.suvi@noaa.gov. The SUVI \nThematic Maps product is a Level 2 data product that (presently) uses a machine learning \nclassifier to generate a pixel-by-pixel map of important solar features digested from all six \nSUVI spectral channels.",
      "261": "The\u00a0goal\u00a0is to link existing hydrological flow data (e.g., USGS stream gages) and models (e.g., USGS Process-Guided Deep Learning Models for flow and temparture) with trout population dynamic models, changes to fish catch, and the economic benefits of recreational fishing. These trout population dynamic models will be developed based on observational data, existing literature estimates, and existing models.",
      "409": "Use AI to detect illegal rhino horn in airplane luggage X-Ray scanners",
      "228": "The Email Analytics application enables a user to review and analyze email data acquired through legal process.  AI is incorporated to accomplish spam message classification, and named entity recognition (NER) for entity extraction of names, organizations, locations, etc.  It also integrates machine translation capabilities using a commercial product.",
      "36": "Routes BMC Remedy tickets to proper work group automatically utilizing python, jupyterhub, scikit learn, gitlab, flask, gunicorn, nginx, erms.",
      "423": "Artificial intelligence\u00a0 recursively analyzes previously collected data to both improve the quality and accuracy of automated algorithms, as well as to screen for markers of neurological disease (e.g. traumatic brain injury, Parkinson's, stroke, etc).",
      "422": "Health professionals can use this artificial intelligence to determine predictors of normal and abnormal lung function and sleep parameters.",
      "223": "Threat hunting and Security Operations Center (SOC) analysts are provided terabytes per day of log data. Manually developed detection alerts and automatic correlation in Security Information and Event Management tool are common, but not comprehensive. Many cyber attacks can be probabilistically determined given sufficient training data and time. Analysts  use automated tooling to further refine the alerts they receive and produce additional automated alerts based on aggregated information and curated subject matter expertise. This tooling allows CISA analysts the capabilities to comb through data in an automated fashion with mathematically and probabilistically based models to ensure high fidelity anomalies are detected in a timely manner. ",
      "226": "HSI uses Artificial Intelligence to verify, validate, correct, and normalize addresses, phone numbers, names, and ID numbers to streamline the process of correcting data entry errors, point out purposeful misidentification, connect information about a person across HSI datasets, and cut down the number of resource hours needed for investigations. \n\nExamples of the normalization services provided include: normalizing less well-defined addresses into usable addresses for analysis- (such as those using mile markers instead of a street number); inferring ID type based on user-provided ID value (such as distinguishing a SSN from a DL number without additional context); categorizing name parts while taking into account additional factors (including generational suffixes and multi-part family names); and validating and normalizing phone numbers to the E164 standard, including their identified county of origin.\n\nThese services are provided as part of the Repository for Analytics in a Virtualized Environment (RAVEn).  RAVEn is a DHS HSI Innovation Lab project that facilitates large, complex analytical projects to support ICE\u2019s mission to enforce and investigate violations of U.S. criminal, civil, and administrative laws. RAVEn also enables tools used to analyze trends and isolate criminal patterns as HSI mission needs arise. For more information, please read the DHS/ICE/PIA-055 - Privacy Impact Assessment 055 for RAVEn.",
      "22": "The Landscape Change Monitoring System (LCMS) is a National landsat/sentinal remote sensing-based data produced by the USDA Forest Service for mapping and monitoring changes related to vegetation canopy cover, as well as land cover and land use. The process utilizes temporal change classifications together with training data in a supervised classification process for vegetation gain, and loss as well as land cover and use.",
      "312": "Text to speech (Neural) for more realistic human sounding applications using natural language processing models.",
      "165": "CMS is using Security Data Lake to modernize the load-extract-load-transform (L-ETL) pipelines and data tooling. CMS will\nbe enhancing Agency security to bring together more system, telemetry and program data in one place with a unifying\ngovernance model. Building on top of a modern data platform will provide opportunities to experiment with machine\nlearning model development against this data--solving any number of problems that require decisions to be made about\ninferences over time series data. There is no actual ML/AI work being done here today, rather, we are beginning work on\nthe scaffolding that will open up these opportunities in 1-2 years time.",
      "26": "A machine learning algorithm is used to interpret readings from satellite-based sensors and CLASSIFY the type of crop or activity that falls in each 30 square meter pixel (a box of fixed size) on the ground.  The algorithms are trained on USDA&%2339;s Farm Services Agency data and other sources of data as sources of &quot;ground truth&quot;.  It allows us to not only produce a classification, but to assess the accuracy of the classification as well.  For commodities, like corn and soybeans, the CDL is highly accurate.  The CDL has been produced for national coverage since 2008.  Some summary and background about the CDL is available in a number of peer reviewed research papers and presentations\nhttps://www.nass.usda.gov/Research_and_Science/Cropland/othercitations/index.php",
      "372": "GEC A&R\u2019s TOPIQ tool automatically classifies text into topics for analyst review and interpretation. The tool uses Latent Dirichlet Allocation (LDA), a natural language processing technique that uncovers a specified number of topics from a collection of documents, and then assigns the probability that each document belongs to a topic.",
      "267": "The Seabird Studies Team at the Western Ecological Research Center (WERC), with support from the Bureau of Ocean Energy Management (BOEM), completed aerial photographic surveys of the ocean off central and southern California between 2018-2021. Over 800,000 high resolution images of the ocean were collected, with the goal of extracting and counting marine birds and mammals contained within. To process this volume of images machine learning offered the best methodology, but publicly available training data did not exist for this specific purpose. Through a collaboration with Conservation Metrics, Inc. we created a labeled training dataset using Faster RCNN models via active learning and transfer learning. We then evaluated a set of candidate models trained on different label aggregation schemes, selected a final model utilizing YOLOv5 architecture, and ran the final model on the complete image dataset. Images output from the final model classified targets into seven categories: bird, dark bird, dark bird flying, light bird, fish, marine mammal, and other. We are currently reviewing the final model output for false positives and negatives to evaluate performance. Next, we will reclassify model labels to the lowest taxonomic group possible. This manual review is occurring in the USGS cloud environment (Amazon Web Services) utilizing the opensource Computer Vision Annotation Tool (CVAT). Once low taxonomic reclassification is complete, we will generate maps of species distribution and abundance to inform BOEM\u2019s planning in advance of potential offshore wind energy development along the California coast.",
      "448": "Machine learning analyzes patient demographics, medication use, and longitudinal laboratory values collected between 2001 and 2015 from adult patients in the Veterans Integrated Service Networks (VISN) 10 cohort. The data was used for analysis in prediction of Crohn\u2019s disease and to model future surgical outcomes within 1 year.",
      "170": "The deduplication algorithm is applied to nonpublic data in the FDA Adverse Event Reporting System (FAERS) to identify\nduplicate reports. Unstructured data in free text FAERS narratives is processed through a natural language processing\nsystem to extract relevant clinical features. Both structured and unstructured data are then used in a probabilistic record\nlinkage approach to score pairs of reports by evaluating multiple data fields and applying relative weights per field. The\noutput of potential duplicate reports is further placed in groups to facilitate identification of FAERS reports during case\nseries evaluation for safety issues of concern.",
      "437": "Machine learning algorithms use EEG and video data from a VHA epilepsy monitoring unit in order to automatically identify seizures without human intervention.",
      "119": "This project will develop passive instrumentation to determine permanent strains \ninduced by irradiation and extract critical parameters using modeling and simulation as \nwell as machine learning algorithms. An irradiation experiment will be conducted that \nwill benefit from engineered anisotropic materials and characterize the directional \ndeformation in response to neutron radiation. The results of the experiment will be \nincorporated into the model so that the material response can be predicted for future \nuses as a probe material.",
      "337": "Duplicate Identification Process's (DIP's) objective is to help the user to\ufffdidentify and flag\ufffdand mark duplicates\ufffdmore efficiently, reducing the amount\ufffdof time spent to review\ufffdcases for\ufffdhearings.\ufffdDIP uses artificial\ufffdintelligence software in the form of image recognition technology to accurately\ufffdidentify duplicates consistent with SSA\ufffdpolicy.?",
      "355": "The Department\u2019s central eRecords archive leverages machine learning models to add additional metadata to assist with record discovery and review. This includes models for entity extraction, sentiment analysis, classification and identifying document types.",
      "74": "The goal of this project is to study green turtles in and around La Jolla Cove in the San \nDiego Region-a highly populated site with ecotourism-by engaging with local \nphotographers to collect green turtle underwater images.  The project uses publicly \navailable facial recognition software (HotSpotter) to identify individual turtles, from which \nwe determine population size, residency patterns, and foraging ecology",
      "338": "AI performs OCR against handwritten entries on specific standard forms submitted by clients. This use case is in support of an Robtic Process Automation effort as well as a standalone use.",
      "78": "Investigated replacing unstructured WW3 in the Great Lakes with (i) a Recurrent Neural \nNetwork (RNN, especially an LSTM) developed by EMC and (ii) a boosted ensemble \ndecision tree (XGBoost) developed by GLERL. These two AI models were trained on two \ndecades of wave observations in Lake Erie and compared to the operational Great Lakes \nunstructured WW3.",
      "180": "The Pango nomenclature, called Pango lineages, is being used by researchers and public health agencies worldwide to\ntrack the transmission and spread of SARS-CoV-2, including variants of concern. The requirements for running the tool\ninclude having conda on a MacOS or Linux system, and the FASTA-formated sequence data. There are 2 methods for\nlineage assignment with Pango; within NCBI Virus we use the process which includes PangoLEARN, where a classification\ntree is used to group similar sequences.",
      "138": "Takes Detailed Data on transactions and classifies each transaction within the Government-wide Category Management Taxonomy",
      "389": "Description: Utilize deep learning models for predicting head kinematics directly from crash videos. The utilization of deep learning techniques enables the extraction of 3D kinematics from 2D views, offering a viable alternative for calculating head kinematics in the absence of sensors or when sensor availability is inadequate, and when high-quality sensor data is absent\nInput:  Vehicle crash videos\nOutput: Angular velocity - injury prediction",
      "45": "The Fisheries Electronic Monitoring Library (FEML) will be the central repository for \nelectronic monitoring (EM) data related to marine life.",
      "93": "This project will research artificial intelligence enabled Monte Carlo algorithms to \nsignificantly reduce the computational burden by reducing the number of finite element \nevaluations when estimating low failure probabilities. These will be implemented in the \nMultiphysics Object-Oriented Simulation Environment, which will help the nuclear \nengineering community to efficiently conduct probabilistic failure analyses and \nuncertainty quantification studies for the design and optimization of advanced reactor \ntechnologies.",
      "193": "Chat Bot to assist users in finding grant related information via OER resources",
      "263": "Our project includes two stages of AI, the first is a binary detector to automate the detection of wildlife in aerial imagery and the second is a robust classification algorithm to automate the taxonomic classification of wildlife from the binary detector. The input of the first and second stage are manually annotated polygons around targets of interest and their taxonomic classification values from family to species, respectively. We use Tallgrass to develop and train our algorithms, BlackPearl/Caldera to store our large image datasets, a hosted instance of a customized version of the Computer Vision Annotation Tool to gather manually annotated data, and a separate PostgreSQL database to store annotations and image metadata.",
      "68": "Volcanic ash is a major aviation hazard. The VOLcanic Cloud Analysis Toolkit (VOLCAT) \nconsists of several AI powered satellite applications including: eruption detection, \nalerting, and volcanic cloud tracking. These applications are routinely utilized by Volcanic \nAsh Advisory Centers to issue volcanic ash advisories. Under this project, the VOLCAT \nproducts will be further developed, and subsequently transitioned to the NESDIS Common \nCloud Framework, to help ensure adherence to new International Civil Aviation \nOrganization requirements.",
      "350": "The Village Monitoring System program uses AI and machine learning to conduct daily scans of moderate resolution commercial satellite imagery to identify anomalies using the near-infrared band.",
      "24": "Machine learning models are used to (1) upscale training data, using Sentinel-2, Landsat,  MODIS, and lidar imagery, that was collected from both the field and high-resolution imagery to map and monitor stages of forest mortality and defoliation across the United States, and (2) to post-process raster outputs to vector polygons.",
      "395": "The NLU model will be located inside the Automated Collections IVR (ACI) \nmain menu. This NLU will take customer speech input aka \u2013 Utterances.  It \nwill map the utterance to a specific intent and direct the taxpayer down to \na certain call path.",
      "436": "AI is used to add value as a transactor for intelligent identity resolution and linking.\u00a0 AI also has a domain cache function that can be used for both Clinical Decision Support and for intelligent state reconstruction over time and real-time discrepancy detection.\u00a0 As a synchronizer, AI can perform intelligent propagation and semi-automated discrepancy resolution.\u00a0 AI adapters can be used for inference via OWL and logic programming.\u00a0 Lastly, AI has long term storage (\u201cblack box flight recorder\u201d) for virtually limitless machine learning and BI applications.",
      "362": "Fast Text is an AI approach to identifying similar terms and phrases based off a root word. This support A&R\u2019s capability to build robust search queries for data collection.",
      "136": "EPA\u2019s Office of Compliance, in partnership with the University of Chicago, built a proof-of-concept to improve enforcement of environmental regulations through facility inspections by the EPA and state partners. The resulting predictive analytics showed a 47% improvement of identifying violations of the Resource Conservation and Recovery Act.",
      "270": "This study involves using orthophotos acquired from a manned, fixed-wing aircraft and multispectral images from two different satellites to map bottom-attached (benthic) algae along the Buffalo National River in northern Arkansas. The training data for this effort consist of field observations of water depth and percent cover of benthic algae along 8-10 cross sections from two distinct reaches of the Buffalo River. These field data are used to train a bagged trees (aka random forest) classification algorithm to distinguish among four ordinal levels of algal density: none, low, medium, and high.",
      "221": "Reverse engineering of malware, and software analysis more broadly, will continue to be a critical activity in support of CISA\u2019s cyber defense mission. Threat Focused Reverse Engineering (TFRE) leverages advanced engineering, formal methods, and deep learning techniques for better cyber threat intelligence. Without scalable, automated tools, it is difficult to disrupt sophisticated adversaries\u2019 malware development lifecycle. New, unique, automated techniques are needed to better target adversaries, augment analysts, and create sophisticated tools for end users. Core tools disrupt the adversary\u2019s development lifecycle by exposing tactics, techniques, and procedures (TTPs). Analysts could spend more time and energy to hunt/takedown threats; adversaries can spend less time operating malware and must commit more resources to reorient. TFRE consists of a broader development pipeline providing tool hardening, enhanced computational abilities, understanding of deployment environments, and other important capabilities.",
      "6": "The algorithm computes a string similarity metric which can be used to classify similar strings into a single category, reducing information duplication and onerous, manual error-checking",
      "244": "UAS derived photogrammetric products contain a large amount of potential information that can be less accurate than required for analysis and time consuming to analyze manually. By formulating a standard reference protocol and applying machine learning/artificial intelligence, this information will be unlocked to provide detailed analysis of Reclamation's assets for better informed decision making.",
      "1": "Identify pixels with HLB infection signature in multispectral and thermal imagery",
      "285": "Once developed, the system will input watershed characteristics (soils, land cover) and long-term meteorological data, and output predictions of flood flow metrics (magnitude, duration, frequency, volume) for stream reaches. Two models will be trained using gage data from regions surrounding the Delaware River Basin and the Colorado River Basin. The resulting models will allow for estimating flood flow metrics in ungaged reaches, which can be used to inform infrastructure designs along those reaches (e.g., bridges). The current deliverable is predictions for minimally altered catchments, and future years may expend to predictions in altered catchments (e.g., those with dam regulation). The models will be built using various R packages on the USGS Tallgrass supercomputer.",
      "357": "A prototype system that collects and analyzes the daily media clips reports from about 70 different Embassy Public Affairs Sections.",
      "114": "This project will develop a learning-based and digital twin enabled modeling and \nsimulation framework for economic and resilient real-time decision-making of physics-\ninformed integrated energy systems (IES) operation. High-fidelity physics models will \nbe linked with large-scale grid monitoring data to provide real-time updates of IES \nstates, predictive control systems, and optimized power dispatch solutions. Learning-\nbased algorithms will make real-time decisions upon detection of component \ncontingencies caused by climate-induced or man-made extreme events, such as \ncyber-attacks or extreme weather, thereby mitigating their impacts through \nappropriate counter measures.",
      "328": "The anomalous iClaim predictive model is a machine learning model that identifies high-risk iClaims. These claims are then sent to Operations for further review before additional action is taken to adjudicate the claims. ",
      "313": "To identify if physician\u2019s note contains causal language by training custom natural language processing models.",
      "13": "A competition to find automated, yet effective, ways of linking USDA nutrition information to 750K food items in a proprietary data set of food purchases and acquisitions. Competing teams used a number of  AI methods including Natural Language Processing (NLP), random forest, and semantic matching.",
      "214": "Frameworks, processes, and testing tools developed to govern the acquisition, development, deployment, and maintenance of AI technologies. Technology integrators within CISA as well as the rest of the federal enterprise use AI-enhanced tools to assure the trustworthy, robust, and secure operation of their AI systems. These tools use Machine Learning and Natural Language Processing to enhance the assessment of AI technology within the agency by speeding up data processing.",
      "131": "Explore the use of big data, artificial intelligence (AI), and machine learning technology \nand tools on phasor measurement unit (PMU) data to identify and improve existing \nknowledge, and to discover new insights and tools for better grid operation and \nmanagement.",
      "233": "This project attempts to train and build a machine learning throughput analysis model to predict when an I-539 \"Application to Extend or Change Nonimmigrant Status\" case will be approved through eProcessing. Allows for some potential improvement for the approval process via eProcessing channel.",
      "56": "AI for right whale photo id began with a Kaggle competition and has since expanded to \ninclude several algorithms to match right whales from different viewpoints (aerial, lateral) \nand body part (head, fluke, peduncle). The system is now live and operational on the \nFlukebook platform for both North Atlantic and southern right whales. We have a paper in \nreview at Mammalian Biology.",
      "90": "This research will develop a digital twin of a centrifugal contactor system that \nreceives data from traditional and real time sensors, constructs a digital \nrepresentation or simulation of the chemical separations component within the nuclear \nfuel cycle, and performs data analysis through machine learning to determine \nanomalies, failures, and trends. The research will include the identification and \nimplementation of advanced artificial intelligence, machine learning, and data analysis \ntechniques advised by a team of nuclear safeguards experts.",
      "421": "This project, a collaboration with Google DeepMind, focuses on detecting acute kidney injury (AKI), ranging from minor loss of kidney function to complete kidney failure. The artificial intelligence can also detect AKI that may be the result of another illness.",
      "323": "Using an open source large language model to summarize publicly available case recording documents which are void of personal identifiable information (PII) or any other sensitive information. This is not hosted in the DOL technical environment and is reviewed by human note takers.",
      "65": "CoralNet is our operational point annotation software for benthic photo quadrat \nannotation. Our development of our classifiers has allowed us to significantly reduce our \nhuman annotation, and we continue to co-develop (and co-fund) new developments in \nCoralNet,",
      "176": "Splunk utilizes machine learning to aggregate system logs from IT infrastructure systems and endpoints for auditing and\nmonitoring purposes",
      "289": "1) This model predicts two interdependent variables, daily average streamflow and daily average stream water temperature, together using multi-task deep learning. A multi-task scaling factor controls the relative contribution of the auxiliary variable\u2019s error to the overall loss during training. Input data include meteorological variables such as rainfall and humidity. 2) The training data were streamflow and water temperature observations. The stream temperature data were collected by the USGS and made available via NWIS. The streamflow observations were also collected by the USGS but collated along with input drivers in the CAMELS dataset. 3) This work was done using Python. The deep learning models were written via TensorFlow and the modeling workflow was scripted via Snakemake.",
      "428": "Researchers are performing chart review to collect true/false positive annotations and construct a vector embedding of patient records, followed by similarity-based retrieval of unlabeled records \"near\" the labeled ones (semi-supervised approach). The aim is to use machine learning as a filter, after the rules-based retrieval, to improve specificity. Embedding inputs will be selected high-value structured data pertinent to stroke risk and possibly selected prior text notes.",
      "11": "Cogito (vendor) software, uses AI for automated subject indexing to annotate peer reviewed journal articles (~500,000 annually) using the National Ag Library Thesaurus concept space (NALT). Only NALT concepts are annotated as metadata to content in the Library's bibliographic citation database, AGRICOLA, PubAg, and Ag Data Commons.",
      "258": "This study focuses on the development of an AI system to recognize individual fish and their disease status from images. Success of this effort could complement or replace traditional mark-recapture methods used for estimating abundance, survival, and movement, and this could greatly reduce costs to fisheries managers. Likewise, disease detection from images could enable new approaches for assessing status and trends in fish health.",
      "97": "This approach exploits the millimeter wave beam directionality and utilizes the beam \nsensing capabilities at end devices to prove that an autonomous radio frequency \nbeam scheduler can support secure 5G spectrum sharing and guarantee optimality for \nbase stations. Measurements and predictive analytics are used to develop the \nautonomous beam scheduling algorithms. These improvements will benefit mission \ncritical communications and emergency response operations as well as enable \nsecure communication for critical infrastructure without expensive and competitive \nlicensed bands.",
      "265": "A course in application of deep learning image segmentation, image classification, and object-in-image detection. Course includes software written in Python using Keras and Tensorflow ML libraries, software documentation, data, website, and slides. See course website https://dbuscombe-usgs.github.io/MLMONDAYS/ for more details",
      "113": "This project will develop a novel deep reinforcement learning approach that can \nmanage distributed or tightly coupled multi-agent systems utilizing deep neural \nnetworks for automatic system representation, modeling, and end-to-end learning. \nThis new control method will enable complex, nonlinear system optimization over \ntimescales from milliseconds to months.",
      "207": "Leverages a commercial constellation of Synthetic Aperture Radar (SAR) satellites with readily available data, capable of imaging any location on Earth, day, and night, regardless of cloud cover. \n\nUtilizes AI, including machine vision, object, detection, object recognition, and annotation to detect airframes, military vehicles, and marine vessels, as well as built-in change detection capabilities for disaster response missions.",
      "315": "Custom machine learning model to extract data from complex forms to tag data entries to field headers. The input is a document or scanned image of the form and the output is a JSON response with key/value pairs extracted by running the form against the custom trained model.",
      "231": "The Facial Recognition Service is used during investigations conducted by HSI agents and analysts for identification of known individuals, as well as extracting faces for further investigations from perpetrators including child exploitation offenses, human rights atrocities, and war criminals.\n\nThis is a DHS HSI Innovation Lab / RAVEn project. The Repository for Analytics in a Virtualized Environment (RAVEn) facilitates large, complex analytical projects to support ICE\u2019s mission to enforce and investigate violations of U.S. criminal, civil, and administrative laws. RAVEn also enables tools used to analyze trends and isolate criminal patterns as HSI mission needs arise. For more information, please read the DHS/ICE/PIA-055 - Privacy Impact Assessment 055 for RAVEn.",
      "239": "Builds models that identify lists of topics and documents that are related to each topic. Topic Modeling provides methods for automatically organizing, understanding, searching, and summarizing text data. It can help with the following: discovering the hidden themes in the collection. classifying the documents into the discovered themes.",
      "396": "Project is evaluating the cost-effectiveness of training a multi-lingual BERT \nmodel on IRS corpora and using the model as means to evaluate software \ntranslation output of IRS content. The framework is leveraging COMET, \nROGUE, and BLEU measures. Furthermore, the product will also be \nassessed for English-Only and Spanish-Only content content classification.",
      "47": "Timely processing of these data is critical for adapting mitigation measures as climate \nchange continues to impact Arctic marine mammals.  Infrastructure for Noise and \nSoundscape Tolerant Investigation of Nonspecific Call Types (INSTINCT) is command line \nsoftware which was developed in-house for model training, evaluation, and deployment \nof machine learning models for the purpose of marine mammal detection in passive \nacoustic data. It also includes annotation workflows for labeling and validation. INSTINCT \nhas been successfully deployed in several analyses, and further development of detectors \nwithin INSTINCT is desired for future novel studies and automation. Continued integration \nof AI methods into existing processes of the CAEP acoustics group requires a skilled \noperator familiar with INSTINCT, machine learning, and acoustic repertoire of Alaska \nregion marine mammals.",
      "10": "NLP of research project plans including term analysis and clustering enables national program leaders to work with an interactive dashboard to find synergies and patterns within and across the various ARS research program portfolios.",
      "371": "GEC A&R uses deep contextual AI of text to identify and extract subjective information within the source material. This sentiment model was trained by fine-tuning a multilingual, BERT model leveraging word embeddings across 2.2 million labeled tweets spanning English, Spanish, Arabic, and traditional and simplified Chinese. The tool will assign a sentiment to each text document and output a CSV containing the sentiment and confidence interval for user review.",
      "288": "1) this model predicts daily minimum, mean, and maximum dissolved oxygen (DO) concentrations at several stream locations in the Delaware River Basin. The inputs used are meteorological inputs (e.g., precipitation, cloud cover) and static catchment attributes (e.g., basin area). 2) the training data are DO concentrations collected by the USGS and made available via the National Water Information System (NWIS). 3) this work is being done using Python and R. The deep learning models were written via TensorFlow, the data prepartion is in R, and the modeling workflow was scripted via Snakemake.",
      "251": "This project extends the application of codes developed for wildlife underpass camera trap image classification. Similarly, the system takes walrus haulout camera trap images as inputs and outputs the probability of the image containing walruses and various human disturbances (boats, aircraft, etc.). We will use and further develop the previous system's capability of supporting training experiments. Training, validation, and testing datasets have human-assigned labels and are used to train and evaluate the models. Once trained, the models can be used to predict classes on unlabeled images from ongoing camera monitoring efforts. We use a convolutional neural network (CNN) approach based on TensorFlow and training is run on the USGS Tallgrass supercomputer designed for AI/ML workflows.",
      "370": "Deep learning model that takes in an image containing a person\u2019s face and classifies the image as either being real (contains a real person\u2019s face) or fake (synthetically generated face, a deepfake often created using Generative Adversarial Networks).",
      "149": "Adjusting the ranking of search results so that most relevant results show up at the top of the list",
      "75": "Develop robust automated machine learning detection and classification tools for acoustic \nspecies identification of toothed whale and dolphin echolocation clicks for up to 20 \nspecies found in the Gulf of Mexico. Tool development project funded from June 2018 to May 2021. Tool will be used for automated analyses of long-term recordings from Gulf- wide passive acoustic moored instruments deployed from 2010-2025 to look at  environmental processes driving trends in marine mammal density and distribution.",
      "76": "NOAA Fisheries Alaska Fisheries Science Center's Marine Mammal Laboratory (MML) is \nmandated to monitor the endangered western Steller sea lion population in Alaska. MML \nconducts annual aerial surveys of known Steller sea lion sites across the southern \nAlaska coastline to capture visual imagery. It requires two full-time, independent counters \nto process overlapping imagery manually (to avoid double counting sea lions in multiple \nframes), and count and classify individuals by age and sex class. These counts are vital \nfor population and ecosystem-based modeling to better understand the species and \necosystem, to inform sustainable fishery management decisions, and are eagerly \nanticipated by stakeholders like the NOAA Alaska Regional Office, industry, and \nenvironmental groups. MML worked with Kitware to develop detection and image \nregistration pipelines with VIAME (updates to the DIVE program to support updated \ninterface needs). MML is now working to assess the algorithms efficacy and develop a \nworkflow to augment the traditional counting method (to RL 9).",
      "122": "This research uses state-of-the-art machine learning (ML) techniques in a new and \nnovel manner to identify and correlate the critical microstructural features in a \nmultiphase alloy that exhibits high strength and fracture toughness. Experimental data \nwill be used to train a convolutional neural network (CNN) in a semi-supervised \nenvironment to identify key microstructural features and correlate those features with \nthe strength and toughness. The resulting machine learning tool can be trained for \nadditional microstructural features, different alloys, and/or target mechanical \nproperties.",
      "101": "The project developed a framework and process to translate industrial control system \nfeatures to a machine-readable format for use with automated cyber tools. This \nresearch also examined other current and evolving standards for usability with diverse \ngrid architectures that represent a set of variable conditions to establish the \nfoundation for determining where future research should focus and to support \nimprovements to industry standards and architecture designs for machine-learning \ncyber defense solutions. This project\u2019s success can serve as the foundation for \nprioritizing the next research steps to realize automated threat response, improving \nthe timeliness and fidelity of cyber incident consequence models, and enriching \nnational capabilities to share actionable threat intelligence at machine speed.",
      "394": "The Natural Language Understanding (NLU) model will be located inside \nthe eGain intent engine. This NLU will take customer typed text input aka \n\u2013 Utterances.  It will map the utterance to a specific intent and return the \nappropriate knowledge article.",
      "400": "This use case seeks to identify a workload selection model that uses two \nrecommender system models to measure overall compliance risk and \nidentify anomalous tax returns and line-item values. The delivered pipeline \ncapabilities can supplement the core case selection model processes by \nproviding additional insight to IRS LB&I reviewers through the use of \nadvanced deep learning techniques for anomaly detection.",
      "133": "Explore the use of big data, artificial intelligence (AI), and machine learning technology \nand tools on phasor measurement unit (PMU) data to identify and improve existing \nknowledge, and to discover new insights and tools for better grid operation and \nmanagement.",
      "37": "Predict impacts of DISC maintenance on infrastructure items.  Utilizes: einblick, mysql, python, linux, tableau",
      "205": "Automates data unification and entity resolution with a high level of trust at enterprise scale and speed.\n\nData and Entity Resolution uses Machine Learning modeling to ingest multiple data sources and develop models that associate disparate records to identify probable connections, unique entities, and/or identify commonalities between multiple independently submitted records.\n\nThe automation of entity resolution within the models is supported by a tool that enables non-technical end users to continuously train models through a user-friendly interface. ",
      "302": "We use a machine learning approach to build a ground motion model (GMM) from a synthetic database of ground motions extracted from the Southern California CyberShake study. An artificial neural network is used to find the optimal weights that best fit the target data (without overfitting), with input parameters chosen to match that of state-of-the-art GMMs. We validate our synthetic-based GMM with empirically based GMMs derived from the globally based Next Generation Attenuation West2 data set, finding near-zero median residuals and similar amplitude and trends (with period) of total variability. Additionally, we find that the artificial neural network GMM has similar bias and variability to empirical GMMs from records of the recent Mw7.1 Ridgecrest event, which neither GMM has included in its formulation. As simulations continue to better model broadband ground motions, machine learning provides a way to utilize the vast amount of synthetically generated data and guide future parameterization of GMMs. ",
      "48": "VIAME - This project focuses on optical survey collected in the Gulf of Mexico: 1) develop \nan image library of landed catch, 2) develop of automated image processing (ML/DL) to \nidentify and enumerate species from underwater imagery and 3) develop automated \nalgorithms to process imagery in near real time and download information to central \ndatabase.",
      "2": "Locate, count, and categorize citrus trees in an orchard to monitor orchard health",
      "115": "Computer vision, a broad set of techniques for training statistical models and neural \nnetworks to process images, has advanced substantially in recent years. Applying \nthese capabilities to satellite imagery can improve critical infrastructure analysis and \ninterdependency data build-outs. Combining advanced computer vision techniques, a \nfunctional taxonomic approach to critical infrastructure, and the unique geo-spatial and \ndependency datasets the research team developed can produce innovative and state-\nof-the-art image processing results that advance abilities to secure and defend \nnational critical infrastructure.",
      "152": "Show related searches that may provide the user with other related, valuable information",
      "359": "GPA\u2019s production system for testing potential messages at scale across segmented foreign sub-audiences to determine effective outreach to target audiences.",
      "319": "Meeting NARA metadata standards for (permanent) federal documents by using AI to identify data within the document, and also using NLP to classify and summarize documents.",
      "190": "RCDC is an electronic budget reporting tool that categorizes projects using AI/NLP. The inputs are grant applications,\nR&D contracts, intramural projects, inter agency agreements. The RCDC Fingerprinting process identifies concepts in the\nextracted text from the source project, person or publication. The text is normalized, concepts are extracted, concepts\nand synonyms are matched to the RCDC thesaurus. A rank is applied based on the frequency of occurrence of the\nconcepts within the text. Project fingerprints are sourced from the application description text (Title, Abstract and\nSpecific Aims). Titles and abstracts provide the source of scientific concepts for publications. The system then outputs the\nprojects into their respective areas of science.",
      "301": "We use initial observations of an earthquake on seismic stations close to an earthquake to predict what the peak ground shaking will be across a region. The initial test dataset are waveforms from the USGS-collected, large-n seismic array in an area of induced seismicity in Oklahoma. Future datasets will include seismic data from the California Seismic Integrated Network (primarily supported by USGS) and possible the Japanese Meterological Agency. Currently running Python-based codes on a desktop, plan to move to AWS or similar. ",
      "57": "Developing fast and accurate NN LW- and SW radiations for GFS and GEFS.  NN LW- and \nSW radiations have been successfully developed for previous version of GFS, see: doi: \n10.1175/2009MWR3149.1 and the stability and robustness of the approach used was \ndemonstrated, see:  https://arxiv.org/ftp/arxiv/papers/2103/2103.07024.pdf  NN LW- and \nSW radiations will be developed for the current versions of for GFS and GEFS.",
      "217": "The Cyber Sentry program provides monitoring of critical infrastructure networks. Within the program, threat hunting analysts require advanced anomaly detection and machine learning capabilities to examine multimodal cyber-physical data on IT and OT networks, including ICS/SCADA. The Critical Infrastructure Anomaly Alerting model provides AI-assistance in processing this information.",
      "242": "Reclamation, along with partners from the CEATI hydropower industry group (e.g. TVA, DOE-PNNL, and others) ran a year-long  evaluation of existing 10-day streamflow foreasting technologies and a companion prize competition open to the public, also focused on 10-day streamflow forecasts. Forecasts were issued every day for a year and verified agains observed flows. Across locations and metrics, the top perfoming foreacst product was a private, AI/ML forecasting company - UpstreamTech. Several competitors from the prize competition also performed strongly; outperforming benchmark forecasts from NOAA. Reclamation is working to further evaluate the UpstreamTech forecast products and also the top performers from the prize competition.  ",
      "25": "We employ a random forest machine learning classifier to produce high resolution land cover maps from aerial and/or satellite imagery.  Training data is generate from a custom-built web application.  We built and operate a 192-node docker cluster to parallize CPU-intensive processing tasks.  We are publishing results through a publicly available  Image service.  To date we have mapped over 600 million acres and have generated over 700 thousand traiing samples.",
      "53": "Drought outlooks by using ML techniques with NCEP models. Simple NN and Deep \nLearning techniques used for GEFSv12 to predict Week 1-5 Prcp & T2m over CONUS",
      "245": "This project is exploring a specific application of photogrammetric products to process analysis of crack mapping on Reclamation facilites.  This analysis is time consuming and has typically required rope access or other means to photograph and locate areas that can now be reached with drones or other devices.  By formulating a standard reference protocol and applying machine learning/AI, this information will be used to provide detailed analysis of Reclamation assets for better decision making. ",
      "110": "This project will develop machine learning enabled integrated resource planning \nmethodologies to help quantify key resilience elements across integrated energy \nsystems and their vulnerabilities to threats and hazards. This includes the ability to \naccurately analyze and visualize a region\u2019s critical infrastructure systems ability to \nsustain impacts, maintain critical functionality, recover from disruptive events. This \nadvanced decision support capability can improve our understanding of these complex \nrelationships and help predict the potential impacts that microreactors and distributed \nenergy resources have on the reliability and resiliency of our energy systems.",
      "412": "AI technology was used to predict bed occupancy at hospitals with MoH data from 2019, with an overall median error by department around 20%. This was a proof-of-concept model developed at the request of the Institute of Public Health (IPH) Batut to understand how AI can work and the value add. CHISU was asked to subsequently focus on a different use case (waiting list optimization for scheduled imaging diagnostics services, specifically CT and MRI), which is considered higher priority to demonstrate the implementation of the national AI strategy and the effect of AI in data use for decision making by the government, and will be addressed in the 2023-4.",
      "435": "Machine learning prediction models evaluate the interactions of known and novel risk factors for opioid use disorder (OUD) and overdose in Post-9/11 Veterans. Several machine learning classification-tree modeling approaches are used to develop predictor profiles of OUD and overdose.\u00a0",
      "177": "The dashboard creates risk profiles, called PVI scorecards, for every county in the United States, continuously updated\nwith the latest data that summarize and visualize overall disease risk.",
      "453": "This pilot project uses TIU documentation on African American Veterans aged 45-50 to extract family medical history data and identify Veterans who are are at risk of prostate cancer but have not undergone prostate cancer screening.",
      "325": "BLS receives bulk data from some corporations related to the cost of goods they sell and services they provide. Consumer Price Index (CPI) staff have hand-coded a segment of the items in these data into Entry Level Item (ELI) codes. To accept and make use of these bulk data transfers at scale, BLS has begun to use machine learning to label data with ELI codes. The machine learning model takes as input word frequency counts from item descriptions. Logistic regression is then used to estimate the probability of each item being classified in each ELI category based on the word frequency categorizations. The highest probability category is selected for inclusion in the data. Any selected classifications that do not meet a certain probability threshold are flagged for human review.",
      "88": "FSA\u2019s virtual assistant uses natural language processing to answer common financial aid questions and help customers get information about their federal aid on StudentAid.gov. In just over two years, Aidan has interacted with over 2.6 million unique customers, resulting in more than 11 million user messages.\u00a0",
      "218": "Cyber incident handling specialists utilize advanced automation tools to process data received through various threat intelligence and cyber incident channels. These tools leverage Machine Learning and Natural Language Processing to increase the accuracy and relevance of data that is filtered and presented to human analysts and decision-makers. Machine Learning techniques also assist to aggregate the information in reports for presentation and further analysis. This includes data received through covered CIRCIA entities.",
      "8": "AI-type statistical techniques are used to model predictive relationships between variables. We routinely use modeling approaches such as random forest, artificial neural networks, k-nearest neighbor clustering, and support vector machines, for statistical prediction. ",
      "128": "Explore the use of big data, artificial intelligence (AI), and machine learning technology \nand tools on phasor measurement unit (PMU) data to identify and improve existing \nknowledge, and to discover new insights and tools for better grid operation and \nmanagement.",
      "286": "This process-guided deep learning model predicts depth-specific lake temperatures while obeying physical laws using inputs of meteorological drivers. Training consists of two stages. In the first stage, the model is pre-trained using process-based modeling outputs. Then, lake temperature observations are used to finetune the model in a second training stage. The models are trained to simultaneously fit observations and honor conservation of energy. The models were developed using various R and Python packages on the USGS Tallgrass supercomputer. The General Lake Model (GLM version 2) software was used for process-based modeling.",
      "185": "A search that is targeted at finding a specific document in databases is called a Single Citation search, which is particularly\nimportant for scholarly databases, such as PubMed, because it is a typical information need of the users. We have\ndeveloped SingleCite, an automated algorithm that establishes a query-document mapping by building a regression\nfunction to predict the probability of a retrieved document being the target based on three variables: the score of the\nhighest scoring retrieved document, the difference in score between the two top retrieved documents, and the fraction\nof a query matched by the candidate citation. SingleCite shows superior performance in benchmarking experiments and\nis applied to rescue queries that would fail otherwise.",
      "141": "Takes monthly historical data for underlying components used to calculate KPIs and creates near-term forecasts for the upcoming fiscal year. Pilot effort focuses on total agency/category spend (the denominator in multiple KPIs). If the pilot program is successful, the same methodology can be extended to other KPIs.",
      "271": "Without knowing how tile-drain extent (sub-surface agricultural drainage) has changed with time, it is difficult to differentiate how streamflow and water quality have changed as a result of spatial extent and characteristics of tile-drain networks.  Our method delineates tile drains in satellite imagery, providing a way to look at historical imagery and to use satellite data to maintain an up-to-date geospatial layer of tile drain extent in basins of interest.  We use panchromatic imagery that is processed using a UNet model that was trained on a library of panchromatic images on which visible tile-drain networks had been traced.  Our workflow uses a combination of python scripting that is encapsulated in a Jupyter notebook; the entire process is open source.  ",
      "351": "The Conflict Observatory program uses AI and machine learning on moderate and high-resolution commerical satellite imagery to document a variety of war crimes and other abuses in Ukraine, including automated damage assessments of a variety of buildings, including critical infrastructure, hospitals, schools, crop storage facilities.",
      "112": "This project addressed limitations in current probabilistic risk assessment (PRA) by \ncombining a support vector machine and PRA software to auto-detect system design \nvulnerabilities and find previously unseen issues, reduce human error, and reduce \nhuman costs. This method does not require training data that would only be available \nin the event of system or subsystem failures.",
      "236": "The vision of Person-Centric Identity Services (PCIS) is to be the authoritative source of trusted biographical and biometric information that provides real-time, two-way visibility between services into an individual's comprehensive immigration history and status. The de-duplication model, ingests person-centric datasets from various source systems for model training and evaluation purposes. Our dataset includes biographic information (name, date of birth, Alien #, Social Security #, passport #, etc.) as well as biographic information (fingerprint IDs, eye color, hair color, height, weight, etc.) for model training and matching purposes. \n\nCritical to the success of PCIS is the entity resolution/deduplication of individual records from various systems of records to create a complete picture of a person. Using machine learning, it is able to identify which case management records belong to the same unique individual with a high degree of confidence. This allows PCIS to pull together a full immigration history for an individual without time-consuming research across multiple disparate systems.\n\nThe Deduplication model plays a critical role in the entity resolution and surfacing of a person and all their associated records. The ML models are more resilient to fuzzy matches, and deals with the reality of different data fill rates more reliably.",
      "404": "To detect narratives and trends in social media alterations of images and video in order to find and counteract malign narratives",
      "92": "The goal this research is to develop and validate novel and scalable models to \nachieve faster-than-real-time prediction and decision-making capabilities. To achieve \nthe project goal of autonomous operation of microreactors, a novel hybrid modeling \napproach combining both physics-based and artificial intelligence techniques will be \ndeveloped at the component or sub-system level, integrated with anticipatory control \ntechniques, and scaled. A novel distributed anticipatory control strategy will be \ndeveloped as part of the scalability analysis to understand the risk of cascading \nfailures when emerging reactors are deployed as part of a full feeder microgrid.",
      "111": "This project focuses on the reduction of manual labor and operational cost required \nfor training an electromagnetic (EM)-based anomaly detection system for legacy \nindustrial control systems devices and Industrial Internet of Things. This research \nwould enable EM-based intrusion detection systems to be deployed to protect legacy \ncontrol systems.",
      "54": "Operational tool that uses boosted regression trees to model the distribution of swordfish \nand bycatch species in the California Current",
      "167": "Inputs - Medicare Claims data, TPE Data, Jurisdiction information\nOutput - forecast the time needed to work on an alert produced by FPS (Random Forest, Decision Tree, Gradient Boost,\nGeneralized Linear Regression)",
      "66": "This is a maintenance and sustainment project for the operational GOES-R fog/low stratus \n(FLS) products. The FLS products are derived from the combination of GOES-R satellite \nimagery and NWP data using machine learning. The FLS products, which are available in \nAWIPS, are routinely used by the NWS Aviation Weather Center and Weather Forecast \nOffices.",
      "124": "AI within GRIP is used to develop metrics that quantify the impact of the anticipated \nweather related extreme events. The platform uses utility data combined with physical \nmodels, distribution power solver  to infer the potential  grid impacts given a major \nstorm.",
      "178": "NIGMS program staff often need information that is available through IMPAC or QVR to perform their daily tasks. In order\nto provide such information, DIMA and IRMB have collaborated to develop functions that utilize artificial intelligence and\nnatural language processing methods to produce data relevant to the program staff\u2019s mission. These tools are collected\ninto a single system to make them available to the NIGMS community for use on a day-to-day basis. ASSIST provides a\nsecure interface supported by Oracle, SQL server and Python analytics. The individual components of ASSIST provide the\nfollowing functions:\n- FLIP module (Development), provides the ability to identify investigators by PPID from Federal RePORTER based on user\ninput of investigator PPIDs.\n- TPAL module (Production), provides the ability to lookup potential matching program officers, including their\ncorresponding predicted Program Area Codes, and ICs based on the input of unstructured scientific data.",
      "160": "CMS/OSFLO: To assist the Security team, this Chatbot (text) provides an automated email response for general physical\nsecurity questions, allowing the help desk team to assist employees and contractors with more in depth issues.",
      "426": "The Digital Command Center seeks to consolidate all data in a medical center and apply predictive prescriptive analytics to allow leaders to better optimize hospital performance.\u00a0\u00a0",
      "452": "The Medtronic GI Genius aids in detection of colon polyps through artificial intelligence.",
      "378": "Successfully demonstrated use of an AI capability to analyze camera images of a wind sock to produce highly accurate surface wind speed and direction information in remote areas that don\u2019t have a weather observing sensor.",
      "129": "Explore the use of big data, artificial intelligence (AI), and machine learning technology \nand tools on phasor measurement unit (PMU) data to identify and improve existing \nknowledge, and to discover new insights and tools for better grid operation and \nmanagement.",
      "318": "AI detection of mismatched addresses and garbled text in official letters sent to benefits recipients.",
      "100": "The Resilient Attack Interceptor for Intelligent Devices approach focuses on \ndeveloping external monitoring methods to protect industrial internet of things devices \nby correlating observable physical aspects that are produced naturally and \ninvoluntarily during the operational lifecycle with anomalous functionality.",
      "416": "This application uses machine learning with Earth observations and weather-modeled data to forecast daily algal blooms in Lake Atitl\u00e1n, Guatemala. The forecasting system is being used by Lake Authorities, such as the  Authority for Sustainable Management of the Lake Atitlan Basin and its surroundings (AMSCLAE),  to inform their Harmful Algal Blooms Alert System. This work is also supported by National Geographic and Microsoft through their Artificial Intelligence (AI) for Innovation grants. ",
      "457": "AI is used with clinical notes to identify social determinants of health (SDOH) information. The extracted SDOH variables can be used during associated health related analysis to determine, among other factors, whether SDOH can be a contributor to disease risks or healthcare inequality.",
      "295": "While machine learning techniques have been increasingly applied to land cover classification problems, these techniques have not focused on separating exposed bare rock from soil covered areas. Therefore, we are using a neural network to differentiate exposed bare rock (rock) from soil cover (other). We started with a training dataset by mapping exposed rock at 20 test sites across the Sierra Nevada Mountains (California, USA) using USDA\u2019s 0.6 m National Aerial Inventory Program (NAIP) orthoimagery. These initial sites were used to train and test the original CNN and now NASA's DELTA toolkit, which is being run on the USGS high-performance computing facilities. The goal is to generate a machine learning approach to classify bare rock in NAIP orthoimagery, starting with the Sierras, in order to provide a more accurate map of soil vs. rock-covered areas for use in landslide hazard mapping, quantifying soil carbon storage, calculating water fluxes, etc.",
      "215": "AIS Automated Scoring & Feedback (AS&F) is uses descriptive analytics from organizational-centric intelligence to support confidence and opinion/reputation classification of indicators of compromise (IOCs). Looking at an indicator AS&F determines if the indicator is present in known-good list by cross-referencing organizational-centric intelligence data of known non-malicious/benign indicators and classifies accordingly if true. If not a known-good, determine if there are sightings of the indicator by cross-referencing organizational-centric intelligence and classify accordingly if true. If there are no sightings for the indicator, determine if this indicator has been verified by an analyst within our organizational-centric intelligence and classify accordingly if true. Lastly if the indicator has not been verified by an analyst, AS&F determines whether there are other reports within our organizational-centric intelligence about this indicator and classifies accordingly. AIS participants can triage against the populated opinion and/or confidence values to identify Indicator objects meeting or exceeding designated criteria and filter out the remaining data. AIS participants may also find value in utilizing the confidence score (if present) and the opinion value to understand whether any difference between the publisher and other organizations exists. Together, these enrichments can help those receiving information from AIS prioritize actioning and investigating Indicator objects.",
      "134": "Prioritizing the potential risk posed to human health by chemicals requires tools that can estimate exposure from limited information. In this study, chemical structure and physicochemical properties were used to predict the probability that a chemical might be associated with any of four exposure pathways leading from sources-consumer (near-field), dietary, far-field industrial, and far-field pesticide-to the general population. The balanced accuracies of these source-based exposure pathway models range from 73 to 81%, with the error rate for identifying positive chemicals ranging from 17 to 36%. We then used exposure pathways to organize predictions from 13 different exposure models as well as other predictors of human intake rates. We created a consensus, meta-model using the Systematic Empirical Evaluation of Models framework in which the predictors of exposure were combined by pathway and weighted according to predictive ability for chemical intake rates inferred from human biomonitoring data for 114 chemicals. The consensus model yields an R2 of\u00a0\u223c0.8. We extrapolate to predict relevant pathway(s), median intake rate, and credible interval for 479 926 chemicals, mostly with minimal exposure information. This approach identifies 1880 chemicals for which the median population intake rates may exceed 0.1 mg/kg bodyweight/day, while there is 95% confidence that the median intake rate is below 1 \u03bcg/kg BW/day for 474572 compounds.\nhttps://pubmed.ncbi.nlm.nih.gov/30516957/",
      "19": "The CLT knowledge database catalogs cross-laminated timber information in an interface that helps users find relevant information. The information system uses data aggregator bots that search the internet for relevant information. These bots search for hundreds of keywords and use machine learning to determine if what is found is relevant. The search engine uses intelligent software to locate and update pertinent CLT references, as well as categorize information with respect to common application and interest areas. As of 2/24/2022, the CLT knowledge database has cataloged >3,600 publications on various aspects of CLT. This system fosters growth of mass timber markets by disseminating knowledge and facilitating collaboration among stakeholders, and by reducing the risk of duplication of efforts. Manufacturers, researchers, design professionals, code officials, government agencies, and other stakeholders directly benefit from the tool, thereby supporting the increasing use of mass timber, which benefits forest health by increasing the economic value of forests.",
      "344": "A/LM plans to expand current risk analytics through development of AI/ML models for detecting anomalous activity within the Integrated Logistics Management System (ILMS) that could be potential fraud or malfeasance. The models will expand upon existing risk models and focus on key supply chain functions such as: Asset Management, Procure-to-Pay, and Fleet Management.",
      "399": "Trained text extraction and tax domain-specific BERT models (called \nTaxBERT) using about 190,000 documents including Internal Revenue \nCode, Internal Revenue Manual, and PDFs from irs.gov, Revenue Rulings, \nPrivate Letter Rulings, Revenue Procedures, Treasury Decisions, and other \nlegal tax-related documents. The extracted text was decomposed into 21 \nmillion sentences with 1 million unique tokens. Further filtering \nrefinement resulted in 11 million unique sentences and 31 thousand unique vocabulary tokens which are then used to train domain-specific  NLP models which can be used for targeted analytics.",
      "254": "This system, once developed, will input drone imagery and output bounding boxes for individual walruses. If successful, this will allow researchers with Alaska Science Center to count the numbers of walruses in drone imagery to support population reseaarch. The system will use TensorFlow-based convolutional neural networks for object detection trained on the USGS Tallgrass supercomputer.",
      "294": "The research is investigating the use of hand annotated hydrography from one region to train an artificial neural net (ANN) to identify where surface water is likely to be in other areas. The input training data includes lidar, radar, and other remotely sensed data along with modeled surface flow to inform the model. The work is using open-source tools in a high-performance computing environment. ",
      "342": "A/LM developed a machine learning model to scan unstructured, user entered procurement data such as Requisition Title and Line Descriptions to automatically detect the commodity and services types being purchased for enhanced procurement categorization.",
      "339": "The Quick Disability Determinations (QDD) process uses a computer-based predictive model to screen initial applications to identify cases where a favorable disability determination is highly likely and medical evidence is readily available. The Agency bases the QDD model\ufffds predictive scores on historical data from application forms completed by millions of applicants. By identifying QDD cases early in the process, the Social Security Administration can prioritize this workload and expedite case processing.  The Agency routinely refines the QDD model to reflect the characteristics of the recent applicant population and optimize its ability to identify strong candidates for expedited processing. ",
      "385": "Description: DeepCNet-based neural network to identify and classify track-related  features (e.g., track components, such as fasteners and ties) for \"change detection\" applications.\nInput: Line-scan images from rail-bound inspection systems\nOutput: Notification of changes from status quo or between different inspections based on geolocation.",
      "189": "The REFERRAL GROUP of Referral, Program Analysis Branch (RPAB) is responsible for program assignments for all\nresearch, training, career, and fellowship grant applications submitted to NIAID, from CSR. The NIAID Program Class Code\nclassification AI project evaluates the projects that are in RAPB and auto assigns these grant applications to the Program\nClass Codes. The inputs are comprised of approximately 6,000+ grant applications that are currently manually assigned\nby RPAB Staff. The output would be grant applications that are categorized into their respective PCC's.",
      "9": "The model reviews the descriptions of expenses tagged to repairs and maintenance and classifies expenses as \"repair\" or \"not repair\" based on keywords in context.",
      "39": "The system's algorithms and AI technology qualifies data and makes B2B matches with \nevent participants according to their specific needs and available opportunities.  The \nsystems inputs are data related to event participants and the outputs are suggested B2B \nmatches between participants and a match strength scorecard.",
      "155": "An interactive interface that can respond to plain language queries in real time using natural language processing",
      "243": "Reclamation was interested in determining if recent advancements in machine learning, specifically convolutional neural network architecture in deep learning, can provide improved seasonal/temporary wetland/floodplain delineation (mapping) when high temporal and spatial resolution remote sensing data is available? If so, then these new mappings could inform the management of protected species and provide critical information to decision-makers during scenario analysis for operations and planning.",
      "224": "Text Analytics for Survey Responses (TASR) is an application for performing Natural Language Processing (NLP) and text analytics on survey responses. It is currently being applied by DHS OCHCO to analyze and extract significant topics/themes from unstructured text responses to open-ended questions in the quarterly DHS Pulse Surveys. Results of extracted topics/themes are provided to DHS Leadership to better inform agency-wide efforts to meet employees\u2019 basic needs and improve job satisfaction",
      "31": "Analysis of over 20 million records of soils data and 20,000 text documents of ecological state and transition information. ",
      "433": "Machine learning is used to identify predictors of veterans' suicidal ideation. The relevant data come from a web-based survey of veterans\u2019 experiences within three months of separation and every six months after for the first three years after leaving military service.",
      "415": "GEOGloWS ECMWF Streamflow Service (GESS) helps to organize the international community engaged in the hydrologic sciences, observations, and their application to forecasting and provides a forum for government-to-government collaboration, and engagement with the academic and private sectors to achieve the delivery of actionable water information. Since the formal creation of the initiative in 2017, the most significant element of GEOGloWS has been the application of Earth Observations (EO) to create a system that forecasts flow on every river of the world while also providing a 40-year simulated historical flow.\n\nThis application uses Long Short Term Memory (LSTM) Model with the time series of discharge data to bias correct the globally available GESS discharge information locally.",
      "168": "Inputs - Medicare Claims data, TPE Data, Jurisdiction information\nOutput - reviews claims for provider before and after education for statistical change in their claim submission patterns",
      "309": "Custom machine learning model to extract data from complex forms to tag data entries to field headers. The input is a document or scanned image of the form and the output is a JSON response with key/value pairs extracted by running the form against the custom trained model.",
      "153": "Suggesting content tags automatically based on a machine-driven evaluation of how existing content is tagged",
      "107": "The team hypothesizes that artificial intelligence can predict events using the \nintegrated data from test bed sensors and physics-based models. A second \nhypothesis is that integrating software and artificial intelligence with sensor data from \na test bed will lead to a framework for future digital twins. The team will train artificial \nintelligence models to determine what attributes are most important for enabling \nintelligent autonomous control and will determine best practices for digital twin \ncybersecurity.",
      "80": "Using CNN to pick out objects of a particular size from sides scan imagery.  Presents users \nwith a probability that allows for automation of contact picking in the field.  Side scan \nimagery is simple one channel intensity image which lends itself well to basic CNN \ntechniques.",
      "275": "NLCD uses AI/ML to develop Landcover across all 50 states. The system includes HPC processes, cloud services, and local resources to create thematic and continuous field classifications. These classifications serve as the base for users and federal agencies across the nation to provide wildlife habitat estimates, urban runoff estimates, population growth, etc. etc.",
      "43": "The Market Diversification Tool identifies potential new export markets using current \ntrade patterns. A user enters what products they make and the markets they currently \nexport to.  The Market Diversification Tool applies a ML algorithm to identify and compare \nmarkets that should be considered.  The tool brings together product-specific trade and \ntariff data and economy-level macroeconomic and governance data to provide a picture \nof which markets make sense for further market research. Users can limit the markets in \nthe results to only the ones they want to consider and modify how each of the eleven \nindicators in the tool contributes to a country\u2019s overall score. Users can export all the data \nto a spreadsheet for further analysis.",
      "293": "This work focuses on developing expertise and resources for Explainable AI (XAI) within WMA PUMP Projects.  The inputs are various models developed for predicting stream temperature, discharge, dissolved oxygen, and other characteristics.  The outputs are interpretable metrics to help understand why models are making the predictions they are and what physical processes are getting captured with the model architectures.",
      "406": "Objective 1 under the Illuminating New Solutions and Programmatic Innovations for Resilient Spaces\u2019 (INSPIRES). Includes program activities\nand website - https://web.sas.upenn.edu/mlp-devlab/",
      "116": "Physics-based multi-scale modeling was coupled with deep, recursive, and transfer \nlearning approaches to accelerate nuclear materials research and qualification of high-\nentropy alloys. Applying AI to combinatorial-based materials research enables \nsubsequent analysis to focus on a limited number of candidates predicted to have the \nnecessary materials properties for the application.",
      "137": "The SRT intakes SAM.gov data for all Information and Communications Technology (ICT) solicitations. The system then compiles the data into a database to be used by machine learning algorithms. The first of these is a Natural Language Processing model that determines if a solicitation contains compliance language. If a solicitation does not have compliance language, then it is marked as non-compliant. Each agency is asked to review their data and validate the SRT predictions. GSA also conducts random manual reviews monthly.",
      "248": "Level 1 surveys obtained from BSEE report the condition of well platforms. The reports include images of well platform components, which can be used to estimate coating condition and structural condition, important factors in the overall condition of the facility. The reports are used to assess the well platforms for safety concerns. The reports are submitted to BSEE and are manually reviewed to determine whether a well platform needs additional audits. Because the manual review process is time-consuming, an automated screening system that can identify parts of the wells that exhibit excess corrosion may greatly reduce report processing time.",
      "154": "Suggesting spelling corrections and reformatted search queries based on Google Analytics data",
      "109": "The goal of this project is to develop an analysis framework enabled by dynamic \nsandboxes that allows for automated analysis, provides non-existing core capabilities \nto analyze industrial control system malware, and outputs to a format that is machine \nreadable and an industry standard in sharing threat information. This will enable further \nanalysis efforts via machine learning and provide a foundational platform that would \nallow for timely, automated analysis of malware samples.",
      "321": "Automatic processing of continuation of benefits form to extract pre-defined selection boxes.",
      "95": "This project will address the efficient use of limited experimental data available for \nnuclear digital twin (NDT) training and demonstration. This involves developing sparse \ndata reconstruction methods and using NDT models to define sensor requirements \n(location, number, accuracy) for the design of demonstration experiments. NDTs \nshould leverage 1) sparse sensing for identifying optimal locations and the minimal set \nof required sensors and 2) sparse learning and recovery of full maps of responses of \ninterest for stronger prediction, diagnostics, and prognostics capabilities.",
      "382": "AVS identified a need to derive the joint aircraft system codes (JASC) chapter codes from the narrative description within service difficulty reports (SDR), a form of safety event reporting from aircraft operators. A team of graduate students at George Mason University collaborated with AVS employees to apply Natural Language Processing (NLP) and Machine Learning to predict JASC codes. This method can be used to check SDR entries to ensure the correct codes were provided or to assign a code when one was not.",
      "425": "CuraPatient is a remote tool that allows patients to better manage their conditions without having to see a provider.\u00a0 Driven by artificial intelligence, it allows patients to create a profile to track their health, enroll in programs, manage insurance, and schedule appointments.",
      "184": "PubMed is a free search engine for biomedical literature accessed by millions of users from around the world each day.\nWith the rapid growth of biomedical literature, finding and retrieving the most relevant papers for a given query is\nincreasingly challenging. We have developed Best Match, a new relevance search algorithm for PubMed that leverages\nthe intelligence of our users and cutting-edge machine-learning technology as an alternative to the traditional date sort\norder. The Best Match algorithm is trained with past user searches with dozens of relevance-ranking signals (factors) and\ndemonstrates state-of-the-art retrieval performance in benchmarking experiments as well as an improved user\nexperience in real-world testing.",
      "429": "Behavidence is a mental health tracking app. Veterans download the app onto their phone and it compares their phone usage to that of a digital phenotype that represents people with confirmed diagnosis of mental health conditions.\u00a0",
      "173": "The first use case being developed is for primary care with behavioral health integration which uses a machine learning\nbased automated clustering engine. The development of this tool allows for BHW to dynamically assess the healthcare\nneed of a population given a specific use case and relevant datasets. The output of the model will be used as part of the\nNotice of Funding Opportunity (NOFO) grant proposal evaluation process.",
      "222": "Duty officers and analysts in CISA's Operations Center use a dashboard powered by artificial intelligence to enable sensemaking of ongoing operational activities. Artificial intelligence uses new near-real-time event data (from open source reporting, partner reporting, CISA regional staff, and cybersecurity sensors) coupled with historical cybersecurity and infrastructure security information and previous operational response activity to recommend courses-of-action and engagement strategies with other government entities and critical infrastructure owners and operators based on potential impacts to the National Critical Functions.",
      "253": "This system will to take pairs of mountain lion (*Puma concolor*) facial images and output the probability that the images come from the same individual mountain lion. This will allow researches to passively \"mark\" individuals and support population estimation analyses. We will use a \"Siamese\" convolutional neural network architecture that has been used in other facial recognition and motion tracking applications.",
      "188": "Chemical indexing is part of the NLM\u2019s MEDLINE citation indexing efforts for improving literature retrieval and\ninformation access. Currently, chemcial indexing is performed manually by expert indexers. To assist this time-consuming\nand resource-intensive process, we have developed NLM-Chem, an automatic tool for finding chemical names in the\nbiomedical literature using advanced natural language processing and deep learning methods. Its performance has been\nassessed on gold-standard evaluation datasets and is to be integrated into the production MEDLINE indexing pipeline.\u00a0\u00a0",
      "77": "Detection and identification of branded steller sea lions from remote camera images in \nthe western Aleutian Islands, AK. The goal is to help streamline photo processing to \nreduce the effort required to review images.",
      "268": "Our product is an end-to-end system that is used to predict and detect sensor (sonde) fouling at USGS stream gages. The system is trained using supervised learning on multiple features derived from archived stream gage data labelled by expert field technicians. The system operated in real-time on Amazon Web Services (AWS), providing predictions every 30 minutes based off of raw data collected from the USGS AQUARIUS database. The system produces values detecting the likelihood that fouling is currently present and likelihood of fouling predicted to occur in the next 24 hours. These values are displayed on a Tableau dashboard that is connected to AWS using Amazon Athena. This dashboard also displays other stream gage network monitoring information from AQUARIUS, like time since a sonde was last visited by a technician.",
      "278": "The Fish and Climate Change Database (FiCli) is a comprehensive database of peer-reviewed literature compiled through an extensive, systematic primary literature review to identify English-language, peer-reviewed journal publications with projected and documented examples of climate change impacts on inland fishes globally. We are currently exploring options to automate certain portions of the review process to increase our efficiency in maintaining and updating the database.",
      "241": "Reclamation has run 2, year-long prize competitions where particants developed and deployed data driven methods for sub-seasonal (2-6 weeks into future) prediction of temperature and precipitation across the western US. Particpants outperformed benchmark forecasts from NOAA. Reclamation is currently working with Scripps Institute of Oceanography to further refine, evaluate, and pilot implement the most promising methods from these two copmetitions. Improving sub-seasonal forecasts has significant potential to enhance water management outcomes.  ",
      "46": "Passive acoustic data is analyzed for detection of beluga whales and classification of the \ndifferent signals emitted by these species. Detection and classification are done with an \nensemble of 4 CNN models and weighted scoring developed in collaboration with \nMicrosoft. Results are being used to inform seasonal distribution, habitat use, and impact \nfrom anthropogenic disturbance within Cook Inlet beluga critical habitat. The project is \naimed to expand to other cetacean species as well as anthropogenic noise.",
      "336": "IMAGEN is an IT Modernization Disability Analytics & Disability Decision Support (ADDS) Product that will provide new tools and services to visualize, search and more easily identify relevant clinical content in medical records.  These tools and services will improve the efficiency and consistency of disability determinations and decisions and provide a foundation for machine-based decisional guidance. IMAGEN will transform text to data and enable disability adjudicators to leverage various machine learning technologies like Natural Language Processing (NLP) and predictive analytics and will support other high-priority agency initiatives such as fraud prevention and detection.",
      "201": "The software analyzes photographs that are taken by field imaging equipment, which are then fed into the ICAD system for review by USBP agents and personnel. The Matroid software currently processes and annotates images using proprietary software to determine if any of the images contain human subjects.\n\nMatroid is the name of the Video Computer Aided Detection system used by CBP. It uses trained computer vision models that recognize objects, people, and events in any image or video stream. Once a detector is trained, it can monitor streaming video in real time, or efficiently search through pre-recorded video data or images to identify objects, people, and events of interest. \n\nThe intent for the ICAD system is to expand the models used to vehicles, and subjects with long-arm rifles, while excluding items of little or no interest such as animals.",
      "79": "Postprocessing that uses k-means clustering to identify spatially and temporally consistent \nwave systems from the output of NWPS v1.3. Has been successfully evaluated in the field \nby NWS marine forecasters nationwide and has been implemented into operations on \nFebruary 3, 2021.",
      "386": "Description: Deep learning computer vision algorithms aimed at analyzing aggregate particle size grading.\nInput: Images of ballast cross sections\nOutput: Ballast fouling index",
      "162": "Predictive Intelligence (PI) is used for incident assignment within the Quality Service Center (QSC). The solution runs on\nQuality Service Center (QSC).\nincidents created from the ServiceNow Service Portal (https://cmsqualitysupport.servicenowservices.com/sp_ess). The\nsolution analyzes the short description provided by the end user in order to find key words with previously submitted\nincidents and assigns the ticket to the appropriate assignment group. This solution is re-trained with the incident data in\nour production instance every 3-6 months based on need.",
      "299": "The USGS National Earthquake Information Center monitors global earthquakes 24/7, rapidly detecting, characterizing, and publically desimating earthquake information. In order to improve the perfomance of their event characterization system, the NEIC has trained AI models to characterize earthquake source information using small portions of waveform data. These models improve autotmatic phase picking, classify phase types, and estimate source-station distances. The outcome of these models is improved automatic earthquake detections. The training dataset used in these models leverages the long standing reveiwed earthquake catalog produced by the NEIC combined with archived continous waveform recordings, many of which are USGS opperated stations. These tools have been developed primarily leveraging Python, Keras, and Tensorflow. ",
      "161": "The Feedback Analysis Solution is a system that uses CMS or other publicly available data (such as Regulations.Gov) to\nreview public comments and/or analyze other information from internal and external stakeholders. The FAS uses Natural\nLanguage Processing (NLP) tools to aggregate, sort and identify duplicates to create efficiencies in the comment review\nprocess. FAS also uses machine learning (ML) tools to identify topics, themes and sentiment outputs for the targeted\nDataset.",
      "23": "Several courses are offered which teach the use of software and scripting which allow for machine learning.  The courses change, but current topics include Intro and Advanced Change Detection, eCognition (software package), Geospatial Scripting for Google Earth Engine.  Some of the courses show how to use Collect Earth Online.",
      "300": "We develop ground-motion models for peak ground acceleration and peak ground velocity using a gradient boosting method (GBM). In total 128 GBM-based ground-motion models are developed for estimating PGA and PGV, respectively, using varying subsets of explanatory variables. We select eight GBM-based ground-motion models that have the lowest root mean squared error (rmse) for the cross-validation datasets among models with the same number of explanatory variables. The secondary variables, in order of importance, that contribute to the model accuracy are: VS30, Ztor, Ry, Rx, Rake, Zhyp, and Dip. By considering the tradeoff between the model accuracy and model complexity (number of explanatory variables), we find an optimal model to predict PGA and PGV uses four explanatory variables: M, Rjb, VS30, and Ztor. The variability decomposition results suggest that the reduction of total variability is mostly due to the reduction of inter-event variability, likely because more source parameters than site or path parameters are included as explanatory variables. ",
      "282": "We are developing a machine learning model to make predictions of the 250 mg/L isochlor (salt front location) within the Delaware River Estuary. The model will be driven by river discharge into the estuary, tidal forcings, and meterological data from several points throughout the estuary. Model predictions will be compared with a process-based, hydrodynamic model, COAWST. The machine learning model is currently in development, but it will consist of a recurrent neural network architecture built using tools from pyTorch.",
      "276": "ARIES is an international research project based at the Basque Centre for Climate Change (Bilbao, Spain), to which USGS has been a long-term collaborator. ARIES uses semantics and machine reasoning to enable AI-assisted multidisciplinary, integrated modeling of coupled human-natural systems. See https://aries.integratedmodelling.org/ and https://docs.integratedmodelling.org/technote/ for full details.\nARIES is a full-stack solution for integrated modelling, supporting the production, curation, linking and deployment of scientific artifacts such as datasets, data services, modular model components and distributed computational services. Its purpose is to ensure\u2009\u2014\u2009by design rather than just intent\u2009\u2014\u2009that the pool of such artifacts constitutes a seamless knowledge commons, readily actionable (by humans and machines) through a full realization of the linked data paradigm augmented with semantics and powered by artificial intelligence. This design enables automation of a wide range of modeling tasks that would normally require human experts to perform.\nARIES\u2019 underlying software stack, called k.LAB, includes client and server components that support the creation, maintenance and use of a distributed semantic web platform where scientific information can be stored, published, curated and connected. The software is licensed through the Affero General Public License (AGPL) v.3.0.",
      "451": "This study is investigating the use of artificial intelligence models for improving clinical management of colorectal polyps. The models receive video frames from colonoscopy video streams and analyze them in real time in order to (1) detect whether a polyp is in the frame and (2) predict the polyp's malignant potential.",
      "360": "Models have been embedded in the backend of the SMART system on OpenNet to perform entity extraction of objects within cables, sentiment analysis of cables, keyword extraction of topics identified within cables, and historical data analysis to recommend addressees and passlines to users when composing cables.",
      "403": "Developed an AI-based recommender for detecting potential non-\ncompliance issues which makes training returns selection more efficient and scalable, which has been applied to the process for selecting training  returns and field work. ",
      "148": "The virtual agent uses manual learning to understand customer needs and provide a response appropriately. Our AI is named SAM and uses natural language.",
      "158": "CDC\u2019s National Center for Health Statistics (NCHS) Data Linkage Program has implemented a supervised machine learning\nalgorithm, known as the Sequential Coverage Algorithm (SCA) in their linkage programs. The SCA was used to develop\nJoining methods (or blocking groups) when working with very large datasets. The SCA method improved the efficiency of\nblocking.",
      "346": "A Natural Language Processing (NLP) model is used in coordination with Intelligent Character Recognition (ICR) to identify and extract values from the JF-62 form for within grade increase payroll actions. Robotic Process Automation (RPA) is then used to validate the data against existing reports, then create a formatted file for approval and processing.",
      "33": "Using neural networks and other AI technologies to detect no-changes in digital imagery for the NRI (national resources inventory) program ",
      "306": "Threat Intake Processing System (TIPS) \ndatabase uses artificial intelligence (AI) \nalgorithms to accurately identify, \nprioritize, and process actionable tips \nin a timely manner. The AI used in this \ncase helps to triage immediate threats \nin order to help FBI field offices and \nlaw enforcement respond to the most \nserious threats first.  Based on the \nalgorithm score, highest priority tips \nare first in the queue for human \nreview.",
      "81": "NTIA\u2019s Institute for Telecommunication Sciences (ITS) is investigating the use of AI to \nautomatically identify and classify clutter obstructed radio frequency propagation paths. \nClutter is vegetation, buildings, and other structures that cause radio signal loss through \ndispersion, reflection, and diffraction. It does not include terrain effects. The classifier is a \nconvolutional neural network (CNN) trained using lidar data coinciding with radio \nfrequency propagation measurements made by ITS. This trained CNN can be fed new \nradio path lidar data and a clutter classification label is predicted.",
      "220": "Vulnerability analysts require advanced automation tools to process data received through various  vulnerability reporting channels, as well as aggregate the information for automated sharing. These tools leverage Machine Learning and Natural Language Processing to increase the accuracy and relevance of data that is filtered and presented to human analysts and decision-makers. Machine Learning techniques also assist to aggregate the information in reports for presentation and further analysis. This includes data in the KEV and CVE databases.",
      "290": "The approach compares the transfer of different model types from well-observed to unobserved lake systems. Process-based models, neural networks, and process-guided neural networks are trained on well observed lakes (source lakes) and then is used to make predictions in unobserved lakes (target lakes). The performance of each of those transfers is used to train a meta-model that uses lake characteristics (e.g., depth, area) to predict which source lakes will be good candidates for transfer to target lakes. The process-guided deep learning models were able to transfer better than process-based and pure machine learning approaches. ",
      "42": "The ADCVD program investigates allegations of dumping and/or countervailing of duties.  \nInvestigations are initiated when a harmed US entity files a petition identifying the alleged \noffence and the specific harm inflicted.  Self-Initiation will allow ITA to monitor trade \npatterns for this activity and preemptively initiate investigations by identifying harmed US \nentities, often before these entities are aware of the harm.",
      "51": "FathomNet provides much-needed training data (e.g., annotated, and localized imagery) \nfor developing machine learning algorithms that will enable fast, sophisticated analysis of \nvisual data. We've utilized interns and college class curriculums to localize annotations on \nNOAA video data for inclusion in FathomNet and to begin training our own algorithms.",
      "345": "ILMS developed and deployed an automated support desk assistant using ServiceNow Virtual Agent to simplify support desk interactions for ILMS customers and to deflect easily resolved issues from higher cost support desk agents.",
      "86": "Data dissemination system that identifies which references, or prior art, were cited in \nspecific patent application office actions, including: bibliographic information of the \nreference, the claims that the prior art was cited against, and the relevant sections that \nthe examiner relied upon.  System extracts information from unstructured office actions \nand provides the information through a structured public facing API.",
      "391": "Artificial Intelligence Support for Rulemaking - Using ChatGPT to support the rulemanking processes to provide significant efficiencies, reduction of effort, or the ability to scale efforts for unusual levels of public scrutiny or interest (e.g. comments on a rulemaking).    ChatGPT will be used to provide: \n1.  Sentiment Analysis \u2013 Is the comment positive / negative or neutral towards the proposed rule.\n2.  Relevance Analysis \u2013 Whether the particular comment posted is relevant to the proposed rule\n3.  Synopsis of the posted comment.\n4.  Cataloging of comments.\n5.  Identification of duplicate comments.",
      "197": "The NIH Office of Portfolio Analysis has developed a neural network approach to analysis of scientific content using\ndimensionality reduction (word2vec OPA ). This method computationally converts words in scientific texts to numbers and\nsummarizes documents by their semantic content by learning relationships between words from their context. This\nmethod is adaptable to specific corpora, including grants and scientific articles. For more information see the publication\ndescribing our word2vec approach: Hoppe et al 2019 (https://www.science.org/doi/10.1126/sciadv.aaw7238)",
      "424": "Automated speech transcription engines analyze the cognitive decline of older VA patients. Digitally recorded speech responses are transcribed using multiple artificial intelligence-based speech-to-text engines. The transcriptions are fused together to reduce or obviate the need for manual transcription of patient speech in order to score the neuropsychological tests.",
      "200": "The AI for autonomous situational awareness system is intended to use IoT sensor kits to covertly detect and track illicit cross-border traffic in remote locations. \n\nThe system will leverage a motion image/video system enhanced with Artificial Intelligence that is capable of vehicle detection and direction determination. It will also incorporate a motion sensor that, when triggered, wakes up a high-resolution camera to capture a series of pictures, with additional sensors providing confirmation prior to camera capture. \n\nImages captured will be processed by Artificial Intelligence models to classify objects, determine vehicle direction at intersections, and provide imagery sufficient for re-identification. Ultimately, the systems is intended to create a low footprint, low cost, low power system to provide situational awareness and covert detection.",
      "225": "RelativityOne is a document review platform used to gain efficiencies in document review in litigation, FOIA, and other arenas where large-scale document review and production is necessary.",
      "123": "This research will develop a methodology that relies on mechanism-informed machine \nlearning models, rapid ion irradiation and creep testing techniques, and advanced \ncharacterization coupled with automated image analysis to enable reactor developers \nto quickly understand the complex linkage between alloy composition, \nthermomechanical processing, the resulting microstructure, and swelling and creep \nbehavior. This project will (1) develop and demonstrate a high-potential methodology \nfor rapid development of future in-core materials and (2) provide critically important \ninformation on alloy design for optimized swelling and creep behavior to the advanced \nreactor development community.",
      "388": "In order to get a full accounting of delay, automated voice detection of ATC and aircraft interaction is required.  Many delay events, such as vectoring, are not currently reported/detected/accounted for and voice detection would enable automated detection.",
      "348": "CSO/AA is developing a suite of conflict and instability forecasting models that use open-source political, social, and economic datasets to predict conflict outcomes including interstate war, mass mobilization, and mass killings. The use of AI is confined to statistical models including machine learning techniques including tree-based methods, neural networks, and clustering approaches.",
      "274": "The objective of this project is to use DL tools to extract terrain features. ",
      "91": "This project will develop a system that utilizes non-traditional measurement sources \nsuch as vibration, acoustics, current, and light, and traditional sources such as flow, \nand temperature in conjunction with data-based, machine learning techniques that will \nallow for signal discovery. The goal is to characterize stages within a solvent \nextraction process can increase target metals recovery, indicate process faults, \naccount for special nuclear material, and inform near real-time decision making.",
      "164": "The Rapid ATO System was built using a natural language processing model and pipeline to process system security plans,\nto identify unique and commonly used technology components used across Federal Information Security Management\nAct (FISMA) systems. Natural language processing (NLP) is a form of machine learning that derives intent or subject out\nof blocks of text. In this particular case it was used to identify common blocks of language used in similar ways across\nsystem security plan (SSP) documents. In this way, CMS could identify similar approaches to solving certain technology or\nprocess-related control areas within the Acceptable Risk Safeguards (ARS). The output was used to create a list of\ncomponents to develop control description language in a re-usable way, as part of the Blueprint/Rapid ATO effort to\nstreamline SSP generation for new systems.",
      "151": "Auto-filling queries as they are typed",
      "156": "MedCoder ICD-10 cause of death codes to the literal text cause of death description provided by the cause of death\ncertifier on the death certificate. This includes codes for the underlying and contributing causes of death.",
      "384": "OPC leverages data from several sources such as weather radar, lightning networks, satellite and numerical models to produce a radar-like depiction of precipitation. The algorithm then applies machine learning techniques based on years of satellite and model data to improve the accuracy of the location and intensity of the precipitation areas.",
      "212": "CISA deploys forensic specialists to analyze cyber events at Federal Civilian Executive Branch (FCEB) departments and agencies, as well as other State, Local, Tribal, Territorial, and Critical Infrastructure partners. Forensic analysts can utilize advanced analytic tooling, in the form of Artificial Intelligence implementations to better understand anomalies and potential threats. This tooling allows forensic specialists the capabilities to comb through data in an automated fashion with mathematically and probabilistically based models to ensure high fidelity anomalies are detected in a timely manner. ",
      "281": "Once developed, the system will input watershed characteristics (soils, land cover), land use (road salt application) and meteorological timeseries, and output predictions of specific conductance (SC) for inland stream reaches in the Delaware River Basin (DRB). The model will be trained using SC sample data from within the DRB. The resulting model will allow for predictions in ungaged locations and time periods, and allow for an evaluation of salinity exposure in these stream reaches. The model will be built using pyTorch on the USGS Tallgrass supercomputer.",
      "87": "Service to help inventors \"get started\" identifying relevant documents, figures, and \nclassification codes used to conduct a novelty search.  System takes a user entered short \ndescription of invention and provides a user selectable set of recommended documents, \nfigures, and classification areas.",
      "171": "The Term Identification and Novel Synthetic Opioid Detection and Evaluation Analytics use publicly available social media\nand forensic chemistry data to identify novel referents to drug products in social media text. It uses the FastText library to\ncreate vector models of each known NSO-related term in a large social media corpus, and provides users with similarity\nscores and expected prevalence estimates for lists of terms that could be used to enhance future data gathering efforts.",
      "455": "Artificial intelligence supports triage of eye patients cared for through telehealth, interprets eye images, and assesses health risks based on retina photos. The goal is to improve diagnosis of a variety of conditions, including glaucoma, macular degeneration, and diabetic retinopathy.",
      "326": "Custom machine learning model to assign a reported expense description from Consumer Expenditure Diary Survey respondents to expense classification categories known as item codes.",
      "174": "Topical characterization of the research portfolio. Inputs are publications and grants abstracts. These are fed into a text\nclassification model and concept extraction. The outputs are category labels and list of concepts.",
      "4": "Generate maps of target trees from ground-level (streetview) imagery",
      "445": "Using CPRS and CDW data, artificial intelligence is used to predict biologic response to thiopurines among Veterans with irritable bowel disease.",
      "441": "Using VA electronic clinical data, the Medication Safety (MedSafe) Clinical Decision Support (CDS) system analyzes current clinical management for diabetes, hypertension, and chronic kidney disease, and makes patient-specific, evidence-based recommendations to primary care providers.\u00a0 The system uses knowledge bases that encode clinical practice guideline recommendations and an automated execution engine to examine multiple comorbidities, laboratory test results, medications, and history of adverse drug events in evaluating patient clinical status and generating patient-specific recommendations",
      "192": "The IRM NLP module automatically refers projects to Program Officers once the grant application is received. The system\ninputs are grant applications - the title, abstract, specific aims and Public Health Relevance is analyzed to automatically\nrefer the grant application to the Program Officer who matches a similar background with the science contained in the\napplications. This process, is operating at a high accuracy rate and has effectively eliminated the referral bottleneck.",
      "264": "This project uses observations of the depth to bedrock reported by private well drillers in the Delaware River Basin to train a Random Forest model to map the thickness of the regolith layer. This data product will support groundwater and hydrologic modeling efforts in the basin.",
      "269": "We are using high frequency satellite images from the Planetscope constellation to estimate water depth in river channels. The short time lags between images allows us to average multiple scenes collected on the same day or within a couple of days to improve accuracy. In addition to established depth retrieval methods, we developed a neural network regression approach for this purpose. The training data consist of field measurements of water depth collected as part of other USGS projects on five different rivers. The neural network regression method is implemented in MATLAB using the Deep  Learning Toolbox.",
      "5": "Natural language processing technique. Data are cleaned (e.g., remove punctuation) to facilitate matching. Cosine similarity is calculated, similar terms are matched, and the results are output.",
      "209": "Video Computer Aided Detection (VCAD) (also known as Matroid AI) is software that enables CBP end users to create and share vision detectors. \n\nVCAD detectors are trained computer vision models that recognize objects, people, and events in any image or video stream. Once a detector is trained, it can monitor streaming video in real time, or efficiently search through pre-recorded video data or images to identify objects, people, and events of interest. \n\nUsers can view detection information via a variety of reports and alert notifications to process and identify important events and trends. Detection data is also available through VCAD's powerful developer Application Programming Interface (API) and language specific clients, so CBP applications can be integrated with the power of computer vision.",
      "287": "Once developed, the system will input lake characteristics (surface area, elevation, and others to be determined) and output predictions of depth-specific lake temperatures. Training data consist of lake temperature observations, meteorological data, and lake characteristics. The models will be developed using various Python packages including PyTorch on the USGS Tallgrass supercomputer.",
      "63": "Machine Learning Product that is a first guess for the WPC Excessive Rainfall Outlook - It is \nlearned from the ERO with atmospheric variables. It is for the Day 4-7 products",
      "206": "The third-party global trade data is used to augment and enrich agency\u2019s investigations into entities of interest. It combines data from companies and goods across multiple languages, then provides network analysis to assess trade flows and risks associated with cross-border trade.\n\nThis can validate agency-held information or provide better understanding of networks of interest to the agency to better inform investigations that cross borders. AI/ML models help manage the information provided through the software, including behind-the-curtain collection of information, structuring of data, entity resolution, network analysis, risk analysis, and other functions that contribute to the software knowledge graph and frontend that end users interact with.  ",
      "108": "This project will implement an advanced machine learning based 5G attack detection \nsystem that can achieve high classification speed (10k packets per second) with high \naccuracy (90% or greater) as well as address a vulnerability to zero-day attacks \n(90% accuracy against real zero-day attacks recorded by Amazon Web Services) \nusing field programmable gate array based deep autoencoders.",
      "272": "The model we developed provides a highly accurate daily classification of waterfowl behavior into 8 life history states/movement patterns using hourly GPS relocations and, optionally, remotely sensed habitat data.  This will provide waterfowl researchers and managers a tool for real-time capable rapid assessments and notification of important life history events to improve research and management outcomes and reduce project operational costs.  ",
      "144": "CALI tool is an automated machine learning evaluation tool built to streamline the evaluation of vendor proposals against the solicitation requirements to support the Source Selection process. Once the Contracting Officer (CO) has received vendor proposals for a solicitation and is ready to perform the evaluation process, the CO will initiate evaluation by sending solicitation documents along with all associated vendor proposal documents to the Source Selection module, which will pass all documents to CALI. CALI will process the documents, associated metadata and begin analyzing the proposals in four key areas: format compliance, forms validation, reps & certs compliance, and requirements compliance. The designated evaluation members can review the evaluation results in CALI and submit finalized evaluation results back to the Source Selection module. CALI is currently being trained with sample data from the EULAs under the Multiple Award Schedule (MAS) program.",
      "198": "High-quality disambiguation is required to correctly link researchers to their grants and outputs including articles,\npatents, and clinical trials. The NIH Office of Portfolio Analysis developed a disambiguation solution that used article level\nmetadata to assign 24.5M unique papers from the PubMed database to 16.0M unique author names, then used a novel\nneural network model trained on ORCID identifiers to determine whether author-publication pairs refer to variant\nrepresentations of the same person. For example, our model can determine whether hypothetical records listing Jane\nSmith and Jane M. Smith were the same person, or two different people, based on variables that include institutional\naffiliation, co-authorship, and article-affiliated Medical Subject Heading (MeSH) terms. For more information see the\npublication describing this method: Yu et al 2021\n(https://www.biorxiv.org/content/10.1101/2021.02.02.429450v1.full.pdf)",
      "49": "We've been compiling image libraries for use in creating automated detection and \nclassification models for use in automating the annotation process for the SEAMAP Reef \nFish Video survey of the Gulf of Mexico. This work is being conducted in VIAME but we're \nlooking at several other paths forward in the project to identify best performing models. \nCurrent status is that models are performing well enough that we will incorporate \nautomated analysis in video reads this spring as part of a supervised annotation-qa/qc \nprocess.",
      "298": "The ML model provides estimates of peak ground-motion from earthquakes given the location, magnitude, and local geological structure at a site of interest. The training data is a compilation of about 12,000 peak ground-motions recorded at seismic stations for moderate to large earthquakes. I constructed the ML model in Python using Keras with TensorFlow.",
      "398": "Large Partnership Compliance is a machine learning model for stratifying \nPartnership data and score risk of potential non-compliance.",
      "402": "Projected contract award dates are generated with a machine learning \nmodel that statistically predicts when procurement requests will become \nsigned contracts. Input data includes funding information, date / time of \nyear, and individual Contract Specialist workload. The model outputs \nprojected contract award timeframes for specific procurement requests.  \n'When will a contract be signed?' is a key question for the IRS and \ngenerally for the federal government. This tool gives insight about when \neach request is likely to turn into a contract. The tool provides a technique \nother federal agencies can implement, potentially affecting $600 billion in \ngovernment contracts. Weblink: https://www.irs.gov/newsroom/irs-\nannounces-use-of-projected-contract-award-date-web-app-that-predicts-\nwhen-contracts-will-be-signed",
      "40": "Chatbot embedded into trade.gov to assist ITA clients with FAQs, locating information and \ncontent, suggesting events and services.  ITA clients would enter input into the chatbot in \nthe form of questions or responses to prompts.  The chatbot would scan ITA content \nlibraries and input from ITA staff and return answers and suggestions based on client \npersona (exporter, foreign buyer, investor).",
      "85": "Clarivate COTS solution to assist examiner identification of similar trademark images, to \nsuggest the correct assignment of mark image design codes, and to determine the \npotential acceptability of the identifications of goods and services.  System is anticipated \nto use both incoming trademark images and registered trademark images and output \ndesign codes and/or other related images.",
      "83": "Augmentation for next generation patent search tool to assist examiners identify relevant \ndocuments and additional areas to search.  System takes input from published or \nunpublished applications and provides recommendations on further prior art areas to \nsearch, giving the user the ability to sort by similarity to concepts of their choosing.",
      "14": "The Comment Analysis pilot has shown that a toolset leveraging recent advances in Natural Language Processing (NLP) can aid the regulatory comment analysis process. We developed tools that help comment reviewers identify the topics and themes of comments, as well as group comments that are semantically similar. Tools like these offer significant value by creating efficiencies through novel insights and streamlined processing of comments, reducing duplicative, upfront development efforts across government, and ultimately realizing cost savings for agencies and the USG. \n",
      "341": "A/LM collaborated with A/OPE to develop a bot to automate the data entry in the Federal Procurement Data System (FPDS), reducing the burden on post\u2019s procurement staff and driving improved compliance on DATA Act reporting. This bot is now used to update ~300 FPDS awards per week.\u00a0 A/LM also partnered with WHA to develop a bot to automate closeout reminders for federal assistance grants nearing the end of the period of performance and begin developing bots to automate receiving report validation and customer service inbox monitoring.",
      "430": "This is an IRB-approved study which aims to examine machine learning approaches to predict health outcomes of VA patients.\u00a0 It will focus on the prediction of Alzheimer's disease, rehospitalization, and Chlostridioides difficile infection.",
      "444": "A machine learning model is used to predict disease progression among veterans with hepatitis C virus.",
      "172": "AI Chatbot \u2022 Successfully developed and deployed HRSA EHBs AI Chatbot using Artificial Solutions Teneo platform for external HRSA EHBs grantees \u2022 Built to allow grantees to communicate with the EHBs Chatbot using regular natural conversational expressions \u2022 Provides knowledge- and action-based responses through a self-service platform with 24/7 availability \u2022 Integrated with existing EHBs application UI and Salesforce for automated ticket creation \u2022 Chatbot has the ability to refine and increase the accuracy of its responses as more and more users invoke/use the Chatbot",
      "381": "The Multiple Airport Route Separation (MARS) program is developing a safety case for reduced separation standards between Performance Based Navigation (PBN) routes in terminal airspace. These new standards may enable deconfliction of airports in high-demand metropolitan areas, including the Northeast Corridor (NEC), North Texas, and Southern California. To build necessary collision risk models for the safety case, several models are needed, including one that describes the behavior of aircraft that fail to navigate the procedure correctly. These events are very rare and difficult to identify with standard data sources. Prior work has used Machine Learning to filter incident data to identify similar events on departure procedures.",
      "262": "The project objective is to take a large dataset of rapid habitat assessment data collected by multiple jurisdictions in the Chesapeake Bay Watershed, train a predictive model using those data, and use that model to predict stream habitat conditions for all unmeasured stream reaches in the region. The model is able to generate predictions for multiple aspects of physical habitat condition. The model directly connects to EPA's database containing the training data, enabling it to be rapidly updated when new data updates occur.",
      "392": "Build and evaluate a multiple linear regression model to predict to \ndetermine if the replenishment of an inventory item was received before \nor after the need by date to predict the likelihood that an item will be \nreceived on time in the future.",
      "280": "Species distribution models are developed for 271 fluvial fish species in their native ranges of the conterminous United States.  Boosted Regression Tree (BRT) models were used to develop presence/absence predictions for each of the National Hydrography Dataset Plus Version 2.1 stream segments within a species' native range.  Landscape data that describe the natural variation (e.g., slope, precip) and anthropogenic impacts (e.g., stream fragmentation) were summarized to stream segments and used as predictor variables. Native species ranges were used to geographically constrain distribution modeling efforts. R Version 4.0.2 (or newer) with \u2018dismo\u2019 and \u2018labdsv\u2019 packages are used for modeling.",
      "70": "A supervised machine learning acoustic event classifier using hierarchical random forests",
      "439": "A machine learning approach is used to build predictive models of perfusionists\u2019 decision-making during critical situations that occur in the cardiopulmonary bypass phase of cardiac surgery. Results may inform future development of computerized clinical decision support tools to be embedded into the operating room, improving patient safety and surgical outcomes.",
      "387": "Description: Leveraging large volumes of these recursive track geometry measurements to develop and implement automated machine-learning-based processes for analyzing, predicting, and reporting track locations of concern, including those with significant rates of degradation.\nInput: Track geometry measurements and exceptions\nOutput: Inspection report that includes the trending of track geometry measures and time to failure (i.e., maintenance and safety limits).",
      "279": "Wetland managers are restoring coastal wetland habitats in the Great Lakes, and often seek more information on when and how fish access restored habitats. Terabytes of hydroacoustic data on fish movement need to be analyzed more efficiently, so a collaboration between USGS, USFWS, and the University of Michigan is developing a machine learning model (MLM) that identifies, tracks, and quantifies fish movement. The completed model will read proprietary sonar image files, convert them to a universal file format (i.e., .mp4), place bounding boxes around individual fish detected by the model, and track them across consecutive image frames to determine bi-directional movement. The model uses training data and TensorFlow-based convolutional neural networks for object detection. Post-processing uses sonar geometry to estimate length of individual fish, and output files include labeled videos showing bounding boxes (.avi format), model metrics (.txt format), an enumeration of bi-directional fish movement (i.e., left or right) in .csv format, and individual fish length estimates (.csv format). Model output will allow USGS researchers to estimate fish habitat use and associated community metrics in restored wetland habitats. This information will support USFWS and other management agencies restoring coastal wetland habitats.",
      "146": "The introduction of a chatbot will enable the GSA FAS NCSC (National Customer Support Center) to streamline the customer experience process, and automate providing answers to documented commonly asked questions through public facing knowledge articles. The end goal is this will reduce staffing requirements for NCSC\u2019s live chat programs and allow the NCSC resources to be dedicated to other proactive customer services initiatives. Customers will still have the option to connect to a live agent if they choose by requesting an agent.",
      "52": "Fan Y., Krasnopolsky, V., van den Dool H., Wu, C. , and Gottschalck J. (2021). Using \nArtificial Neural Networks to Improve CFS Week 3-4 Precipitation and Temperature \nForecasts.",
      "106": "This research will advance the state of the art for red team security assessment of \nmachine learning and artificial intelligence systems by providing methods for the \nreverse engineering, exploitation, risk assessment and vulnerability remediation. The \ninsights gained from the explorations into vulnerability assessment research will \nproactively address critical gaps in the cybersecurity community\u2019s understanding of \nthese systems and can be used to create appropriate risk evaluation metrics and \nprovide best practices for inclusion into consequence-driven cyber-informed \nengineering.",
      "450": "This prognostic study used data on patients with hepatitis C virus (HCV)-related cirrhosis in the national Veterans Health Administration who had at least 3 years of follow-up after the diagnosis of cirrhosis. The data was used to examine whether deep learning recurrent neural network (RNN) models that use raw longitudinal data extracted directly from electronic health records outperform conventional regression models in predicting the risk of developing hepatocellular carcinoma (HCC).",
      "405": "University of California, Berkeley, is building a machine learning model to conduct gender differentiated credit scoring for customers of Rappicard in Mexico. They will compare this ML model to Rappi's \"status quo\" model to determine whether a gender differentiated model leads to greater access to credit for women.",
      "99": "Typical contingency analysis for a power utility is limited to n-1 due to computational \ncomplexity and cost. A machine learning framework and resilience-chaos plots are \nleveraged to reduce computational expense required to discover, with 90% accuracy, \nn-2 contingencies by 50%.",
      "61": "Continued support of multispectral aerial imaging payload running detection model \npipelines in real-time. This is a nine camera (color, infrared, ultraviolet) payload controlled \nby dedicated on-board computers with GPUs. YOLO detection models run at a rate faster \nthan image collection, allowing real-time processing of imagery as it comes off the \ncameras. Goals of effort are to reduce overall data burden (by TBs) and reduce the data \nprocessing timeline, expediting analysis and population assessment for arctic mammals.",
      "7": "Artificial intelligence used to automate document processing and information extraction. Program managers often need information from specific form fields that are sent as PDF email attachments. Many emailed documents are received each day, making manually opening each attachment and copying the needed information too time-consuming. ",
      "186": "PubMed users frequently use author names in queries for retrieving scientific literature. However, author name\nambiguity (different authors share the same name) may lead to irrelevant retrieval results. Thus we have developed a\nmachine-learning method to score the features for disambiguating a pair of papers with ambiguous names.\nSubsequently, agglomerative clustering is employed to collect all papers belong to the same authors from those classified\npairs. Disambiguation performance is evaluated with manual verification of random samples of pairs from clustering\nresults, with a higher accuracy than other state-of-the-art methods. It has been integrated into PubMed to facilitate\nauthor name searches.",
      "283": "We published a machine learning model to make water temperature predictions at 456 reaches in the Delaware River Basin. The recurrent graph convolutional network (RGCN) was pre-trained with predictions from a coupled process-based model that predicts stream flow and temperature (the Precipitation Runoff Modeling System with the coupled Stream Network Temperature Model or PRMS-SNTemp).",
      "330": "This model uses machine learning to estimate the probability of resource misuse by representative payees and flag the cases for a technician to examine.",
      "232": "I-485 Family Matching is designed to create models to match family members to underlying I-485 petitions. The underlying immigrant petition defines if the I-485 is employment-based or family-based. It also has information about the visa classification and priority date which, when compared against the Department of State\u2019s monthly Visa Bulletin, helps predict visa usage. It is difficult to match an I-485 to its underlying immigrant petition, because the only available field on which to match is the A-number. This number is not always present on the immigrant petition, and name/date of birth matching is not as reliable. The goal of I-485 Family Matching is to leverage AI to more confidently create connections between petitioners and their families based on limited data.\n\nAdditionally, it will be able to help identify and group I485s filed by family members, as well as gather up the many ancillary forms they may have pending (such as I765, I131). Similar to immigrant petition matching, it can be difficult to match up I485s filed by family members. In these cases the only similar fields are a common address. Efforts have been made in the past to identify family members by address, but it is effective only to a point. The AI model will help make working with this data more reliable, as well as group individual petitioners, their families, and other helpful associated data together for faster and more accurate processing.",
      "21": "TreeMap 2016 provides a tree-level model of the forests of the conterminous United States. It matches forest plot data from Forest Inventory and Analysis (FIA) to a 30x30 meter (m) grid. TreeMap 2016 is being used in both the private and public sectors for projects including fuel treatment planning, snag hazard mapping, and estimation of terrestrial carbon resources. A random forests machine-learning algorithm was used to impute the forest plot data to a set of target rasters provided by Landscape Fire and Resource Management Planning Tools (LANDFIRE: https://landfire.gov). Predictor variables consisted of percent forest cover, height, and vegetation type, as well as topography (slope, elevation, and aspect), location (latitude and longitude), biophysical variables (photosynthetically active radiation, precipitation, maximum temperature, minimum temperature, relative humidity, and vapour pressure deficit), and disturbance history (time since disturbance and disturbance type) for the landscape circa 2016.",
      "213": "Threat hunting and Security Operations Center (SOC) analysts are provided terabytes per day of data from the National Cybersecurity Protection System's (NCPS) Einstein sensors. Manually developed detection alerts and automatic correlation via off the shelf tooling are common, but not comprehensive. Many network attacks can be probabilistically determined given sufficient training data and time. Analysts use automated tooling to further refine the alerts they receive and produce additional automated alerts based on aggregated information and backed in subject matter expertise. This tooling allows CISA analysts the capabilities to comb through data in an automated fashion with mathematically and probabilistically based models to ensure high fidelity anomalies are detected in a timely manner. ",
      "408": "The project proposes to establish a social innovation lab for a machine vision program that will be used by youth in the Morogoro region of Tanzania. There are young people in the area who have studied information technologies and allied sciences, and while most of them can write computer programs, they cannot solve machine vision problems. This project aims to increase awareness among the youth of Morogoro and nearby regions to address machine vision problems in agriculture. Machine vision is a new and understudied practice in Tanzania; hence, this project will contribute to efforts in the creation of scientific societies that address the most pressing problems faced by more than 80% of Tanzania\u2019s population who engage in farming. The main agricultural problems can be classified into five categories, as explained below: (1) Disease Detection and Classification: The project will develop experts who will solve problems in disease identification using machine vision for most of the diseases in crops and livestock, which are misdiagnosed by farmers. (2) Weed Classification: The project will develop algorithms that accurately identify weeds and contribute to the growing scientific database for automatic weed detection. (3) Pest Detection and Classification: Appropriate tools using machine vision for Integrated Pest Management (IPM) are needed in Tanzania, as IPM has been hindered due to a lack of extension officers to train farmers on mitigation and identification of pests in agriculture. (4) Crop Seedlings Stand Count and Yield Estimation: Use of machine vision and drones instead of scouting manually to estimate stand counts would provide appropriate mitigation strategies for replanting that would be beneficial to commercial farmers. Also of importance are algorithms to sort and estimate yield by counting the fruits and to estimate the amount of other agricultural products. (5) Crop Vigor Estimation: Most farmers apply inputs evenly across the farm because they cannot predetermine crop vigor. Accurate estimation of crop health would help farmers to mitigate the problems earlier and improve crop performance and avoid failure. Algorithms to determine crop vigor developed in this project will contribute to the improvement of the methods to estimate crop performance earlier.",
      "250": "This software system takes wildlife camera trap images as inputs and outputs the probability of the image belonging to user-specified taxonomic classes based on wildlife species present in each image. (Wildlife camera traps are motion-triggered, time lapse, and other camera systems placed in the field to capture images of wildlife at the location and times where and when the cameras are placed.) The process of humans reviewing, labeling, and QA/QCing labels is labor intensive, time consuming, and costly. Developing AI systems that can perform these tasks within an acceptable level of accuracy can reduce the costs in extracting tabular data from camera-based datasets and increase the volume of data for analysis. The system supports training experiments where model hyperparameters and training dataset characteristics can be varied to find those that are more optimal for training. Training, validation, and testing datasets have human-assigned labels and are used to train and evaluate the models. Once trained, the models can be used to predict classes on unlabeled images. We use a convolutional neural network (CNN) approach based on TensorFlow and training is run on the USGS Tallgrass supercomputer designed for AI/ML workflows.",
      "118": "This project developed method to analyze collected radiation spectra using advanced, \nscalable deep learning by combining spectroscopic expertise with high performance \ncomputing. Sophisticated deep learning can overcome the weaknesses of existing \nspectroscopic techniques and enhance the value of difficult measurements. This \nmethod was trained, tested, and operated on the International Space Station\u2019s \nSpaceborne Computer-2 supercomputer, returning zero errors over the course of 100 \ntraining hours. This demonstrated performance autonomously in far-edge, low-wattage \ncomputing situations and in hazardous radiological environments where interference \ncan cause errors.",
      "169": "ASSIST4Tobacco is a novel tool that will use semantic indexing to search tobacco authorization applications. The system\nwill be based on an AI (artificial intelligence)\u2010based NLP (Natural Language Processing) model which provides deeper\nsearch capabilities using a language model developed to represent relationships between words and concepts within a\nbody of text.",
      "259": "The River Image Sensing (RISE) project is charged with the development of a reliable camera system for integration into the operational streamgage monitoring network of the USGS Water Mission Area. In addition to capturing images and videos, the RISE system will be capable of producing time-series of surface water levels derived from still camera images using AI/ML modeling techniques.",
      "181": "Titles and abstracts from MEDLINE Citations are provided through SVM machine learning algorithm provides confidence\nscores for a set of MeSH CheckTags to the NLM Medical Text Indexer (MTI) program. These CheckTags are small set of\nMeSH Descriptors designed to indicate Species, Sex, and Age in MEDLINE articles.",
      "104": "The objective of this project is to research, assess, and implement machine learning \nand artificial intelligence and physics-based algorithms for signal decomposition and \nprovide a straightforward framework wherein an anomaly detection algorithm can be \ntrained on existing expected data and then used for false data injection detection. An \nadvanced library for signal decomposition and analysis will be developed that allows \ncombining machine learning and artificial intelligence algorithms and high-fidelity model \ncomparisons for greatly improved false data injection detection. This library will \nfacilitate online and posteriori analysis of digital signals for the purpose of detecting \npotential malicious tampering in physical processes.",
      "303": "We evaluate the readiness of machine-learning models for automatic earthquake detection and phase picking to enhance the Southern California Seismic Network earthquake catalog, with the end-goal of using these models in routine seismic network operations. We first test a model called Generalized Phase Detection (GPD), trained on millions of manually-picked P- and S- arrival times from Southern California earthquakes and examples of noisy time series data.  Inputs are continuous seismic data time series, with 3 components (north, east, vertical), at hundreds of seismic stations located in southern California.  Outputs are arrival times of P and S seismic waves, with associated probabilities between 0 and 1, with a threshold probability applied for detection; these arrival times are fed into existing software to estimate earthquake locations, origin times, and magnitudes.  Custom software is written in Python with the model implemented in the PyTorch library.  We are also developing a cloud-native software architecture that takes real-time seismic data as input (~15 seconds at a time) and applies the GPD model within Amazon Web Services.",
      "84": "System that classifies incoming patent application based on the cooperative patent \nclassification scheme for operational assignment of work and symbol recommendation for \naI search.  Backoffice processing system that uses incoming patent applications as input \nand outputs the resulting classification symbols.",
      "317": "Conversational chatbot on DOL intranet websites to help answer common procurement questions, as well as specific contract questions.",
      "135": "The records management technology team is using machine learning to predict the retention schedule for records. The machine learning model will be incorporated into a records management application to help users apply retention schedules when they submit new records.",
      "419": "The artificial intelligence coach in cardiac surgery infers misalignment in team members\u2019 mental models during complex healthcare task execution. Of interest are safety-critical domains (e.g., aviation, healthcare), where lack of shared mental models can lead to preventable errors and harm. Identifying model misalignment provides a building block for enabling computer-assisted interventions to improve teamwork and augment human cognition in the operating room.",
      "28": "The response propensity scores to the COA are derived from random forest models that use historical data, control data, and other survey data. These scores are used to help target more effective data collection.",
      "304": "We enhance the earthquake catalog for the 2020-2021 southwestern Puerto Rico earthquake sequence with a variety of deep learning approaches to understand its complex fault system, triggering mechanisms, and long-lived vigorous nature of the aftershock sequence.  We use an existing deep learning model for earthquake detection and phase picking called EQTransformer, which was trained on a global data set of earthquake waveforms called STEAD, using the TensorFlow library.  We also apply deep learning methods for earthquake location (EikoNet and HypoSVI), trained on a known velocity model with a physics informed neural network using the PyTorch library, which then allows grid-free rapid seismic wave travel time calculation between any 2 locations within a 3D volume .  These machine learning methods for automatic earthquake detection, phase-picking, and location, which are all available as open-source Python codes, help increase the number of small earthquake observations and improve earthquake depth estimates, thus offering more detailed information about active faults and physical processes in this earthquake sequence.",
      "418": "This app is a physical therapy support tool.\u00a0 It is a data source agnostic tool which takes input from a variety of wearable sensors and then analyzes the data to give feedback to the physical therapist in an explainable format.\u00a0",
      "73": "LSTM model that uses ocean and atmospheric predictors throughout the tropical Pacific \nto forecast ONI values up to 1 year in advance. An extension of this was submitted to the \ncloud portfolio with the intent of adding a CNN layer that that uses reforecast data to \nimprove the ONI forecasts.",
      "368": "Cluster text into themes based on frequency of used words in documents; has been applied to digital media articles as well as social media posts; performed using available Python libraries",
      "316": "AI used by Inspectors to visually inspect high and unsafe areas from a safe location.",
      "202": "Aerostat capability that uses three tethers instead of the traditional single tether, coupled with advanced weather sensors, analytic capabilities, and powerful winches. The AI/ML model is used to detect the need to launch and land based on weather. It also leverages AI and robotics to autonomously launch and recover the aerostat during inclement weather events without the need for on-site staffing, allowing the aerostat to operate autonomously, saving time and manpower.",
      "32": "The goal is to predict conservation benefits at the field level. The model uses farmer survey data, APEX modeling results and environmental data.",
      "175": "Natural language processing of grant applications for the purpose of classification for review assignment",
      "252": "The mission of the USGS Amphibian and Reptile Minitoring Initiative (ARMI) is to provide essential scientific information to managers to help arrest or reverse amphibian population declines. Acoustic monitoring of amphibian (anuran) vocalizations are a core technique used by ARMI researchers. Reviewing audio recordings and identifying species vocalizations captured therein is time consuming and labor intensive. For these reasons, many recordings remain unprocessed, preventing valuable data from being available for analysis. Our goal is to train convlutional neural networks (CNNs) that take audio clips that have been converted to sonograms (images) and classify the species generating the vocalizations in the recordings. Our initial prototype project will attempt to develop models that can identify audio clips containing bullfrog (*Lithobates catesbeianus*, which are native in some parts of the US and a destructive invasive species in others) vocalizations. The software will be build using the TensorFlow Python API and training will be performed on the USGS Tallgrass supercomputer.",
      "216": "The Automated PII Detection and Human Review Process incorporates descriptive, predictive, and prescriptive analytics. Automated PII Detection leverages natural language processing (NLP) tasks including named entity recognition (NER) coupled with Privacy guidance thresholds to automatically detect potential PII from within AIS submissions. If submissions are flagged for possible PII, the submission will be queued for human review where the analysts will be provided with the submission and AI-assisted guidance to the specific PII concerns. Within Human Review, analysts are able to confirm/deny proper identification of PII and redact the information (if needed). Privacy experts are also able to review the actions of the system and analysts to ensure proper performance of the entire process along with providing feedback to the system and analysts for process improvements (if needed). The system learns from feedback from the analysts and Privacy experts. Through the incorporation of the automated PII detection, CISA fully compliances with Privacy, Civil Rights and Civil Liberties requirements of CISA 2015 and scaled analyst review of submissions by removing false positives and providing guidance to submission to be reviewed. Through continual audits CISA will maintain integrity and trust in system and human processes.",
      "204": "Autonomously Detects, Identifies, and Tracks items of interest using Artificial Intelligence integrated with the tower. It does not require a dedicated operator, is rapidly deployable, and is relocatable in less than a day by 2-3 people.\n\nThe system features a hybrid command and control capability, hosted in the government cloud, and is accessible via URL by desktop, laptop, tablet, or Smartphone. It is solar powered with battery backup and requires no accompanying physical infrastructure while providing visibility for 1.5 miles (2.4 km) for people, 3 miles (4.8km) for vehicles.\n\nThe Lattice system permits autonomous detection, identification, and tracking of Items of Interest (IoIs).  The tower scans constantly and autonomously.  The radar detects and recognizes movement. The camera slews autonomously to the IoI and the system software identifies the object.  The system alerts the user and autonomously tracks the IoI. End users can monitor the system and see near real time photos by logging into the User Interface on any CBP device. ",
      "432": "This model interprets various real time inputs in a diagnostic and predictive capacity in order to forewarn episodes of PTSD and suicidality, support early and accurate diagnosis of the same, and gain a better understanding of the short and long term effects of stress, especially in extreme situations, as it relates to the onset of PTSD.",
      "240": "Exploring the potential to identify patterns, rule alignment or conflicts, discovery, and mapping of geo history and/or rules. Inputs included unstructured planning documents. Outputs identify conflicts in resource management planning rules with proposed action locations requiring exclusion, restrictions, or stipluations as defined in the planning documents. ",
      "292": "1) This work uses meteorological drivers to predict network wide daily average stream temperature in the Delaware River Basin. 2) The training data are water temperature observations available through NWIS and collected by the UGSS. 3) The work focuses on developing a custom loss function that helps deep learning models learn to account for groundwater influence on stream temperature.  Specifically, it uses the phase lag and amplitude dampening effect of groundwater to identify reaches likely influenced by shallow and deep groundwater inputs. ",
      "132": "Explore the use of big data, artificial intelligence (AI), and machine learning technology \nand tools on phasor measurement unit (PMU) data to identify and improve existing \nknowledge, and to discover new insights and tools for better grid operation and \nmanagement.",
      "373": "GEC A&R\u2019s Text Similarity capability identified different texts that are identical or nearly identical by calculating cosine similarity between each text. Texts are then grouped if they share high cosine similarity and then available for analysts to review further.",
      "227": "Systran provides machine translation for over 100 different language combinations.  Currently the Innovation Lab has licenses for translating Chinese, Spanish, Arabic, Farsi, Russian, German, Ukrainian and Filipino to English.  Systran can translate plain text, word documents, and PDFS.  A web-based UI and API endpoint are available.",
      "194": "The Grants Analytics Portal uses AI to enhance HHS OIG staff\u2019s ability to access grants related data quickly and easily by:\nquickly navigating directly to the text of relevant findings across thousands of audits, the ability to discover similar\nfindings, analyze trends, compare data between OPDIVs, and the means to see preliminary assessments of potential\nanomalies between grantees.",
      "331": "This model uses machine learning techniques to identify disability cases with the greatest likelihood of medical improvement and flag them for a coninuing disability review.",
      "34": "The AI Solution invoves Robotic Process Automation + AI/ML model solution to automatically classify and remove spam and marketing emails that appear in civil rights complaints email channels. A significant portion of incoming OASCR emails are spam, marketing and phishing emails. \n",
      "367": "Extract text from images using standard python libraries; inputs have been websites to collect data",
      "89": "This project aims to develop theories and algorithms for objective-driven reduction of \nscientific data in workflows that are composed of various models, including data-\ndriven AI models",
      "379": "ROMIO is an operational demonstration to evaluate the feasibility to uplink convective weather information to aircraft operating over the ocean and remote regions. Capability converted weather satellite data, lightning and weather prediction model data into areas of thunderstorm activity and cloud top heights. AI is used to improve the accuracy of the output based on previous activity compared to ground truth data.",
      "434": "PredictMod uses artificial intelligence to determine if predictions can be made about diabetes based on the gut microbiome.",
      "383": "The AVS International office is required to identify means of compliance to ICAO Standards and Recommended Practices (SARPs).\u00a0 Both SARPs and means of compliance evidence are text paragraphs scattered across thousands of pages of documents.\u00a0 AOV identified a need to find each SARP, evaluate the text of many FAA Orders, and suggest evidence of compliance based upon the evaluation of the text.\u00a0 The base dataset used by RCMT is the documents\u2019 texts deconstructed into paragraphs.\u00a0 RCMT processes all the documents\u2019 paragraphs run through Natural Language Processing (NLP) (this process has an AI aspect) to extract the meaning (semantics) of the text.\u00a0\u00a0\u00a0 RCMT then employs a recommender system (also using some AI technology) to take the texts augmented by the texts\u2019 meaning to establish candidate matches between the ICAO SARPs and FAA text that provides means of compliance.",
      "291": "1) This work uses meteorological drivers to predict network wide daily average stream temperature in the Delaware River Basin. 2) The training data are water temperature observations available through NWIS and collected by the UGSS. 3) The work compares the performance of two deep learning achictectures, both of which incorporate process guidance through pretraining on process-based modelling outputs.  For each architecture, we're testing the ability of the model to generalize outside the bounds of its training data in order to better understand the limitations of each modelling approach for accurately predicting stream temperature under changing climate and precipitation regimes.",
      "456": "National VHA administrative data is used to adapt tools that use electronic health records to predict the risk for esophageal adenocarcinoma.",
      "343": "A/LM plans to use available ILMS transactional data and planned transactions to develop tailored user experiences and analytics to meet the specifics needs of the user at that moment. By mining real system actions and clicks we can extract more meaningful information about our users to simplify their interactions with the system and reduce time to complete their daily actions.",
      "414": "AI technology will be used to develop a forecasting AI model for TB sensitive drugs to inform more accurate annual quantification exercises for the MoH linked to their national data integration platform SatuSehat",
      "366": "Cluster countries into tiers based off data collected from open source and bureau data using k-means clustering",
      "347": "The Bureau of Conflict and Stabilization Operations ran a pilot project to test how the use of a technology service, Sealr, could verify the delivery of foreign assistance to conflict-affected areas where neither U.S. Department of State nor our implementing partner could go.\u00a0 Sealr uses blockchain encryption to secure photographs taken on smartphones from digital tampering.\u00a0 It also uses artificial intelligence to detect spoofs, like taking a picture of a picture of something.\u00a0 Sealr also has some image recognition capabilities.\u00a0 The pilot demonstrated technology like Sealr can be used as a way to strengthen remote monitoring of foreign assistance to dangerous or otherwise inaccessible areas.",
      "187": "Gene indexing is part of the NLM\u2019s MEDLINE citation indexing efforts for improving literature retrieval and information\naccess. Currently, gene indexing is performed manually by expert indexers. To assist this time-consuming and resource-\nintensive process, we have developed NLM-Gene, an automatic tool for finding gene names in the biomedical literature\nusing advanced natural language processing and deep learning methods. Its performance has been assessed on gold-\nstandard evaluation datasets and is to be integrated into the production MEDLINE indexing pipeline.\u00a0\u00a0",
      "145": "USAGov and USAGov en Espa\u00f1ol collect large amounts of qualitative data from survey comments, web searches and call center chat transcripts. Comments are grouped together by topic to determine where we need to make product updates/enhancements",
      "307": "The Office of Records Management Policy \nuses an AI and Natural Language Processing \n(NLP) tool to assess the similarity of records \nschedules across all Department records \nschedules. The tool provides clusters of \nsimilar items to significantly reduce the time \nthat the Records Manager spends manually \nreviewing schedules for possible \nconsolidation. An AI powered dashboard \nprovides recommendations for schedule \nconsolidation and review, while also \nproviding the Records Manager with the \nability to review by cluster or by individual \nrecord. The solution's technical approach \nhas applicability with other domains that \nrequire text similarity analysis.",
      "16": "The goal of the this Dashboard is to provide a county-level visualization of FNS nutrition support, specifically nutrition education and local food access, alongside other metrics related to hunger and nutritional health.\u00a0As part of this dashboard, the team developed a K-means clustering script to group States by 7 different clustering options:  Farm to School Intensity & Size, Program Activity Intensity, Ethnicity & Race, Fresh Food Access, School Size, and Program Participation. This allows users to find like-minded, or similar, States based on any of these characteristics, opening up avenues for partnerships with States that they otherwise may not have considered.",
      "58": "Optimize NCEP EMC Training and Validation System for efficient handling of high spatial \nresolution model data produced by the new generation of NCEP's operational models",
      "277": "We applied coupled manual and machine learning methods to an expansive literature set for major global inland fisheries to explore opportunities for improving user efficiency for linking anthropogenic drivers of environmental change to direct impacts. This work informs the relative influence of threats in the development of a global inland fisheries assessment using boosted regression trees to derive a spatially-explicit risk index of stressors.",
      "305": "DEA's Special Testing and Research \nLaboratory utilizes AI/ML techniques and \nhas developed a robust statistical \nmethodology including multi-variate \nstatistical analysis tools to automatically \nclassify the geographical region of origin \nof samples selected for DEA's Heroin and \nCocaine signature programs. The system \nprovides for detection of anomalies and \nlow confidence results.",
      "255": "The PROSPER modeling framework was developed to incorporate sparse streamflow observation data representing wet or dry stream conditions and gridded hydroclimatic explanatory data to predict the annual probability of streamflow permanence at 30-m (PROSPER Pacific Northwest) or 10-m (PROSPER Upper Missouri) resolution. The training data are point observations of wet or dry at locations in the Pacific Northwest or Upper Missouri River basin. The PROSPER models were primarily developed using the FCPGTools (Barnhart, Sando, et al., 2020), R, and USGS HPC resources (Yeti).",
      "320": "Automatic analysis of recorded calls made to Benefits Advisors in the DOL Interactive Voice Repsonse (IVR) center.",
      "324": "The input is state submitted response files that include occupation title and sometimes job description of the surveyed units. The autocoder reads the job title and assigns up to two 6-digit Standard Occupational Classification (SOC) codes along with their probabilities as recommendations for human coders. Codes above a certain threshold are appended to the submitted response file and sent back to states to assist them with their SOC code assignment."
    },
    "Lifecycle": {
      "296": "In production: less than 1 year",
      "333": null,
      "411": "Operation and Maintenance",
      "82": null,
      "230": "Operation and Maintenance",
      "150": null,
      "15": "Development and Acquisition",
      "195": null,
      "297": "Planned (not in production)",
      "311": "Operation and Maintenance",
      "159": null,
      "427": null,
      "363": null,
      "397": "In production: more than one year",
      "266": "In production: less than 6 months",
      "365": null,
      "238": "Operation and Maintenance",
      "257": "Planned (not in production)",
      "102": null,
      "449": null,
      "71": null,
      "121": "Kerman, Mitchell C.",
      "55": null,
      "143": "Operation and Maintenance",
      "191": null,
      "374": null,
      "314": "Implementation",
      "211": "Development and Acquisition",
      "163": null,
      "273": "In production: more than 1 year",
      "237": "Implementation ",
      "364": null,
      "256": "Planned (not in production)",
      "20": "Operation and Management",
      "183": null,
      "60": null,
      "353": null,
      "62": null,
      "117": "Kerman, Mitchell C.",
      "260": "In production: less than 1 year",
      "447": null,
      "284": "In production: less than 1 year",
      "179": null,
      "234": "Operation and Maintenance",
      "417": "Initiation",
      "356": null,
      "327": null,
      "96": null,
      "210": "Development and Acquisition",
      "199": "Initiation",
      "229": "Development and Acquisition",
      "310": "Implementation",
      "235": "Operation and Maintenance",
      "182": null,
      "340": null,
      "442": null,
      "401": "In production: less than one year",
      "139": "Development and Acquisition",
      "17": "Operation and Management",
      "166": null,
      "147": "Operation and Maintenance",
      "157": null,
      "27": "Operation and Management",
      "67": null,
      "208": "Development and Acquisition",
      "354": null,
      "120": "Kerman, Mitchell C.",
      "140": "Operation and Maintenance",
      "431": null,
      "332": null,
      "35": "Operation and Management",
      "322": "Initiation",
      "358": null,
      "64": null,
      "127": null,
      "59": null,
      "126": null,
      "12": "Implementation",
      "103": null,
      "105": null,
      "334": null,
      "410": "Development and Acquisition",
      "335": null,
      "219": "Initiation",
      "18": "Development and Acquisition",
      "203": "Development and Acquisition",
      "142": "Implementation",
      "393": "Planned (not in production)",
      "440": null,
      "125": null,
      "369": null,
      "443": null,
      "407": "Development and Acquisition",
      "308": "In production: less than 6 months",
      "44": null,
      "29": "Development and Acquisition",
      "98": null,
      "390": "Planned (not in production)",
      "438": null,
      "329": null,
      "3": "Operation and Management",
      "375": null,
      "50": null,
      "246": "Investigating/Proof of concept",
      "41": null,
      "72": null,
      "413": "Implementation",
      "349": null,
      "380": "In production: more than 1 year",
      "420": null,
      "94": null,
      "30": "Development and Acquisition",
      "0": "Operation and Management",
      "130": null,
      "446": null,
      "454": null,
      "249": "Planned (not in production)",
      "247": "Planned (not in production)",
      "196": null,
      "38": "Operation and Management",
      "352": null,
      "69": null,
      "261": "In production: less than 6 months",
      "409": "Operation and Maintenance",
      "228": "Implementation",
      "36": "Operation and Management",
      "423": null,
      "422": null,
      "223": "Initiation ",
      "226": "Operation and Maintenance",
      "22": "Development and Acquisition",
      "312": "Operation and Maintenance",
      "165": null,
      "26": "Operation and Management",
      "372": null,
      "267": "Review final model output",
      "448": null,
      "170": null,
      "437": null,
      "119": "Kerman, Mitchell C.",
      "337": null,
      "355": null,
      "74": null,
      "338": null,
      "78": null,
      "180": null,
      "138": "Operation and Maintenance",
      "389": "Planned (not in production)",
      "45": null,
      "93": null,
      "193": null,
      "263": "In production: less than 1 year",
      "68": null,
      "350": null,
      "24": "Operation and Management",
      "395": "In production: less than six months",
      "436": null,
      "362": null,
      "136": null,
      "270": "Planned (not in production)",
      "221": "Initiation ",
      "6": "Operation and Management",
      "244": "Proof-of-concept completed",
      "1": "Operation and Management",
      "285": "Planned (not in production)",
      "357": null,
      "114": "Kerman, Mitchell C.",
      "328": null,
      "313": "Implementation",
      "13": "Operation and Management",
      "214": "Initiation ",
      "131": null,
      "233": "Development and Acquisition",
      "56": null,
      "90": null,
      "421": null,
      "323": "Development and Acquisition",
      "65": null,
      "176": null,
      "289": "Planned (not in production)",
      "428": null,
      "11": "Operation and Management",
      "258": "In production: less than 1 year",
      "97": null,
      "265": "In production: more than 1 year",
      "113": "Kerman, Mitchell C.",
      "207": "Development and Acquisition",
      "315": "Initiation",
      "231": "Operation and Maintenance",
      "239": "Development and Acquisition",
      "396": "In production: less than six months",
      "47": null,
      "10": "Operation and Management",
      "371": null,
      "288": "Planned (not in production)",
      "251": "Planned (not in production)",
      "370": null,
      "149": null,
      "75": null,
      "76": null,
      "122": "Kerman, Mitchell C.",
      "101": null,
      "394": "In production: less than six months",
      "400": "In production: less than six months",
      "133": null,
      "37": "Operation and Management",
      "205": "Operation and Maintenance",
      "302": "In production: more than 1 year",
      "48": null,
      "2": "Operation and Management",
      "115": "Kerman, Mitchell C.",
      "152": null,
      "359": null,
      "319": "Initiation",
      "190": null,
      "301": "Planned (not in production)",
      "57": null,
      "217": "Initiation ",
      "242": "Development (not in production) ",
      "25": "Operation and Management",
      "53": null,
      "245": "Proof-of-concept completed",
      "110": null,
      "412": "Implementation",
      "435": null,
      "177": null,
      "453": null,
      "325": "Operation and Maintenance",
      "88": "Continuous Monitoring",
      "218": "Initiation",
      "8": "Operation and Management",
      "128": null,
      "286": "In production: more than 1 year",
      "185": null,
      "141": "Implementation",
      "271": "We have the final version of the Unet model.  We are working on a manscript to document the model and workflow.  ",
      "351": null,
      "112": "Kerman, Mitchell C.",
      "236": "Operation and Maintenance",
      "404": "Initiation",
      "92": null,
      "111": "Kerman, Mitchell C.",
      "54": null,
      "167": null,
      "66": null,
      "124": null,
      "178": null,
      "160": null,
      "426": null,
      "452": null,
      "378": "Planned (not in production)",
      "129": null,
      "318": "Implementation",
      "100": null,
      "416": "Implementation",
      "457": null,
      "295": "In production: more than 1 year",
      "215": "Operation and Maintenance",
      "134": null,
      "19": "Operation and Management",
      "344": null,
      "399": "In production: less than six months",
      "254": "Planned (not in production)",
      "294": "Planned (not in production)",
      "342": null,
      "339": null,
      "385": "In production: more than 1 year",
      "189": null,
      "9": "Operation and Management",
      "39": null,
      "155": null,
      "243": "Completed",
      "224": "Operation and Maintenance",
      "31": "Development and Acquisition",
      "433": null,
      "415": "Development and Acquisition",
      "168": null,
      "309": "Operation and Maintenance",
      "153": null,
      "107": null,
      "80": null,
      "275": null,
      "43": null,
      "293": "Planned (not in production)",
      "406": "Development and Acquisition",
      "116": "Kerman, Mitchell C.",
      "137": "Operation and Maintenance",
      "248": "Planned (not in production)",
      "154": null,
      "109": null,
      "321": "Implementation",
      "95": null,
      "382": "Planned (not in production)",
      "425": null,
      "184": null,
      "429": null,
      "173": null,
      "222": "Initiation",
      "253": "Planned (not in production)",
      "188": null,
      "77": null,
      "268": "In production: 1 year",
      "278": "In production: less than 1 year",
      "241": "Development (not in production) ",
      "46": null,
      "336": null,
      "201": "Operation and Maintenance",
      "79": null,
      "386": "In production: less than 1 year",
      "162": null,
      "299": "In production: less than 1 year",
      "161": null,
      "23": "Operation and Management",
      "300": "Planned (not in production)",
      "282": "Planned (not in production)",
      "276": "In production: more than 1 year",
      "451": null,
      "360": null,
      "403": "In production: less than 6 months",
      "148": "Operation and Maintenance",
      "158": null,
      "346": null,
      "33": "Initiation",
      "306": "In production: more than 1 year",
      "81": null,
      "220": "Initiation ",
      "290": "In production: more than 1 year",
      "42": null,
      "51": null,
      "345": null,
      "86": null,
      "391": "Planned (not in production)",
      "197": null,
      "424": null,
      "200": "Development and Acquisition",
      "225": "Operation and Maintenance",
      "123": "Kerman, Mitchell C.",
      "388": "In production: less than 1 year",
      "348": null,
      "274": "In production: more than 1 year",
      "91": null,
      "164": null,
      "151": null,
      "156": null,
      "384": "In production: more than 1 year",
      "212": "Initiation ",
      "281": "Planned (not in production)",
      "87": null,
      "171": null,
      "455": null,
      "326": "Development and Acquisition",
      "174": null,
      "4": "Development and Acquisition",
      "445": null,
      "441": null,
      "192": null,
      "264": "In production: less than 1 year",
      "269": "Planned (not in production)",
      "5": "Implementation",
      "209": "Deployment",
      "287": "Planned (not in production)",
      "63": null,
      "206": "Development and Acquisition",
      "108": null,
      "272": "Planned (not in production)",
      "144": "Implementation",
      "198": null,
      "49": null,
      "298": "Planned (not in production)",
      "398": "In production: more than one year",
      "402": "In production: less than one year",
      "40": null,
      "85": null,
      "83": null,
      "14": "Development and Acquisition",
      "341": null,
      "430": null,
      "444": null,
      "172": null,
      "381": "Planned (not in production)",
      "262": "In production: less than 1 year",
      "392": "Planned (not in production)",
      "280": "In production: less than 6 months",
      "70": null,
      "439": null,
      "387": "In production: more than 1 year",
      "279": "In production: less than 1 year",
      "146": "Operation and Maintenance",
      "52": null,
      "106": null,
      "450": null,
      "405": "Initiation",
      "99": null,
      "61": null,
      "7": "Operation and Management",
      "186": null,
      "283": "In production: more than 1 year",
      "330": null,
      "232": "Development and Acquisition",
      "21": "Operation and Management",
      "213": "Initiation ",
      "408": "Development and Acquisition",
      "250": "Planned (not in production)",
      "118": "Kerman, Mitchell C.",
      "169": null,
      "259": "In production: less than 1 year",
      "181": null,
      "104": null,
      "303": "Planned (not in production)",
      "84": null,
      "317": "Initiation",
      "135": null,
      "419": null,
      "28": "Operation and Management",
      "304": "Planned (not in production)",
      "418": null,
      "73": null,
      "368": null,
      "316": "Operation and Maintenance",
      "202": "Development and Acquisition",
      "32": "Development and Acquisition",
      "175": null,
      "252": "Planned (not in production)",
      "216": "Operation and Maintenance",
      "204": "Operation and Maintenance",
      "432": null,
      "240": "Planned (not in production)",
      "292": "Planned (not in production)",
      "132": null,
      "373": null,
      "227": "Operation and Maintenance",
      "194": null,
      "331": null,
      "34": "Development and Acquisition",
      "367": null,
      "89": "Problem Scoping",
      "379": "Planned (not in production)",
      "434": null,
      "383": "Planned (not in production)",
      "291": "Planned (not in production)",
      "456": null,
      "343": null,
      "414": "Initiation",
      "366": null,
      "347": null,
      "187": null,
      "145": "Operation and Maintenance",
      "307": "In production: more than 1 year",
      "16": "Operation and Management",
      "58": null,
      "277": "In production: more than 1 year",
      "305": "In production: more than 1 year",
      "255": "In production: more than 1 year",
      "320": "Initiation",
      "324": "Operation and Maintenance"
    },
    "Contact Name": {
      "296": "Coyan Joshua",
      "333": null,
      "411": "Vachhani, Ankit",
      "82": "Voran, Steve",
      "230": null,
      "150": null,
      "15": null,
      "195": null,
      "297": "David Wald",
      "311": null,
      "159": null,
      "427": null,
      "363": null,
      "397": null,
      "266": "Buscombe, Daniel",
      "365": null,
      "238": null,
      "257": "John Hammond",
      "102": "Kerman, Mitchell C.",
      "449": null,
      "71": "Reeves, Heather",
      "121": "mitchell.kerman@inl.gov",
      "55": "Herold, Nate",
      "143": null,
      "191": null,
      "374": null,
      "314": null,
      "211": null,
      "163": null,
      "273": "Arundel, Samantha",
      "237": null,
      "364": null,
      "256": "Stacey Archfield",
      "20": null,
      "183": null,
      "60": "Moore, Stephanie",
      "353": null,
      "62": "Moreland, Erin",
      "117": "mitchell.kerman@inl.gov",
      "260": "Letcher, Ben",
      "447": null,
      "284": "Zwart, Jacob",
      "179": null,
      "234": null,
      "417": "Vachhani, Ankit",
      "356": null,
      "327": null,
      "96": "Kerman, Mitchell C.",
      "210": null,
      "199": null,
      "229": null,
      "310": null,
      "235": null,
      "182": null,
      "340": null,
      "442": null,
      "401": null,
      "139": null,
      "17": null,
      "166": null,
      "147": null,
      "157": null,
      "27": null,
      "67": "Pavolonis, Mike",
      "208": null,
      "354": null,
      "120": "mitchell.kerman@inl.gov",
      "140": null,
      "431": null,
      "332": null,
      "35": null,
      "322": null,
      "358": null,
      "64": "Nelson, James",
      "127": "Frank, Gregory",
      "59": "Manzello, Derek",
      "126": "Frank, Gregory",
      "12": null,
      "103": "Kerman, Mitchell C.",
      "105": "Kerman, Mitchell C.",
      "334": null,
      "410": "Vachhani, Ankit",
      "335": null,
      "219": null,
      "18": null,
      "203": null,
      "142": null,
      "393": null,
      "440": null,
      "125": "Frank, Gregory",
      "369": null,
      "443": null,
      "407": "Vachhani, Ankit",
      "308": "Bourque, Monique",
      "44": "Bajwa, Prabhjot",
      "29": null,
      "98": "Kerman, Mitchell C.",
      "390": null,
      "438": null,
      "329": null,
      "3": null,
      "375": null,
      "50": "Collins, Dan",
      "246": "Agee, Stephen",
      "41": "Kirwin, Patrick",
      "72": "Richards, Benjamin",
      "413": "Vachhani, Ankit",
      "349": null,
      "380": null,
      "420": null,
      "94": "Kerman, Mitchell C.",
      "30": null,
      "0": null,
      "130": "Frank, Gregory",
      "446": null,
      "454": null,
      "249": "Boone, Adam",
      "247": "Boone, Adam",
      "196": null,
      "38": null,
      "352": null,
      "69": "Rachmeler, Laurel",
      "261": "Letcher, Ben",
      "409": "Vachhani, Ankit",
      "228": null,
      "36": null,
      "423": null,
      "422": null,
      "223": null,
      "226": null,
      "22": null,
      "312": null,
      "165": null,
      "26": null,
      "372": null,
      "267": "Adams, Josh",
      "448": null,
      "170": null,
      "437": null,
      "119": "mitchell.kerman@inl.gov",
      "337": null,
      "355": null,
      "74": "Seminoff, Jeffrey",
      "338": null,
      "78": "Van Der Westhuysen, Andre",
      "180": null,
      "138": null,
      "389": null,
      "45": "Alger, Brett",
      "93": "Kerman, Mitchell C.",
      "193": null,
      "263": "Landolt, Kyle",
      "68": "Pavolonis, Mike",
      "350": null,
      "24": null,
      "395": null,
      "436": null,
      "362": null,
      "136": null,
      "270": "Legleiter, Carl",
      "221": null,
      "6": null,
      "244": "Klein, Matthew",
      "1": null,
      "285": "Smith, Jared",
      "357": null,
      "114": "mitchell.kerman@inl.gov",
      "328": null,
      "313": null,
      "13": null,
      "214": null,
      "131": "Frank, Gregory",
      "233": null,
      "56": "Khan, Christin",
      "90": "Kerman, Mitchell C.",
      "421": null,
      "323": null,
      "65": "Oliver, Thomas",
      "176": null,
      "289": "Sadler, Jeffrey",
      "428": null,
      "11": null,
      "258": "Hitt, Nathaniel",
      "97": "Kerman, Mitchell C.",
      "265": "Buscombe, Daniel",
      "113": "mitchell.kerman@inl.gov",
      "207": null,
      "315": null,
      "231": null,
      "239": null,
      "396": null,
      "47": "Berchok, Catherine",
      "10": null,
      "371": null,
      "288": "Sadler, Jeffrey",
      "251": "Tracey, Jeff",
      "370": null,
      "149": null,
      "75": "Soldevilla, Melissa",
      "76": "Sweeney, Katie",
      "122": "mitchell.kerman@inl.gov",
      "101": "Kerman, Mitchell C.",
      "394": null,
      "400": null,
      "133": "Frank, Gregory",
      "37": null,
      "205": null,
      "302": "Withers, Kyle",
      "48": "Campbell, Matthew",
      "2": null,
      "115": "mitchell.kerman@inl.gov",
      "152": null,
      "359": null,
      "319": null,
      "190": null,
      "301": "Cochran, Elizabeth",
      "57": "Krasnopolosky, Vladimir",
      "217": null,
      "242": "Nowak, Kenneth",
      "25": null,
      "53": "Fan, Yun",
      "245": "Klein, Matthew",
      "110": "Kerman, Mitchell C.",
      "412": "Vachhani, Ankit",
      "435": null,
      "177": null,
      "453": null,
      "325": null,
      "88": null,
      "218": null,
      "8": null,
      "128": "Frank, Gregory",
      "286": "Read, Jordan",
      "185": null,
      "141": null,
      "271": "Williamson, Tanja",
      "351": null,
      "112": "mitchell.kerman@inl.gov",
      "236": null,
      "404": "Vachhani, Ankit",
      "92": "Kerman, Mitchell C.",
      "111": "mitchell.kerman@inl.gov",
      "54": "Hazen, Elliott",
      "167": null,
      "66": "Pavolonis, Mike",
      "124": "Frank, Gregory",
      "178": null,
      "160": null,
      "426": null,
      "452": null,
      "378": null,
      "129": "Frank, Gregory",
      "318": null,
      "100": "Kerman, Mitchell C.",
      "416": "Vachhani, Ankit",
      "457": null,
      "295": "Cerovski-Darriau, Corina",
      "215": null,
      "134": null,
      "19": null,
      "344": null,
      "399": null,
      "254": "Tracey, Jeff",
      "294": "Shavers, Ethan",
      "342": null,
      "339": null,
      "385": null,
      "189": null,
      "9": null,
      "39": "Russell, Ryan",
      "155": null,
      "243": "King, Vanessa",
      "224": null,
      "31": null,
      "433": null,
      "415": "Vachhani, Ankit",
      "168": null,
      "309": null,
      "153": null,
      "107": "Kerman, Mitchell C.",
      "80": "Zhang, Chen",
      "275": "Dewitz, Jon",
      "43": "Barr, Morgan",
      "293": "Topp, Simon",
      "406": "Vachhani, Ankit",
      "116": "mitchell.kerman@inl.gov",
      "137": null,
      "248": "Boone, Adam",
      "154": null,
      "109": "Kerman, Mitchell C.",
      "321": null,
      "95": "Kerman, Mitchell C.",
      "382": null,
      "425": null,
      "184": null,
      "429": null,
      "173": null,
      "222": null,
      "253": "Tracey, Jeff",
      "188": null,
      "77": "Sweeney, Katie",
      "268": "Katoski, Michelle",
      "278": "Lynch, Abigail",
      "241": "Nowak, Kenneth",
      "46": "Angliss, Robyn",
      "336": null,
      "201": null,
      "79": "Van Der Westhuysen, Andre",
      "386": null,
      "162": null,
      "299": "Yeck, William",
      "161": null,
      "23": null,
      "300": "Cochran, Elizabeth",
      "282": "Gorski, Galen",
      "276": "Bagstad, Kenneth",
      "451": null,
      "360": null,
      "403": null,
      "148": null,
      "158": null,
      "346": null,
      "33": null,
      "306": "Bourque, Monique",
      "81": "Eales, Bradley",
      "220": null,
      "290": "Read, Jordan",
      "42": "Kennedy, Brooke",
      "51": "Cromwell, Megan",
      "345": null,
      "86": "Yang, Nelson",
      "391": null,
      "197": null,
      "424": null,
      "200": null,
      "225": null,
      "123": "mitchell.kerman@inl.gov",
      "388": null,
      "348": null,
      "274": "Arundel, Samantha",
      "91": "Kerman, Mitchell C.",
      "164": null,
      "151": null,
      "156": null,
      "384": null,
      "212": null,
      "281": "Smith, Jared",
      "87": "Beliveau, Scott",
      "171": null,
      "455": null,
      "326": null,
      "174": null,
      "4": null,
      "445": null,
      "441": null,
      "192": null,
      "264": "Goodling, Phillip",
      "269": "Legleiter, Carl",
      "5": null,
      "209": null,
      "287": "McAliley, Wallace (Andy)",
      "63": "Nelson, James",
      "206": null,
      "108": "Kerman, Mitchell C.",
      "272": "Casazza, Michael",
      "144": null,
      "198": null,
      "49": "Campbell, Matthew",
      "298": "Aagaard, Brad",
      "398": null,
      "402": null,
      "40": "Howard, Ed",
      "85": "Doninger, Chris",
      "83": "Horner, Jon",
      "14": null,
      "341": null,
      "430": null,
      "444": null,
      "172": null,
      "381": null,
      "262": "Cashman, Matthew",
      "392": null,
      "280": "Wieferich, Daniel",
      "70": "Rankin, Shannon",
      "439": null,
      "387": null,
      "279": "Kowalski, Kurt",
      "146": null,
      "52": "Fan, Yun",
      "106": "Kerman, Mitchell C.",
      "450": null,
      "405": "Vachhani, Ankit",
      "99": "Kerman, Mitchell C.",
      "61": "Moreland, Erin",
      "7": null,
      "186": null,
      "283": "Oliver, Samantha",
      "330": null,
      "232": null,
      "21": null,
      "213": null,
      "408": "Vachhani, Ankit",
      "250": "Tracey, Jeff",
      "118": "mitchell.kerman@inl.gov",
      "169": null,
      "259": "Lotspeich, Russ",
      "181": null,
      "104": "Kerman, Mitchell C.",
      "303": "Yoon, Clara",
      "84": "Yang, Nelson",
      "317": null,
      "135": null,
      "419": null,
      "28": null,
      "304": "Yoon, Clara",
      "418": null,
      "73": "Rosencrans, Matthew",
      "368": null,
      "316": null,
      "202": null,
      "32": null,
      "175": null,
      "252": "Tracey, Jeff",
      "216": null,
      "204": null,
      "432": null,
      "240": "German, Jesse",
      "292": "Barclay, Janet",
      "132": "Frank, Gregory",
      "373": null,
      "227": null,
      "194": null,
      "331": null,
      "34": null,
      "367": null,
      "89": "Byung-Jun, Yoon",
      "379": null,
      "434": null,
      "383": null,
      "291": "Topp, Simon",
      "456": null,
      "343": null,
      "414": "Vachhani, Ankit",
      "366": null,
      "347": null,
      "187": null,
      "145": null,
      "307": "Bourque, Monique",
      "16": null,
      "58": "Krasnopolosky, Vladimir",
      "277": "Lynch, Abigail",
      "305": "Bourque, Monique",
      "255": "Roy Sando",
      "320": null,
      "324": null
    },
    "Contact Email": {
      "296": "jcoyan@usgs.gov",
      "333": null,
      "411": "AI@usaid.gov",
      "82": "svoran@ntia.gov",
      "230": null,
      "150": null,
      "15": null,
      "195": null,
      "297": "wald@usgs.gov",
      "311": null,
      "159": null,
      "427": null,
      "363": null,
      "397": null,
      "266": "dbuscombe@contractor.usgs.gov",
      "365": null,
      "238": null,
      "257": "jhammond@usgs.gov",
      "102": "mitchell.kerman@inl.gov",
      "449": null,
      "71": "heather.reeves@noaa.gov",
      "121": null,
      "55": "nate.herold@noaa.gov",
      "143": null,
      "191": null,
      "374": null,
      "314": null,
      "211": null,
      "163": null,
      "273": "sarundel@usgs.gov",
      "237": null,
      "364": null,
      "256": "sarch@usgs.gov",
      "20": null,
      "183": null,
      "60": "stephanie.moore@noaa.gov",
      "353": null,
      "62": "erin.moreland@noaa.gov",
      "117": null,
      "260": "bletcher@usgs.gov",
      "447": null,
      "284": "jzwart@usgs.gov",
      "179": null,
      "234": null,
      "417": "AI@usaid.gov",
      "356": null,
      "327": null,
      "96": "mitchell.kerman@inl.gov",
      "210": null,
      "199": null,
      "229": null,
      "310": null,
      "235": null,
      "182": null,
      "340": null,
      "442": null,
      "401": null,
      "139": null,
      "17": null,
      "166": null,
      "147": null,
      "157": null,
      "27": null,
      "67": "mike.pavolonis@noaa.gov",
      "208": null,
      "354": null,
      "120": null,
      "140": null,
      "431": null,
      "332": null,
      "35": null,
      "322": null,
      "358": null,
      "64": "james.a.nelson@noaa.gov",
      "127": "gregory.frank@hq.doe.gov",
      "59": "derek.manzello@noaa.gov",
      "126": "gregory.frank@hq.doe.gov",
      "12": null,
      "103": "mitchell.kerman@inl.gov",
      "105": "mitchell.kerman@inl.gov",
      "334": null,
      "410": "AI@usaid.gov",
      "335": null,
      "219": null,
      "18": null,
      "203": null,
      "142": null,
      "393": null,
      "440": null,
      "125": "gregory.frank@hq.doe.gov",
      "369": null,
      "443": null,
      "407": "AI@usaid.gov",
      "308": "monique.bourque@usdoj.gov",
      "44": "pbajwa@doc.gov",
      "29": null,
      "98": "mitchell.kerman@inl.gov",
      "390": null,
      "438": null,
      "329": null,
      "3": null,
      "375": null,
      "50": "dan.collins@noaa.gov",
      "246": "sagee@usbr.gov",
      "41": "patrick.kirwin@trade.gov",
      "72": "benjamin.richards@noaa.gov",
      "413": "AI@usaid.gov",
      "349": null,
      "380": null,
      "420": null,
      "94": "mitchell.kerman@inl.gov",
      "30": null,
      "0": null,
      "130": "gregory.frank@hq.doe.gov",
      "446": null,
      "454": null,
      "249": "adam.boone@bsee.gov",
      "247": "adam.boone@bsee.gov",
      "196": null,
      "38": null,
      "352": null,
      "69": "laurel.rachmeler@noaa.gov",
      "261": "bletcher@usgs.gov",
      "409": "AI@usaid.gov",
      "228": null,
      "36": null,
      "423": null,
      "422": null,
      "223": null,
      "226": null,
      "22": null,
      "312": null,
      "165": null,
      "26": null,
      "372": null,
      "267": "josh_adams@usgs.gov",
      "448": null,
      "170": null,
      "437": null,
      "119": null,
      "337": null,
      "355": null,
      "74": "jeffrey.seminoff@noaa.gov",
      "338": null,
      "78": "andre.vanderwesthuysen@noaa.gov",
      "180": null,
      "138": null,
      "389": null,
      "45": "brett.alger@noaa.gov",
      "93": "mitchell.kerman@inl.gov",
      "193": null,
      "263": "klandolt@usgs.gov",
      "68": "mike.pavolonis@noaa.gov",
      "350": null,
      "24": null,
      "395": null,
      "436": null,
      "362": null,
      "136": null,
      "270": "cjl@usgs.gov",
      "221": null,
      "6": null,
      "244": "mklein@usbr.gov",
      "1": null,
      "285": "jsmith@usgs.gov",
      "357": null,
      "114": null,
      "328": null,
      "313": null,
      "13": null,
      "214": null,
      "131": "gregory.frank@hq.doe.gov",
      "233": null,
      "56": "christin.khan@noaa.gov",
      "90": "mitchell.kerman@inl.gov",
      "421": null,
      "323": null,
      "65": "thomas.oliver@noaa.gov",
      "176": null,
      "289": "jsadler@usgs.gov",
      "428": null,
      "11": null,
      "258": "nhitt@usgs.gov",
      "97": "mitchell.kerman@inl.gov",
      "265": "dbuscombe@contractor.usgs.gov",
      "113": null,
      "207": null,
      "315": null,
      "231": null,
      "239": null,
      "396": null,
      "47": "cathering.bderchok@noaa.gov",
      "10": null,
      "371": null,
      "288": "jsadler@usgs.gov",
      "251": "jatracey@usgs.gov",
      "370": null,
      "149": null,
      "75": "melissa.soldevilla@noaa.gov",
      "76": "katie.sweeney@noaa.gov",
      "122": null,
      "101": "mitchell.kerman@inl.gov",
      "394": null,
      "400": null,
      "133": "gregory.frank@hq.doe.gov",
      "37": null,
      "205": null,
      "302": "kwithers@usgs.gov",
      "48": "matthew.d.campbell@noaa.gov",
      "2": null,
      "115": null,
      "152": null,
      "359": null,
      "319": null,
      "190": null,
      "301": "ecochran@usgs.gov",
      "57": "vladimir.krasnopolsky@noaa.gov",
      "217": null,
      "242": "knowak@usbr.gov",
      "25": null,
      "53": "yun.fan@noaa.gov",
      "245": "mklein@usbr.gov",
      "110": "mitchell.kerman@inl.gov",
      "412": "AI@usaid.gov",
      "435": null,
      "177": null,
      "453": null,
      "325": null,
      "88": null,
      "218": null,
      "8": null,
      "128": "gregory.frank@hq.doe.gov",
      "286": "jread@usgs.gov",
      "185": null,
      "141": null,
      "271": "tnwillia@usgs.gov",
      "351": null,
      "112": null,
      "236": null,
      "404": "AI@usaid.gov",
      "92": "mitchell.kerman@inl.gov",
      "111": null,
      "54": "elliot.hazen@noaa.gov",
      "167": null,
      "66": "mike.pavolonis@noaa.gov",
      "124": "gregory.frank@hq.doe.gov",
      "178": null,
      "160": null,
      "426": null,
      "452": null,
      "378": null,
      "129": "gregory.frank@hq.doe.gov",
      "318": null,
      "100": "mitchell.kerman@inl.gov",
      "416": "AI@usaid.gov",
      "457": null,
      "295": "ccerovski-darriau@usgs.gov",
      "215": null,
      "134": null,
      "19": null,
      "344": null,
      "399": null,
      "254": "jatracey@usgs.gov",
      "294": "eshavers@usgs.gov",
      "342": null,
      "339": null,
      "385": null,
      "189": null,
      "9": null,
      "39": "Ryan.Russell@trade.gov",
      "155": null,
      "243": "vking@usbr.gov",
      "224": null,
      "31": null,
      "433": null,
      "415": "AI@usaid.gov",
      "168": null,
      "309": null,
      "153": null,
      "107": "mitchell.kerman@inl.gov",
      "80": "chen.zhang@noaa.gov",
      "275": "dewitz@usgs.gov",
      "43": "morgan.barr@trade.gov",
      "293": "stopp@usgs.gov",
      "406": "AI@usaid.gov",
      "116": null,
      "137": null,
      "248": "adam.boone@bsee.gov",
      "154": null,
      "109": "mitchell.kerman@inl.gov",
      "321": null,
      "95": "mitchell.kerman@inl.gov",
      "382": null,
      "425": null,
      "184": null,
      "429": null,
      "173": null,
      "222": null,
      "253": "jatracey@usgs.gov",
      "188": null,
      "77": "katie.sweeney@noaa.gov",
      "268": "mkatoski@usgs.gov",
      "278": "ajlynch@usgs.gov",
      "241": "knowak@usbr.gov",
      "46": "robyn.angliss@noaa.gov",
      "336": null,
      "201": null,
      "79": "andre.vanderwesthuysen@noaa.gov",
      "386": null,
      "162": null,
      "299": "wyeck@usgs.gov",
      "161": null,
      "23": null,
      "300": "ecochran@usgs.gov",
      "282": "ggorski@usgs.gov",
      "276": "kjbagstad@usgs.gov",
      "451": null,
      "360": null,
      "403": null,
      "148": null,
      "158": null,
      "346": null,
      "33": null,
      "306": "monique.bourque@usdoj.gov",
      "81": "beales@ntia.gov",
      "220": null,
      "290": "jread@usgs.gov",
      "42": "brook.kennedy@trade.gov",
      "51": "megan.cromwell@noaa.gov",
      "345": null,
      "86": "nelson.yang@uspto.gov",
      "391": null,
      "197": null,
      "424": null,
      "200": null,
      "225": null,
      "123": null,
      "388": null,
      "348": null,
      "274": "sarundel@usgs.gov",
      "91": "mitchell.kerman@inl.gov",
      "164": null,
      "151": null,
      "156": null,
      "384": null,
      "212": null,
      "281": "jsmith@usgs.gov",
      "87": "scott.beliveau@uspto.gov",
      "171": null,
      "455": null,
      "326": null,
      "174": null,
      "4": null,
      "445": null,
      "441": null,
      "192": null,
      "264": "pgoodling@usgs.gov",
      "269": "cjl@usgs.gov",
      "5": null,
      "209": null,
      "287": "wmcaliley@usgs.gov",
      "63": "james.a.nelson@noaa.gov",
      "206": null,
      "108": "mitchell.kerman@inl.gov",
      "272": "mike_casazza@usgs.gov",
      "144": null,
      "198": null,
      "49": "matthew.d.campbell@noaa.gov",
      "298": "baagaard@usgs.gov",
      "398": null,
      "402": null,
      "40": "Ed.Howard@trade.gov",
      "85": "chris.doninger@uspto.gov",
      "83": "jonathan.horner@uspto.gov",
      "14": null,
      "341": null,
      "430": null,
      "444": null,
      "172": null,
      "381": null,
      "262": "mcashman@usgs.gov",
      "392": null,
      "280": "dwieferich@usgs.gov",
      "70": "shannon.rankin@noaa.gov",
      "439": null,
      "387": null,
      "279": "kkowalski@usgs.gov",
      "146": null,
      "52": "yun.fan@noaa.gov",
      "106": "mitchell.kerman@inl.gov",
      "450": null,
      "405": "AI@usaid.gov",
      "99": "mitchell.kerman@inl.gov",
      "61": "erin.moreland@noaa.gov",
      "7": null,
      "186": null,
      "283": "soliver@usgs.gov",
      "330": null,
      "232": null,
      "21": null,
      "213": null,
      "408": "AI@usaid.gov",
      "250": "jatracey@usgs.gov",
      "118": null,
      "169": null,
      "259": "rlotspei@usgs.gov",
      "181": null,
      "104": "mitchell.kerman@inl.gov",
      "303": "cyoon@usgs.gov",
      "84": "nelson.yang@uspto.gov",
      "317": null,
      "135": null,
      "419": null,
      "28": null,
      "304": "cyoon@usgs.gov",
      "418": null,
      "73": "matthew.rosencrans@noaa.gov",
      "368": null,
      "316": null,
      "202": null,
      "32": null,
      "175": null,
      "252": "jatracey@usgs.gov",
      "216": null,
      "204": null,
      "432": null,
      "240": "jgerman@blm.gov",
      "292": "jbarclay@usgs.gov",
      "132": "gregory.frank@hq.doe.gov",
      "373": null,
      "227": null,
      "194": null,
      "331": null,
      "34": null,
      "367": null,
      "89": "byoon@bnl.gov",
      "379": null,
      "434": null,
      "383": null,
      "291": "stopp@usgs.gov",
      "456": null,
      "343": null,
      "414": "AI@usaid.gov",
      "366": null,
      "347": null,
      "187": null,
      "145": null,
      "307": "monique.bourque@usdoj.gov",
      "16": null,
      "58": "vladimir.krasnopolsky@noaa.gov",
      "277": "ajlynch@usgs.gov",
      "305": "monique.bourque@usdoj.gov",
      "255": "tsando@usgs.gov",
      "320": null,
      "324": null
    },
    "project_title_text": {
      "296": "Data\u2013driven prospectivity modelling of sediment\u2013hosted Zn\u2013Pb mineral systems and their critical raw materials\nRegional data (magnetics and their derivatives, gravity and their derivatives, black shales, terrane boundaries, LAB depths, permissive geology, paleo-latitude etc.) is loaded into Uber's H3 cube. Clastic Dominated (CD) and  Mississippi Valley Type (MVT) deposits are used to train a Weights of Evidence model and two different Gradient-Boosting Machine models. After training occured the result was a prospecticvity map for CD and MVT deposits in the three countries. ",
      "333": "Medicare Part D Subsidy Model\nThis model uses machine learning to identify cases most likely to have incorrect Medicare Part D subsidies and flag them for technician review.",
      "411": "Breakthrough RESEARCH\u2019s Social Media Listening\nSocial media listening draws on machine learning to synthesize and organize the vast quantities of data shared over social media platforms. Breakthrough RESEARCH carried out social listening on 12,301 social media posts in Nigeria to explore how gender-related online conversations manifest themselves and whether they have changed in the last five years. Using Crimson Hexagon\u2019s machine learning algorithm, \u201cBrightview,\u201d publicly available social media content originating in the countries of interest was scraped by the algorithm, for posts relevant to RH/FP and youth. The resulting social media posts were then classified by topic, using language detected in the content. This provided a dataset categorizing conversations into overarching topics, allowing analyses to uncover key trends in topic specific conversation volume, insights about misinformation, attitudes and social norms, and more. The machine learning algorithm was able to identify relevant social media content. The 12,301 social media posts were qualitatively assessed and categorized, allowing researchers to monitor and track social media conversations far more expansively than allowed by research methods more traditionally used in public health and SBC programs.",
      "82": "WAWENETS\nThe algorithm produces estimates of telecommunications speech quality and speech \nintelligibility.  The input is a recording of speech from a telecommunications system in \ndigital file format.  The output is a single number that indicates speech quality (typically \non a 1 to 5 scale) or speech intelligibility (typically on a 0 to 1 scale).",
      "230": "Barcode Scanner \nThe Barcode Scanner has been developed to scan and populate detected information into corresponding text fields within the RAVEn GO's Encounter Card. The barcode scanner currently supports\u00a0MRZ and PDF417 barcode types, frequently found on travel documents (Passport and Passport cards) and US Driver's Licenses.\u00a0\n\nThis is a DHS HSI Innovation Lab / RAVEn project. The Repository for Analytics in a Virtualized Environment (RAVEn) facilitates large, complex analytical projects to support ICE\u2019s mission to enforce and investigate violations of U.S. criminal, civil, and administrative laws. RAVEn also enables tools used to analyze trends and isolate criminal patterns as HSI mission needs arise. For more information, please read the DHS/ICE/PIA-055 - Privacy Impact Assessment 055 for RAVEn.",
      "150": "Auto-generation Synonyms\nBehind the scenes, adding synonyms to search queries to improve search results",
      "15": "Retailer Receipt Analysis\nThe Retailer Receipt Analysis is a Proof of Concept (POC) that uses Optical Character Recognition (OCR), an application of artificial intelligence on a sample (no more than 1000) of FNS receipt and invoice data. Consultants will use this data to demonstrate how the existing manual process can be automated, saving staff time, ensuring accurate review, and detecting difficult patterns. The goal of this POC will pave the way for a review system that (1) has an automated workflow and learns from analyst feedback (2) can incorporate know SNAP fraud patterns, look for new patterns, and visualize alerts on these patterns on retailer invoices and receipts.",
      "195": "Text Analytics Portal\nThe text analytics portal allows personnel without an analytics background to quickly examine text documents through a\nrelated set of search, topic modeling and entity recognition technologies",
      "297": "Updating Real-time Earthquake Shaking, Ground Failure, and Impact products with remote sensing and ground truth observations\nA breakthrough for rapid post-earthquake ground failure (GF) and loss modeling and reporting has been achieved with initial Bayesian updating of our global loss and GF models with ground-truth observations. Empirical models suffer from limited performance due to the complex, event-specific causal effects underlying the cascading processes of earthquake-triggered hazards and impacts. In contrast, satellite imagery-based impact assessments (e.g., NASA\u2019s Damage Proxy Maps, or DPMs), while spatially accurate, lack the specificity as to what physical process caused those image changes. We present the first rapid seismic multi-hazard and damage updating framework based on variational Bayesian causal inference and remotely sensed DPMs. This machine learning framework enables accurate and high-resolution multi-hazard and damage estimates by jointly inferring shaking and secondary hazards and resulting building damage and quantifying their causal dependencies from imagery and prior loss and GF models. The underlying physical causal dependencies are modeled using a multi-layer causal Bayesian network. Initial results are impressive, showing that our framework significantly improves the GF prediction abilities. It also reveals the event-specific causal dependencies among ground shaking, GF, building damage, and other environmental factors. We expect improved PAGER products to more rapidly evolve to accurate and thus more actionable images, maps, and products. ",
      "311": "Audio Transcription\nTranscription of speech to text for records keeping using natural language processing models.",
      "159": "Chatbot \u2013 Voice\nCMS/OSFLO: To assist the CMS Badging Help Desk, this Chatbot (voice) is an automated phone response for general\nbadging questions allowing help desk personnel to assist employees and contractors with more detailed/larger issues.",
      "427": "Disentangling dementia patterns using artificial intelligence on brain imaging and electrophysiological data\nThis collaborative effort focuses on developing a deep learning framework to predict the various patterns of dementia seen on MRI and EEG and explore the use of these imaging modalities as biomarkers for various dementias and epilepsy disorders.\u00a0 The VA is performing retrospective chart review to achieve this.",
      "363": "Behavioral Analytics for Online Surveys Test (Makor Analytics)\nGEC executes a Technology Testbed to rapidly test emerging technology applications against foreign disinformation and propaganda challenges. GEC works with interagency and foreign partners to understand operational threats they\u2019re facing and identifies technological countermeasures to apply against the operational challenge via short-duration tests of promising technologies. Makor Analytics is an AI quantitative research company that helps clients understand their audience\u2019s perceptions and feelings helping to mitigate some of the limitations in traditional survey research. Makor Analytics\u2019 proprietary behavioral analytics technology was developed to uncover true convictions and subtle emotions adding additional insights into traditional online survey results. The desired outcome of the pilot is a report analyzing the survey responses using behavioral analytics to provide target audience sentiment insights and subsequent recommendations. By leveraging AI behavioral analytics, the pilot aims to provide additional information beyond self-reported data that reflects sentiment analysis in the country of interest.",
      "397": "Large Corporate \nCompliance\nLarge Corporate Compliance is a machine learning model for classifying \ncorporate taxes.",
      "266": "Coast Train\nCoast Train is a multi-labeler ML-ready dataset of orthomosaic and satellite images of coastal, estuarine, and wetland environments and corresponding thematic label masks. The data consist of spatial and time-series, and contains 1.2 billion labelled pixels, representing over 3.6 million hectares.",
      "365": "NLP to pull key information from unstructured text\nUse NLP to extract information such as country names and agreement dates from dozens of pages of unstructured pdf document",
      "238": "Sentiment Analysis - Surveys\nThe Sentiment Analysis - Surveys system provides a statistical analysis of quantitative results from survey results and then uses Natural Language Processing (NLP) modeling software to assign \"sentiments\" to categories ranging from strongly positive to strongly negative. This allows survey administrators to glean valuable information from employee satisfaction surveys from both quantitative and qualitative data. This capability is currently available on demand.",
      "257": "Water Mission Area Regional Drought Early Warning System\nThe goal of this project is to build and test multiple ML models for predicting and forecasting daily hydrologic drought in the Colorado River Basin (CRB). Similar to the project listed in line 9, we use gridded meteorologic forcing data and daily streamflow data in the CRB to build random forest and neural networks (long-short term memory) to determine the best approach to predicting and forecasting hydrologic drought. The project is being developed on AWS and in cooperation with CHS. We are also using the USGS HPC systems.",
      "102": "Protocol Analytics to enable Forensics \nof Industrial Control Systems\nThe goal of this research is to discover methods and technologies to bridge gaps \nbetween the various industrial control systems (ICS) communication protocols and \nstandard Ethernet to enable existing cybersecurity tools defend ICS networks and \nempower cybersecurity analysts to detect compromise before threat actors can \ndisrupt infrastructure, damage property, and inflict harm. Research focuses on \nelectronic signal analysis of captured communication to determine the protocol, using \nuse machine learning to identify unknown protocols. Findings will be incorporated into \na prototype device.",
      "449": "Reinforcement learning evaluation of treatment policies for patients with hepatitis C virus\nA machine learning model is used to predict disease progression among veterans with hepatitis C virus.",
      "71": "ProbSR (probability of subfreezing \nroads\nA machine-learned algorithm that provides a 0-100% probability roads are subfreezing",
      "121": "Data-driven failure diagnosis and \nprognosis of solid-state ceramic \nmembrane reactor under harsh \nconditions using deep learning \ntechnology with internal voltage sensors\nThis research will investigate in situ the effects of different components on the \ndegradation behavior in a solid-state ceramic membrane reactor by embedding \nsensors that will collect current and impedance data during operation. Artificial \nintelligence will be used to understand the large amounts of data and predict reactor \nfailure under harsh operating conditions.",
      "55": "Coastal Change Analysis Program \n(C-CAP)\nBeginning in 2015, C-CAP embarked on operational high resolution land cover \ndevelopment effort that utilized geographic object-based image analysis and ML \nalgorithms such as Random Forest to classify coastal land cover from 1m multispectral \nimagery. More recently, C-CAP has been relying on a CNN approach for the deriving the \nimpervious surface component of their land cover products. The majority of the work is \naccomplished through external contracts. Prior to the high-res effort, C-CAP focused on \ndeveloping Landsat based moderate resolution multi-date land cover for the coastal U.S. \nIn 2002, C-CAP adopted a methodology that employed Classification and Regression Trees \nfor land cover data development.",
      "143": "Service Desk Virtual Agent (Curie)\nVirtual agent that uses ML to provide predictive results for chat entries. A natural language chatbot (virtual assistant), we named Curie, as part of a multi-model customer service experience for employee's IT service requests leveraging knowledge-based articles.",
      "191": "Query View Report (QVR) LIKE\nThe LIKE feature in QVR makes use of the NIH Research, Condition and Disease Categorization (RCDC) indexing results to\ncompare scientific terms associated with a project, person or publication and find scientifically similar projects, persons\nor publications.",
      "374": "Image Clustering\nUses a pretrained deep learning model to generate image embeddings, then uses hierarchical clustering to identify similar images.",
      "314": "Website Chatbot Assistant\nThe chatbot helps the end user with basic information about the program, information on who to contact, or seeking petition case status.",
      "211": "Vessel Detection\nIntegrated technologies and analytics enhance maritime detection and the sensor network. Machine-assisted and AI-enhanced detection and tracking allows for improved illicit vessel detection in areas with high volumes of legitimate trade and recreational water vessel traffic by increasing situational awareness and responsiveness to threats.\n\nVessel Detection allows an agent to set a search area with criteria (e.g., people, drones, vehicles) and transmit that criteria to the sensors.  Images detected by the sensors are auto-recognized using Artificial Intelligence. The AI algorithms filter, detect, and recognize objects and divides them into Items of Interest (IoI) and \"other\" objects. \n\nDetections of IoI are shared with other detection systems while detections of other objects (e.g., animals) are not shared. IoIs can be tracked and maintained across multiple sensors seamlessly.",
      "163": "Reasonable Accommodation RPA Bot\nThe Bot pulls HR data related to staffing changes, e.g. promotions, reassignments, change in supervisor, and generates\ninformation for action by Reasonable Accommodation staff to ensure disability reasonable accommodations follow the\nEmployee.",
      "273": "Spot Elevation OCR from historical topo maps\nThe goal of this project is to create a database of summit spot elevations from the HTMC labeled for summits in CONUS.",
      "237": "Predicted to Naturalize\nThe Predicted to Naturalize model predicts when Legal Permanent Residents would be eligible to naturalize, and attempts to provide a current address. This model could potentially be used to send correspondence to USCIS customers of their resident status, and notify others of potential USCIS benefits.",
      "364": "Crisis Campaign Cable Analytics\nUse optical character recognition and natural language processing on Department cables in order to evaluate gaps and trends in crisis training and bolster post preparedness for crisis events.",
      "256": "Water Mission Area Drought Prediction Project\nThe goal of this project is to develop a method for predicting daily hydrologic drought using machine learning models calibrated on streamflow data (response) and meteorological forcing data. Models will be built at individual gages across CONUS, then transferred to ungaged basins using a 'donor model' approach that identifies which gages are most similar to the ungaged basin and combines the models from those gages for the final prediction. Models will be developed and run on the USGS HPC systems. ",
      "20": "RMRS Raster Utility\nRMRS Raster Utility is a .NET object oriented library that simplifies data acquisition, raster sampling, and statistical and spatial modeling while reducing the processing time and storage space associated with raster analysis. It includes machine learning techniques.",
      "183": "MetaMap to identity potential terms for indexing MEDLINE articles\nMetaMap is a widely available program providing access from biomedical text to the concepts in the unified medical\nlanguage system (UMLS) Metathesaurus. MetaMap uses NLP to provide a link between the text of biomedical literature\nand the knowledge, including synonymy relationships, embedded in the Metathesaurus. The flexible architecture in\nwhich to explore mapping strategies and their application are made available. MTI uses the MetaMap to generate\npotential indexing terms.",
      "60": "Robotic microscopes and machine \nlearning algorithms remotely and \nautonomously track lower trophic \nlevels for improved ecosystem \nmonitoring and assessment\nPhytoplankton are the foundation of marine food webs supporting fisheries and coastal \ncommunities. They respond rapidly to physical and chemical oceanography, and changes \nin phytoplankton communities can impact the structure and functioning of food webs. We \nuse a robotic microscope called an Imaging Flow Cytobot (IFCB) to continuously collect \nimages of phytoplankton from seawater. Automated taxonomic identification of imaged \nphytoplankton uses a supervised machine learning approach (random forest algorithm). \nWe deploy the IFCB on fixed (docks) and roving (aboard survey ships) platforms to \nautonomously monitor phytoplankton communities in aquaculture areas in Puget Sound \nand in the California Current System. We map the distribution and abundance of \nphytoplankton functional groups and their relative food value to support fisheries and \naquaculture and describe their changes in relation to ocean and climate variability and \nchange.",
      "353": "Apptio\nWorking Capital Fund (IRM/WCF) uses Apptio to bill bureaus for consolidated services run from the WCF. Cost models are built in Apptio so bureaus can budget for the service costs in future FYs. Apptio has the capability to extrapolate future values using several available formulas.",
      "62": "Ice seal detection and species \nclassification in multispectral \naerial imagery\nRefine and improve detection and classification pipelines with the goal of reducing false \npositive rates (to < 50%) while maintaining > 90% accuracy and significantly reducing or \neliminating the labor intensive, post survey review process.",
      "117": "Evaluating thermal properties of \nadvanced materials\nThe standard thermal diffusivity measurement technique laser flash is enhanced by \nmodifying the traditional experimental set up and analyzing results with a machine \nlearning based tool that includes a finite element model, a least-squares fitting \nalgorithm and experimental data treatment algorithms. This tool helps elucidate thermo-\nphysical properties of a material from a single laser flash measurement.",
      "260": "Estimating stream flow from images in headwaters\nThe goals of this project are to 1) measure how much water flows in small, ungaged stream networks using timelapse images captured by inexpensive and off-the-shelf cameras and 2) provide a web-based platform for making the images, associated climate and other related data as well as the model itself easy to access and explore. Data for training come from user-uploaded imagery and flow data (when available). Database is available for uploading and image viewing here: https://www.usgs.gov/apps/ecosheds/fpe/",
      "447": "Predicting corticosteroid free endoscopic remission with Vedolizumab in ulcerative colitis\nThis work uses random forest modeling on a cohort of 594 patients with Vedolizumab to predict the outcome of corticosteroid-free biologic remission at week 52 on the testing cohort. Models were constructed using baseline data or data through week 6 of VDZ therapy.",
      "284": "Forecasting Water Temperature in the Delaware River Basin \nWe developed a process-guided deep learning and data assimilation approach to operationally produce 7-day forecasts of daily maximum stream water temperature downstream of drinking water reservoirs in support of water management decisions. Our process-guided deep learning model was pretrained on output from an integrated stream-reservoir process-based model and used an autoregressive technique and data assimilation to ingest real-time observations of stream temperature to improve near-term forecasts. Our modeling system produced forecasts of daily maximum water temperature with an average root mean squared error (RMSE) from 1.1 to 1.4\u00b0C for 1-day-ahead and 1.4 to 1.9\u00b0C for 7-day-ahead forecasts across all sites. ",
      "179": "Leveraging AI for Business Process Automation\nNIGMS has developed a method to automate the initial referral of grant applications to the proper scientific expertise\nwithin the Institute using Natural Language Processing and Machine Learning. NIGMS IRMB and DIMA are currently using\nthis NLP/ML algorithm developed in R statistical software to parse grant applications and to determine Project Officer\ncandidates for grant assignment. This process was previously fully manual and required a substantial person hour effort.\nNIGMS has collaborated with the Electronic Records Administration group to incorporate this technique into the Internal\nReferral Module, and the tool is now available to be adapted for broader use across the NIH.",
      "234": "Identity Match Option (IMO) Process with DBIS Data Marts\nThe Identity Match Option (IMO) is used to derive a single identity across multiple systems for each applicant or beneficiary who interacts with USCIS. The IMO aims to aid in person-centric research and analytics. \n\nUSCIS maintains a variety of systems to track specific interactions with individuals \u2013 benefits case management, appointment scheduling, background check validation, and customer service inquiries.  Each system captures its own person-centric data attributes (e.g. SSN, A-number, Name, DOB, address, etc.) related to individuals interacting with the agency. The identity derivation process uses standard entity matching algorithms included as part of the IMO product to leverage these individual instances of person-centric data attributes to derive identities. The system is able to account for a variety of data formats and potential data quality issues in the source data. The resulting identities are linked back to the original source records, allowing analysts to see an individual\u2019s comprehensive immigration history with the agency, perform fraud detection, and identify data quality issues requiring resolution.",
      "417": "NASA SERVIR - Mapping urban vulnerability using AI techniques\nThis activity will improve urban vulnerability assessment in key population centers, particularly by co-creating replicable methods to use satellite imagery to map informal settlements. ",
      "356": "Facebook Ad Test Optimization System\nGPA\u2019s production media collection and analysis system that pulls data from half a dozen different open and commercial media clips services to give an up-to-date global picture of media coverage around the world.",
      "327": "Modernized Development Worksheet (MDW)\nThis process uses AI to review textual data that is part of claim development tasks so it can be categorized into workload topics using natural language processing to facilitate faster technician review.",
      "96": "Artificial Intelligence Enhanced \nAdvanced Post Irradiation Examination\nThis project uses post irradiation examination of uranium-10wt.% zirconium (UZr) \nmetallic fuel as a case study to show how artificial intelligence (AI)-based technology \ncan facilitate and accelerate nuclear fuel development. The approach will 1) revisit the \nmicrostructural image and local thermal conductivity data collected from UZr, 2) build a \nbenchmark dataset for the microstructural patterns of irradiated UZr, and 3) train the \nmachine learning and deep learning models to uncover the relationships between \nmicro/nanoscale structure, zirconium phase redistribution, local thermal conductivity, \nand engineering scale fuel properties.",
      "210": "Use of technology to identify proof of life\nThe Use of technology to identify proof of life, or \"Liveness Detection,\" uses Artificial Intelligence to reduce fraudulent activity, primarily for use within the CBP One app.\n\nThe CBP One app is designed to provide the public with a single portal to a variety of CBP services. It includes different functionality for travelers, importers, brokers, carriers, International Organizations, and other entities under a single consolidated log-in, and uses guided questions to help users determine the correct services, forms, or applications needed.\n\nThe Liveness Detection component used by the authentication system for the CBP One app uses the user's mobile device camera in addition to Artificial Intelligence algorithms to determine if the face presented to the app is the person in front of the camera at the time of capture and not a photo, mask, or other spoofing mechanism. Being able to accept submitted data with confidence that the submitting individual is who and where they claim to be is critical to the functionality of the app within the agency environment. ",
      "199": "AI Curated Synthetic Data\nAI Curated Synthetic Data creates synthetic data for computer vision to enable more capable and ethical AI when detecting anomalies in complex environments.\n\nSpecifically, it creates an emulated X-ray sensor that can produce visually realistic synthetic X-ray scan images similar to real X-ray scan images, and virtual 3D Assets of vehicles and narcotics containers. These images will be used to enhance the development of Anomaly Detection Algorithms for Non-Intrusive Inspection, incorporating AI/ML for the detection of narcotics and other contraband in conveyances and cargo.",
      "229": "Mobile Device Analytics\nMobile Device Analytics (MDA) has been developed to meet the demand on investigators to view and analyze massive amounts of data resulting from court ordered mobile device extractions.  The overarching goal of MDA is to improve the efficacy of agents and analysts in identifying pertinent evidence, relationships, and criminal networks from data extracted from cellular phones. Machine Learning is being developed for object detection (such as firearms, drugs, money, etc.) in photos and videos contained in the data.\n\nThis is a DHS HSI Innovation Lab / RAVEn project. The Repository for Analytics in a Virtualized Environment (RAVEn) facilitates large, complex analytical projects to support ICE\u2019s mission to enforce and investigate violations of U.S. criminal, civil, and administrative laws. RAVEn also enables tools used to analyze trends and isolate criminal patterns as HSI mission needs arise. For more information, please read the DHS/ICE/PIA-055 - Privacy Impact Assessment 055 for RAVEn.",
      "310": "Language Translation\nLanguage translation of published documents and website using natural language processing models.",
      "235": "Person-Centric Identity Services A-Number Management Model\nThe vision of Person-Centric Identity Services (PCIS) is to be the authoritative source of trusted biographical and biometric information that provides real-time, two-way visibility between services into an individual's comprehensive immigration history and status. The A-Number Management model ingests person-centric datasets from various source systems for model training and evaluation purposes. The dataset includes biographic information (name, date of birth, Alien #, Social Security #, passport #, etc.) as well as biographic information (fingerprint IDs, eye color, hair color, height, weight, etc.) for model training and matching purposes. \n\nThe A-Number Management identifies which records from within our identity database best match search criteria. The model uses machine learning to ensure that search results presented to authorized external partners for external integrations and servicing have a high degree of confidence with the search criteria so that trust in the PCIS entity resolution remains high.\n\nThe A-Number Management model plays a critical role in the entity resolution and surfacing of a person and all their associated records. The machine learning models are more capable of resolving \"fuzzy\" matches, and deal with the reality of different data quality.",
      "182": "Determining selection for indexing MEDLINE articles using Neural Network Architecture with a Convolutional Neural Network (CNN)\nUsing the article title, abstract, journal, publication year, and indexing year of indexed and non-indexed articles that were\nsubmitted to MEDLINE in 2018, methods to automate the selection of indexed articles was researched. A classifier was\ndeveloped that combines the predictions of many traditional machine learning algorithms and a Convolutional Neural\nNetwork (CNN). The final classification layer uses a sigmoid activation function to generate a single output value between\nzero and one, which can be interpreted as the probability of an article being in-scope for MEDLINE.",
      "340": "Mobile Wage Reporting (MOBWR) \nMobile Wage Reporting uses AI to extract text/data from scanned images/documents represeting pay stubs or payroll information to enable faster processing.",
      "442": "Prediction of health outcomes, including suicide death, opioid overdose, and decompensated outcomes of chronic diseases.\nUsing electronic health records (EHR) (both structured and unstructured data) as\u00a0 inputs, this tool outputs deep phenotypes and predictions of health outcomes including suicide death, opioid overdose, and decompensated outcomes of chronic diseases.",
      "401": "NRP Redesign\nDeploy innovative active learning methods to provide a lower opportunity \ncost method of estimating a compliance baseline to support tax gap \nestimation, improper papyments reporting, development and validation of \nworkload identfication and selection models, and inform policy analysis.  \nSystem inputs require existing NRP data which provide an acceptable level \nof precision and quality for an acceptable level of data quality output.",
      "139": "City Pairs Program Ticket Forecast and Scenario Analysis Tools\nTakes segment-level City Pair Program air travel purchase data and creates near-term forecasts for the current and upcoming fiscal year by month and at various levels of granularity including DOD vs Civilian, Agency, and Region.",
      "17": "Ecosystem Management Decision Support System (EMDS)\nEMDS is a spatial decision support system for landscape analysis and planning that runs as a component of ArcGIS and QGIS. Users develop applications for their specific problem that may use any combination of four AI engines for 1) logic processing, 2) multi-criteria decision analysis, 3) Bayesian networks, and Prolog-based decision trees.",
      "166": "Priority Score Model - ranks providers within the Fraud Prevention System using logistic regression based on program integrity guidelines.\nInputs - Medicare Claims data, Targeted Probe and Educate (TPE) Data, Jurisdiction information\nOutput - ranks providers within the FPS system using logistic regression based on program integrity guidelines.",
      "147": "Document Workflow / Intelligent Data Capture and Extraction\nGSA is driving towards a more accurate and scalable document workflow platform. GSA seeks to intelligently capture, classify, and transfer critical data from unstructured and structured documents, namely PDF files, to the right process, workflow, or decision engine.",
      "157": "Item Nonresponse Detection in Open-text\nResponse Data\nNCHS is developing an item nonresponse detection model, to identify cases of item nonresponse (e.g., gibberish,\nuncertain/don\u2019t know, refusals, or high-risk) among open-text responses to help improve survey data and question and\nQuestionnaire design. The system is a Natural Language Processing (NLP) model pre-trained using Contrastive Learning\nand fine-tuned on a custom dataset from survey responses.",
      "27": "List Frame Deadwood Identification\nThe deadwood model leverages boosted regression trees with inputs such as  administrative linkage data, frame data, and historical response information as inputs, to produce a propensity score representing a relative likelihood of a farm operation being out of business.  Common tree splits were identified using the model and combined with expert knowledge to develop a recurring process for deadwood clean up.",
      "67": "The Development of ProbSevere \nv3 - An improved nowcasting \nmodel in support of severe \nweather warning operations\nProbSevere is a ML model that utilizes NWP, satellite, radar, and lightning data to nowcast \nsevere wind, severe hail, and tornadoes. ProbSevere, which was transitioned to NWS \noperations in October 2020, is a proven tool that enhances operational severe weather \nwarnings. This project aims to develop the next version of ProbSevere, ProbSevere v3. \nProbSevere v3 utilizes additional data sets and improved machine learning techniques to \nimprove upon the operational version of ProbSevere. ProbSevere v3 was successfully \ndemonstrated in the 2021 Hazardous Weather Testbed and a JTTI proposal was recently \nsubmitted to facilitate an operational update. The development is funded by GOES-R.",
      "208": "Integrated Digital Environment\nThe Integrated Digital Environment provides managers with a better understanding of end user workflows, most and least used applications, and opportunities for improvement. \n\nThe AI/ML model applies to end user activity data (e.g., use of applications, flow between applications) to help CBP identify opportunities for more efficient or effective configuration of interfaces, use of resources, or development and deployment of CBP\u2019s applications.  It tailors analytics and insight generation to allow metrics gathering, usage recording/observation, dashboarding, and workflow experimentations/suggestions to support analysts utilizing the entire suite of agency and open-source data systems. It also customizes existing capabilities to allow the exact automations needed for agency applications and systems, creating an integrated digital environment for greater connectivity and security between applications, and better ability for CBP administrators to manage and optimize use of applications by end users.",
      "354": "NLP for Foreign Assistance Appropriations Analysis\nNatural language processing application for F/RA to streamline the extraction of earmarks and directives from the annual appropriations bill. Before NLP this was an entirely manual process.",
      "120": "Machine Learning Interatomic \nPotentials for Radiation Damage and \nPhysical Properties in Model Fluorite \nSystems\nThis project will use machine learning interatomic potentials to study the influence of \nradiation damage on physical properties of calcium fluoride and uranium dioxide. \nElectron irradiation experiments and thermal conductivity measurements will be \nperformed to validate the effectiveness of the developed potentials. The high \nthroughput capability of this method will become an important combinatorial materials \nscience tool for developing and qualifying new nuclear fuels.",
      "140": "Category Taxonomy Refinement Using NLP\nUses token extraction from product descriptions more accurately shape intended markets for Product Service Codes (PSCs).",
      "431": "Nediser reports QA\nNediser is a continuously trained artificial intelligence \u201cradiology resident\u201d that assists radiologists in confirming the X-ray properties in their radiology reports.\u00a0 Nediser can select normal templates, detect hardware, evaluate patella alignment and leg length and angle discrepancy, and measure Cobb angles.",
      "332": "SSI Redetermination Model\nThis model uses machine learning to identify supplemental security income cases with highest expected overpayments due to changes in financial eligibility and flag them for technician review.  ",
      "35": "Acquisition Approval Request Compliance Tool\nA natural language processing (NLP) model was developed to utilize the text in procurement header and line descriptions within USDA's Integrated Acquisition System (IAS) to determine the likelihood that an award is IT-related, and therefore might require an AAR. The model uses the text characteristics for awards that have an AAR number entered into IAS and then calculates the probability of being IT-related for those procurements that did not have an AAR Number entered in IAS.",
      "322": "Automatic Data Processing Workflow with Form Recognizer\nAutomatic processing of current complex worflow to extract required data.",
      "358": "Machine-Learning Assisted Measurement and Evaluation of Public Outreach\nGPA\u2019s production system for collecting, analyzing, and summarizing the global digital content footprint of the Department.",
      "64": "First Guess Excessive Rainfall \nOutlook\nMachine Learning Product that is a first guess for the WPC Excessive Rainfall Outlook - It is \nlearned from the ERO with atmospheric variables. It is for the Day 1, 2, 3 products",
      "127": "Combinatorial Evaluation of Physical \nFeature Engineering and Deep \nTemporal Modeling  for Synchrophasor \nData at Scale\nExplore the use of big data, artificial intelligence (AI), and machine learning technology \nand tools on phasor measurement unit (PMU) data to identify and improve existing \nknowledge, and to discover new insights and tools for better grid operation and \nmanagement.",
      "59": "Coral Reef Watch\nFor more than 20 years, NOAA Coral Reef Watch (CRW) has been using remote sensing, \nmodeled, and in situ data to operate a Decision Support System (DSS) to help resource \nmanagers (our target audience), researchers, decision makers, and other stakeholders \naround the world prepare for and respond to coral reef ecosystem stressors, \npredominantly resulting from climate change and warming of the Earth's oceans. Offering \nthe world's only global early-warning system of coral reef ecosystem physical \nenvironmental changes, CRW remotely monitors conditions that can cause coral \nbleaching, disease, and death; delivers information and early warnings in near real-time to \nour user community; and uses operational climate forecasts to provide outlooks of \nstressful environmental conditions at targeted reef locations worldwide. CRW products \nare primarily sea surface temperature (SST)-based but also incorporate light and ocean \ncolor, among other variables.",
      "126": "Big Data Synchrophasor Monitoring and \nAnalytics for Resiliency Tracking \n(BDSMART)\nExplore the use of big data, artificial intelligence (AI), and machine learning technology \nand tools on phasor measurement unit (PMU) data to identify and improve existing \nknowledge, and to discover new insights and tools for better grid operation and \nmanagement.",
      "12": "Democratizing Data\nThe purpose of this project is to use AI tools, machine learning and natural language processing to understand how publicly-funded data and evidence are used to serve science and society.",
      "103": "Automated Type and Data Structure \nResolution\nThis research identified and labeled type and structure data in an automated and \nscalable way such that the information can be used in other tools and other Reverse \nEngineering at Scale research areas such as symbolic execution. This was done \ninitially by utilizing heuristic methods and then scaled by adopting a machine learning \napproach.",
      "105": "Advanced Machine Learning-based \nFifth Generation Network Attack \nDetection System\nThe project goal is to prove that enhancing attack detection via innovative machine \nlearning and artificial intelligence techniques into the fifth generation (5G) cellular \nnetwork can help to secure mission-critical applications, such as automated vehicles \nand drones, connected health, emergency response operations, and other mission-\ncritical devices that either are or will be connected to the 5G cellular network.",
      "334": "PATH Model\nThis model uses machine learning to identify cases likely to receive an allowance at the hearing level and refer them to administrative law judges or senior adjudicators for prioritized review.",
      "410": "Using ML for predicting treatment interruption among PLHIV in Nigeria\nUsing data from USAID funded Strengthening Integrated Delivery of HIV/AIDS Services (SIDHAS) project in Nigeria we trained and tested an algorithm that can be used for predicting the probability that someone newly initiated on ART will interrupt treatment. The algorithm has been successfully integrated into the Lafiya Management Information System (LAMIS), the individual-level client level electronic medical record system. Each week the outputs, for each new patient is shared with staff at the health facilities and those at high risk are provided with more intensive follow up support to reduce the risk of treatment interruption. We also conducted a qualitative assessment among to health care workers at the facilities to determine their perception of ML and determine what additional support are required for institutionalizing ML into their routine work.   ",
      "335": "Insight\nInsight is decision support software used by hearings and appeals-level Disability Program adjudicators to help maximize the quality, speed, and consistency of their decision making.  Insight analyzes the free text of disability decisions and other case data to offer adjudicators real-time alerts on potential quality issues and case-specific reference information within a web application.  It also offers adjudicators a series of interactive tools to help streamline their work.  Adjudicators can leverage these features to speed their work and fix issues before the case moves forward (e.g. to another reviewing employee or to the claimant).  Insight\ufffds features are powered by several natural language processing and artificial intelligence packages and techniques.",
      "219": "Cyber Threat Intelligence Feed Correlation\nCyber Threat Intelligence Feed Correlation uses AI enabled capabilities to provide accelerated correlation across multiple incoming information feeds. This enables more timely enrichment to improve the externally shared information feeds. AI allows the algorithm to use the information items and results to learn most efficient ways to perform the task. Additionally, tailored algorithms could be created to provided sustained surveillance of threat actor TTPs.\n",
      "18": "Wildland Urban Interface - Mapping Wildfire Loss\nThis is a proof-of-concept study to investigate the use of machine learning (deep learning / convolutional neural networks) and object-based image classification techniques to identify buildings, building loss, and defensible space around buildings before and after a wildfire event in wildland-urban interface settings.",
      "203": "Autonomous Maritime Awareness\nThe Autonomous Maritime Awareness system combines surveillance towers, ocean data solutions, unmanned autonomous surface vehicles (ASV), and AI to autonomously detect, identify, and track items of interest in a maritime environment.\n\nThe towers are low-cost, customizable, and relocatable surveillance systems. They are equipped with a suite of radars and day/night camera sensors. The ASVs have been ruggedized for the open ocean and are powered by wind, solar, and/or onboard engine as required, allowing them to operate in an area of responsibility (AOR) for up to 12 months. Their sensor suite includes cameras and radar. \n\nBoth systems use AI/ML to detect and identify objects, determine items of interest (IoI) and autonomously track those items using their sensor suites. Once identified, these systems can send alerts to monitoring agencies for at-sea interdictions of potential targets and/or intel collections.",
      "142": "Service Desk Generic Ticket Classification\nWe are building a model to take generic Service Desk tickets and classify them so that they can be automatically re-routed to the correct team that handles these types of tickets. The process of re-routing generic tickets is currently done manually, so the model will allow us to automate it. The initial model will target the top 5 most common ticket types.",
      "393": "Inventory Item \nReplenishment MLR \nModeling POC - Phase 2\nBuilt and evaluate a multiple linear regression model to predict to \ndetermine if the replenishment of an inventory item would receive by the \nstandard Need By time of 128 days set for all inventory items.",
      "440": "Gait signatures in patients with peripheral artery disease\nMachine learning is used to improve treatment of functional problems in patients with peripheral artery disease (PAD). Previously collected biomechanics data is used to identify representative gait signatures of PAD to 1) determine the gait signatures of patients with PAD and 2) the ability of limb acceleration measurements to identify and model the meaningful biomechanics measures from PAD data.",
      "125": "Open-Source High-Fidelity Aggregate \nComposite Load Models of Emerging \nLoad Behaviors for Large-Scale \nAnalysis (GMLC 0064)\n1. Machine learning methods such as cross-correlation, random forest, regression \ntree and transfer learning are used to estimate the load composition data and motor \nprotection profiles for different climante regions in the Western US\n2. Deep learning algorithm is appplied to calibrate the parameters of WECC \ncomposite load model to match the responses with detailed feeder model",
      "369": "forecasting\nusing statistical models, projecting expected outcome into the future; this has been applied to COVID cases as well as violent events in relation to tweets",
      "443": "VA-DoE Suicide Exemplar Project\nThe VA-DoE Suicide Exemplar project is currently utilizing artificial intelligence to improve VA's ability to identify Veterans at risk for suicide through three closely related projects that all involve collaborations with the Department of Energy.",
      "407": "Long-term impacts of land-use/land-cover dynamics on surface water quality in Botswana\u2019s reservoirs using satellite data and artificial intelligence methods: Case study of the Botswana\u2019s Limpopo River Basin (1984-2019)\nFor water supply, semi-arid Botswana relies on the reservoirs within the Botswana\u2019s LRB. Reservoirs are particularly susceptible to the negative impacts of land-use and land-cover (LULC) activities and runoff because of their complex dynamics, relatively longer water residence times, and their role as an integrating sink for pollutants from their drainage basins. Despite these interrelationships and significance in regional and global economic stability, land and water (L-W) are often treated in \u201csilos\u201d. To understand the complex L-W nexus within the LRB, this study will use data-driven artificial intelligence for quantitative determination of the relationships between LULC change, together with socioeconomic development indicators and climate change, and their impacts on water quality and availability within the basin, both for 1984-2019 and to predict future scenarios (2020-2050). To advance data acquisition for LULC analysis and climate change, the study utilizes optical Earth-observation and meteorological satellite data. To provide near real-time and cost-effective approach for continuous monitoring of reservoir water quality within the basin, the study will develop empirical models for water quality estimation and water quality index mapping using 35-years of in-situ water quality measurements and water spectral observations using drone-borne spectrometer and optical satellite imagery through regression modeling and geospatial methods.",
      "308": "Privileged Material Identification\nThe application scans documents and \nlooks for attorney/client privileged \ninformation. It does this based on \nkeyword input by the system \noperator.",
      "44": "Azure Chatbot\nAzure Chatbot is being leveraged to automate and streamline the user response to \npotential questions for MBDA users while interacting with the external facing MBDA \nwebsite. The solution leverages AI based chatbot response coupled with Machine \nLearning and Natural Language Processing capabilities.",
      "29": "Climate Change Classification NLP\nThe model classifies NIFA funded projects as climate change related or not climate related through natural language processing techniques. The model input features include text fields containing the project's title, non-technical summary, objectives and keywords. The target is a dummy variable classification of projects as climate change related or not climate change related.",
      "98": "Artificial Intelligence Based Process \nControl and Optimization for Advanced \nManufacturing\nThis project will develop the capability to intelligently control and optimize advanced \nmanufacturing processes instead of the existing trial and error approach. To achieve \nthis goal, artificial intelligence (AI) based control algorithms will be developed by \nemploying deep reinforcement learning. To reduce the computational expense with \nadvanced manufacturing models, physics-informed reduced order models (ROMs) will \nbe developed. The AI-based control algorithms will employ the ROMs\u2019 predictions to \nadaptively inform processing decisions in a simulation environment.",
      "390": "Machine Learning for Occupant Safety Research\nDescription: Utilize deep learning for predicting crash parameters, Delta-V (change in velocity) and PDOF (principal direction of force), directly from real-world crash images. Delta-V and PDOF are two most important parameters affecting injury outcome. Deep learning models can help predict both Delta-V and PDOF, without the need to run WinSmash software for Delta-V computation, and without requiring estimations by crash examiners.  Moreover, with deep learning models, the Delta-V and PDOF can be obtained within milliseconds, providing rapid results for improved efficiency\"\nInput:  Real world crash images\nOutput:  Delta-V & PDOF",
      "438": "SoKat Suicidial Ideation Detection Engine\nThe SoKat Suicide Ideation Engine (SSIE) uses natural language processing (NLP) to improve identification of Veteran suicide ideation (SI) from survey data collected by the Office of Mental Health (OMH) Veteran Crisis Line (VCL) support team (VSignals).",
      "329": "Pre-Effectuation Review / Targeted Denial Review Models\nThese review models use machine learning to identify cases with greatest likelihood of disability eligibility determination error and refer them for quality review checks.  ",
      "3": "Detection of aquatic weeds\nIdentify and locate aquatic weeds",
      "375": "Louvain Community Detection\nTakes in a social network and clusters nodes together into \u201ccommunities\u201d (i.e., similar nodes are grouped together)",
      "50": "A Hybrid Statistical-Dynamical \nSystem for the Seamless \nPrediction of Daily Extremes and \nSubseasonal to Seasonal Climate \nVariability\nDemonstrate the skill and suitability for operations of a statistical- dynamical prediction \nsystem that yields seamless probabilistic forecasts of daily extremes and sub seasonal-to-\nseasonal temperature and precipitation. We recently demonstrated a Bayesian statistical \nmethod for post-processing seasonal forecasts of mean temperature and precipitation \nfrom the North American Multi-Model Ensemble (NMME). We now seek to test the utility \nof an updated hybrid statistical-dynamical prediction system that facilitates seamless sub \nseasonal and seasonal forecasting. Importantly, this method allows for the representation \nof daily extremes consistent with climate conditions. This project explores the use of \nmachine learning.",
      "246": "Improved Processing and Analysis of Test and Operating Data from Rotating Machines\nThis project is exploring a better method to analyze DC ramp test data from rotating machines. Previous DC ramp test analysis requires engineering expertise to recognize characteristic curves from DC ramp test plots. DC ramp tests produce a plot of voltage vs current for a ramping voltage applied to a rotating machine. By using machine learning/AI tools, such as linear regression, the ramp test plots can be analyzed by computer software, rather than manual engineering analysis, to recognize characteristic curves. The anticipated result will be faster and more reliable analysis of field-performed DC ramp testing.",
      "41": "Consolidated Screening List\nThe Consolidated Screening List (CSL) is a list of parties for which the United States \nGovernment maintains restrictions on certain exports, reexports, or transfers of items. It \nconsists of the consolidation of 13 export screening lists of the Departments of \nCommerce, State, and Treasury.  The CSL search engine has \u201cFuzzy Name Search\u201d \ncapabilities, allowing a search without knowing the exact spelling of an entity\u2019s name. In \nFuzzy Name mode, the CSL returns a \u201cscore\u201d for results that exactly or nearly match the \nsearched name. This is particularly helpful when searching on CSL for names that have \nbeen translated into English from non-Latin alphabet languages.",
      "72": "VIAME: Video and Image Analysis \nfor the Marine Environment \nSoftware Toolkit\nThe Video and Image Analysis for the Marine Environment Software Toolkit, commonly \nknown as VIAME, is an open-source, modular software toolkit that allows users to employ \nhigh-level, deep-learning algorithms for automated annotation of imagery using a low \ncode/no code graphical user interface. VIAME is available free of charge to all NOAA \nusers.  The NOAA Fisheries Office of Science and Technology supports an annual \nmaintenance contract covering technical and customer support by the developer, routine \nsoftware updates, bug fixes, and development efforts that support broad, cross center \napplication needs.",
      "413": "Mali: AI predictions for the optimization of the allocation of the distribution of COVID-19 vaccines  \nAI technology was used to develop a pandemic preparedness AI model to support allocation of COVID-19 vaccines based on a multi-tiered strategy for target populations: 1) hotspots for COVID-19 positive cases and 2) pregnant/breastfeeding women using DHIS2 data. This was a proof-of-concept model.",
      "349": "Automatic Detection of Authentic Material\nThe Foreign Service Institute School of Language Studies is developing a tool for automated discovery of authentic native language texts classified for both topic and Interagency Language Roundtable (ILR) proficiency level to support foreign language curriculum and language testing kit development.",
      "380": "Surface Report Classifiier (SCM/Auto-Class)\nSCM classifies surface incident reports by event type, such as Runway Incursion, Runway Excursion, Taxiway Incursion/Excursion and categorizes runway incursions further by severity type (Category A, B, C, D, E)",
      "420": "AI Cure\nAICURE is a phone app that monitors adherence to orally prescribed medications during clinical or pharmaceutical sponsor\u00a0 drug studies.",
      "94": "Accelerating deployment of nuclear \nfuels through reduced-order thermo-\nphysical property models and machine \nlearning\nThis project will develop a novel physics-based tool that combines 1) reduced-order \nmodels, 2) machine learning algorithms, 3) fuel performance methods, and 4) state-of-\nthe-art thermal property characterization equipment and irradiated nuclear fuel data \nsets to accelerate nuclear fuel discovery, development, and deployment. The models \nwill describe thermal conductivity, specific heat, thermal expansion, and self-diffusion \ncoefficients as a function of temperature and irradiation.",
      "30": "Operational water supply forecasting for western US rivers\nWestern US water management is underpinned by forecasts of spring-summer river flow volumes made using operational hydrologic models. The USDA Natural Resources Conservation Service (NRCS) National Water and Climate Center operates the largest such forecast system regionally, carrying on a nearly century-old tradition. The NWCC recently developed a next-generation prototype for generating such operational water supply forecasts (WSFs), the multi-model machine-learning metasystem (M4), which integrates a variety of AI and other data-science technologies carefully chosen or developed to satisfy specific user needs. Required inputs are data around snow and precipitation from the NRCS Snow Survey and Water Supply Forecast program SNOTEL environmental monitoring network, but are flexible.  In hindcasting test-cases spanning diverse environments across the western US and Alaska, out-of-sample accuracy improved markedly over current benchmarks. Various technical design elements, including multi-model ensemble modeling, autonomous machine learning (AutoML), hyperparameter pre-calibration, and theory-guided data science, collectively permitted automated training and operation.  Live operational testing at a subset of sites additionally demonstrated logistical feasibility of workflows, as well as geophysical explainability of results in terms of known hydroclimatic processes, belying the black-box reputation of machine learning and enabling relatable forecast storylines for NRCS customers.",
      "0": "Predictive modeling of invasive pest species and category at the port of entry using machine learning algorithms\nMacine learning algorithms are used to develop with inspection data and improve prediction ability of detecting invasive/quarantine significant pests at the port of entry.",
      "130": "A Robust Event Diagnostic Platform: \nIntegrating Tensor Analytics and \nMachine Learning Into Real-time Grid \nMonitoring\nExplore the use of big data, artificial intelligence (AI), and machine learning technology \nand tools on phasor measurement unit (PMU) data to identify and improve existing \nknowledge, and to discover new insights and tools for better grid operation and \nmanagement.",
      "446": "Predicting hospitalization and corticosteroid use as a surrogate for IBD flares\u00a0\nThis work examines data from 20,368 Veterans Health Administration (VHA) patients with an irritable bowel disease (IBD) diagnosis between 2002 and 2009. Longitudinal labs and associated predictors were used in random forest models to predict hospitalizations and steroid usage as a surrogate for IBD Flares.",
      "454": "VA /IRB approved research study for finding colon polyps\nThis IRB approved research study uses\u00a0 a randomized trial for finding colon polyps with artifical intelligence.",
      "249": "Well Activity Report Classification\nResearching use of self-supervised deep neural networks to identify classification systems for significant well event using data from well Activity Reports",
      "247": "Sustained Casing Pressure Identification\nWell casing pressure requests are submitted to BSEE to determine whether a well platform is experiencing a sustained casing pressure (SCP) problem. SCP is usually caused by gas migration from a high-pressured subsurface formation through the leaking cement sheath in one of the well\u2019s casing annuli, but SCP can also be caused by defects in tube connections, downhole accessories, or seals. Because SCP can lead to major safety issues, quickly identifying wells with SCP could greatly mitigate accidents on the well platforms",
      "196": "Machine learning system to predict translational progress in biomedical research\nFundamental scientific advances can take decades to translate into improvements in human health. Shortening this\ninterval would increase the rate at which scientific discoveries lead to successful treatment of human disease. One way to\naccomplish this would be to identify which advances in knowledge are most likely to translate into clinical research.\nToward that end, the NIH Office of Portfolio Analysis built a machine learning system that detects whether a paper is\nlikely to be cited by a future clinical trial or guideline. Despite the noisiness of citation dynamics, as little as 2 years of\npostpublication data yield accurate predictions about a paper\u2019s eventual citation by a clinical article (accuracy = 84%, F1\nscore = 0.56; compared to 19% accuracy by chance). We found that distinct knowledge flow trajectories are linked to\npapers that either succeed or fail to influence clinical research. Translational progress in biomedicine can therefore be\nassessed and predicted in real time based on information conveyed by the scientific community\u2019s early reaction to a\npaper. For more information see the publication describing this system: Hutchins et al 2019\n(https://journals.plos.org/plosbiology/article?id=10.1371/journal.pbio.3000416)",
      "38": "Video Surveillance System\nThe Video Surveillance System: the VSS system design will include a video management system, NVRs, DVRs, encoders, fixed cameras, Pan and Tilt cameras, network switches, routers, IP cables, equipment racks and mounting hardware. The Video Surveillance System (VSS)- shall control multiple sources of video surveillance subsystems to collect, manage, and present video clearly and concisely. VMS shall integrate the capabilities of each subsystem across single or multiple sites, allowing video management of any compatible analog or digital video device through a unified configuration platform and viewer. Disparate video systems are normalized and funneled through a shared video experience. Drag and drop cameras from the Security Management System hardware tree into VMS views and leverage Security Management System alarm integration and advanced features that help the operator track a target through a set of sequential cameras with a simplified method to select a new central camera and surrounding camera views.",
      "352": "ServiceNow AI-Powered Virtual Agent (Chatbot)\nIRM\u2019s BMP Systems is planning to incorporate ServiceNow\u2019s Virtual Agent into our existing applications to connect users with support and data requests. The Artificial Intelligence (AI) is provided by ServiceNow as part of their Platform as a Service (PaaS).",
      "69": "SUVI Thematic Maps\nThe GOES-16 Solar Ultraviolet Imager (SUVI) is NOAA's operational solar extreme-\nultraviolet imager. The SUVI Level 2 Thematic Map files in these directories are produced \nby NOAA's National Centers for Environmental Information in Boulder, Colorado. These \ndata have been processed from Level 2 High Dynamic Range (HDR) composite SUVI \nimages. The FITS file headers are populated with metadata to facilitate interpretation by \nusers of these observations. Please note that these files are considered to be \nexperimental and thus will be improved in future releases. Users requiring assistance with \nthese files can contact the NCEI SUVI team by emailing goesr.suvi@noaa.gov. The SUVI \nThematic Maps product is a Level 2 data product that (presently) uses a machine learning \nclassifier to generate a pixel-by-pixel map of important solar features digested from all six \nSUVI spectral channels.",
      "261": "Economic valuation of fisheries in the Delaware River\nThe\u00a0goal\u00a0is to link existing hydrological flow data (e.g., USGS stream gages) and models (e.g., USGS Process-Guided Deep Learning Models for flow and temparture) with trout population dynamic models, changes to fish catch, and the economic benefits of recreational fishing. These trout population dynamic models will be developed based on observational data, existing literature estimates, and existing models.",
      "409": "Project Vikela\nUse AI to detect illegal rhino horn in airplane luggage X-Ray scanners",
      "228": "Email Analytics \nThe Email Analytics application enables a user to review and analyze email data acquired through legal process.  AI is incorporated to accomplish spam message classification, and named entity recognition (NER) for entity extraction of names, organizations, locations, etc.  It also integrates machine translation capabilities using a commercial product.",
      "36": "Intelligent Ticket Routing\nRoutes BMC Remedy tickets to proper work group automatically utilizing python, jupyterhub, scikit learn, gitlab, flask, gunicorn, nginx, erms.",
      "423": "Automated eye movement analysis and diagnostic prediction of neurological disease\nArtificial intelligence\u00a0 recursively analyzes previously collected data to both improve the quality and accuracy of automated algorithms, as well as to screen for markers of neurological disease (e.g. traumatic brain injury, Parkinson's, stroke, etc).",
      "422": "Assessing lung function in health and disease\nHealth professionals can use this artificial intelligence to determine predictors of normal and abnormal lung function and sleep parameters.",
      "223": "Security Information and Event Management (SIEM) Alerting Models\nThreat hunting and Security Operations Center (SOC) analysts are provided terabytes per day of log data. Manually developed detection alerts and automatic correlation in Security Information and Event Management tool are common, but not comprehensive. Many cyber attacks can be probabilistically determined given sufficient training data and time. Analysts  use automated tooling to further refine the alerts they receive and produce additional automated alerts based on aggregated information and curated subject matter expertise. This tooling allows CISA analysts the capabilities to comb through data in an automated fashion with mathematically and probabilistically based models to ensure high fidelity anomalies are detected in a timely manner. ",
      "226": "Normalization Services\nHSI uses Artificial Intelligence to verify, validate, correct, and normalize addresses, phone numbers, names, and ID numbers to streamline the process of correcting data entry errors, point out purposeful misidentification, connect information about a person across HSI datasets, and cut down the number of resource hours needed for investigations. \n\nExamples of the normalization services provided include: normalizing less well-defined addresses into usable addresses for analysis- (such as those using mile markers instead of a street number); inferring ID type based on user-provided ID value (such as distinguishing a SSN from a DL number without additional context); categorizing name parts while taking into account additional factors (including generational suffixes and multi-part family names); and validating and normalizing phone numbers to the E164 standard, including their identified county of origin.\n\nThese services are provided as part of the Repository for Analytics in a Virtualized Environment (RAVEn).  RAVEn is a DHS HSI Innovation Lab project that facilitates large, complex analytical projects to support ICE\u2019s mission to enforce and investigate violations of U.S. criminal, civil, and administrative laws. RAVEn also enables tools used to analyze trends and isolate criminal patterns as HSI mission needs arise. For more information, please read the DHS/ICE/PIA-055 - Privacy Impact Assessment 055 for RAVEn.",
      "22": "Landscape Change Monitoring System (LCMS)\nThe Landscape Change Monitoring System (LCMS) is a National landsat/sentinal remote sensing-based data produced by the USDA Forest Service for mapping and monitoring changes related to vegetation canopy cover, as well as land cover and land use. The process utilizes temporal change classifications together with training data in a supervised classification process for vegetation gain, and loss as well as land cover and use.",
      "312": "Text to Speech Conversion\nText to speech (Neural) for more realistic human sounding applications using natural language processing models.",
      "165": "Data Lake/Load-Extract-Load-Transform (L-ETL)\nCMS is using Security Data Lake to modernize the load-extract-load-transform (L-ETL) pipelines and data tooling. CMS will\nbe enhancing Agency security to bring together more system, telemetry and program data in one place with a unifying\ngovernance model. Building on top of a modern data platform will provide opportunities to experiment with machine\nlearning model development against this data--solving any number of problems that require decisions to be made about\ninferences over time series data. There is no actual ML/AI work being done here today, rather, we are beginning work on\nthe scaffolding that will open up these opportunities in 1-2 years time.",
      "26": "Cropland Data Layer\nA machine learning algorithm is used to interpret readings from satellite-based sensors and CLASSIFY the type of crop or activity that falls in each 30 square meter pixel (a box of fixed size) on the ground.  The algorithms are trained on USDA&%2339;s Farm Services Agency data and other sources of data as sources of &quot;ground truth&quot;.  It allows us to not only produce a classification, but to assess the accuracy of the classification as well.  For commodities, like corn and soybeans, the CDL is highly accurate.  The CDL has been produced for national coverage since 2008.  Some summary and background about the CDL is available in a number of peer reviewed research papers and presentations\nhttps://www.nass.usda.gov/Research_and_Science/Cropland/othercitations/index.php",
      "372": "TOPIQ\nGEC A&R\u2019s TOPIQ tool automatically classifies text into topics for analyst review and interpretation. The tool uses Latent Dirichlet Allocation (LDA), a natural language processing technique that uncovers a specified number of topics from a collection of documents, and then assigns the probability that each document belongs to a topic.",
      "267": "Seabird and Marine Mammal Surveys Near Potential Renewable Energy Sites Offshore Central and Southern California\nThe Seabird Studies Team at the Western Ecological Research Center (WERC), with support from the Bureau of Ocean Energy Management (BOEM), completed aerial photographic surveys of the ocean off central and southern California between 2018-2021. Over 800,000 high resolution images of the ocean were collected, with the goal of extracting and counting marine birds and mammals contained within. To process this volume of images machine learning offered the best methodology, but publicly available training data did not exist for this specific purpose. Through a collaboration with Conservation Metrics, Inc. we created a labeled training dataset using Faster RCNN models via active learning and transfer learning. We then evaluated a set of candidate models trained on different label aggregation schemes, selected a final model utilizing YOLOv5 architecture, and ran the final model on the complete image dataset. Images output from the final model classified targets into seven categories: bird, dark bird, dark bird flying, light bird, fish, marine mammal, and other. We are currently reviewing the final model output for false positives and negatives to evaluate performance. Next, we will reclassify model labels to the lowest taxonomic group possible. This manual review is occurring in the USGS cloud environment (Amazon Web Services) utilizing the opensource Computer Vision Annotation Tool (CVAT). Once low taxonomic reclassification is complete, we will generate maps of species distribution and abundance to inform BOEM\u2019s planning in advance of potential offshore wind energy development along the California coast.",
      "448": "Use of machine learning to predict surgery in Crohn\u2019s disease\nMachine learning analyzes patient demographics, medication use, and longitudinal laboratory values collected between 2001 and 2015 from adult patients in the Veterans Integrated Service Networks (VISN) 10 cohort. The data was used for analysis in prediction of Crohn\u2019s disease and to model future surgical outcomes within 1 year.",
      "170": "Artificial Intelligence-based Deduplication\nAlgoirthm for Classfication of Duplicate Reports\nin the FDA Adverse Event Reports (FAERS)\nThe deduplication algorithm is applied to nonpublic data in the FDA Adverse Event Reporting System (FAERS) to identify\nduplicate reports. Unstructured data in free text FAERS narratives is processed through a natural language processing\nsystem to extract relevant clinical features. Both structured and unstructured data are then used in a probabilistic record\nlinkage approach to score pairs of reports by evaluating multiple data fields and applying relative weights per field. The\noutput of potential duplicate reports is further placed in groups to facilitate identification of FAERS reports during case\nseries evaluation for safety issues of concern.",
      "437": "Seizure detection from EEG and video\nMachine learning algorithms use EEG and video data from a VHA epilepsy monitoring unit in order to automatically identify seizures without human intervention.",
      "119": "Passive Strain Measurements for \nExperiments in Radiation Environments\nThis project will develop passive instrumentation to determine permanent strains \ninduced by irradiation and extract critical parameters using modeling and simulation as \nwell as machine learning algorithms. An irradiation experiment will be conducted that \nwill benefit from engineered anisotropic materials and characterize the directional \ndeformation in response to neutron radiation. The results of the experiment will be \nincorporated into the model so that the material response can be predicted for future \nuses as a probe material.",
      "337": "Duplicate Identification Process (DIP)\nDuplicate Identification Process's (DIP's) objective is to help the user to\ufffdidentify and flag\ufffdand mark duplicates\ufffdmore efficiently, reducing the amount\ufffdof time spent to review\ufffdcases for\ufffdhearings.\ufffdDIP uses artificial\ufffdintelligence software in the form of image recognition technology to accurately\ufffdidentify duplicates consistent with SSA\ufffdpolicy.?",
      "355": "eRecords M/L Metadata Enrichment\nThe Department\u2019s central eRecords archive leverages machine learning models to add additional metadata to assist with record discovery and review. This includes models for entity extraction, sentiment analysis, classification and identifying document types.",
      "74": "Using community-sourced \nunderwater photography and \nimage recognition software to \nstudy green sea turtle distribution \nand ecology in southern California\nThe goal of this project is to study green turtles in and around La Jolla Cove in the San \nDiego Region-a highly populated site with ecotourism-by engaging with local \nphotographers to collect green turtle underwater images.  The project uses publicly \navailable facial recognition software (HotSpotter) to identify individual turtles, from which \nwe determine population size, residency patterns, and foraging ecology",
      "338": "Handwriting recognition from forms\nAI performs OCR against handwritten entries on specific standard forms submitted by clients. This use case is in support of an Robtic Process Automation effort as well as a standalone use.",
      "78": "Replacing unstructured WW3 in \nthe Great Lakes with a Recurrent \nneural network and a boosted \nensemble decision tree\nInvestigated replacing unstructured WW3 in the Great Lakes with (i) a Recurrent Neural \nNetwork (RNN, especially an LSTM) developed by EMC and (ii) a boosted ensemble \ndecision tree (XGBoost) developed by GLERL. These two AI models were trained on two \ndecades of wave observations in Lake Erie and compared to the operational Great Lakes \nunstructured WW3.",
      "180": "Pangolin lineage classifications to support\naccessing and analysis of SARS-CoV-2 sequence\nData.\nThe Pango nomenclature, called Pango lineages, is being used by researchers and public health agencies worldwide to\ntrack the transmission and spread of SARS-CoV-2, including variants of concern. The requirements for running the tool\ninclude having conda on a MacOS or Linux system, and the FASTA-formated sequence data. There are 2 methods for\nlineage assignment with Pango; within NCBI Virus we use the process which includes PangoLEARN, where a classification\ntree is used to group similar sequences.",
      "138": "Acquisition Analytics\nTakes Detailed Data on transactions and classifies each transaction within the Government-wide Category Management Taxonomy",
      "389": "Machine Learning for Occupant Safety Research\nDescription: Utilize deep learning models for predicting head kinematics directly from crash videos. The utilization of deep learning techniques enables the extraction of 3D kinematics from 2D views, offering a viable alternative for calculating head kinematics in the absence of sensors or when sensor availability is inadequate, and when high-quality sensor data is absent\nInput:  Vehicle crash videos\nOutput: Angular velocity - injury prediction",
      "45": "Fisheries Electronic Monitoring \nImage Library\nThe Fisheries Electronic Monitoring Library (FEML) will be the central repository for \nelectronic monitoring (EM) data related to marine life.",
      "93": "Accelerating and Improving the \nReliability of Low Failure Probability \nComputations to Support the Efficient \nSafety Evaluation and Deployment of \nAdvanced Reactor Technologies\nThis project will research artificial intelligence enabled Monte Carlo algorithms to \nsignificantly reduce the computational burden by reducing the number of finite element \nevaluations when estimating low failure probabilities. These will be implemented in the \nMultiphysics Object-Oriented Simulation Environment, which will help the nuclear \nengineering community to efficiently conduct probabilistic failure analyses and \nuncertainty quantification studies for the design and optimization of advanced reactor \ntechnologies.",
      "193": "NIH Grants Virtual Assistant\nChat Bot to assist users in finding grant related information via OER resources",
      "263": "Deep Learning for Automated Detection and Classification of Waterfowl, Seabirds, and other Wildlife from Digital Aerial Imagery\nOur project includes two stages of AI, the first is a binary detector to automate the detection of wildlife in aerial imagery and the second is a robust classification algorithm to automate the taxonomic classification of wildlife from the binary detector. The input of the first and second stage are manually annotated polygons around targets of interest and their taxonomic classification values from family to species, respectively. We use Tallgrass to develop and train our algorithms, BlackPearl/Caldera to store our large image datasets, a hosted instance of a customized version of the Computer Vision Annotation Tool to gather manually annotated data, and a separate PostgreSQL database to store annotations and image metadata.",
      "68": "The VOLcanic Cloud Analysis \nToolkit (VOLCAT): An application \nsystem for detecting, tracking, \ncharacterizing, and forecasting \nhazardous volcanic events\nVolcanic ash is a major aviation hazard. The VOLcanic Cloud Analysis Toolkit (VOLCAT) \nconsists of several AI powered satellite applications including: eruption detection, \nalerting, and volcanic cloud tracking. These applications are routinely utilized by Volcanic \nAsh Advisory Centers to issue volcanic ash advisories. Under this project, the VOLCAT \nproducts will be further developed, and subsequently transitioned to the NESDIS Common \nCloud Framework, to help ensure adherence to new International Civil Aviation \nOrganization requirements.",
      "350": "Automated Burning Detection\nThe Village Monitoring System program uses AI and machine learning to conduct daily scans of moderate resolution commercial satellite imagery to identify anomalies using the near-infrared band.",
      "24": "Forest Health Detection Monitoring\nMachine learning models are used to (1) upscale training data, using Sentinel-2, Landsat,  MODIS, and lidar imagery, that was collected from both the field and high-resolution imagery to map and monitor stages of forest mortality and defoliation across the United States, and (2) to post-process raster outputs to vector polygons.",
      "395": "Collection Voice Bot\nThe NLU model will be located inside the Automated Collections IVR (ACI) \nmain menu. This NLU will take customer speech input aka \u2013 Utterances.  It \nwill map the utterance to a specific intent and direct the taxpayer down to \na certain call path.",
      "436": "Provider directory data accuracy and system of record alignment\nAI is used to add value as a transactor for intelligent identity resolution and linking.\u00a0 AI also has a domain cache function that can be used for both Clinical Decision Support and for intelligent state reconstruction over time and real-time discrepancy detection.\u00a0 As a synchronizer, AI can perform intelligent propagation and semi-automated discrepancy resolution.\u00a0 AI adapters can be used for inference via OWL and logic programming.\u00a0 Lastly, AI has long term storage (\u201cblack box flight recorder\u201d) for virtually limitless machine learning and BI applications.",
      "362": "Fast Text Word Builder\nFast Text is an AI approach to identifying similar terms and phrases based off a root word. This support A&R\u2019s capability to build robust search queries for data collection.",
      "136": "Enforcement Targeting\nEPA\u2019s Office of Compliance, in partnership with the University of Chicago, built a proof-of-concept to improve enforcement of environmental regulations through facility inspections by the EPA and state partners. The resulting predictive analytics showed a 47% improvement of identifying violations of the Resource Conservation and Recovery Act.",
      "270": "Mapping benthic algae along the Buffalo National River from remotely sensed data\nThis study involves using orthophotos acquired from a manned, fixed-wing aircraft and multispectral images from two different satellites to map bottom-attached (benthic) algae along the Buffalo National River in northern Arkansas. The training data for this effort consist of field observations of water depth and percent cover of benthic algae along 8-10 cross sections from two distinct reaches of the Buffalo River. These field data are used to train a bagged trees (aka random forest) classification algorithm to distinguish among four ordinal levels of algal density: none, low, medium, and high.",
      "221": "Malware Reverse Engineering\nReverse engineering of malware, and software analysis more broadly, will continue to be a critical activity in support of CISA\u2019s cyber defense mission. Threat Focused Reverse Engineering (TFRE) leverages advanced engineering, formal methods, and deep learning techniques for better cyber threat intelligence. Without scalable, automated tools, it is difficult to disrupt sophisticated adversaries\u2019 malware development lifecycle. New, unique, automated techniques are needed to better target adversaries, augment analysts, and create sophisticated tools for end users. Core tools disrupt the adversary\u2019s development lifecycle by exposing tactics, techniques, and procedures (TTPs). Analysts could spend more time and energy to hunt/takedown threats; adversaries can spend less time operating malware and must commit more resources to reorient. TFRE consists of a broader development pipeline providing tool hardening, enhanced computational abilities, understanding of deployment environments, and other important capabilities.",
      "6": "Approximate string or fuzzy matching, used to automate matching similar, but not identical, text in administrative documents\nThe algorithm computes a string similarity metric which can be used to classify similar strings into a single category, reducing information duplication and onerous, manual error-checking",
      "244": "Improving UAS-derived photogrammetric data and analysis accuracy and confidence for high-resolution data sets using artificial intelligence and machine learning\nUAS derived photogrammetric products contain a large amount of potential information that can be less accurate than required for analysis and time consuming to analyze manually. By formulating a standard reference protocol and applying machine learning/artificial intelligence, this information will be unlocked to provide detailed analysis of Reclamation's assets for better informed decision making.",
      "1": "Detection of pre-symptomatic HLB infected citrus\nIdentify pixels with HLB infection signature in multispectral and thermal imagery",
      "285": "Prediction of Flood Flow Metrics for Minimally Altered Catchments\nOnce developed, the system will input watershed characteristics (soils, land cover) and long-term meteorological data, and output predictions of flood flow metrics (magnitude, duration, frequency, volume) for stream reaches. Two models will be trained using gage data from regions surrounding the Delaware River Basin and the Colorado River Basin. The resulting models will allow for estimating flood flow metrics in ungaged reaches, which can be used to inform infrastructure designs along those reaches (e.g., bridges). The current deliverable is predictions for minimally altered catchments, and future years may expend to predictions in altered catchments (e.g., those with dam regulation). The models will be built using various R packages on the USGS Tallgrass supercomputer.",
      "357": "Global Audience Segmentation Framework\nA prototype system that collects and analyzes the daily media clips reports from about 70 different Embassy Public Affairs Sections.",
      "114": "Nuclear-Renewable-Storage Digital \nTwin: Enhancing Design, Dispatch, and \nCyber Response of Integrated Energy \nSystems\nThis project will develop a learning-based and digital twin enabled modeling and \nsimulation framework for economic and resilient real-time decision-making of physics-\ninformed integrated energy systems (IES) operation. High-fidelity physics models will \nbe linked with large-scale grid monitoring data to provide real-time updates of IES \nstates, predictive control systems, and optimized power dispatch solutions. Learning-\nbased algorithms will make real-time decisions upon detection of component \ncontingencies caused by climate-induced or man-made extreme events, such as \ncyber-attacks or extreme weather, thereby mitigating their impacts through \nappropriate counter measures.",
      "328": "Anomalous iClaim Predictive Model\nThe anomalous iClaim predictive model is a machine learning model that identifies high-risk iClaims. These claims are then sent to Operations for further review before additional action is taken to adjudicate the claims. ",
      "313": "Claims Document Processing\nTo identify if physician\u2019s note contains causal language by training custom natural language processing models.",
      "13": "Westat\nA competition to find automated, yet effective, ways of linking USDA nutrition information to 750K food items in a proprietary data set of food purchases and acquisitions. Competing teams used a number of  AI methods including Natural Language Processing (NLP), random forest, and semantic matching.",
      "214": "AI Security and Robustness\nFrameworks, processes, and testing tools developed to govern the acquisition, development, deployment, and maintenance of AI technologies. Technology integrators within CISA as well as the rest of the federal enterprise use AI-enhanced tools to assure the trustworthy, robust, and secure operation of their AI systems. These tools use Machine Learning and Natural Language Processing to enhance the assessment of AI technology within the agency by speeding up data processing.",
      "131": "Discovery of Signatures, Anomalies, \nand Precursors in Synchrophasor Data \nwith Matrix Profile and Deep Recurrent \nNeural Networks\nExplore the use of big data, artificial intelligence (AI), and machine learning technology \nand tools on phasor measurement unit (PMU) data to identify and improve existing \nknowledge, and to discover new insights and tools for better grid operation and \nmanagement.",
      "233": "I-539 approval prediction\nThis project attempts to train and build a machine learning throughput analysis model to predict when an I-539 \"Application to Extend or Change Nonimmigrant Status\" case will be approved through eProcessing. Allows for some potential improvement for the approval process via eProcessing channel.",
      "56": "Deep learning algorithms to \nautomate right whale photo id\nAI for right whale photo id began with a Kaggle competition and has since expanded to \ninclude several algorithms to match right whales from different viewpoints (aerial, lateral) \nand body part (head, fluke, peduncle). The system is now live and operational on the \nFlukebook platform for both North Atlantic and southern right whales. We have a paper in \nreview at Mammalian Biology.",
      "90": "Advances in Nuclear Fuel Cycle \nNonproliferation, Safeguards, and \nSecurity Using an Integrated Data \nScience Approach\nThis research will develop a digital twin of a centrifugal contactor system that \nreceives data from traditional and real time sensors, constructs a digital \nrepresentation or simulation of the chemical separations component within the nuclear \nfuel cycle, and performs data analysis through machine learning to determine \nanomalies, failures, and trends. The research will include the identification and \nimplementation of advanced artificial intelligence, machine learning, and data analysis \ntechniques advised by a team of nuclear safeguards experts.",
      "421": "Acute kidney injury (AKI)\nThis project, a collaboration with Google DeepMind, focuses on detecting acute kidney injury (AKI), ranging from minor loss of kidney function to complete kidney failure. The artificial intelligence can also detect AKI that may be the result of another illness.",
      "323": "Case Recording summarization\nUsing an open source large language model to summarize publicly available case recording documents which are void of personal identifiable information (PII) or any other sensitive information. This is not hosted in the DOL technical environment and is reviewed by human note takers.",
      "65": "CoralNet: Ongoing operational \nuse, improvement, and \ndevelopment, of machine vision \npoint classification\nCoralNet is our operational point annotation software for benthic photo quadrat \nannotation. Our development of our classifiers has allowed us to significantly reduce our \nhuman annotation, and we continue to co-develop (and co-fund) new developments in \nCoralNet,",
      "176": "Splunk IT System Monitoring Software\nSplunk utilizes machine learning to aggregate system logs from IT infrastructure systems and endpoints for auditing and\nmonitoring purposes",
      "289": "Multi-task deep learning for daily streamflow and water temperature\n1) This model predicts two interdependent variables, daily average streamflow and daily average stream water temperature, together using multi-task deep learning. A multi-task scaling factor controls the relative contribution of the auxiliary variable\u2019s error to the overall loss during training. Input data include meteorological variables such as rainfall and humidity. 2) The training data were streamflow and water temperature observations. The stream temperature data were collected by the USGS and made available via NWIS. The streamflow observations were also collected by the USGS but collated along with input drivers in the CAMELS dataset. 3) This work was done using Python. The deep learning models were written via TensorFlow and the modeling workflow was scripted via Snakemake.",
      "428": "Machine learning (ML) for enhanced diagnostic error detection and ML classification of protein electrophoresis text\nResearchers are performing chart review to collect true/false positive annotations and construct a vector embedding of patient records, followed by similarity-based retrieval of unlabeled records \"near\" the labeled ones (semi-supervised approach). The aim is to use machine learning as a filter, after the rules-based retrieval, to improve specificity. Embedding inputs will be selected high-value structured data pertinent to stroke risk and possibly selected prior text notes.",
      "11": "NAL Automated indexing\nCogito (vendor) software, uses AI for automated subject indexing to annotate peer reviewed journal articles (~500,000 annually) using the National Ag Library Thesaurus concept space (NALT). Only NALT concepts are annotated as metadata to content in the Library's bibliographic citation database, AGRICOLA, PubAg, and Ag Data Commons.",
      "258": "AI system to recognize individual fish and disease\nThis study focuses on the development of an AI system to recognize individual fish and their disease status from images. Success of this effort could complement or replace traditional mark-recapture methods used for estimating abundance, survival, and movement, and this could greatly reduce costs to fisheries managers. Likewise, disease detection from images could enable new approaches for assessing status and trends in fish health.",
      "97": "Secure Millimeter Wave Spectrum \nSharing with Autonomous Beam \nScheduling\nThis approach exploits the millimeter wave beam directionality and utilizes the beam \nsensing capabilities at end devices to prove that an autonomous radio frequency \nbeam scheduler can support secure 5G spectrum sharing and guarantee optimality for \nbase stations. Measurements and predictive analytics are used to develop the \nautonomous beam scheduling algorithms. These improvements will benefit mission \ncritical communications and emergency response operations as well as enable \nsecure communication for critical infrastructure without expensive and competitive \nlicensed bands.",
      "265": "ML-Mondays course on applications of deep learning to image analysis\nA course in application of deep learning image segmentation, image classification, and object-in-image detection. Course includes software written in Python using Keras and Tensorflow ML libraries, software documentation, data, website, and slides. See course website https://dbuscombe-usgs.github.io/MLMONDAYS/ for more details",
      "113": "Deep Reinforcement Learning and \nDecision Analytics for Integrated \nEnergy Systems\nThis project will develop a novel deep reinforcement learning approach that can \nmanage distributed or tightly coupled multi-agent systems utilizing deep neural \nnetworks for automatic system representation, modeling, and end-to-end learning. \nThis new control method will enable complex, nonlinear system optimization over \ntimescales from milliseconds to months.",
      "207": "Geospatial imagery utilizing annotation\nLeverages a commercial constellation of Synthetic Aperture Radar (SAR) satellites with readily available data, capable of imaging any location on Earth, day, and night, regardless of cloud cover. \n\nUtilizes AI, including machine vision, object, detection, object recognition, and annotation to detect airframes, military vehicles, and marine vessels, as well as built-in change detection capabilities for disaster response missions.",
      "315": "Data Ingestion of Payroll Forms\nCustom machine learning model to extract data from complex forms to tag data entries to field headers. The input is a document or scanned image of the form and the output is a JSON response with key/value pairs extracted by running the form against the custom trained model.",
      "231": "Facial Recognition Service \nThe Facial Recognition Service is used during investigations conducted by HSI agents and analysts for identification of known individuals, as well as extracting faces for further investigations from perpetrators including child exploitation offenses, human rights atrocities, and war criminals.\n\nThis is a DHS HSI Innovation Lab / RAVEn project. The Repository for Analytics in a Virtualized Environment (RAVEn) facilitates large, complex analytical projects to support ICE\u2019s mission to enforce and investigate violations of U.S. criminal, civil, and administrative laws. RAVEn also enables tools used to analyze trends and isolate criminal patterns as HSI mission needs arise. For more information, please read the DHS/ICE/PIA-055 - Privacy Impact Assessment 055 for RAVEn.",
      "239": "Topic Modeling  on Request For Evidence data sets\nBuilds models that identify lists of topics and documents that are related to each topic. Topic Modeling provides methods for automatically organizing, understanding, searching, and summarizing text data. It can help with the following: discovering the hidden themes in the collection. classifying the documents into the discovered themes.",
      "396": "Evaluate Multilingual BERT \nfor Software Translation \nUse Case Evaluations\nProject is evaluating the cost-effectiveness of training a multi-lingual BERT \nmodel on IRS corpora and using the model as means to evaluate software \ntranslation output of IRS content. The framework is leveraging COMET, \nROGUE, and BLEU measures. Furthermore, the product will also be \nassessed for English-Only and Spanish-Only content content classification.",
      "47": "AI-based automation of acoustic \ndetection of marine mammals\nTimely processing of these data is critical for adapting mitigation measures as climate \nchange continues to impact Arctic marine mammals.  Infrastructure for Noise and \nSoundscape Tolerant Investigation of Nonspecific Call Types (INSTINCT) is command line \nsoftware which was developed in-house for model training, evaluation, and deployment \nof machine learning models for the purpose of marine mammal detection in passive \nacoustic data. It also includes annotation workflows for labeling and validation. INSTINCT \nhas been successfully deployed in several analyses, and further development of detectors \nwithin INSTINCT is desired for future novel studies and automation. Continued integration \nof AI methods into existing processes of the CAEP acoustics group requires a skilled \noperator familiar with INSTINCT, machine learning, and acoustic repertoire of Alaska \nregion marine mammals.",
      "10": "ARS Project Mapping\nNLP of research project plans including term analysis and clustering enables national program leaders to work with an interactive dashboard to find synergies and patterns within and across the various ARS research program portfolios.",
      "371": "SentiBERTIQ\nGEC A&R uses deep contextual AI of text to identify and extract subjective information within the source material. This sentiment model was trained by fine-tuning a multilingual, BERT model leveraging word embeddings across 2.2 million labeled tweets spanning English, Spanish, Arabic, and traditional and simplified Chinese. The tool will assign a sentiment to each text document and output a CSV containing the sentiment and confidence interval for user review.",
      "288": "Process-Guided Deep Learning for Dissolved Oxygen Predictions on Stream Networks\n1) this model predicts daily minimum, mean, and maximum dissolved oxygen (DO) concentrations at several stream locations in the Delaware River Basin. The inputs used are meteorological inputs (e.g., precipitation, cloud cover) and static catchment attributes (e.g., basin area). 2) the training data are DO concentrations collected by the USGS and made available via the National Water Information System (NWIS). 3) this work is being done using Python and R. The deep learning models were written via TensorFlow, the data prepartion is in R, and the modeling workflow was scripted via Snakemake.",
      "251": "Walrus Haulout Camera Trap Image Classification\nThis project extends the application of codes developed for wildlife underpass camera trap image classification. Similarly, the system takes walrus haulout camera trap images as inputs and outputs the probability of the image containing walruses and various human disturbances (boats, aircraft, etc.). We will use and further develop the previous system's capability of supporting training experiments. Training, validation, and testing datasets have human-assigned labels and are used to train and evaluate the models. Once trained, the models can be used to predict classes on unlabeled images from ongoing camera monitoring efforts. We use a convolutional neural network (CNN) approach based on TensorFlow and training is run on the USGS Tallgrass supercomputer designed for AI/ML workflows.",
      "370": "Deepfake Detector\nDeep learning model that takes in an image containing a person\u2019s face and classifies the image as either being real (contains a real person\u2019s face) or fake (synthetically generated face, a deepfake often created using Generative Adversarial Networks).",
      "149": "Relevancy Tailoring\nAdjusting the ranking of search results so that most relevant results show up at the top of the list",
      "75": "An Interactive Machine Learning Signals in Passive Acoustic  Recordings\nToolkit for Classifying Species \nIdentity of Cetacean Echolocation\nDevelop robust automated machine learning detection and classification tools for acoustic \nspecies identification of toothed whale and dolphin echolocation clicks for up to 20 \nspecies found in the Gulf of Mexico. Tool development project funded from June 2018 to May 2021. Tool will be used for automated analyses of long-term recordings from Gulf- wide passive acoustic moored instruments deployed from 2010-2025 to look at  environmental processes driving trends in marine mammal density and distribution.",
      "76": "Steller sea lion automated count \nprogram\nNOAA Fisheries Alaska Fisheries Science Center's Marine Mammal Laboratory (MML) is \nmandated to monitor the endangered western Steller sea lion population in Alaska. MML \nconducts annual aerial surveys of known Steller sea lion sites across the southern \nAlaska coastline to capture visual imagery. It requires two full-time, independent counters \nto process overlapping imagery manually (to avoid double counting sea lions in multiple \nframes), and count and classify individuals by age and sex class. These counts are vital \nfor population and ecosystem-based modeling to better understand the species and \necosystem, to inform sustainable fishery management decisions, and are eagerly \nanticipated by stakeholders like the NOAA Alaska Regional Office, industry, and \nenvironmental groups. MML worked with Kitware to develop detection and image \nregistration pipelines with VIAME (updates to the DIVE program to support updated \ninterface needs). MML is now working to assess the algorithms efficacy and develop a \nworkflow to augment the traditional counting method (to RL 9).",
      "122": "Tailoring the Properties of Multiphase \nMaterials Through the Use of \nCorrelative Microscopy and Machine \nLearning\nThis research uses state-of-the-art machine learning (ML) techniques in a new and \nnovel manner to identify and correlate the critical microstructural features in a \nmultiphase alloy that exhibits high strength and fracture toughness. Experimental data \nwill be used to train a convolutional neural network (CNN) in a semi-supervised \nenvironment to identify key microstructural features and correlate those features with \nthe strength and toughness. The resulting machine learning tool can be trained for \nadditional microstructural features, different alloys, and/or target mechanical \nproperties.",
      "101": "Infrastructure eXpression\nThe project developed a framework and process to translate industrial control system \nfeatures to a machine-readable format for use with automated cyber tools. This \nresearch also examined other current and evolving standards for usability with diverse \ngrid architectures that represent a set of variable conditions to establish the \nfoundation for determining where future research should focus and to support \nimprovements to industry standards and architecture designs for machine-learning \ncyber defense solutions. This project\u2019s success can serve as the foundation for \nprioritizing the next research steps to realize automated threat response, improving \nthe timeliness and fidelity of cyber incident consequence models, and enriching \nnational capabilities to share actionable threat intelligence at machine speed.",
      "394": "Collection Chat Bot\nThe Natural Language Understanding (NLU) model will be located inside \nthe eGain intent engine. This NLU will take customer typed text input aka \n\u2013 Utterances.  It will map the utterance to a specific intent and return the \nappropriate knowledge article.",
      "400": "Line Anomaly \nRecommender\nThis use case seeks to identify a workload selection model that uses two \nrecommender system models to measure overall compliance risk and \nidentify anomalous tax returns and line-item values. The delivered pipeline \ncapabilities can supplement the core case selection model processes by \nproviding additional insight to IRS LB&I reviewers through the use of \nadvanced deep learning techniques for anomaly detection.",
      "133": "Robust Learning of Dynamic \nInteractions for Enhancing Power \nSystem Resilience\nExplore the use of big data, artificial intelligence (AI), and machine learning technology \nand tools on phasor measurement unit (PMU) data to identify and improve existing \nknowledge, and to discover new insights and tools for better grid operation and \nmanagement.",
      "37": "Predictive Maintenance Impacts\nPredict impacts of DISC maintenance on infrastructure items.  Utilizes: einblick, mysql, python, linux, tableau",
      "205": "Data and Entity Resolution\nAutomates data unification and entity resolution with a high level of trust at enterprise scale and speed.\n\nData and Entity Resolution uses Machine Learning modeling to ingest multiple data sources and develop models that associate disparate records to identify probable connections, unique entities, and/or identify commonalities between multiple independently submitted records.\n\nThe automation of entity resolution within the models is supported by a tool that enables non-technical end users to continuously train models through a user-friendly interface. ",
      "302": "A machine learning approach to developing ground motion models from simulated ground motions\nWe use a machine learning approach to build a ground motion model (GMM) from a synthetic database of ground motions extracted from the Southern California CyberShake study. An artificial neural network is used to find the optimal weights that best fit the target data (without overfitting), with input parameters chosen to match that of state-of-the-art GMMs. We validate our synthetic-based GMM with empirically based GMMs derived from the globally based Next Generation Attenuation West2 data set, finding near-zero median residuals and similar amplitude and trends (with period) of total variability. Additionally, we find that the artificial neural network GMM has similar bias and variability to empirical GMMs from records of the recent Mw7.1 Ridgecrest event, which neither GMM has included in its formulation. As simulations continue to better model broadband ground motions, machine learning provides a way to utilize the vast amount of synthetically generated data and guide future parameterization of GMMs. ",
      "48": "Developing automation to \ndetermine species and count \nusing optical survey data in the \nGulf of Mexico\nVIAME - This project focuses on optical survey collected in the Gulf of Mexico: 1) develop \nan image library of landed catch, 2) develop of automated image processing (ML/DL) to \nidentify and enumerate species from underwater imagery and 3) develop automated \nalgorithms to process imagery in near real time and download information to central \ndatabase.",
      "2": "High throughput phenotyping in citrus orchards\nLocate, count, and categorize citrus trees in an orchard to monitor orchard health",
      "115": "Automated Infrastructure & Dependency \nDetection via Satellite Imagery and \nDependency Profiles\nComputer vision, a broad set of techniques for training statistical models and neural \nnetworks to process images, has advanced substantially in recent years. Applying \nthese capabilities to satellite imagery can improve critical infrastructure analysis and \ninterdependency data build-outs. Combining advanced computer vision techniques, a \nfunctional taxonomic approach to critical infrastructure, and the unique geo-spatial and \ndependency datasets the research team developed can produce innovative and state-\nof-the-art image processing results that advance abilities to secure and defend \nnational critical infrastructure.",
      "152": "Suggested Related Content\nShow related searches that may provide the user with other related, valuable information",
      "359": "GPATools and GPAIX\nGPA\u2019s production system for testing potential messages at scale across segmented foreign sub-audiences to determine effective outreach to target audiences.",
      "319": "Electronic Records Management\nMeeting NARA metadata standards for (permanent) federal documents by using AI to identify data within the document, and also using NLP to classify and summarize documents.",
      "190": "Research, Condition, and Disease Categorization (RCDC)\nRCDC is an electronic budget reporting tool that categorizes projects using AI/NLP. The inputs are grant applications,\nR&D contracts, intramural projects, inter agency agreements. The RCDC Fingerprinting process identifies concepts in the\nextracted text from the source project, person or publication. The text is normalized, concepts are extracted, concepts\nand synonyms are matched to the RCDC thesaurus. A rank is applied based on the frequency of occurrence of the\nconcepts within the text. Project fingerprints are sourced from the application description text (Title, Abstract and\nSpecific Aims). Titles and abstracts provide the source of scientific concepts for publications. The system then outputs the\nprojects into their respective areas of science.",
      "301": "Application of machine learning to  ground motion-based earthquake early warning\nWe use initial observations of an earthquake on seismic stations close to an earthquake to predict what the peak ground shaking will be across a region. The initial test dataset are waveforms from the USGS-collected, large-n seismic array in an area of induced seismicity in Oklahoma. Future datasets will include seismic data from the California Seismic Integrated Network (primarily supported by USGS) and possible the Japanese Meterological Agency. Currently running Python-based codes on a desktop, plan to move to AWS or similar. ",
      "57": "NN Radiation\nDeveloping fast and accurate NN LW- and SW radiations for GFS and GEFS.  NN LW- and \nSW radiations have been successfully developed for previous version of GFS, see: doi: \n10.1175/2009MWR3149.1 and the stability and robustness of the approach used was \ndemonstrated, see:  https://arxiv.org/ftp/arxiv/papers/2103/2103.07024.pdf  NN LW- and \nSW radiations will be developed for the current versions of for GFS and GEFS.",
      "217": "Critical Infrastructure Anomaly Alerting\nThe Cyber Sentry program provides monitoring of critical infrastructure networks. Within the program, threat hunting analysts require advanced anomaly detection and machine learning capabilities to examine multimodal cyber-physical data on IT and OT networks, including ICS/SCADA. The Critical Infrastructure Anomaly Alerting model provides AI-assistance in processing this information.",
      "242": "Data Driven Streamflow Forecasting\nReclamation, along with partners from the CEATI hydropower industry group (e.g. TVA, DOE-PNNL, and others) ran a year-long  evaluation of existing 10-day streamflow foreasting technologies and a companion prize competition open to the public, also focused on 10-day streamflow forecasts. Forecasts were issued every day for a year and verified agains observed flows. Across locations and metrics, the top perfoming foreacst product was a private, AI/ML forecasting company - UpstreamTech. Several competitors from the prize competition also performed strongly; outperforming benchmark forecasts from NOAA. Reclamation is working to further evaluate the UpstreamTech forecast products and also the top performers from the prize competition.  ",
      "25": "Land Change Analysis Tool (LCAT)\nWe employ a random forest machine learning classifier to produce high resolution land cover maps from aerial and/or satellite imagery.  Training data is generate from a custom-built web application.  We built and operate a 192-node docker cluster to parallize CPU-intensive processing tasks.  We are publishing results through a publicly available  Image service.  To date we have mapped over 600 million acres and have generated over 700 thousand traiing samples.",
      "53": "Drought outlooks by using ML \ntechniques\nDrought outlooks by using ML techniques with NCEP models. Simple NN and Deep \nLearning techniques used for GEFSv12 to predict Week 1-5 Prcp & T2m over CONUS",
      "245": "Photogrammetric Data Set Crack Mapping Technology Search \nThis project is exploring a specific application of photogrammetric products to process analysis of crack mapping on Reclamation facilites.  This analysis is time consuming and has typically required rope access or other means to photograph and locate areas that can now be reached with drones or other devices.  By formulating a standard reference protocol and applying machine learning/AI, this information will be used to provide detailed analysis of Reclamation assets for better decision making. ",
      "110": "Interdependent Infrastructure Systems \nResilience Analysis for Enhanced \nMicroreactor Power Grid Penetration\nThis project will develop machine learning enabled integrated resource planning \nmethodologies to help quantify key resilience elements across integrated energy \nsystems and their vulnerabilities to threats and hazards. This includes the ability to \naccurately analyze and visualize a region\u2019s critical infrastructure systems ability to \nsustain impacts, maintain critical functionality, recover from disruptive events. This \nadvanced decision support capability can improve our understanding of these complex \nrelationships and help predict the potential impacts that microreactors and distributed \nenergy resources have on the reliability and resiliency of our energy systems.",
      "412": "Serbia: AI predictions for the utilization of hospital beds \nAI technology was used to predict bed occupancy at hospitals with MoH data from 2019, with an overall median error by department around 20%. This was a proof-of-concept model developed at the request of the Institute of Public Health (IPH) Batut to understand how AI can work and the value add. CHISU was asked to subsequently focus on a different use case (waiting list optimization for scheduled imaging diagnostics services, specifically CT and MRI), which is considered higher priority to demonstrate the implementation of the national AI strategy and the effect of AI in data use for decision making by the government, and will be addressed in the 2023-4.",
      "435": "Predictor profiles of OUD and overdose\nMachine learning prediction models evaluate the interactions of known and novel risk factors for opioid use disorder (OUD) and overdose in Post-9/11 Veterans. Several machine learning classification-tree modeling approaches are used to develop predictor profiles of OUD and overdose.\u00a0",
      "177": "COVID-19 Pandemic Vulnerability Index\nDashboard\nThe dashboard creates risk profiles, called PVI scorecards, for every county in the United States, continuously updated\nwith the latest data that summarize and visualize overall disease risk.",
      "453": "Extraction of family medical history from patient records\nThis pilot project uses TIU documentation on African American Veterans aged 45-50 to extract family medical history data and identify Veterans who are are at risk of prostate cancer but have not undergone prostate cancer screening.",
      "325": "Scanner Data Product Classification\nBLS receives bulk data from some corporations related to the cost of goods they sell and services they provide. Consumer Price Index (CPI) staff have hand-coded a segment of the items in these data into Entry Level Item (ELI) codes. To accept and make use of these bulk data transfers at scale, BLS has begun to use machine learning to label data with ELI codes. The machine learning model takes as input word frequency counts from item descriptions. Logistic regression is then used to estimate the probability of each item being classified in each ELI category based on the word frequency categorizations. The highest probability category is selected for inclusion in the data. Any selected classifications that do not meet a certain probability threshold are flagged for human review.",
      "88": "Aidan\nFSA\u2019s virtual assistant uses natural language processing to answer common financial aid questions and help customers get information about their federal aid on StudentAid.gov. In just over two years, Aidan has interacted with over 2.6 million unique customers, resulting in more than 11 million user messages.\u00a0",
      "218": "Cyber Incident Reporting\nCyber incident handling specialists utilize advanced automation tools to process data received through various threat intelligence and cyber incident channels. These tools leverage Machine Learning and Natural Language Processing to increase the accuracy and relevance of data that is filtered and presented to human analysts and decision-makers. Machine Learning techniques also assist to aggregate the information in reports for presentation and further analysis. This includes data received through covered CIRCIA entities.",
      "8": "Artificial Intelligence for correlative statistical analysis\nAI-type statistical techniques are used to model predictive relationships between variables. We routinely use modeling approaches such as random forest, artificial neural networks, k-nearest neighbor clustering, and support vector machines, for statistical prediction. ",
      "128": "MindSynchro\nExplore the use of big data, artificial intelligence (AI), and machine learning technology \nand tools on phasor measurement unit (PMU) data to identify and improve existing \nknowledge, and to discover new insights and tools for better grid operation and \nmanagement.",
      "286": "Process-Guided Deep Learning Predictions of Lake Water Temperature\nThis process-guided deep learning model predicts depth-specific lake temperatures while obeying physical laws using inputs of meteorological drivers. Training consists of two stages. In the first stage, the model is pre-trained using process-based modeling outputs. Then, lake temperature observations are used to finetune the model in a second training stage. The models are trained to simultaneously fit observations and honor conservation of energy. The models were developed using various R and Python packages on the USGS Tallgrass supercomputer. The General Lake Model (GLM version 2) software was used for process-based modeling.",
      "185": "SingleCite: Improving single citation search in\nPubMed\nA search that is targeted at finding a specific document in databases is called a Single Citation search, which is particularly\nimportant for scholarly databases, such as PubMed, because it is a typical information need of the users. We have\ndeveloped SingleCite, an automated algorithm that establishes a query-document mapping by building a regression\nfunction to predict the probability of a retrieved document being the target based on three variables: the score of the\nhighest scoring retrieved document, the difference in score between the two top retrieved documents, and the fraction\nof a query matched by the candidate citation. SingleCite shows superior performance in benchmarking experiments and\nis applied to rescue queries that would fail otherwise.",
      "141": "Key KPI Forecasts for GWCM\nTakes monthly historical data for underlying components used to calculate KPIs and creates near-term forecasts for the upcoming fiscal year. Pilot effort focuses on total agency/category spend (the denominator in multiple KPIs). If the pilot program is successful, the same methodology can be extended to other KPIs.",
      "271": "Characterization of Sub-surface drainage (tile drains) from satellite imagery\nWithout knowing how tile-drain extent (sub-surface agricultural drainage) has changed with time, it is difficult to differentiate how streamflow and water quality have changed as a result of spatial extent and characteristics of tile-drain networks.  Our method delineates tile drains in satellite imagery, providing a way to look at historical imagery and to use satellite data to maintain an up-to-date geospatial layer of tile drain extent in basins of interest.  We use panchromatic imagery that is processed using a UNet model that was trained on a library of panchromatic images on which visible tile-drain networks had been traced.  Our workflow uses a combination of python scripting that is encapsulated in a Jupyter notebook; the entire process is open source.  ",
      "351": "Automated Damage Assessments\nThe Conflict Observatory program uses AI and machine learning on moderate and high-resolution commerical satellite imagery to document a variety of war crimes and other abuses in Ukraine, including automated damage assessments of a variety of buildings, including critical infrastructure, hospitals, schools, crop storage facilities.",
      "112": "Support Vector Analysis for \nComputational Risk Assessment, \nDecision-Making, and Vulnerability \nDiscovery in Complex Systems\nThis project addressed limitations in current probabilistic risk assessment (PRA) by \ncombining a support vector machine and PRA software to auto-detect system design \nvulnerabilities and find previously unseen issues, reduce human error, and reduce \nhuman costs. This method does not require training data that would only be available \nin the event of system or subsystem failures.",
      "236": "Person-Centric Identity Services Deduplication Model\nThe vision of Person-Centric Identity Services (PCIS) is to be the authoritative source of trusted biographical and biometric information that provides real-time, two-way visibility between services into an individual's comprehensive immigration history and status. The de-duplication model, ingests person-centric datasets from various source systems for model training and evaluation purposes. Our dataset includes biographic information (name, date of birth, Alien #, Social Security #, passport #, etc.) as well as biographic information (fingerprint IDs, eye color, hair color, height, weight, etc.) for model training and matching purposes. \n\nCritical to the success of PCIS is the entity resolution/deduplication of individual records from various systems of records to create a complete picture of a person. Using machine learning, it is able to identify which case management records belong to the same unique individual with a high degree of confidence. This allows PCIS to pull together a full immigration history for an individual without time-consuming research across multiple disparate systems.\n\nThe Deduplication model plays a critical role in the entity resolution and surfacing of a person and all their associated records. The ML models are more resilient to fuzzy matches, and deals with the reality of different data fill rates more reliably.",
      "404": "Media Early Warning System (MEWS)\nTo detect narratives and trends in social media alterations of images and video in order to find and counteract malign narratives",
      "92": "Scalable Framework of Hybrid Modeling \nwith Anticipatory Control Strategy for \nAutonomous Operation of Modular and \nMicroreactors\nThe goal this research is to develop and validate novel and scalable models to \nachieve faster-than-real-time prediction and decision-making capabilities. To achieve \nthe project goal of autonomous operation of microreactors, a novel hybrid modeling \napproach combining both physics-based and artificial intelligence techniques will be \ndeveloped at the component or sub-system level, integrated with anticipatory control \ntechniques, and scaled. A novel distributed anticipatory control strategy will be \ndeveloped as part of the scalability analysis to understand the risk of cascading \nfailures when emerging reactors are deployed as part of a full feeder microgrid.",
      "111": "Adaptive Fingerprinting of Control \nSystem Devices through Generative \nAdversarial Networks\nThis project focuses on the reduction of manual labor and operational cost required \nfor training an electromagnetic (EM)-based anomaly detection system for legacy \nindustrial control systems devices and Industrial Internet of Things. This research \nwould enable EM-based intrusion detection systems to be deployed to protect legacy \ncontrol systems.",
      "54": "EcoCast: A dynamic ocean \nmanagement tool to reduce \nbycatch and support sustainable \nfisheries\nOperational tool that uses boosted regression trees to model the distribution of swordfish \nand bycatch species in the California Current",
      "167": "Priority Score Timeliness - forecast the time needed to work on an alert produced by Fraud Prevention System (Random Forest, Decision Tree, Gradient Boost, Generalized Linear Regression)\nInputs - Medicare Claims data, TPE Data, Jurisdiction information\nOutput - forecast the time needed to work on an alert produced by FPS (Random Forest, Decision Tree, Gradient Boost,\nGeneralized Linear Regression)",
      "66": "Automated detection of \nhazardous low clouds in support \nof safe and efficient \ntransportation\nThis is a maintenance and sustainment project for the operational GOES-R fog/low stratus \n(FLS) products. The FLS products are derived from the combination of GOES-R satellite \nimagery and NWP data using machine learning. The FLS products, which are available in \nAWIPS, are routinely used by the NWS Aviation Weather Center and Weather Forecast \nOffices.",
      "124": "The Grid Resilience and Intelligence \nPlatform (GRIP)\nAI within GRIP is used to develop metrics that quantify the impact of the anticipated \nweather related extreme events. The platform uses utility data combined with physical \nmodels, distribution power solver  to infer the potential  grid impacts given a major \nstorm.",
      "178": "National Institute of General Medical Sciences\n(NIGMS) AI Supported Searches, Information\nSystems and Tools\nSystem Acronym: NIGMS ASSIST)\nNIGMS program staff often need information that is available through IMPAC or QVR to perform their daily tasks. In order\nto provide such information, DIMA and IRMB have collaborated to develop functions that utilize artificial intelligence and\nnatural language processing methods to produce data relevant to the program staff\u2019s mission. These tools are collected\ninto a single system to make them available to the NIGMS community for use on a day-to-day basis. ASSIST provides a\nsecure interface supported by Oracle, SQL server and Python analytics. The individual components of ASSIST provide the\nfollowing functions:\n- FLIP module (Development), provides the ability to identify investigators by PPID from Federal RePORTER based on user\ninput of investigator PPIDs.\n- TPAL module (Production), provides the ability to lookup potential matching program officers, including their\ncorresponding predicted Program Area Codes, and ICs based on the input of unstructured scientific data.",
      "160": "Chatbot \u2013 Text\nCMS/OSFLO: To assist the Security team, this Chatbot (text) provides an automated email response for general physical\nsecurity questions, allowing the help desk team to assist employees and contractors with more in depth issues.",
      "426": "Digital command center\nThe Digital Command Center seeks to consolidate all data in a medical center and apply predictive prescriptive analytics to allow leaders to better optimize hospital performance.\u00a0\u00a0",
      "452": "GI Genius (Medtronic)\nThe Medtronic GI Genius aids in detection of colon polyps through artificial intelligence.",
      "378": "Determining Surface Winds with Machine Learning Software\nSuccessfully demonstrated use of an AI capability to analyze camera images of a wind sock to produce highly accurate surface wind speed and direction information in remote areas that don\u2019t have a weather observing sensor.",
      "129": "PMU-Based Data Analytics Using \nDigital Twin Phasor Analytics Software\nExplore the use of big data, artificial intelligence (AI), and machine learning technology \nand tools on phasor measurement unit (PMU) data to identify and improve existing \nknowledge, and to discover new insights and tools for better grid operation and \nmanagement.",
      "318": "Official Document Validation\nAI detection of mismatched addresses and garbled text in official letters sent to benefits recipients.",
      "100": "Resilient Attack Interceptor for \nIntelligent Devices\nThe Resilient Attack Interceptor for Intelligent Devices approach focuses on \ndeveloping external monitoring methods to protect industrial internet of things devices \nby correlating observable physical aspects that are produced naturally and \ninvoluntarily during the operational lifecycle with anomalous functionality.",
      "416": "NASA SERVIR - Using artificial intelligence to forecast harmful algae blooms in Lake Atitl\u00e1n, Guatemala\nThis application uses machine learning with Earth observations and weather-modeled data to forecast daily algal blooms in Lake Atitl\u00e1n, Guatemala. The forecasting system is being used by Lake Authorities, such as the  Authority for Sustainable Management of the Lake Atitlan Basin and its surroundings (AMSCLAE),  to inform their Harmful Algal Blooms Alert System. This work is also supported by National Geographic and Microsoft through their Artificial Intelligence (AI) for Innovation grants. ",
      "457": "Social determinants of health extractor\nAI is used with clinical notes to identify social determinants of health (SDOH) information. The extracted SDOH variables can be used during associated health related analysis to determine, among other factors, whether SDOH can be a contributor to disease risks or healthcare inequality.",
      "295": "Where\u2019s the Rock: Using Neural Networks to Improve Land Cover Classification\nWhile machine learning techniques have been increasingly applied to land cover classification problems, these techniques have not focused on separating exposed bare rock from soil covered areas. Therefore, we are using a neural network to differentiate exposed bare rock (rock) from soil cover (other). We started with a training dataset by mapping exposed rock at 20 test sites across the Sierra Nevada Mountains (California, USA) using USDA\u2019s 0.6 m National Aerial Inventory Program (NAIP) orthoimagery. These initial sites were used to train and test the original CNN and now NASA's DELTA toolkit, which is being run on the USGS high-performance computing facilities. The goal is to generate a machine learning approach to classify bare rock in NAIP orthoimagery, starting with the Sierras, in order to provide a more accurate map of soil vs. rock-covered areas for use in landslide hazard mapping, quantifying soil carbon storage, calculating water fluxes, etc.",
      "215": "AIS Scoring and Feedback\nAIS Automated Scoring & Feedback (AS&F) is uses descriptive analytics from organizational-centric intelligence to support confidence and opinion/reputation classification of indicators of compromise (IOCs). Looking at an indicator AS&F determines if the indicator is present in known-good list by cross-referencing organizational-centric intelligence data of known non-malicious/benign indicators and classifies accordingly if true. If not a known-good, determine if there are sightings of the indicator by cross-referencing organizational-centric intelligence and classify accordingly if true. If there are no sightings for the indicator, determine if this indicator has been verified by an analyst within our organizational-centric intelligence and classify accordingly if true. Lastly if the indicator has not been verified by an analyst, AS&F determines whether there are other reports within our organizational-centric intelligence about this indicator and classifies accordingly. AIS participants can triage against the populated opinion and/or confidence values to identify Indicator objects meeting or exceeding designated criteria and filter out the remaining data. AIS participants may also find value in utilizing the confidence score (if present) and the opinion value to understand whether any difference between the publisher and other organizations exists. Together, these enrichments can help those receiving information from AIS prioritize actioning and investigating Indicator objects.",
      "134": "Use of random forest model to predict exposure pathways\nPrioritizing the potential risk posed to human health by chemicals requires tools that can estimate exposure from limited information. In this study, chemical structure and physicochemical properties were used to predict the probability that a chemical might be associated with any of four exposure pathways leading from sources-consumer (near-field), dietary, far-field industrial, and far-field pesticide-to the general population. The balanced accuracies of these source-based exposure pathway models range from 73 to 81%, with the error rate for identifying positive chemicals ranging from 17 to 36%. We then used exposure pathways to organize predictions from 13 different exposure models as well as other predictors of human intake rates. We created a consensus, meta-model using the Systematic Empirical Evaluation of Models framework in which the predictors of exposure were combined by pathway and weighted according to predictive ability for chemical intake rates inferred from human biomonitoring data for 114 chemicals. The consensus model yields an R2 of\u00a0\u223c0.8. We extrapolate to predict relevant pathway(s), median intake rate, and credible interval for 479 926 chemicals, mostly with minimal exposure information. This approach identifies 1880 chemicals for which the median population intake rates may exceed 0.1 mg/kg bodyweight/day, while there is 95% confidence that the median intake rate is below 1 \u03bcg/kg BW/day for 474572 compounds.\nhttps://pubmed.ncbi.nlm.nih.gov/30516957/",
      "19": "CLT Knowledge Database\nThe CLT knowledge database catalogs cross-laminated timber information in an interface that helps users find relevant information. The information system uses data aggregator bots that search the internet for relevant information. These bots search for hundreds of keywords and use machine learning to determine if what is found is relevant. The search engine uses intelligent software to locate and update pertinent CLT references, as well as categorize information with respect to common application and interest areas. As of 2/24/2022, the CLT knowledge database has cataloged >3,600 publications on various aspects of CLT. This system fosters growth of mass timber markets by disseminating knowledge and facilitating collaboration among stakeholders, and by reducing the risk of duplication of efforts. Manufacturers, researchers, design professionals, code officials, government agencies, and other stakeholders directly benefit from the tool, thereby supporting the increasing use of mass timber, which benefits forest health by increasing the economic value of forests.",
      "344": "Supply Chain Fraud and Risk Models\nA/LM plans to expand current risk analytics through development of AI/ML models for detecting anomalous activity within the Integrated Logistics Management System (ILMS) that could be potential fraud or malfeasance. The models will expand upon existing risk models and focus on key supply chain functions such as: Asset Management, Procure-to-Pay, and Fleet Management.",
      "399": "LB&I Text Analytics \n(including Appeals Case \nManagement)\nTrained text extraction and tax domain-specific BERT models (called \nTaxBERT) using about 190,000 documents including Internal Revenue \nCode, Internal Revenue Manual, and PDFs from irs.gov, Revenue Rulings, \nPrivate Letter Rulings, Revenue Procedures, Treasury Decisions, and other \nlegal tax-related documents. The extracted text was decomposed into 21 \nmillion sentences with 1 million unique tokens. Further filtering \nrefinement resulted in 11 million unique sentences and 31 thousand unique vocabulary tokens which are then used to train domain-specific  NLP models which can be used for targeted analytics.",
      "254": "Walrus Object Detection in Drone/Satelite Imagery\nThis system, once developed, will input drone imagery and output bounding boxes for individual walruses. If successful, this will allow researchers with Alaska Science Center to count the numbers of walruses in drone imagery to support population reseaarch. The system will use TensorFlow-based convolutional neural networks for object detection trained on the USGS Tallgrass supercomputer.",
      "294": "AI applications to mapping surface water\nThe research is investigating the use of hand annotated hydrography from one region to train an artificial neural net (ANN) to identify where surface water is likely to be in other areas. The input training data includes lidar, radar, and other remotely sensed data along with modeled surface flow to inform the model. The work is using open-source tools in a high-performance computing environment. ",
      "342": "Product Service Code Automation ML Model\nA/LM developed a machine learning model to scan unstructured, user entered procurement data such as Requisition Title and Line Descriptions to automatically detect the commodity and services types being purchased for enhanced procurement categorization.",
      "339": "Quick Disability Determinations Process\nThe Quick Disability Determinations (QDD) process uses a computer-based predictive model to screen initial applications to identify cases where a favorable disability determination is highly likely and medical evidence is readily available. The Agency bases the QDD model\ufffds predictive scores on historical data from application forms completed by millions of applicants. By identifying QDD cases early in the process, the Social Security Administration can prioritize this workload and expedite case processing.  The Agency routinely refines the QDD model to reflect the characteristics of the recent applicant population and optimize its ability to identify strong candidates for expedited processing. ",
      "385": "Automatic Track Change Detection Demonstration and Analysis\nDescription: DeepCNet-based neural network to identify and classify track-related  features (e.g., track components, such as fasteners and ties) for \"change detection\" applications.\nInput: Line-scan images from rail-bound inspection systems\nOutput: Notification of changes from status quo or between different inspections based on geolocation.",
      "189": "Program Class Code (Area of Science) Referral for NIAID\nThe REFERRAL GROUP of Referral, Program Analysis Branch (RPAB) is responsible for program assignments for all\nresearch, training, career, and fellowship grant applications submitted to NIAID, from CSR. The NIAID Program Class Code\nclassification AI project evaluates the projects that are in RAPB and auto assigns these grant applications to the Program\nClass Codes. The inputs are comprised of approximately 6,000+ grant applications that are currently manually assigned\nby RPAB Staff. The output would be grant applications that are categorized into their respective PCC's.",
      "9": "4% Repair Dashboard\nThe model reviews the descriptions of expenses tagged to repairs and maintenance and classifies expenses as \"repair\" or \"not repair\" based on keywords in context.",
      "39": "B2B Matchmaking\nThe system's algorithms and AI technology qualifies data and makes B2B matches with \nevent participants according to their specific needs and available opportunities.  The \nsystems inputs are data related to event participants and the outputs are suggested B2B \nmatches between participants and a match strength scorecard.",
      "155": "Chatbot\nAn interactive interface that can respond to plain language queries in real time using natural language processing",
      "243": "Seasonal/Temporary Wetland/Floodplain Delineation using Remote Sensing and Deep Learning\nReclamation was interested in determining if recent advancements in machine learning, specifically convolutional neural network architecture in deep learning, can provide improved seasonal/temporary wetland/floodplain delineation (mapping) when high temporal and spatial resolution remote sensing data is available? If so, then these new mappings could inform the management of protected species and provide critical information to decision-makers during scenario analysis for operations and planning.",
      "224": "Text Analytics for Survey Responses (TASR)\nText Analytics for Survey Responses (TASR) is an application for performing Natural Language Processing (NLP) and text analytics on survey responses. It is currently being applied by DHS OCHCO to analyze and extract significant topics/themes from unstructured text responses to open-ended questions in the quarterly DHS Pulse Surveys. Results of extracted topics/themes are provided to DHS Leadership to better inform agency-wide efforts to meet employees\u2019 basic needs and improve job satisfaction",
      "31": "Ecological Site Descriptions (machine learning)\nAnalysis of over 20 million records of soils data and 20,000 text documents of ecological state and transition information. ",
      "433": "Prediction of Veterans' Suicidal Ideation following Transition from Military Service\nMachine learning is used to identify predictors of veterans' suicidal ideation. The relevant data come from a web-based survey of veterans\u2019 experiences within three months of separation and every six months after for the first three years after leaving military service.",
      "415": "NASA SERVIR - Bias Correcting Historical GEOGloWS ECMWF Streamflow Service (GESS) data using Machine Learning (ML) Techniques\nGEOGloWS ECMWF Streamflow Service (GESS) helps to organize the international community engaged in the hydrologic sciences, observations, and their application to forecasting and provides a forum for government-to-government collaboration, and engagement with the academic and private sectors to achieve the delivery of actionable water information. Since the formal creation of the initiative in 2017, the most significant element of GEOGloWS has been the application of Earth Observations (EO) to create a system that forecasts flow on every river of the world while also providing a 40-year simulated historical flow.\n\nThis application uses Long Short Term Memory (LSTM) Model with the time series of discharge data to bias correct the globally available GESS discharge information locally.",
      "168": "Provider Education 90 Day - reviews claims for provider before and after education for statistical change in their claim submission patterns\nInputs - Medicare Claims data, TPE Data, Jurisdiction information\nOutput - reviews claims for provider before and after education for statistical change in their claim submission patterns",
      "309": "Form Recognizer for Benefits Forms\nCustom machine learning model to extract data from complex forms to tag data entries to field headers. The input is a document or scanned image of the form and the output is a JSON response with key/value pairs extracted by running the form against the custom trained model.",
      "153": "Auto Tagging\nSuggesting content tags automatically based on a machine-driven evaluation of how existing content is tagged",
      "107": "Unattended Operation through Digital \nTwin Innovations\nThe team hypothesizes that artificial intelligence can predict events using the \nintegrated data from test bed sensors and physics-based models. A second \nhypothesis is that integrating software and artificial intelligence with sensor data from \na test bed will lead to a framework for future digital twins. The team will train artificial \nintelligence models to determine what attributes are most important for enabling \nintelligent autonomous control and will determine best practices for digital twin \ncybersecurity.",
      "80": "Picky\nUsing CNN to pick out objects of a particular size from sides scan imagery.  Presents users \nwith a probability that allows for automation of contact picking in the field.  Side scan \nimagery is simple one channel intensity image which lends itself well to basic CNN \ntechniques.",
      "275": "The National Landcover database\nNLCD uses AI/ML to develop Landcover across all 50 states. The system includes HPC processes, cloud services, and local resources to create thematic and continuous field classifications. These classifications serve as the base for users and federal agencies across the nation to provide wildlife habitat estimates, urban runoff estimates, population growth, etc. etc.",
      "43": "Market Diversification Toolkit\nThe Market Diversification Tool identifies potential new export markets using current \ntrade patterns. A user enters what products they make and the markets they currently \nexport to.  The Market Diversification Tool applies a ML algorithm to identify and compare \nmarkets that should be considered.  The tool brings together product-specific trade and \ntariff data and economy-level macroeconomic and governance data to provide a picture \nof which markets make sense for further market research. Users can limit the markets in \nthe results to only the ones they want to consider and modify how each of the eleven \nindicators in the tool contributes to a country\u2019s overall score. Users can export all the data \nto a spreadsheet for further analysis.",
      "293": "Explainable AI and interpretable machine learning\nThis work focuses on developing expertise and resources for Explainable AI (XAI) within WMA PUMP Projects.  The inputs are various models developed for predicting stream temperature, discharge, dissolved oxygen, and other characteristics.  The outputs are interpretable metrics to help understand why models are making the predictions they are and what physical processes are getting captured with the model architectures.",
      "406": "Machine Learning for Peace\nObjective 1 under the Illuminating New Solutions and Programmatic Innovations for Resilient Spaces\u2019 (INSPIRES). Includes program activities\nand website - https://web.sas.upenn.edu/mlp-devlab/",
      "116": "Accelerated Nuclear Materials and Fuel \nQualification by Adopting a First to \nFailure Approach\nPhysics-based multi-scale modeling was coupled with deep, recursive, and transfer \nlearning approaches to accelerate nuclear materials research and qualification of high-\nentropy alloys. Applying AI to combinatorial-based materials research enables \nsubsequent analysis to focus on a limited number of candidates predicted to have the \nnecessary materials properties for the application.",
      "137": "Solicitation Review Tool (SRT)\nThe SRT intakes SAM.gov data for all Information and Communications Technology (ICT) solicitations. The system then compiles the data into a database to be used by machine learning algorithms. The first of these is a Natural Language Processing model that determines if a solicitation contains compliance language. If a solicitation does not have compliance language, then it is marked as non-compliant. Each agency is asked to review their data and validate the SRT predictions. GSA also conducts random manual reviews monthly.",
      "248": "Level 1 Report Corrosion Level Classification\nLevel 1 surveys obtained from BSEE report the condition of well platforms. The reports include images of well platform components, which can be used to estimate coating condition and structural condition, important factors in the overall condition of the facility. The reports are used to assess the well platforms for safety concerns. The reports are submitted to BSEE and are manually reviewed to determine whether a well platform needs additional audits. Because the manual review process is time-consuming, an automated screening system that can identify parts of the wells that exhibit excess corrosion may greatly reduce report processing time.",
      "154": "Did you mean\nSuggesting spelling corrections and reformatted search queries based on Google Analytics data",
      "109": "Automated Malware Analysis Via \nDynamic Sandboxes\nThe goal of this project is to develop an analysis framework enabled by dynamic \nsandboxes that allows for automated analysis, provides non-existing core capabilities \nto analyze industrial control system malware, and outputs to a format that is machine \nreadable and an industry standard in sharing threat information. This will enable further \nanalysis efforts via machine learning and provide a foundational platform that would \nallow for timely, automated analysis of malware samples.",
      "321": "Automatic Document Processing\nAutomatic processing of continuation of benefits form to extract pre-defined selection boxes.",
      "95": "Promoting Optimal Sparse Sensing and \nSparse Learning for Nuclear Digital \nTwins\nThis project will address the efficient use of limited experimental data available for \nnuclear digital twin (NDT) training and demonstration. This involves developing sparse \ndata reconstruction methods and using NDT models to define sensor requirements \n(location, number, accuracy) for the design of demonstration experiments. NDTs \nshould leverage 1) sparse sensing for identifying optimal locations and the minimal set \nof required sensors and 2) sparse learning and recovery of full maps of responses of \ninterest for stronger prediction, diagnostics, and prognostics capabilities.",
      "382": "JASC Code classification in Safety Difficulty Reports (SDR)\nAVS identified a need to derive the joint aircraft system codes (JASC) chapter codes from the narrative description within service difficulty reports (SDR), a form of safety event reporting from aircraft operators. A team of graduate students at George Mason University collaborated with AVS employees to apply Natural Language Processing (NLP) and Machine Learning to predict JASC codes. This method can be used to check SDR entries to ensure the correct codes were provided or to assign a code when one was not.",
      "425": "CuraPatient\nCuraPatient is a remote tool that allows patients to better manage their conditions without having to see a provider.\u00a0 Driven by artificial intelligence, it allows patients to create a profile to track their health, enroll in programs, manage insurance, and schedule appointments.",
      "184": "Best Match: New relevance search for PubMed\nPubMed is a free search engine for biomedical literature accessed by millions of users from around the world each day.\nWith the rapid growth of biomedical literature, finding and retrieving the most relevant papers for a given query is\nincreasingly challenging. We have developed Best Match, a new relevance search algorithm for PubMed that leverages\nthe intelligence of our users and cutting-edge machine-learning technology as an alternative to the traditional date sort\norder. The Best Match algorithm is trained with past user searches with dozens of relevance-ranking signals (factors) and\ndemonstrates state-of-the-art retrieval performance in benchmarking experiments as well as an improved user\nexperience in real-world testing.",
      "429": "Behavidence\nBehavidence is a mental health tracking app. Veterans download the app onto their phone and it compares their phone usage to that of a digital phenotype that represents people with confirmed diagnosis of mental health conditions.\u00a0",
      "173": "BHW Community Need Analysis Platform\nThe first use case being developed is for primary care with behavioral health integration which uses a machine learning\nbased automated clustering engine. The development of this tool allows for BHW to dynamically assess the healthcare\nneed of a population given a specific use case and relevant datasets. The output of the model will be used as part of the\nNotice of Funding Opportunity (NOFO) grant proposal evaluation process.",
      "222": "Operational Activities Explorer\nDuty officers and analysts in CISA's Operations Center use a dashboard powered by artificial intelligence to enable sensemaking of ongoing operational activities. Artificial intelligence uses new near-real-time event data (from open source reporting, partner reporting, CISA regional staff, and cybersecurity sensors) coupled with historical cybersecurity and infrastructure security information and previous operational response activity to recommend courses-of-action and engagement strategies with other government entities and critical infrastructure owners and operators based on potential impacts to the National Critical Functions.",
      "253": "Individual Mountain Lion ID from Camera Data\nThis system will to take pairs of mountain lion (*Puma concolor*) facial images and output the probability that the images come from the same individual mountain lion. This will allow researches to passively \"mark\" individuals and support population estimation analyses. We will use a \"Siamese\" convolutional neural network architecture that has been used in other facial recognition and motion tracking applications.",
      "188": "National Library of Medicine NLM-Chem: towards automatic chemical indexing in PubMed articles\nChemical indexing is part of the NLM\u2019s MEDLINE citation indexing efforts for improving literature retrieval and\ninformation access. Currently, chemcial indexing is performed manually by expert indexers. To assist this time-consuming\nand resource-intensive process, we have developed NLM-Chem, an automatic tool for finding chemical names in the\nbiomedical literature using advanced natural language processing and deep learning methods. Its performance has been\nassessed on gold-standard evaluation datasets and is to be integrated into the production MEDLINE indexing pipeline.\u00a0\u00a0",
      "77": "Steller sea lion brand sighting\nDetection and identification of branded steller sea lions from remote camera images in \nthe western Aleutian Islands, AK. The goal is to help streamline photo processing to \nreduce the effort required to review images.",
      "268": "Fouling Identification Neural Network (FINN)\nOur product is an end-to-end system that is used to predict and detect sensor (sonde) fouling at USGS stream gages. The system is trained using supervised learning on multiple features derived from archived stream gage data labelled by expert field technicians. The system operated in real-time on Amazon Web Services (AWS), providing predictions every 30 minutes based off of raw data collected from the USGS AQUARIUS database. The system produces values detecting the likelihood that fouling is currently present and likelihood of fouling predicted to occur in the next 24 hours. These values are displayed on a Tableau dashboard that is connected to AWS using Amazon Athena. This dashboard also displays other stream gage network monitoring information from AQUARIUS, like time since a sonde was last visited by a technician.",
      "278": "Fish and Climate Change Database (FiCli)\nThe Fish and Climate Change Database (FiCli) is a comprehensive database of peer-reviewed literature compiled through an extensive, systematic primary literature review to identify English-language, peer-reviewed journal publications with projected and documented examples of climate change impacts on inland fishes globally. We are currently exploring options to automate certain portions of the review process to increase our efficiency in maintaining and updating the database.",
      "241": "Data Driven Sub-Seasonal Forecasting of Temperature and Precipitation \nReclamation has run 2, year-long prize competitions where particants developed and deployed data driven methods for sub-seasonal (2-6 weeks into future) prediction of temperature and precipitation across the western US. Particpants outperformed benchmark forecasts from NOAA. Reclamation is currently working with Scripps Institute of Oceanography to further refine, evaluate, and pilot implement the most promising methods from these two copmetitions. Improving sub-seasonal forecasts has significant potential to enhance water management outcomes.  ",
      "46": "Passive acoustic analysis using ML \nin Cook Inlet, AK\nPassive acoustic data is analyzed for detection of beluga whales and classification of the \ndifferent signals emitted by these species. Detection and classification are done with an \nensemble of 4 CNN models and weighted scoring developed in collaboration with \nMicrosoft. Results are being used to inform seasonal distribution, habitat use, and impact \nfrom anthropogenic disturbance within Cook Inlet beluga critical habitat. The project is \naimed to expand to other cetacean species as well as anthropogenic noise.",
      "336": "Intelligent Medical Language Analysis Generation (IMAGEN)\nIMAGEN is an IT Modernization Disability Analytics & Disability Decision Support (ADDS) Product that will provide new tools and services to visualize, search and more easily identify relevant clinical content in medical records.  These tools and services will improve the efficiency and consistency of disability determinations and decisions and provide a foundation for machine-based decisional guidance. IMAGEN will transform text to data and enable disability adjudicators to leverage various machine learning technologies like Natural Language Processing (NLP) and predictive analytics and will support other high-priority agency initiatives such as fraud prevention and detection.",
      "201": "Automated Item of Interest Detection - ICAD\nThe software analyzes photographs that are taken by field imaging equipment, which are then fed into the ICAD system for review by USBP agents and personnel. The Matroid software currently processes and annotates images using proprietary software to determine if any of the images contain human subjects.\n\nMatroid is the name of the Video Computer Aided Detection system used by CBP. It uses trained computer vision models that recognize objects, people, and events in any image or video stream. Once a detector is trained, it can monitor streaming video in real time, or efficiently search through pre-recorded video data or images to identify objects, people, and events of interest. \n\nThe intent for the ICAD system is to expand the models used to vehicles, and subjects with long-arm rifles, while excluding items of little or no interest such as animals.",
      "79": "Using k-means clustering to \nidentify spatially and temporally \nconsistent wave systems\nPostprocessing that uses k-means clustering to identify spatially and temporally consistent \nwave systems from the output of NWPS v1.3. Has been successfully evaluated in the field \nby NWS marine forecasters nationwide and has been implemented into operations on \nFebruary 3, 2021.",
      "386": "Crushed Aggregate Gradation Evaluation System\nDescription: Deep learning computer vision algorithms aimed at analyzing aggregate particle size grading.\nInput: Images of ballast cross sections\nOutput: Ballast fouling index",
      "162": "Predictive Intelligence - Incident Assignment for Quality Service Center (QSC).\nPredictive Intelligence (PI) is used for incident assignment within the Quality Service Center (QSC). The solution runs on\nQuality Service Center (QSC).\nincidents created from the ServiceNow Service Portal (https://cmsqualitysupport.servicenowservices.com/sp_ess). The\nsolution analyzes the short description provided by the end user in order to find key words with previously submitted\nincidents and assigns the ticket to the appropriate assignment group. This solution is re-trained with the incident data in\nour production instance every 3-6 months based on need.",
      "299": "Leveraging Deep Learning to Improve Earthquake Monitoring\nThe USGS National Earthquake Information Center monitors global earthquakes 24/7, rapidly detecting, characterizing, and publically desimating earthquake information. In order to improve the perfomance of their event characterization system, the NEIC has trained AI models to characterize earthquake source information using small portions of waveform data. These models improve autotmatic phase picking, classify phase types, and estimate source-station distances. The outcome of these models is improved automatic earthquake detections. The training dataset used in these models leverages the long standing reveiwed earthquake catalog produced by the NEIC combined with archived continous waveform recordings, many of which are USGS opperated stations. These tools have been developed primarily leveraging Python, Keras, and Tensorflow. ",
      "161": "Feedback Analysis Solution (FAS)\nThe Feedback Analysis Solution is a system that uses CMS or other publicly available data (such as Regulations.Gov) to\nreview public comments and/or analyze other information from internal and external stakeholders. The FAS uses Natural\nLanguage Processing (NLP) tools to aggregate, sort and identify duplicates to create efficiencies in the comment review\nprocess. FAS also uses machine learning (ML) tools to identify topics, themes and sentiment outputs for the targeted\nDataset.",
      "23": "Geospatial and Remote Sensing Training Courses\nSeveral courses are offered which teach the use of software and scripting which allow for machine learning.  The courses change, but current topics include Intro and Advanced Change Detection, eCognition (software package), Geospatial Scripting for Google Earth Engine.  Some of the courses show how to use Collect Earth Online.",
      "300": "Using Gradient Boosting Method and Feature Selection to Reduce Aleatory Uncertainty of Earthquake Ground-Motion Models\nWe develop ground-motion models for peak ground acceleration and peak ground velocity using a gradient boosting method (GBM). In total 128 GBM-based ground-motion models are developed for estimating PGA and PGV, respectively, using varying subsets of explanatory variables. We select eight GBM-based ground-motion models that have the lowest root mean squared error (rmse) for the cross-validation datasets among models with the same number of explanatory variables. The secondary variables, in order of importance, that contribute to the model accuracy are: VS30, Ztor, Ry, Rx, Rake, Zhyp, and Dip. By considering the tradeoff between the model accuracy and model complexity (number of explanatory variables), we find an optimal model to predict PGA and PGV uses four explanatory variables: M, Rjb, VS30, and Ztor. The variability decomposition results suggest that the reduction of total variability is mostly due to the reduction of inter-event variability, likely because more source parameters than site or path parameters are included as explanatory variables. ",
      "282": "Prediction of Salt Front Location in the Delaware River Estuary\nWe are developing a machine learning model to make predictions of the 250 mg/L isochlor (salt front location) within the Delaware River Estuary. The model will be driven by river discharge into the estuary, tidal forcings, and meterological data from several points throughout the estuary. Model predictions will be compared with a process-based, hydrodynamic model, COAWST. The machine learning model is currently in development, but it will consist of a recurrent neural network architecture built using tools from pyTorch.",
      "276": "Artificial Intelligence for Environment & Sustainability (ARIES)\nARIES is an international research project based at the Basque Centre for Climate Change (Bilbao, Spain), to which USGS has been a long-term collaborator. ARIES uses semantics and machine reasoning to enable AI-assisted multidisciplinary, integrated modeling of coupled human-natural systems. See https://aries.integratedmodelling.org/ and https://docs.integratedmodelling.org/technote/ for full details.\nARIES is a full-stack solution for integrated modelling, supporting the production, curation, linking and deployment of scientific artifacts such as datasets, data services, modular model components and distributed computational services. Its purpose is to ensure\u2009\u2014\u2009by design rather than just intent\u2009\u2014\u2009that the pool of such artifacts constitutes a seamless knowledge commons, readily actionable (by humans and machines) through a full realization of the linked data paradigm augmented with semantics and powered by artificial intelligence. This design enables automation of a wide range of modeling tasks that would normally require human experts to perform.\nARIES\u2019 underlying software stack, called k.LAB, includes client and server components that support the creation, maintenance and use of a distributed semantic web platform where scientific information can be stored, published, curated and connected. The software is licensed through the Affero General Public License (AGPL) v.3.0.",
      "451": "Computer-aided detection and classification of colorectal polyps\nThis study is investigating the use of artificial intelligence models for improving clinical management of colorectal polyps. The models receive video frames from colonoscopy video streams and analyze them in real time in order to (1) detect whether a polyp is in the frame and (2) predict the polyp's malignant potential.",
      "360": "AI Capabilities Embedded in SMART\nModels have been embedded in the backend of the SMART system on OpenNet to perform entity extraction of objects within cables, sentiment analysis of cables, keyword extraction of topics identified within cables, and historical data analysis to recommend addressees and passlines to users when composing cables.",
      "403": "SBSE Issue Recommender\nDeveloped an AI-based recommender for detecting potential non-\ncompliance issues which makes training returns selection more efficient and scalable, which has been applied to the process for selecting training  returns and field work. ",
      "148": "IAE FSD CCAI Virtual Agent\nThe virtual agent uses manual learning to understand customer needs and provide a response appropriately. Our AI is named SAM and uses natural language.",
      "158": "Sequential Coverage Algorithm (SCA) in Record\nLinkage\nCDC\u2019s National Center for Health Statistics (NCHS) Data Linkage Program has implemented a supervised machine learning\nalgorithm, known as the Sequential Coverage Algorithm (SCA) in their linkage programs. The SCA was used to develop\nJoining methods (or blocking groups) when working with very large datasets. The SCA method improved the efficiency of\nblocking.",
      "346": "Within Grade Increase Automation\nA Natural Language Processing (NLP) model is used in coordination with Intelligent Character Recognition (ICR) to identify and extract values from the JF-62 form for within grade increase payroll actions. Robotic Process Automation (RPA) is then used to validate the data against existing reports, then create a formatted file for approval and processing.",
      "33": "Digital Imagery (no-change) for NRI program\nUsing neural networks and other AI technologies to detect no-changes in digital imagery for the NRI (national resources inventory) program ",
      "306": "Complaint Lead Value Probability\nThreat Intake Processing System (TIPS) \ndatabase uses artificial intelligence (AI) \nalgorithms to accurately identify, \nprioritize, and process actionable tips \nin a timely manner. The AI used in this \ncase helps to triage immediate threats \nin order to help FBI field offices and \nlaw enforcement respond to the most \nserious threats first.  Based on the \nalgorithm score, highest priority tips \nare first in the queue for human \nreview.",
      "81": "Data Science: Clutter\nNTIA\u2019s Institute for Telecommunication Sciences (ITS) is investigating the use of AI to \nautomatically identify and classify clutter obstructed radio frequency propagation paths. \nClutter is vegetation, buildings, and other structures that cause radio signal loss through \ndispersion, reflection, and diffraction. It does not include terrain effects. The classifier is a \nconvolutional neural network (CNN) trained using lidar data coinciding with radio \nfrequency propagation measurements made by ITS. This trained CNN can be fed new \nradio path lidar data and a clutter classification label is predicted.",
      "220": "Cyber Vulnerability Reporting\nVulnerability analysts require advanced automation tools to process data received through various  vulnerability reporting channels, as well as aggregate the information for automated sharing. These tools leverage Machine Learning and Natural Language Processing to increase the accuracy and relevance of data that is filtered and presented to human analysts and decision-makers. Machine Learning techniques also assist to aggregate the information in reports for presentation and further analysis. This includes data in the KEV and CVE databases.",
      "290": "Predicting Water Temperature Dynamics of Unmonitored Lakes With Meta\u2010Transfer Learning\nThe approach compares the transfer of different model types from well-observed to unobserved lake systems. Process-based models, neural networks, and process-guided neural networks are trained on well observed lakes (source lakes) and then is used to make predictions in unobserved lakes (target lakes). The performance of each of those transfers is used to train a meta-model that uses lake characteristics (e.g., depth, area) to predict which source lakes will be good candidates for transfer to target lakes. The process-guided deep learning models were able to transfer better than process-based and pure machine learning approaches. ",
      "42": "AD/CVD Self Initiation\nThe ADCVD program investigates allegations of dumping and/or countervailing of duties.  \nInvestigations are initiated when a harmed US entity files a petition identifying the alleged \noffence and the specific harm inflicted.  Self-Initiation will allow ITA to monitor trade \npatterns for this activity and preemptively initiate investigations by identifying harmed US \nentities, often before these entities are aware of the harm.",
      "51": "FathomNet\nFathomNet provides much-needed training data (e.g., annotated, and localized imagery) \nfor developing machine learning algorithms that will enable fast, sophisticated analysis of \nvisual data. We've utilized interns and college class curriculums to localize annotations on \nNOAA video data for inclusion in FathomNet and to begin training our own algorithms.",
      "345": "Tailored Integration Logistics Management System (ILMS) Automated User Support Bot\nILMS developed and deployed an automated support desk assistant using ServiceNow Virtual Agent to simplify support desk interactions for ILMS customers and to deflect easily resolved issues from higher cost support desk agents.",
      "86": "Enriched Citation\nData dissemination system that identifies which references, or prior art, were cited in \nspecific patent application office actions, including: bibliographic information of the \nreference, the claims that the prior art was cited against, and the relevant sections that \nthe examiner relied upon.  System extracts information from unstructured office actions \nand provides the information through a structured public facing API.",
      "391": "PHMSA Rule Making\nArtificial Intelligence Support for Rulemaking - Using ChatGPT to support the rulemanking processes to provide significant efficiencies, reduction of effort, or the ability to scale efforts for unusual levels of public scrutiny or interest (e.g. comments on a rulemaking).    ChatGPT will be used to provide: \n1.  Sentiment Analysis \u2013 Is the comment positive / negative or neutral towards the proposed rule.\n2.  Relevance Analysis \u2013 Whether the particular comment posted is relevant to the proposed rule\n3.  Synopsis of the posted comment.\n4.  Cataloging of comments.\n5.  Identification of duplicate comments.",
      "197": "Semantic analysis of scientific documents\n(word2vec OPA )\nThe NIH Office of Portfolio Analysis has developed a neural network approach to analysis of scientific content using\ndimensionality reduction (word2vec OPA ). This method computationally converts words in scientific texts to numbers and\nsummarizes documents by their semantic content by learning relationships between words from their context. This\nmethod is adaptable to specific corpora, including grants and scientific articles. For more information see the publication\ndescribing our word2vec approach: Hoppe et al 2019 (https://www.science.org/doi/10.1126/sciadv.aaw7238)",
      "424": "Automatic speech transcription engines to aid scoring neuropsychological tests.\nAutomated speech transcription engines analyze the cognitive decline of older VA patients. Digitally recorded speech responses are transcribed using multiple artificial intelligence-based speech-to-text engines. The transcriptions are fused together to reduce or obviate the need for manual transcription of patient speech in order to score the neuropsychological tests.",
      "200": "AI for Autonomous Situational Awareness\nThe AI for autonomous situational awareness system is intended to use IoT sensor kits to covertly detect and track illicit cross-border traffic in remote locations. \n\nThe system will leverage a motion image/video system enhanced with Artificial Intelligence that is capable of vehicle detection and direction determination. It will also incorporate a motion sensor that, when triggered, wakes up a high-resolution camera to capture a series of pictures, with additional sensors providing confirmation prior to camera capture. \n\nImages captured will be processed by Artificial Intelligence models to classify objects, determine vehicle direction at intersections, and provide imagery sufficient for re-identification. Ultimately, the systems is intended to create a low footprint, low cost, low power system to provide situational awareness and covert detection.",
      "225": "RelativityOne\nRelativityOne is a document review platform used to gain efficiencies in document review in litigation, FOIA, and other arenas where large-scale document review and production is necessary.",
      "123": "Microstructurally-driven Framework for \nOptimization of In-core Materials\nThis research will develop a methodology that relies on mechanism-informed machine \nlearning models, rapid ion irradiation and creep testing techniques, and advanced \ncharacterization coupled with automated image analysis to enable reactor developers \nto quickly understand the complex linkage between alloy composition, \nthermomechanical processing, the resulting microstructure, and swelling and creep \nbehavior. This project will (1) develop and demonstrate a high-potential methodology \nfor rapid development of future in-core materials and (2) provide critically important \ninformation on alloy design for optimized swelling and creep behavior to the advanced \nreactor development community.",
      "388": "Automated Delay detection using voice processing\nIn order to get a full accounting of delay, automated voice detection of ATC and aircraft interaction is required.  Many delay events, such as vectoring, are not currently reported/detected/accounted for and voice detection would enable automated detection.",
      "348": "Conflict Forecasting\nCSO/AA is developing a suite of conflict and instability forecasting models that use open-source political, social, and economic datasets to predict conflict outcomes including interstate war, mass mobilization, and mass killings. The use of AI is confined to statistical models including machine learning techniques including tree-based methods, neural networks, and clustering approaches.",
      "274": "TerrainFeatures detection and recognition\nThe objective of this project is to use DL tools to extract terrain features. ",
      "91": "Development of a multi-sensor data \nscience system used for signature \ndevelopment on solvent extraction \nprocesses conducted within Beartooth \nfacility\nThis project will develop a system that utilizes non-traditional measurement sources \nsuch as vibration, acoustics, current, and light, and traditional sources such as flow, \nand temperature in conjunction with data-based, machine learning techniques that will \nallow for signal discovery. The goal is to characterize stages within a solvent \nextraction process can increase target metals recovery, indicate process faults, \naccount for special nuclear material, and inform near real-time decision making.",
      "164": "Rapid Authority to Operate (ATO)\nThe Rapid ATO System was built using a natural language processing model and pipeline to process system security plans,\nto identify unique and commonly used technology components used across Federal Information Security Management\nAct (FISMA) systems. Natural language processing (NLP) is a form of machine learning that derives intent or subject out\nof blocks of text. In this particular case it was used to identify common blocks of language used in similar ways across\nsystem security plan (SSP) documents. In this way, CMS could identify similar approaches to solving certain technology or\nprocess-related control areas within the Acceptable Risk Safeguards (ARS). The output was used to create a list of\ncomponents to develop control description language in a re-usable way, as part of the Blueprint/Rapid ATO effort to\nstreamline SSP generation for new systems.",
      "151": "Automated Suggestions\nAuto-filling queries as they are typed",
      "156": "ICD-10 Coding of Cause of Death reported on\nDeath Certificates (MedCoder)\nMedCoder ICD-10 cause of death codes to the literal text cause of death description provided by the cause of death\ncertifier on the death certificate. This includes codes for the underlying and contributing causes of death.",
      "384": "Offshore Precipitation Capability (OPC)\nOPC leverages data from several sources such as weather radar, lightning networks, satellite and numerical models to produce a radar-like depiction of precipitation. The algorithm then applies machine learning techniques based on years of satellite and model data to improve the accuracy of the location and intensity of the precipitation areas.",
      "212": "Advanced Analytic Enabled Forensic Investigation\nCISA deploys forensic specialists to analyze cyber events at Federal Civilian Executive Branch (FCEB) departments and agencies, as well as other State, Local, Tribal, Territorial, and Critical Infrastructure partners. Forensic analysts can utilize advanced analytic tooling, in the form of Artificial Intelligence implementations to better understand anomalies and potential threats. This tooling allows forensic specialists the capabilities to comb through data in an automated fashion with mathematically and probabilistically based models to ensure high fidelity anomalies are detected in a timely manner. ",
      "281": "Prediction of Inland Salinity in the Delaware River Basin\nOnce developed, the system will input watershed characteristics (soils, land cover), land use (road salt application) and meteorological timeseries, and output predictions of specific conductance (SC) for inland stream reaches in the Delaware River Basin (DRB). The model will be trained using SC sample data from within the DRB. The resulting model will allow for predictions in ungaged locations and time periods, and allow for an evaluation of salinity exposure in these stream reaches. The model will be built using pyTorch on the USGS Tallgrass supercomputer.",
      "87": "Inventor Search Assistant (iSAT)\nService to help inventors \"get started\" identifying relevant documents, figures, and \nclassification codes used to conduct a novelty search.  System takes a user entered short \ndescription of invention and provides a user selectable set of recommended documents, \nfigures, and classification areas.",
      "171": "Opioid Data Warehouse Term Identification Novel Synthetic Opioid Detection and Evaluation Analytics\nThe Term Identification and Novel Synthetic Opioid Detection and Evaluation Analytics use publicly available social media\nand forensic chemistry data to identify novel referents to drug products in social media text. It uses the FastText library to\ncreate vector models of each known NSO-related term in a large social media corpus, and provides users with similarity\nscores and expected prevalence estimates for lists of terms that could be used to enhance future data gathering efforts.",
      "455": "Interpretation/triage of eye images\nArtificial intelligence supports triage of eye patients cared for through telehealth, interprets eye images, and assesses health risks based on retina photos. The goal is to improve diagnosis of a variety of conditions, including glaucoma, macular degeneration, and diabetic retinopathy.",
      "326": "Expenditure Classification Autocoder\nCustom machine learning model to assign a reported expense description from Consumer Expenditure Diary Survey respondents to expense classification categories known as item codes.",
      "174": "Leveraging AI/ML for classification and\ncategorization of scientific concepts\nTopical characterization of the research portfolio. Inputs are publications and grants abstracts. These are fed into a text\nclassification model and concept extraction. The outputs are category labels and list of concepts.",
      "4": "Automated Detection & Mapping of Host Plants from Ground Level Imagery\nGenerate maps of target trees from ground-level (streetview) imagery",
      "445": "Prediction of biologic response to thiopurines\nUsing CPRS and CDW data, artificial intelligence is used to predict biologic response to thiopurines among Veterans with irritable bowel disease.",
      "441": "Medication Safety (MedSafe) Clinical Decision Support (CDS)\nUsing VA electronic clinical data, the Medication Safety (MedSafe) Clinical Decision Support (CDS) system analyzes current clinical management for diabetes, hypertension, and chronic kidney disease, and makes patient-specific, evidence-based recommendations to primary care providers.\u00a0 The system uses knowledge bases that encode clinical practice guideline recommendations and an automated execution engine to examine multiple comorbidities, laboratory test results, medications, and history of adverse drug events in evaluating patient clinical status and generating patient-specific recommendations",
      "192": "Internal Referral Module (IRM) NLP\nThe IRM NLP module automatically refers projects to Program Officers once the grant application is received. The system\ninputs are grant applications - the title, abstract, specific aims and Public Health Relevance is analyzed to automatically\nrefer the grant application to the Program Officer who matches a similar background with the science contained in the\napplications. This process, is operating at a high accuracy rate and has effectively eliminated the referral bottleneck.",
      "264": "Prediction of Regolith Thickness in the Delaware River Basin\nThis project uses observations of the depth to bedrock reported by private well drillers in the Delaware River Basin to train a Random Forest model to map the thickness of the regolith layer. This data product will support groundwater and hydrologic modeling efforts in the basin.",
      "269": "Mapping river bathymetry from remotely sensed data \nWe are using high frequency satellite images from the Planetscope constellation to estimate water depth in river channels. The short time lags between images allows us to average multiple scenes collected on the same day or within a couple of days to improve accuracy. In addition to established depth retrieval methods, we developed a neural network regression approach for this purpose. The training data consist of field measurements of water depth collected as part of other USGS projects on five different rivers. The neural network regression method is implemented in MATLAB using the Deep  Learning Toolbox.",
      "5": "Standardization of cut flower business names for message set data\nNatural language processing technique. Data are cleaned (e.g., remove punctuation) to facilitate matching. Cosine similarity is calculated, similar terms are matched, and the results are output.",
      "209": "RVSS Legacy Overhauled System Project (INVNT)\nVideo Computer Aided Detection (VCAD) (also known as Matroid AI) is software that enables CBP end users to create and share vision detectors. \n\nVCAD detectors are trained computer vision models that recognize objects, people, and events in any image or video stream. Once a detector is trained, it can monitor streaming video in real time, or efficiently search through pre-recorded video data or images to identify objects, people, and events of interest. \n\nUsers can view detection information via a variety of reports and alert notifications to process and identify important events and trends. Detection data is also available through VCAD's powerful developer Application Programming Interface (API) and language specific clients, so CBP applications can be integrated with the power of computer vision.",
      "287": "Prediction of Lake Water Temperature using Lake Attributes\nOnce developed, the system will input lake characteristics (surface area, elevation, and others to be determined) and output predictions of depth-specific lake temperatures. Training data consist of lake temperature observations, meteorological data, and lake characteristics. The models will be developed using various Python packages including PyTorch on the USGS Tallgrass supercomputer.",
      "63": "First Guess Excessive Rainfall \nOutlook\nMachine Learning Product that is a first guess for the WPC Excessive Rainfall Outlook - It is \nlearned from the ERO with atmospheric variables. It is for the Day 4-7 products",
      "206": "Entity Resolution\nThe third-party global trade data is used to augment and enrich agency\u2019s investigations into entities of interest. It combines data from companies and goods across multiple languages, then provides network analysis to assess trade flows and risks associated with cross-border trade.\n\nThis can validate agency-held information or provide better understanding of networks of interest to the agency to better inform investigations that cross borders. AI/ML models help manage the information provided through the software, including behind-the-curtain collection of information, structuring of data, entity resolution, network analysis, risk analysis, and other functions that contribute to the software knowledge graph and frontend that end users interact with.  ",
      "108": "Secure and Resilient Machine Learning \nSystem for Detecting Fifth Generation \n(5G) Attacks including Zero-Day Attacks\nThis project will implement an advanced machine learning based 5G attack detection \nsystem that can achieve high classification speed (10k packets per second) with high \naccuracy (90% or greater) as well as address a vulnerability to zero-day attacks \n(90% accuracy against real zero-day attacks recorded by Amazon Web Services) \nusing field programmable gate array based deep autoencoders.",
      "272": "Waterfowl Lifehistory and Behavior Classification\nThe model we developed provides a highly accurate daily classification of waterfowl behavior into 8 life history states/movement patterns using hourly GPS relocations and, optionally, remotely sensed habitat data.  This will provide waterfowl researchers and managers a tool for real-time capable rapid assessments and notification of important life history events to improve research and management outcomes and reduce project operational costs.  ",
      "144": "Contract Acquisition Lifecycle Intelligence (CALI)\nCALI tool is an automated machine learning evaluation tool built to streamline the evaluation of vendor proposals against the solicitation requirements to support the Source Selection process. Once the Contracting Officer (CO) has received vendor proposals for a solicitation and is ready to perform the evaluation process, the CO will initiate evaluation by sending solicitation documents along with all associated vendor proposal documents to the Source Selection module, which will pass all documents to CALI. CALI will process the documents, associated metadata and begin analyzing the proposals in four key areas: format compliance, forms validation, reps & certs compliance, and requirements compliance. The designated evaluation members can review the evaluation results in CALI and submit finalized evaluation results back to the Source Selection module. CALI is currently being trained with sample data from the EULAs under the Multiple Award Schedule (MAS) program.",
      "198": "Person-level disambiguation for PubMed authors and NIH grant applicants\nHigh-quality disambiguation is required to correctly link researchers to their grants and outputs including articles,\npatents, and clinical trials. The NIH Office of Portfolio Analysis developed a disambiguation solution that used article level\nmetadata to assign 24.5M unique papers from the PubMed database to 16.0M unique author names, then used a novel\nneural network model trained on ORCID identifiers to determine whether author-publication pairs refer to variant\nrepresentations of the same person. For example, our model can determine whether hypothetical records listing Jane\nSmith and Jane M. Smith were the same person, or two different people, based on variables that include institutional\naffiliation, co-authorship, and article-affiliated Medical Subject Heading (MeSH) terms. For more information see the\npublication describing this method: Yu et al 2021\n(https://www.biorxiv.org/content/10.1101/2021.02.02.429450v1.full.pdf)",
      "49": "Fast tracking the use of VIAME for \nautomated identification of reef \nfish\nWe've been compiling image libraries for use in creating automated detection and \nclassification models for use in automating the annotation process for the SEAMAP Reef \nFish Video survey of the Gulf of Mexico. This work is being conducted in VIAME but we're \nlooking at several other paths forward in the project to identify best performing models. \nCurrent status is that models are performing well enough that we will incorporate \nautomated analysis in video reads this spring as part of a supervised annotation-qa/qc \nprocess.",
      "298": "Using Artificial Neural Networks to Improve Earthquake Ground-Motion Models\nThe ML model provides estimates of peak ground-motion from earthquakes given the location, magnitude, and local geological structure at a site of interest. The training data is a compilation of about 12,000 peak ground-motions recorded at seismic stations for moderate to large earthquakes. I constructed the ML model in Python using Keras with TensorFlow.",
      "398": "Large Partnership \nCompliance\nLarge Partnership Compliance is a machine learning model for stratifying \nPartnership data and score risk of potential non-compliance.",
      "402": "Projected Contract Award \nDate Web App\nProjected contract award dates are generated with a machine learning \nmodel that statistically predicts when procurement requests will become \nsigned contracts. Input data includes funding information, date / time of \nyear, and individual Contract Specialist workload. The model outputs \nprojected contract award timeframes for specific procurement requests.  \n'When will a contract be signed?' is a key question for the IRS and \ngenerally for the federal government. This tool gives insight about when \neach request is likely to turn into a contract. The tool provides a technique \nother federal agencies can implement, potentially affecting $600 billion in \ngovernment contracts. Weblink: https://www.irs.gov/newsroom/irs-\nannounces-use-of-projected-contract-award-date-web-app-that-predicts-\nwhen-contracts-will-be-signed",
      "40": "Chatbot Pilot\nChatbot embedded into trade.gov to assist ITA clients with FAQs, locating information and \ncontent, suggesting events and services.  ITA clients would enter input into the chatbot in \nthe form of questions or responses to prompts.  The chatbot would scan ITA content \nlibraries and input from ITA staff and return answers and suggestions based on client \npersona (exporter, foreign buyer, investor).",
      "85": "AI retrieval for TM design coding \nand Image search\nClarivate COTS solution to assist examiner identification of similar trademark images, to \nsuggest the correct assignment of mark image design codes, and to determine the \npotential acceptability of the identifications of goods and services.  System is anticipated \nto use both incoming trademark images and registered trademark images and output \ndesign codes and/or other related images.",
      "83": "AI retrieval for patent search\nAugmentation for next generation patent search tool to assist examiners identify relevant \ndocuments and additional areas to search.  System takes input from published or \nunpublished applications and provides recommendations on further prior art areas to \nsearch, giving the user the ability to sort by similarity to concepts of their choosing.",
      "14": "OCIO/CDO Council Comment Analysis Tool\nThe Comment Analysis pilot has shown that a toolset leveraging recent advances in Natural Language Processing (NLP) can aid the regulatory comment analysis process. We developed tools that help comment reviewers identify the topics and themes of comments, as well as group comments that are semantically similar. Tools like these offer significant value by creating efficiencies through novel insights and streamlined processing of comments, reducing duplicative, upfront development efforts across government, and ultimately realizing cost savings for agencies and the USG. \n",
      "341": "Federal Procurement Data System (FPDS) Auto-Populate Bot\nA/LM collaborated with A/OPE to develop a bot to automate the data entry in the Federal Procurement Data System (FPDS), reducing the burden on post\u2019s procurement staff and driving improved compliance on DATA Act reporting. This bot is now used to update ~300 FPDS awards per week.\u00a0 A/LM also partnered with WHA to develop a bot to automate closeout reminders for federal assistance grants nearing the end of the period of performance and begin developing bots to automate receiving report validation and customer service inbox monitoring.",
      "430": "Machine learning tools to predict outcomes of hospitalized VA patients\nThis is an IRB-approved study which aims to examine machine learning approaches to predict health outcomes of VA patients.\u00a0 It will focus on the prediction of Alzheimer's disease, rehospitalization, and Chlostridioides difficile infection.",
      "444": "Machine learning models to predict disease progression among veterans with hepatitis C virus\nA machine learning model is used to predict disease progression among veterans with hepatitis C virus.",
      "172": "Electronic Handbooks (EHBs) AI Chatbot \nAI Chatbot \u2022 Successfully developed and deployed HRSA EHBs AI Chatbot using Artificial Solutions Teneo platform for external HRSA EHBs grantees \u2022 Built to allow grantees to communicate with the EHBs Chatbot using regular natural conversational expressions \u2022 Provides knowledge- and action-based responses through a self-service platform with 24/7 availability \u2022 Integrated with existing EHBs application UI and Salesforce for automated ticket creation \u2022 Chatbot has the ability to refine and increase the accuracy of its responses as more and more users invoke/use the Chatbot",
      "381": "Course Deviation Identification for Multiple Airport Route Separation (MARS)\nThe Multiple Airport Route Separation (MARS) program is developing a safety case for reduced separation standards between Performance Based Navigation (PBN) routes in terminal airspace. These new standards may enable deconfliction of airports in high-demand metropolitan areas, including the Northeast Corridor (NEC), North Texas, and Southern California. To build necessary collision risk models for the safety case, several models are needed, including one that describes the behavior of aircraft that fail to navigate the procedure correctly. These events are very rare and difficult to identify with standard data sources. Prior work has used Machine Learning to filter incident data to identify similar events on departure procedures.",
      "262": "Stream physical habitat characterization in the Chesapeake Bay Watershed\nThe project objective is to take a large dataset of rapid habitat assessment data collected by multiple jurisdictions in the Chesapeake Bay Watershed, train a predictive model using those data, and use that model to predict stream habitat conditions for all unmeasured stream reaches in the region. The model is able to generate predictions for multiple aspects of physical habitat condition. The model directly connects to EPA's database containing the training data, enabling it to be rapidly updated when new data updates occur.",
      "392": "Inventory Item \nReplenishment MLR \nModeling POC - Phase 1\nBuild and evaluate a multiple linear regression model to predict to \ndetermine if the replenishment of an inventory item was received before \nor after the need by date to predict the likelihood that an item will be \nreceived on time in the future.",
      "280": "Fluvial Fish Native Distributions for the Conterminous United States using the NHDPlusV2.1 and Boosted Regression Tree (BRT) Models\nSpecies distribution models are developed for 271 fluvial fish species in their native ranges of the conterminous United States.  Boosted Regression Tree (BRT) models were used to develop presence/absence predictions for each of the National Hydrography Dataset Plus Version 2.1 stream segments within a species' native range.  Landscape data that describe the natural variation (e.g., slope, precip) and anthropogenic impacts (e.g., stream fragmentation) were summarized to stream segments and used as predictor variables. Native species ranges were used to geographically constrain distribution modeling efforts. R Version 4.0.2 (or newer) with \u2018dismo\u2019 and \u2018labdsv\u2019 packages are used for modeling.",
      "70": "BANTER, a machine learning \nacoustic event classifier\nA supervised machine learning acoustic event classifier using hierarchical random forests",
      "439": "Using machine learning to predict perfusionists\u2019 critical decision-making during cardiac surgery\nA machine learning approach is used to build predictive models of perfusionists\u2019 decision-making during critical situations that occur in the cardiopulmonary bypass phase of cardiac surgery. Results may inform future development of computerized clinical decision support tools to be embedded into the operating room, improving patient safety and surgical outcomes.",
      "387": "Development of Predictive Analytics Using Autonomous Track Geometry Measurement System (ATGMS) Data\nDescription: Leveraging large volumes of these recursive track geometry measurements to develop and implement automated machine-learning-based processes for analyzing, predicting, and reporting track locations of concern, including those with significant rates of degradation.\nInput: Track geometry measurements and exceptions\nOutput: Inspection report that includes the trending of track geometry measures and time to failure (i.e., maintenance and safety limits).",
      "279": "Evaluating fish movement in restored coastal wetlands using imaging sonar and machine learning models\nWetland managers are restoring coastal wetland habitats in the Great Lakes, and often seek more information on when and how fish access restored habitats. Terabytes of hydroacoustic data on fish movement need to be analyzed more efficiently, so a collaboration between USGS, USFWS, and the University of Michigan is developing a machine learning model (MLM) that identifies, tracks, and quantifies fish movement. The completed model will read proprietary sonar image files, convert them to a universal file format (i.e., .mp4), place bounding boxes around individual fish detected by the model, and track them across consecutive image frames to determine bi-directional movement. The model uses training data and TensorFlow-based convolutional neural networks for object detection. Post-processing uses sonar geometry to estimate length of individual fish, and output files include labeled videos showing bounding boxes (.avi format), model metrics (.txt format), an enumeration of bi-directional fish movement (i.e., left or right) in .csv format, and individual fish length estimates (.csv format). Model output will allow USGS researchers to estimate fish habitat use and associated community metrics in restored wetland habitats. This information will support USFWS and other management agencies restoring coastal wetland habitats.",
      "146": "Chatbot for Federal Acquisition Community\nThe introduction of a chatbot will enable the GSA FAS NCSC (National Customer Support Center) to streamline the customer experience process, and automate providing answers to documented commonly asked questions through public facing knowledge articles. The end goal is this will reduce staffing requirements for NCSC\u2019s live chat programs and allow the NCSC resources to be dedicated to other proactive customer services initiatives. Customers will still have the option to connect to a live agent if they choose by requesting an agent.",
      "52": "ANN to improve CFS T and P \noutlooks\nFan Y., Krasnopolsky, V., van den Dool H., Wu, C. , and Gottschalck J. (2021). Using \nArtificial Neural Networks to Improve CFS Week 3-4 Precipitation and Temperature \nForecasts.",
      "106": "Red Teaming Artificial Intelligence\nThis research will advance the state of the art for red team security assessment of \nmachine learning and artificial intelligence systems by providing methods for the \nreverse engineering, exploitation, risk assessment and vulnerability remediation. The \ninsights gained from the explorations into vulnerability assessment research will \nproactively address critical gaps in the cybersecurity community\u2019s understanding of \nthese systems and can be used to create appropriate risk evaluation metrics and \nprovide best practices for inclusion into consequence-driven cyber-informed \nengineering.",
      "450": "Predicting hepatocellular carcinoma in patients with hepatitis C\nThis prognostic study used data on patients with hepatitis C virus (HCV)-related cirrhosis in the national Veterans Health Administration who had at least 3 years of follow-up after the diagnosis of cirrhosis. The data was used to examine whether deep learning recurrent neural network (RNN) models that use raw longitudinal data extracted directly from electronic health records outperform conventional regression models in predicting the risk of developing hepatocellular carcinoma (HCC).",
      "405": "Gender differentiated credit scoring\nUniversity of California, Berkeley, is building a machine learning model to conduct gender differentiated credit scoring for customers of Rappicard in Mexico. They will compare this ML model to Rappi's \"status quo\" model to determine whether a gender differentiated model leads to greater access to credit for women.",
      "99": "Smart Contingency Analysis Neural \nNetwork for in-depth Power Grid \nVulnerability Analyses\nTypical contingency analysis for a power utility is limited to n-1 due to computational \ncomplexity and cost. A machine learning framework and resilience-chaos plots are \nleveraged to reduce computational expense required to discover, with 90% accuracy, \nn-2 contingencies by 50%.",
      "61": "Edge AI survey payload \ndevelopment\nContinued support of multispectral aerial imaging payload running detection model \npipelines in real-time. This is a nine camera (color, infrared, ultraviolet) payload controlled \nby dedicated on-board computers with GPUs. YOLO detection models run at a rate faster \nthan image collection, allowing real-time processing of imagery as it comes off the \ncameras. Goals of effort are to reduce overall data burden (by TBs) and reduce the data \nprocessing timeline, expediting analysis and population assessment for arctic mammals.",
      "7": "Training machine learning models to automatically read file attachments and save information into a more convenient Excel format. \nArtificial intelligence used to automate document processing and information extraction. Program managers often need information from specific form fields that are sent as PDF email attachments. Many emailed documents are received each day, making manually opening each attachment and copying the needed information too time-consuming. ",
      "186": "Computed Author: author name disambiguation National Institutes of Health (NIH) NLM\nfor PubMed\nPubMed users frequently use author names in queries for retrieving scientific literature. However, author name\nambiguity (different authors share the same name) may lead to irrelevant retrieval results. Thus we have developed a\nmachine-learning method to score the features for disambiguating a pair of papers with ambiguous names.\nSubsequently, agglomerative clustering is employed to collect all papers belong to the same authors from those classified\npairs. Disambiguation performance is evaluated with manual verification of random samples of pairs from clustering\nresults, with a higher accuracy than other state-of-the-art methods. It has been integrated into PubMed to facilitate\nauthor name searches.",
      "283": "Prediction of Water Temperature in the Delaware River Basin\nWe published a machine learning model to make water temperature predictions at 456 reaches in the Delaware River Basin. The recurrent graph convolutional network (RGCN) was pre-trained with predictions from a coupled process-based model that predicts stream flow and temperature (the Precipitation Runoff Modeling System with the coupled Stream Network Temperature Model or PRMS-SNTemp).",
      "330": "Rep Payee Misuse Model\nThis model uses machine learning to estimate the probability of resource misuse by representative payees and flag the cases for a technician to examine.",
      "232": "I-485 Family Matching\nI-485 Family Matching is designed to create models to match family members to underlying I-485 petitions. The underlying immigrant petition defines if the I-485 is employment-based or family-based. It also has information about the visa classification and priority date which, when compared against the Department of State\u2019s monthly Visa Bulletin, helps predict visa usage. It is difficult to match an I-485 to its underlying immigrant petition, because the only available field on which to match is the A-number. This number is not always present on the immigrant petition, and name/date of birth matching is not as reliable. The goal of I-485 Family Matching is to leverage AI to more confidently create connections between petitioners and their families based on limited data.\n\nAdditionally, it will be able to help identify and group I485s filed by family members, as well as gather up the many ancillary forms they may have pending (such as I765, I131). Similar to immigrant petition matching, it can be difficult to match up I485s filed by family members. In these cases the only similar fields are a common address. Efforts have been made in the past to identify family members by address, but it is effective only to a point. The AI model will help make working with this data more reliable, as well as group individual petitioners, their families, and other helpful associated data together for faster and more accurate processing.",
      "21": "TreeMap 2016\nTreeMap 2016 provides a tree-level model of the forests of the conterminous United States. It matches forest plot data from Forest Inventory and Analysis (FIA) to a 30x30 meter (m) grid. TreeMap 2016 is being used in both the private and public sectors for projects including fuel treatment planning, snag hazard mapping, and estimation of terrestrial carbon resources. A random forests machine-learning algorithm was used to impute the forest plot data to a set of target rasters provided by Landscape Fire and Resource Management Planning Tools (LANDFIRE: https://landfire.gov). Predictor variables consisted of percent forest cover, height, and vegetation type, as well as topography (slope, elevation, and aspect), location (latitude and longitude), biophysical variables (photosynthetically active radiation, precipitation, maximum temperature, minimum temperature, relative humidity, and vapour pressure deficit), and disturbance history (time since disturbance and disturbance type) for the landscape circa 2016.",
      "213": "Advanced Network Anomaly Alerting\nThreat hunting and Security Operations Center (SOC) analysts are provided terabytes per day of data from the National Cybersecurity Protection System's (NCPS) Einstein sensors. Manually developed detection alerts and automatic correlation via off the shelf tooling are common, but not comprehensive. Many network attacks can be probabilistically determined given sufficient training data and time. Analysts use automated tooling to further refine the alerts they receive and produce additional automated alerts based on aggregated information and backed in subject matter expertise. This tooling allows CISA analysts the capabilities to comb through data in an automated fashion with mathematically and probabilistically based models to ensure high fidelity anomalies are detected in a timely manner. ",
      "408": "Morogoro youth empowerment through establishment of social innovation (YEESI) lab for problem-centered training in machine vision\nThe project proposes to establish a social innovation lab for a machine vision program that will be used by youth in the Morogoro region of Tanzania. There are young people in the area who have studied information technologies and allied sciences, and while most of them can write computer programs, they cannot solve machine vision problems. This project aims to increase awareness among the youth of Morogoro and nearby regions to address machine vision problems in agriculture. Machine vision is a new and understudied practice in Tanzania; hence, this project will contribute to efforts in the creation of scientific societies that address the most pressing problems faced by more than 80% of Tanzania\u2019s population who engage in farming. The main agricultural problems can be classified into five categories, as explained below: (1) Disease Detection and Classification: The project will develop experts who will solve problems in disease identification using machine vision for most of the diseases in crops and livestock, which are misdiagnosed by farmers. (2) Weed Classification: The project will develop algorithms that accurately identify weeds and contribute to the growing scientific database for automatic weed detection. (3) Pest Detection and Classification: Appropriate tools using machine vision for Integrated Pest Management (IPM) are needed in Tanzania, as IPM has been hindered due to a lack of extension officers to train farmers on mitigation and identification of pests in agriculture. (4) Crop Seedlings Stand Count and Yield Estimation: Use of machine vision and drones instead of scouting manually to estimate stand counts would provide appropriate mitigation strategies for replanting that would be beneficial to commercial farmers. Also of importance are algorithms to sort and estimate yield by counting the fruits and to estimate the amount of other agricultural products. (5) Crop Vigor Estimation: Most farmers apply inputs evenly across the farm because they cannot predetermine crop vigor. Accurate estimation of crop health would help farmers to mitigate the problems earlier and improve crop performance and avoid failure. Algorithms to determine crop vigor developed in this project will contribute to the improvement of the methods to estimate crop performance earlier.",
      "250": "Wildlife Underpass Camera Trap Image Classification, San Diego CA\nThis software system takes wildlife camera trap images as inputs and outputs the probability of the image belonging to user-specified taxonomic classes based on wildlife species present in each image. (Wildlife camera traps are motion-triggered, time lapse, and other camera systems placed in the field to capture images of wildlife at the location and times where and when the cameras are placed.) The process of humans reviewing, labeling, and QA/QCing labels is labor intensive, time consuming, and costly. Developing AI systems that can perform these tasks within an acceptable level of accuracy can reduce the costs in extracting tabular data from camera-based datasets and increase the volume of data for analysis. The system supports training experiments where model hyperparameters and training dataset characteristics can be varied to find those that are more optimal for training. Training, validation, and testing datasets have human-assigned labels and are used to train and evaluate the models. Once trained, the models can be used to predict classes on unlabeled images. We use a convolutional neural network (CNN) approach based on TensorFlow and training is run on the USGS Tallgrass supercomputer designed for AI/ML workflows.",
      "118": "Spectral Observation Convolutional \nNeural Network\nThis project developed method to analyze collected radiation spectra using advanced, \nscalable deep learning by combining spectroscopic expertise with high performance \ncomputing. Sophisticated deep learning can overcome the weaknesses of existing \nspectroscopic techniques and enhance the value of difficult measurements. This \nmethod was trained, tested, and operated on the International Space Station\u2019s \nSpaceborne Computer-2 supercomputer, returning zero errors over the course of 100 \ntraining hours. This demonstrated performance autonomously in far-edge, low-wattage \ncomputing situations and in hazardous radiological environments where interference \ncan cause errors.",
      "169": "Advanced Semantic Search and Indexing of Text for Tobacco Applications (ASSIST4Tobacco)\nASSIST4Tobacco is a novel tool that will use semantic indexing to search tobacco authorization applications. The system\nwill be based on an AI (artificial intelligence)\u2010based NLP (Natural Language Processing) model which provides deeper\nsearch capabilities using a language model developed to represent relationships between words and concepts within a\nbody of text.",
      "259": "River Image SEnsing\nThe River Image Sensing (RISE) project is charged with the development of a reliable camera system for integration into the operational streamgage monitoring network of the USGS Water Mission Area. In addition to capturing images and videos, the RISE system will be capable of producing time-series of surface water levels derived from still camera images using AI/ML modeling techniques.",
      "181": "Providing MeSH Check Tag of NLM\u2019s Medical\nText Indexer (MTI) ons using Support Vector\nMachines (SVM)\nTitles and abstracts from MEDLINE Citations are provided through SVM machine learning algorithm provides confidence\nscores for a set of MeSH CheckTags to the NLM Medical Text Indexer (MTI) program. These CheckTags are small set of\nMeSH Descriptors designed to indicate Species, Sex, and Age in MEDLINE articles.",
      "104": "Signal Decomposition for Intrusion \nDetection in Reliability Assessment in \nCyber Resilience\nThe objective of this project is to research, assess, and implement machine learning \nand artificial intelligence and physics-based algorithms for signal decomposition and \nprovide a straightforward framework wherein an anomaly detection algorithm can be \ntrained on existing expected data and then used for false data injection detection. An \nadvanced library for signal decomposition and analysis will be developed that allows \ncombining machine learning and artificial intelligence algorithms and high-fidelity model \ncomparisons for greatly improved false data injection detection. This library will \nfacilitate online and posteriori analysis of digital signals for the purpose of detecting \npotential malicious tampering in physical processes.",
      "303": "Integrating machine learning phase pickers into the Southern California Seismic Network earthquake catalog\nWe evaluate the readiness of machine-learning models for automatic earthquake detection and phase picking to enhance the Southern California Seismic Network earthquake catalog, with the end-goal of using these models in routine seismic network operations. We first test a model called Generalized Phase Detection (GPD), trained on millions of manually-picked P- and S- arrival times from Southern California earthquakes and examples of noisy time series data.  Inputs are continuous seismic data time series, with 3 components (north, east, vertical), at hundreds of seismic stations located in southern California.  Outputs are arrival times of P and S seismic waves, with associated probabilities between 0 and 1, with a threshold probability applied for detection; these arrival times are fed into existing software to estimate earthquake locations, origin times, and magnitudes.  Custom software is written in Python with the model implemented in the PyTorch library.  We are also developing a cloud-native software architecture that takes real-time seismic data as input (~15 seconds at a time) and applies the GPD model within Amazon Web Services.",
      "84": "AI use for CPC classification\nSystem that classifies incoming patent application based on the cooperative patent \nclassification scheme for operational assignment of work and symbol recommendation for \naI search.  Backoffice processing system that uses incoming patent applications as input \nand outputs the resulting classification symbols.",
      "317": "DOL Intranet Website Chatbot Assistant\nConversational chatbot on DOL intranet websites to help answer common procurement questions, as well as specific contract questions.",
      "135": "Records Categorization\nThe records management technology team is using machine learning to predict the retention schedule for records. The machine learning model will be incorporated into a records management application to help users apply retention schedules when they submit new records.",
      "419": "Artificial intelligence coach in cardiac surgery\nThe artificial intelligence coach in cardiac surgery infers misalignment in team members\u2019 mental models during complex healthcare task execution. Of interest are safety-critical domains (e.g., aviation, healthcare), where lack of shared mental models can lead to preventable errors and harm. Identifying model misalignment provides a building block for enabling computer-assisted interventions to improve teamwork and augment human cognition in the operating room.",
      "28": "Census of Agricuilture Response Propensity Scores\nThe response propensity scores to the COA are derived from random forest models that use historical data, control data, and other survey data. These scores are used to help target more effective data collection.",
      "304": "Understanding the 2020-2021 Puerto Rico Earthquake sequence with deep learning approaches\nWe enhance the earthquake catalog for the 2020-2021 southwestern Puerto Rico earthquake sequence with a variety of deep learning approaches to understand its complex fault system, triggering mechanisms, and long-lived vigorous nature of the aftershock sequence.  We use an existing deep learning model for earthquake detection and phase picking called EQTransformer, which was trained on a global data set of earthquake waveforms called STEAD, using the TensorFlow library.  We also apply deep learning methods for earthquake location (EikoNet and HypoSVI), trained on a known velocity model with a physics informed neural network using the PyTorch library, which then allows grid-free rapid seismic wave travel time calculation between any 2 locations within a 3D volume .  These machine learning methods for automatic earthquake detection, phase-picking, and location, which are all available as open-source Python codes, help increase the number of small earthquake observations and improve earthquake depth estimates, thus offering more detailed information about active faults and physical processes in this earthquake sequence.",
      "418": "Artificial Intelligence physical therapy app\nThis app is a physical therapy support tool.\u00a0 It is a data source agnostic tool which takes input from a variety of wearable sensors and then analyzes the data to give feedback to the physical therapist in an explainable format.\u00a0",
      "73": "ENSO Outlooks using \nobserved/analyzed fields\nLSTM model that uses ocean and atmospheric predictors throughout the tropical Pacific \nto forecast ONI values up to 1 year in advance. An extension of this was submitted to the \ncloud portfolio with the intent of adding a CNN layer that that uses reforecast data to \nimprove the ONI forecasts.",
      "368": "Topic Modeling\nCluster text into themes based on frequency of used words in documents; has been applied to digital media articles as well as social media posts; performed using available Python libraries",
      "316": "Hololens\nAI used by Inspectors to visually inspect high and unsafe areas from a safe location.",
      "202": "Autonomous Aerostat\nAerostat capability that uses three tethers instead of the traditional single tether, coupled with advanced weather sensors, analytic capabilities, and powerful winches. The AI/ML model is used to detect the need to launch and land based on weather. It also leverages AI and robotics to autonomously launch and recover the aerostat during inclement weather events without the need for on-site staffing, allowing the aerostat to operate autonomously, saving time and manpower.",
      "32": "Conservation Effects Assessment Project\nThe goal is to predict conservation benefits at the field level. The model uses farmer survey data, APEX modeling results and environmental data.",
      "175": "Grant Application Subject-Matter Classification\nTool\nNatural language processing of grant applications for the purpose of classification for review assignment",
      "252": "ARMI Amphibian Species ID from Acoustic Data\nThe mission of the USGS Amphibian and Reptile Minitoring Initiative (ARMI) is to provide essential scientific information to managers to help arrest or reverse amphibian population declines. Acoustic monitoring of amphibian (anuran) vocalizations are a core technique used by ARMI researchers. Reviewing audio recordings and identifying species vocalizations captured therein is time consuming and labor intensive. For these reasons, many recordings remain unprocessed, preventing valuable data from being available for analysis. Our goal is to train convlutional neural networks (CNNs) that take audio clips that have been converted to sonograms (images) and classify the species generating the vocalizations in the recordings. Our initial prototype project will attempt to develop models that can identify audio clips containing bullfrog (*Lithobates catesbeianus*, which are native in some parts of the US and a destructive invasive species in others) vocalizations. The software will be build using the TensorFlow Python API and training will be performed on the USGS Tallgrass supercomputer.",
      "216": "Automated Indicator Sharing (AIS) Automated PII Detection\nThe Automated PII Detection and Human Review Process incorporates descriptive, predictive, and prescriptive analytics. Automated PII Detection leverages natural language processing (NLP) tasks including named entity recognition (NER) coupled with Privacy guidance thresholds to automatically detect potential PII from within AIS submissions. If submissions are flagged for possible PII, the submission will be queued for human review where the analysts will be provided with the submission and AI-assisted guidance to the specific PII concerns. Within Human Review, analysts are able to confirm/deny proper identification of PII and redact the information (if needed). Privacy experts are also able to review the actions of the system and analysts to ensure proper performance of the entire process along with providing feedback to the system and analysts for process improvements (if needed). The system learns from feedback from the analysts and Privacy experts. Through the incorporation of the automated PII detection, CISA fully compliances with Privacy, Civil Rights and Civil Liberties requirements of CISA 2015 and scaled analyst review of submissions by removing false positives and providing guidance to submission to be reviewed. Through continual audits CISA will maintain integrity and trust in system and human processes.",
      "204": "Autonomous Surveillance Towers (Anduril)\nAutonomously Detects, Identifies, and Tracks items of interest using Artificial Intelligence integrated with the tower. It does not require a dedicated operator, is rapidly deployable, and is relocatable in less than a day by 2-3 people.\n\nThe system features a hybrid command and control capability, hosted in the government cloud, and is accessible via URL by desktop, laptop, tablet, or Smartphone. It is solar powered with battery backup and requires no accompanying physical infrastructure while providing visibility for 1.5 miles (2.4 km) for people, 3 miles (4.8km) for vehicles.\n\nThe Lattice system permits autonomous detection, identification, and tracking of Items of Interest (IoIs).  The tower scans constantly and autonomously.  The radar detects and recognizes movement. The camera slews autonomously to the IoI and the system software identifies the object.  The system alerts the user and autonomously tracks the IoI. End users can monitor the system and see near real time photos by logging into the User Interface on any CBP device. ",
      "432": "Precision medicine PTSD and suicidality diagnostic and predictive tool\nThis model interprets various real time inputs in a diagnostic and predictive capacity in order to forewarn episodes of PTSD and suicidality, support early and accurate diagnosis of the same, and gain a better understanding of the short and long term effects of stress, especially in extreme situations, as it relates to the onset of PTSD.",
      "240": "Land Use Plan Document and Data Mining and Analysis R&D\nExploring the potential to identify patterns, rule alignment or conflicts, discovery, and mapping of geo history and/or rules. Inputs included unstructured planning documents. Outputs identify conflicts in resource management planning rules with proposed action locations requiring exclusion, restrictions, or stipluations as defined in the planning documents. ",
      "292": "Process guidance for learning groundwater influence on stream temperature predictions\n1) This work uses meteorological drivers to predict network wide daily average stream temperature in the Delaware River Basin. 2) The training data are water temperature observations available through NWIS and collected by the UGSS. 3) The work focuses on developing a custom loss function that helps deep learning models learn to account for groundwater influence on stream temperature.  Specifically, it uses the phase lag and amplitude dampening effect of groundwater to identify reaches likely influenced by shallow and deep groundwater inputs. ",
      "132": "Machine Learning Guided Operational \nIntelligence\nExplore the use of big data, artificial intelligence (AI), and machine learning technology \nand tools on phasor measurement unit (PMU) data to identify and improve existing \nknowledge, and to discover new insights and tools for better grid operation and \nmanagement.",
      "373": "Text Similarity\nGEC A&R\u2019s Text Similarity capability identified different texts that are identical or nearly identical by calculating cosine similarity between each text. Texts are then grouped if they share high cosine similarity and then available for analysts to review further.",
      "227": "Machine Translation\n(Previously Language Translator)\nSystran provides machine translation for over 100 different language combinations.  Currently the Innovation Lab has licenses for translating Chinese, Spanish, Arabic, Farsi, Russian, German, Ukrainian and Filipino to English.  Systran can translate plain text, word documents, and PDFS.  A web-based UI and API endpoint are available.",
      "194": "Grants Analytics Portal\nThe Grants Analytics Portal uses AI to enhance HHS OIG staff\u2019s ability to access grants related data quickly and easily by:\nquickly navigating directly to the text of relevant findings across thousands of audits, the ability to discover similar\nfindings, analyze trends, compare data between OPDIVs, and the means to see preliminary assessments of potential\nanomalies between grantees.",
      "331": "CDR Model\nThis model uses machine learning techniques to identify disability cases with the greatest likelihood of medical improvement and flag them for a coninuing disability review.",
      "34": "Artificial Intelligence SPAM Mitigation Project\nThe AI Solution invoves Robotic Process Automation + AI/ML model solution to automatically classify and remove spam and marketing emails that appear in civil rights complaints email channels. A significant portion of incoming OASCR emails are spam, marketing and phishing emails. \n",
      "367": "Optical Character Recognition \u2013 text extraction\nExtract text from images using standard python libraries; inputs have been websites to collect data",
      "89": "Objective-Driven Data Reduction for \nScientific Workflows\nThis project aims to develop theories and algorithms for objective-driven reduction of \nscientific data in workflows that are composed of various models, including data-\ndriven AI models",
      "379": "Remote Oceanic Meteorological Information Operations (ROMIO)\nROMIO is an operational demonstration to evaluate the feasibility to uplink convective weather information to aircraft operating over the ocean and remote regions. Capability converted weather satellite data, lightning and weather prediction model data into areas of thunderstorm activity and cloud top heights. AI is used to improve the accuracy of the output based on previous activity compared to ground truth data.",
      "434": "PredictMod\nPredictMod uses artificial intelligence to determine if predictions can be made about diabetes based on the gut microbiome.",
      "383": "Regulatory Compliance Mapping Tool\nThe AVS International office is required to identify means of compliance to ICAO Standards and Recommended Practices (SARPs).\u00a0 Both SARPs and means of compliance evidence are text paragraphs scattered across thousands of pages of documents.\u00a0 AOV identified a need to find each SARP, evaluate the text of many FAA Orders, and suggest evidence of compliance based upon the evaluation of the text.\u00a0 The base dataset used by RCMT is the documents\u2019 texts deconstructed into paragraphs.\u00a0 RCMT processes all the documents\u2019 paragraphs run through Natural Language Processing (NLP) (this process has an AI aspect) to extract the meaning (semantics) of the text.\u00a0\u00a0\u00a0 RCMT then employs a recommender system (also using some AI technology) to take the texts augmented by the texts\u2019 meaning to establish candidate matches between the ICAO SARPs and FAA text that provides means of compliance.",
      "291": "Process-guided deep learning for predicting stream temperature in out-of-bound conditions\n1) This work uses meteorological drivers to predict network wide daily average stream temperature in the Delaware River Basin. 2) The training data are water temperature observations available through NWIS and collected by the UGSS. 3) The work compares the performance of two deep learning achictectures, both of which incorporate process guidance through pretraining on process-based modelling outputs.  For each architecture, we're testing the ability of the model to generalize outside the bounds of its training data in order to better understand the limitations of each modelling approach for accurately predicting stream temperature under changing climate and precipitation regimes.",
      "456": "Screening for esophageal adenocarcinoma\nNational VHA administrative data is used to adapt tools that use electronic health records to predict the risk for esophageal adenocarcinoma.",
      "343": "Tailored Integration Logistics Management System (ILMS) User Analytics\nA/LM plans to use available ILMS transactional data and planned transactions to develop tailored user experiences and analytics to meet the specifics needs of the user at that moment. By mining real system actions and clicks we can extract more meaningful information about our users to simplify their interactions with the system and reduce time to complete their daily actions.",
      "414": "Indonesia: AI predictions for improving forecasts for TB drugs\nAI technology will be used to develop a forecasting AI model for TB sensitive drugs to inform more accurate annual quantification exercises for the MoH linked to their national data integration platform SatuSehat",
      "366": "K-Means clustering into tiers\nCluster countries into tiers based off data collected from open source and bureau data using k-means clustering",
      "347": "Verified Imagery Pilot Project\nThe Bureau of Conflict and Stabilization Operations ran a pilot project to test how the use of a technology service, Sealr, could verify the delivery of foreign assistance to conflict-affected areas where neither U.S. Department of State nor our implementing partner could go.\u00a0 Sealr uses blockchain encryption to secure photographs taken on smartphones from digital tampering.\u00a0 It also uses artificial intelligence to detect spoofs, like taking a picture of a picture of something.\u00a0 Sealr also has some image recognition capabilities.\u00a0 The pilot demonstrated technology like Sealr can be used as a way to strengthen remote monitoring of foreign assistance to dangerous or otherwise inaccessible areas.",
      "187": "National Library of Medicine NLM-Gene: towards automatic gene indexing in PubMed articles\nGene indexing is part of the NLM\u2019s MEDLINE citation indexing efforts for improving literature retrieval and information\naccess. Currently, gene indexing is performed manually by expert indexers. To assist this time-consuming and resource-\nintensive process, we have developed NLM-Gene, an automatic tool for finding gene names in the biomedical literature\nusing advanced natural language processing and deep learning methods. Its performance has been assessed on gold-\nstandard evaluation datasets and is to be integrated into the production MEDLINE indexing pipeline.\u00a0\u00a0",
      "145": "Classifying Qualitative Data\nUSAGov and USAGov en Espa\u00f1ol collect large amounts of qualitative data from survey comments, web searches and call center chat transcripts. Comments are grouped together by topic to determine where we need to make product updates/enhancements",
      "307": "Intelligent Records Consolidation Tool\nThe Office of Records Management Policy \nuses an AI and Natural Language Processing \n(NLP) tool to assess the similarity of records \nschedules across all Department records \nschedules. The tool provides clusters of \nsimilar items to significantly reduce the time \nthat the Records Manager spends manually \nreviewing schedules for possible \nconsolidation. An AI powered dashboard \nprovides recommendations for schedule \nconsolidation and review, while also \nproviding the Records Manager with the \nability to review by cluster or by individual \nrecord. The solution's technical approach \nhas applicability with other domains that \nrequire text similarity analysis.",
      "16": "Nutrition Education & Local Access Dashboard\nThe goal of the this Dashboard is to provide a county-level visualization of FNS nutrition support, specifically nutrition education and local food access, alongside other metrics related to hunger and nutritional health.\u00a0As part of this dashboard, the team developed a K-means clustering script to group States by 7 different clustering options:  Farm to School Intensity & Size, Program Activity Intensity, Ethnicity & Race, Fresh Food Access, School Size, and Program Participation. This allows users to find like-minded, or similar, States based on any of these characteristics, opening up avenues for partnerships with States that they otherwise may not have considered.",
      "58": "NN training software for the new \ngeneration of NCEP models\nOptimize NCEP EMC Training and Validation System for efficient handling of high spatial \nresolution model data produced by the new generation of NCEP's operational models",
      "277": "Global Inland Fisheries Risk Index\nWe applied coupled manual and machine learning methods to an expansive literature set for major global inland fisheries to explore opportunities for improving user efficiency for linking anthropogenic drivers of environmental change to direct impacts. This work informs the relative influence of threats in the development of a global inland fisheries assessment using boosted regression trees to derive a spatially-explicit risk index of stressors.",
      "305": "Drug Signature Program Algorithms\nDEA's Special Testing and Research \nLaboratory utilizes AI/ML techniques and \nhas developed a robust statistical \nmethodology including multi-variate \nstatistical analysis tools to automatically \nclassify the geographical region of origin \nof samples selected for DEA's Heroin and \nCocaine signature programs. The system \nprovides for detection of anomalies and \nlow confidence results.",
      "255": "PRObability of Streamflow PERmanence\nThe PROSPER modeling framework was developed to incorporate sparse streamflow observation data representing wet or dry stream conditions and gridded hydroclimatic explanatory data to predict the annual probability of streamflow permanence at 30-m (PROSPER Pacific Northwest) or 10-m (PROSPER Upper Missouri) resolution. The training data are point observations of wet or dry at locations in the Pacific Northwest or Upper Missouri River basin. The PROSPER models were primarily developed using the FCPGTools (Barnhart, Sando, et al., 2020), R, and USGS HPC resources (Yeti).",
      "320": "Call Recording Analysis\nAutomatic analysis of recorded calls made to Benefits Advisors in the DOL Interactive Voice Repsonse (IVR) center.",
      "324": "OEWS Occupation Autocoder\nThe input is state submitted response files that include occupation title and sometimes job description of the surveyed units. The autocoder reads the job title and assigns up to two 6-digit Standard Occupational Classification (SOC) codes along with their probabilities as recommendations for human coders. Codes above a certain threshold are appended to the submitted response file and sent back to states to assist them with their SOC code assignment."
    },
    "LLM_summary_text": {
      "296": "The main idea of the response is that a data-driven approach using various regional data and machine learning models was used to create a prospectivity map for Clastic Dominated (CD) and Mississippi Valley Type (MVT) deposits in three countries. This approach involved loading the data into Uber's H3 cube and training Weights of Evidence and Gradient-Boosting Machine models.",
      "333": "The Medicare Part D Subsidy Model utilizes machine learning to identify and highlight cases that may have incorrect Medicare Part D subsidies. These flagged cases are then reviewed by technicians for further assessment.",
      "411": "Breakthrough RESEARCH used social media listening and machine learning to analyze over 12,000 social media posts in Nigeria and examine how gender-related online conversations have changed in the past five years. By scraping publicly available social media content and using language detection, the algorithm categorized the posts into different topics, providing insights into conversation volume, misinformation, attitudes, and social norms. This approach allowed for a more comprehensive monitoring and tracking of social media conversations compared to traditional research methods in public health and SBC programs.",
      "82": "The WAWENETS algorithm is used to estimate the speech quality and intelligibility of telecommunications recordings. It takes a digital file as input and produces a single number indicating the quality or intelligibility of the speech.",
      "230": "The Barcode Scanner is a project developed by the DHS HSI Innovation Lab / RAVEn to scan and populate information from MRZ and PDF417 barcodes into text fields on the RAVEn GO's Encounter Card. This project supports ICE's mission to enforce and investigate violations of U.S. laws and allows for the analysis of trends and criminal patterns. For more information, refer to the DHS/ICE/PIA-055 Privacy Impact Assessment.",
      "150": "The main idea is that auto-generation synonyms are being used to enhance search results by adding synonyms to search queries. These synonyms are implemented behind the scenes to improve the overall search experience.",
      "15": "The Retailer Receipt Analysis is a Proof of Concept that uses artificial intelligence to automate the manual process of reviewing FNS receipts and invoices. It aims to save staff time, ensure accuracy, and detect difficult patterns. The goal is to develop a review system that has an automated workflow, learns from analyst feedback, and can detect and visualize fraud patterns on retailer invoices and receipts.",
      "195": "The text analytics portal is designed for individuals who do not have a background in analytics but need to analyze text documents. It provides a range of tools such as search, topic modeling, and entity recognition to help users quickly examine and understand text data.",
      "297": "The main idea of the response is that a breakthrough has been made in rapidly assessing and modeling the ground failure and loss caused by earthquakes using remote sensing and ground truth observations. The use of a machine learning framework and Bayesian causal inference allows for accurate and high-resolution estimates of multi-hazards and damage, improving prediction abilities and revealing causal dependencies. This advancement is expected to result in more accurate and actionable images, maps, and products for post-earthquake assessment.",
      "311": "The main idea of the response is that audio transcription involves converting speech into written text. This process is done using natural language processing models and is primarily used for record-keeping purposes.",
      "159": "The Chatbot - Voice CMS/OSFLO is an automated phone response system designed to help the CMS Badging Help Desk. It provides general information about badging and allows help desk personnel to focus on more complex issues faced by employees and contractors.",
      "427": "The main idea of this response is that researchers are using artificial intelligence to analyze brain imaging and electrophysiological data in order to identify patterns of dementia. They are also investigating the potential of these imaging modalities as biomarkers for different types of dementia and epilepsy disorders, with the help of retrospective chart reviews conducted by the VA.",
      "363": "The main idea of the response is that the Global Engagement Center (GEC) is conducting a Technology Testbed to test emerging technology applications against foreign disinformation and propaganda challenges. Makor Analytics, an AI quantitative research company, is involved in the pilot by using their proprietary behavioral analytics technology to analyze survey responses and provide target audience sentiment insights and recommendations. The pilot aims to provide additional information beyond self-reported data that reflects sentiment analysis in the country of interest.",
      "397": "The main idea is that Large Corporate Compliance is a machine learning model specifically designed for classifying corporate taxes. It implies that the model utilizes machine learning techniques to accurately categorize and manage corporate tax data.",
      "266": "The Coast Train Coast Train dataset is a collection of orthomosaic and satellite images of coastal, estuarine, and wetland environments along with corresponding thematic label masks. The dataset includes spatial and time-series data and contains over 1.2 billion labelled pixels, representing more than 3.6 million hectares.",
      "365": "The main idea is that natural language processing (NLP) can be used to extract important information from unstructured text, specifically in this case, from multiple pages of a PDF document. The specific examples mentioned are extracting country names and agreement dates.",
      "238": "The Sentiment Analysis - Surveys system uses statistical analysis and Natural Language Processing (NLP) modeling software to assign sentiments to survey results. This helps survey administrators analyze both quantitative and qualitative data from employee satisfaction surveys. The system is currently available on demand.",
      "257": "The main goal of this project is to develop and test machine learning models for predicting and forecasting daily hydrologic drought in the Colorado River Basin. The project involves using gridded meteorologic forcing data and daily streamflow data to build random forest and neural network models. The project is being developed on AWS and in cooperation with CHS, and the USGS HPC systems are also being utilized.",
      "102": "The research aims to develop methods and technologies that will allow existing cybersecurity tools to defend industrial control systems (ICS) networks and enable cybersecurity analysts to detect compromise before any harm can be done. The focus is on analyzing captured communication signals to determine the protocol being used, and machine learning will be employed to identify unknown protocols. The findings will be used to create a prototype device.",
      "449": "A machine learning model is being used to evaluate treatment policies for patients with hepatitis C virus. The model is focused on predicting disease progression among veterans with this virus.",
      "71": "ProbSR is a machine-learned algorithm that predicts the probability of roads being subfreezing on a scale of 0 to 100%.",
      "121": "This research aims to use deep learning technology and internal voltage sensors to diagnose and predict failure in solid-state ceramic membrane reactors under harsh conditions. By collecting data on current and impedance during operation, artificial intelligence will be utilized to analyze the data and anticipate reactor failure.",
      "55": "The Coastal Change Analysis Program (C-CAP) has been using geographic object-based image analysis and machine learning algorithms to classify coastal land cover from high-resolution imagery. They have recently started using a convolutional neural network (CNN) approach for deriving the impervious surface component of their land cover products. Prior to this, C-CAP focused on developing moderate resolution land cover using Landsat data and employed Classification and Regression Trees for data development in 2002.",
      "143": "The Service Desk Virtual Agent, known as Curie, is a chatbot that utilizes machine learning to offer predictive responses during chats. This virtual assistant is designed to enhance the customer service experience for employees seeking IT support by providing relevant information from knowledge-based articles.",
      "191": "The QVR's LIKE feature utilizes the NIH RCDC indexing results to compare scientific terms related to a project, person, or publication. This allows for the discovery of projects, individuals, or publications that are scientifically similar.",
      "374": "The main idea is that image clustering involves using a pretrained deep learning model to create image embeddings. These embeddings are then used in a hierarchical clustering process to find and group similar images together.",
      "314": "The website chatbot assistant is designed to provide basic information about the program, offer guidance on who to contact for assistance, and can help users check the status of their petition cases. It serves as a helpful resource for users seeking information and support related to the program.",
      "211": "The main idea of the response is that integrated technologies and analytics can enhance maritime detection and the sensor network. Machine-assisted and AI-enhanced detection and tracking can improve the detection of illicit vessels in areas with high volumes of legitimate trade and recreational water vessel traffic. The use of AI algorithms and sharing of detections of Items of Interest (IoI) can help in tracking and maintaining these IoIs across multiple sensors.",
      "163": "The Reasonable Accommodation RPA Bot is designed to gather HR data regarding staffing changes and generate information for the Reasonable Accommodation staff to ensure that disability reasonable accommodations are properly implemented. This bot helps streamline the process of managing accommodations for employees with disabilities.",
      "273": "The main goal of this project is to create a database of spot elevations for summit locations in the contiguous United States. The focus is on extracting this information from historical topographic maps.",
      "237": "The Predicted to Naturalize model predicts when Legal Permanent Residents would be eligible to naturalize and provides their current address. The model can be utilized to send correspondence to USCIS customers regarding their resident status and notify others about potential USCIS benefits.",
      "364": "The main idea of the response is that Crisis Campaign Cable Analytics utilizes optical character recognition and natural language processing on Department cables to identify gaps and trends in crisis training. This aims to enhance post preparedness for crisis events.",
      "256": "The Water Mission Area Drought Prediction Project aims to create a method for predicting daily hydrologic drought by using machine learning models calibrated on streamflow and meteorological data. The models will be developed for specific locations and then applied to similar ungaged basins through a \"donor model\" approach. The project will utilize the USGS HPC systems for model development and running.",
      "20": "The RMRS Raster Utility is a .NET library that helps with data acquisition, raster sampling, and statistical and spatial modeling. It aims to streamline raster analysis by reducing processing time and storage space, and it also incorporates machine learning techniques.",
      "183": "The main idea of the response is that MetaMap is a program that allows access to the concepts in the unified medical language system (UMLS) Metathesaurus from biomedical text. It uses natural language processing (NLP) to link the text of biomedical literature to the knowledge and synonymy relationships in the Metathesaurus. The program provides a flexible architecture to explore mapping strategies and generate potential indexing terms.",
      "60": "The main idea of the response is that robotic microscopes and machine learning algorithms are being used to track and monitor phytoplankton, which are important for marine food webs and can be impacted by changes in the ocean. These technologies are being deployed in various areas to assess phytoplankton communities and their changes in relation to ocean and climate variability.",
      "353": "The Apptio Working Capital Fund (IRM/WCF) utilizes Apptio to invoice bureaus for combined services managed by the WCF. Apptio also allows for the creation of cost models, enabling bureaus to plan and allocate budgets for future fiscal years. Additionally, Apptio has the ability to predict future values using various formulas.",
      "62": "The main objective of this project is to enhance the detection and classification process of ice seals in aerial imagery by reducing false positive rates and maintaining high accuracy. Additionally, the project aims to minimize the need for post-survey review, which requires extensive labor.",
      "117": "The response states that the standard technique for measuring thermal diffusivity, laser flash, is improved by modifying the experimental setup and using a machine learning tool. This tool, which includes a finite element model and algorithms, allows for the analysis of thermal properties of a material from a single laser flash measurement.",
      "260": "The main goals of this project are to use timelapse images captured by affordable cameras to estimate the amount of water flowing in small, unmonitored stream networks. They also aim to create a web-based platform that allows easy access and exploration of the images, climate data, and the model itself. Users can contribute data by uploading imagery and flow data to the database.",
      "447": "The study aimed to predict the likelihood of achieving corticosteroid-free remission with Vedolizumab in ulcerative colitis patients. The researchers used random forest modeling on a group of 594 patients and found that baseline data or data through week 6 of therapy could be used to construct predictive models.",
      "284": "The researchers developed a process-guided deep learning and data assimilation approach to forecast water temperature in the Delaware River Basin. Their model used real-time observations and an autoregressive technique to improve near-term forecasts, with an average root mean squared error ranging from 1.1 to 1.9\u00b0C for 1-day-ahead and 7-day-ahead forecasts.",
      "179": "The National Institute of General Medical Sciences (NIGMS) has developed a method to automate the referral of grant applications using artificial intelligence (AI). They are using natural language processing (NLP) and machine learning (ML) algorithms to parse grant applications and determine the appropriate project officer candidates for grant assignment. This automation process, previously done manually, has significantly reduced the amount of time and effort required. NIGMS has collaborated with the Electronic Records Administration group to incorporate this technique into the Internal Referral Module, making it available for broader use across the National Institutes of Health (NIH).",
      "234": "The Identity Match Option (IMO) is a process used by USCIS to determine a single identity for each applicant or beneficiary across multiple systems. This process combines data from various systems to create comprehensive immigration histories for individuals, allowing for analysis, fraud detection, and resolution of data quality issues.",
      "417": "NASA SERVIR is working on a project to enhance urban vulnerability assessment in major population centers. The focus is on developing techniques to utilize satellite imagery and artificial intelligence to map informal settlements, with the aim of creating replicable methods for future use.",
      "356": "The main idea is that Facebook has developed a system called GPA that collects and analyzes data from multiple media sources to provide a comprehensive global view of media coverage. This system helps optimize Facebook's ad tests by providing up-to-date information on media coverage worldwide.",
      "327": "The Modernized Development Worksheet (MDW) is a process that utilizes artificial intelligence (AI) to analyze textual data in claim development tasks. Through natural language processing, the AI categorizes the data into workload topics, making it easier for technicians to review the information quickly.",
      "96": "The project aims to use artificial intelligence technology to expedite the development of nuclear fuel by studying the post irradiation examination of uranium-10wt.% zirconium (UZr) metallic fuel. The project will analyze microstructural image and thermal conductivity data from UZr, create a dataset for the microstructural patterns of irradiated UZr, and train machine learning and deep learning models to understand the relationships between various factors in fuel properties.",
      "210": "The main idea is that the use of technology, specifically Artificial Intelligence and mobile device cameras, is being utilized in the CBP One app to detect proof of life or \"Liveness Detection.\" This technology is important for reducing fraudulent activity and ensuring that the submitted data is from the actual person in front of the camera.",
      "199": "AI Curated Synthetic Data is a technology that generates artificial data for computer vision, specifically in the field of anomaly detection in complex environments. It creates synthetic X-ray scan images and virtual 3D assets to improve the development of algorithms for detecting narcotics and contraband in vehicles and cargo.",
      "229": "Mobile Device Analytics (MDA) has been developed to help investigators analyze large amounts of data extracted from mobile devices. The goal of MDA is to improve the efficiency of agents in identifying relevant evidence and criminal networks. The project also involves the development of machine learning for object detection in photos and videos.",
      "310": "The main idea is that language translation services are being provided for published documents and websites using natural language processing models.",
      "235": "The main idea of the response is that Person-Centric Identity Services aims to be the trusted source of biographical and biometric information for immigration history and status. The A-Number Management model is used to train and evaluate the datasets, ensuring accurate matching of records and maintaining high confidence and trust in the PCIS entity resolution. Machine learning is employed to handle fuzzy matches and variations in data quality.",
      "182": "The main idea of the response is that the researchers have developed a classifier using a Convolutional Neural Network (CNN) to automate the selection of indexed articles for MEDLINE. The classifier combines predictions from traditional machine learning algorithms and uses a sigmoid activation function to generate a probability of an article being in-scope for MEDLINE.",
      "340": "Mobile Wage Reporting (MOBWR) is a technology that utilizes artificial intelligence (AI) to extract text and data from scanned images or documents containing pay stubs or payroll information. This allows for quicker processing and analysis of the information.",
      "442": "This response states that a tool can predict health outcomes such as suicide death, opioid overdose, and decompensated outcomes of chronic diseases by using electronic health records as inputs. The tool can analyze both structured and unstructured data to generate deep phenotypes and predictions of these outcomes.",
      "401": "The NRP Redesign aims to implement innovative active learning methods that would estimate compliance baselines more efficiently, supporting tax gap estimation, improper payments reporting, workload identification and selection models, and policy analysis. However, the system inputs depend on existing NRP data that must meet a certain level of precision and quality for satisfactory data output.",
      "139": "The City Pairs Program Ticket Forecast and Scenario Analysis Tools use segment-level City Pair Program air travel purchase data to generate predictions for air travel purchases in the current and upcoming fiscal year. These forecasts are provided at different levels, such as DOD vs Civilian, Agency, and Region.",
      "17": "The Ecosystem Management Decision Support System (EMDS) is a spatial decision support system that operates within ArcGIS and QGIS. It allows users to create applications tailored to their specific needs using various AI engines, including logic processing, multi-criteria decision analysis, Bayesian networks, and Prolog-based decision trees.",
      "166": "The Priority Score Model is a system that uses logistic regression to rank providers within the Fraud Prevention System (FPS) based on program integrity guidelines. It takes inputs such as Medicare Claims data, Targeted Probe and Educate (TPE) Data, and Jurisdiction information to determine the ranking of providers within the FPS system.",
      "147": "The General Services Administration (GSA) is working on improving their document workflow platform to be more accurate and scalable. They aim to implement intelligent data capture and extraction techniques to efficiently transfer important data from PDF files to the appropriate processes, workflows, or decision engines.",
      "157": "The National Center for Health Statistics (NCHS) is creating a model to detect item nonresponse in open-text survey data. The model uses Natural Language Processing (NLP) and is trained to identify instances of gibberish, uncertainty, refusals, and high-risk responses, with the goal of improving survey data and questionnaire design.",
      "27": "The deadwood model uses boosted regression trees with various inputs to create a propensity score indicating the likelihood of a farm operation being out of business. This model is used in conjunction with expert knowledge to develop a systematic process for identifying and removing deadwood.",
      "67": "The main ideas of the response are that ProbSevere v3 is an improved nowcasting model that uses various data sources to predict severe weather events. The project aims to enhance the operational version of ProbSevere by incorporating additional data sets and improved machine learning techniques. The development of ProbSevere v3 has been successfully demonstrated and a proposal has been submitted for an operational update, with funding provided by GOES-R.",
      "208": "The Integrated Digital Environment is a system that uses AI/ML models to analyze end user activity data and identify opportunities for improving workflows and application usage. It provides analytics, dashboarding, and workflow suggestions to support analysts and allows for customization and automation of agency applications for greater connectivity and security.",
      "354": "The main idea is that natural language processing (NLP) is being used for Foreign Assistance Appropriations Analysis (F/RA) to automate the extraction of earmarks and directives from the annual appropriations bill. This process used to be done manually before the implementation of NLP.",
      "120": "This project aims to use machine learning interatomic potentials to investigate the impact of radiation damage on the physical properties of calcium fluoride and uranium dioxide. The developed potentials will be validated through electron irradiation experiments and thermal conductivity measurements, providing a high-throughput method for developing and qualifying new nuclear fuels.",
      "140": "The response describes a method called Category Taxonomy Refinement using Natural Language Processing (NLP) to extract tokens from product descriptions. This technique helps accurately identify and categorize products to determine their intended markets based on Product Service Codes (PSCs).",
      "431": "Nediser is an AI system designed to assist radiologists in analyzing X-ray properties. It can perform various tasks such as selecting normal templates, detecting hardware, evaluating patella alignment and leg length, and measuring Cobb angles.",
      "332": "The SSI Redetermination Model utilizes machine learning to pinpoint cases of supplemental security income that are likely to have significant overpayments due to alterations in financial eligibility. These cases are then flagged for review by technicians.",
      "35": "The USDA has developed a natural language processing model to analyze text in procurement descriptions and determine the likelihood of an award being IT-related and requiring an Acquisition Approval Request (AAR). The model calculates the probability of IT-relatedness for procurements without an AAR number in the Integrated Acquisition System (IAS).",
      "322": "The main idea of the response is that there is an automatic data processing workflow in place that uses Form Recognizer technology to extract the necessary data from complex documents. This workflow eliminates the need for manual data extraction and streamlines the process.",
      "358": "The response discusses the use of machine learning in GPA's production system to collect, analyze, and summarize the global digital content footprint of the Department. This technology assists in measuring and evaluating public outreach efforts more efficiently.",
      "64": "The response describes a machine learning product called the First Guess Excessive Rainfall Outlook that provides predictions for excessive rainfall. It is developed using the ERO dataset and atmospheric variables, and it offers forecasts for Day 1, 2, and 3.",
      "127": "The response discusses the application of big data, artificial intelligence, and machine learning to analyze phasor measurement unit (PMU) data. The goal is to enhance grid operation and management by identifying and improving existing knowledge, as well as discovering new insights and tools.",
      "59": "NOAA Coral Reef Watch has been using remote sensing, modeling, and in situ data to operate a Decision Support System to help resource managers, researchers, decision makers, and stakeholders prepare for and respond to coral reef ecosystem stressors caused by climate change and warming oceans. They offer the world's only global early-warning system for coral reef ecosystem changes and provide information, early warnings, and outlooks of stressful environmental conditions at targeted reef locations worldwide. Their products primarily focus on sea surface temperature but also incorporate other variables such as light and ocean color.",
      "126": "The main idea of BDSMART is to utilize big data, AI, and machine learning technology to analyze PMU data in order to enhance grid operation and management. The goal is to gain new insights and tools for improving existing knowledge and resiliency tracking.",
      "12": "The main idea of the response is that the project aims to utilize AI tools, machine learning, and natural language processing to analyze the usage of publicly-funded data and evidence in serving science and society. The goal is to democratize access to this information and make it more widely available.",
      "103": "The research focused on automating the identification and labeling of type and structure data, making it usable in other tools and research areas. Initially, heuristic methods were used, but later a machine learning approach was adopted to scale the process.",
      "105": "The main goal of the project is to develop a machine learning-based system that can detect attacks in the fifth generation (5G) cellular network. This system aims to enhance security for mission-critical applications such as automated vehicles, drones, connected health, and emergency response operations that rely on the 5G network.",
      "334": "The PATH Model is a machine learning system that predicts which cases are likely to receive an allowance at the hearing level. It then refers these cases to administrative law judges or senior adjudicators for prioritized review, potentially speeding up the decision-making process.",
      "410": "The main idea of the response is that machine learning (ML) is being used to predict the likelihood of treatment interruption among people living with HIV in Nigeria. The algorithm developed from the data is integrated into the Lafiya Management Information System (LAMIS) and used to provide more intensive follow-up support to patients at high risk of interrupting treatment. A qualitative assessment was also conducted to determine healthcare workers' perception of ML and identify additional support needed for incorporating ML into their routine work.",
      "335": "Insight is decision support software used by Disability Program adjudicators to improve the quality, speed, and consistency of their decision making. It analyzes case data to provide real-time alerts and reference information, as well as interactive tools to streamline their work. The software utilizes natural language processing and artificial intelligence techniques to power its features.",
      "219": "The Cyber Threat Intelligence Feed Correlation utilizes AI to quickly correlate information from multiple feeds, enhancing the quality of externally shared information. The AI algorithm can learn and improve its efficiency in performing the task, and customized algorithms can be developed for continuous monitoring of threat actors' tactics, techniques, and procedures (TTPs).",
      "18": "This study aims to explore the application of machine learning and object-based image classification techniques to identify buildings, building loss, and defensible space in wildland-urban interface areas before and after a wildfire. It serves as a proof-of-concept for using these methods to map wildfire damage and assess the effectiveness of defensible space measures.",
      "203": "The Autonomous Maritime Awareness system utilizes surveillance towers, ocean data solutions, unmanned autonomous surface vehicles (ASV), and AI to detect, identify, and track objects of interest in a maritime environment. The system uses low-cost surveillance towers equipped with radars and cameras, as well as ruggedized ASVs powered by wind, solar, or onboard engines. Both systems employ AI/ML to autonomously detect and track objects, and can send alerts to monitoring agencies for potential interdictions or intelligence collection.",
      "142": "The main idea is that the company is developing a model to classify generic Service Desk tickets and automatically route them to the appropriate team. This will automate the current manual process of re-routing tickets. The initial focus of the model will be on the top 5 most common ticket types.",
      "393": "The response mentions the completion of phase 2 of a project involving the creation and assessment of a multiple linear regression model. This model aims to predict if an inventory item will be replenished within the standard Need By time of 128 days.",
      "440": "Machine learning is being used to enhance the treatment of functional issues in patients with peripheral artery disease (PAD). By analyzing previously collected biomechanics data, researchers are able to identify gait signatures specific to PAD patients and assess the effectiveness of using limb acceleration measurements to model important biomechanics measures from PAD data.",
      "125": "The main ideas of the response are that machine learning methods are used to estimate load composition data and motor protection profiles for different climate regions in the Western US, and a deep learning algorithm is applied to calibrate the parameters of the WECC composite load model to match responses with a detailed feeder model.",
      "369": "The main idea is that statistical models are being used to forecast future outcomes, such as COVID cases and violent events, by projecting expected results based on data analysis. These models have been applied to analyze tweets and predict the occurrence of violent events.",
      "443": "The VA-DoE Suicide Exemplar project is using artificial intelligence to enhance the VA's capacity to identify veterans who are at risk of suicide. This project involves three different initiatives that all involve partnerships with the Department of Energy.",
      "407": "This study aims to analyze the long-term impacts of land-use and land-cover dynamics on surface water quality in Botswana's Limpopo River Basin. It will use satellite data and artificial intelligence methods to determine the relationships between land-use change, socioeconomic development indicators, climate change, and their effects on water quality and availability. The study will also develop empirical models for estimating water quality and mapping a water quality index using in-situ measurements and satellite imagery.",
      "308": "The response discusses a specific application that scans documents to identify attorney/client privileged information. The application uses keyword input provided by the system operator to perform this task.",
      "44": "The main idea of the response is that Azure Chatbot is being used to automate and improve user responses to potential questions on the MBDA website. The solution uses AI, machine learning, and natural language processing to provide effective chatbot responses.",
      "29": "The response describes a model that uses natural language processing techniques to classify NIFA funded projects as either climate change related or not. The model uses text fields such as the project's title, non-technical summary, objectives, and keywords as input features, and it assigns a dummy variable classification to determine if a project is climate change related or not.",
      "98": "This project aims to develop artificial intelligence (AI) based control algorithms to intelligently control and optimize advanced manufacturing processes. By using deep reinforcement learning and physics-informed reduced order models (ROMs), the algorithms will be able to make adaptive processing decisions in a simulation environment, reducing the need for a trial and error approach.",
      "390": "The main idea of the response is that machine learning, specifically deep learning, can be used to predict crash parameters such as Delta-V and PDOF directly from real-world crash images. This eliminates the need for manual calculations or estimations by crash examiners and provides rapid results for improved efficiency.",
      "438": "The SoKat Suicide Ideation Engine (SSIE) is a tool that uses natural language processing (NLP) to better detect suicidal thoughts among veterans. It focuses on analyzing survey data collected by the Office of Mental Health Veteran Crisis Line support team.",
      "329": "The response mentions two review models, the Pre-Effectuation Review and the Targeted Denial Review, that utilize machine learning to identify cases that are more likely to have errors in determining disability eligibility. These cases are then referred for quality review checks.",
      "3": "The main focus of this response is on the detection and identification of aquatic weeds. It emphasizes the need to identify and locate these weeds in aquatic environments.",
      "375": "The Louvain Community Detection algorithm is used to identify and group similar nodes in a social network into communities. This algorithm helps in clustering nodes based on their similarities and can be used to analyze the structure and relationships within a social network.",
      "50": "The response explains the development and testing of a hybrid statistical-dynamical prediction system that can generate seamless probabilistic forecasts for daily extremes and subseasonal to seasonal temperature and precipitation. The system incorporates a Bayesian statistical method for post-processing seasonal forecasts and uses machine learning techniques. The goal is to improve the accuracy and suitability of climate variability predictions.",
      "246": "This project aims to improve the analysis of DC ramp test data from rotating machines. Currently, engineering expertise is required to recognize characteristic curves from the test plots, but by using machine learning and AI tools, such as linear regression, computer software can analyze the plots and identify the curves, leading to faster and more reliable analysis.",
      "41": "The Consolidated Screening List (CSL) is a compilation of 13 export screening lists from the Departments of Commerce, State, and Treasury. It allows for a fuzzy name search, meaning that users can search for entities without knowing the exact spelling of their name, which is useful for finding names translated into English from non-Latin alphabet languages.",
      "72": "VIAME is an open-source software toolkit called Video and Image Analysis for the Marine Environment. It allows users to use deep-learning algorithms to automatically annotate imagery using a graphical user interface. It is available for free to NOAA users and is supported by the NOAA Fisheries Office of Science and Technology.",
      "413": "In Mali, AI technology was utilized to create an AI model for distributing COVID-19 vaccines more efficiently. The model focused on prioritizing areas with high COVID-19 cases and pregnant/breastfeeding women using data from DHIS2. However, it should be noted that this model was only a proof-of-concept.",
      "349": "The Foreign Service Institute School of Language Studies is creating a tool to automatically find authentic texts in native languages that are classified by topic and proficiency level. This tool will be used to support the development of foreign language curriculum and language testing kits.",
      "380": "The Surface Report Classifier (SCM/Auto-Class) is a system that categorizes surface incident reports based on event type, including Runway Incursion, Runway Excursion, and Taxiway Incursion/Excursion. It also further classifies runway incursions based on severity type, ranging from Category A to E.",
      "420": "AICURE is a mobile application designed to track and ensure adherence to prescribed medication in clinical or pharmaceutical drug studies. It uses artificial intelligence to monitor and analyze patient behavior and provide accurate data to sponsors.",
      "94": "This project aims to develop a tool that combines reduced-order models, machine learning algorithms, fuel performance methods, and thermal property characterization equipment to accelerate the discovery, development, and deployment of nuclear fuels. The tool will focus on describing thermal conductivity, specific heat, thermal expansion, and self-diffusion coefficients as they relate to temperature and irradiation.",
      "30": "The USDA Natural Resources Conservation Service (NRCS) National Water and Climate Center has developed a next-generation prototype for generating operational water supply forecasts (WSFs) called the multi-model machine-learning metasystem (M4). This system integrates AI and other data-science technologies to improve the accuracy of spring-summer river flow volume forecasts. Through hindcasting and live operational testing, M4 has shown improved accuracy and the ability to provide geophysical explanations for its results, making it a valuable tool for water management in the western US.",
      "0": "The main idea of the response is that machine learning algorithms are being used to predict and improve the detection of invasive and quarantine significant pests at the port of entry. These algorithms use inspection data to develop predictive models for identifying these pests.",
      "130": "The main idea of the response is to explore the use of big data, artificial intelligence, and machine learning technology and tools on phasor measurement unit data to improve grid operation and management. The goal is to identify existing knowledge, discover new insights, and develop better tools for monitoring the grid in real-time.",
      "446": "The study focuses on predicting hospitalization and corticosteroid use as indicators of irritable bowel disease (IBD) flare-ups. The researchers used data from over 20,000 patients from the Veterans Health Administration and employed random forest models to analyze longitudinal lab data and other factors to make these predictions.",
      "454": "The main idea of the response is that there is an approved research study that uses a randomized trial and artificial intelligence to find colon polyps. This study has been approved by the VA and IRB.",
      "249": "The main idea of the response is that the research involves using self-supervised deep neural networks to identify classification systems for significant well events. This research is conducted by analyzing data from well Activity Reports.",
      "247": "The response explains that sustained casing pressure (SCP) in well platforms is usually caused by gas migration through leaking cement sheaths or defects in tube connections, downhole accessories, or seals. Identifying wells with SCP quickly is crucial to preventing safety issues and accidents on the platforms.",
      "196": "The NIH Office of Portfolio Analysis has developed a machine learning system that can predict whether a scientific paper is likely to be cited by a future clinical trial or guideline. By analyzing postpublication data, the system can accurately predict a paper's eventual citation with an 84% accuracy rate. This system allows for the assessment and prediction of translational progress in biomedicine based on early reactions from the scientific community.",
      "38": "The Video Surveillance System (VSS) is a comprehensive system that includes various components such as cameras, network switches, and routers. It is designed to collect, manage, and present video from multiple sources in a clear and concise manner. The system allows for the integration of different video subsystems and provides advanced features for tracking targets and selecting cameras.",
      "352": "IRM's BMP Systems is looking to integrate ServiceNow's Virtual Agent into their applications to facilitate support and data requests for users. This AI-powered chatbot will be provided by ServiceNow's Platform as a Service.",
      "69": "The GOES-16 Solar Ultraviolet Imager (SUVI) is an operational solar extreme-ultraviolet imager produced by NOAA. The SUVI Level 2 Thematic Map files are produced by NOAA's National Centers for Environmental Information and are processed from Level 2 HDR composite SUVI images. These files are experimental and will be improved in future releases, and users can contact the NCEI SUVI team for assistance. The SUVI Thematic Maps product is a Level 2 data product that uses a machine learning classifier to generate a pixel-by-pixel map of important solar features from all six SUVI spectral channels.",
      "261": "The main goal of this study is to connect data on the flow of the Delaware River with models of trout population dynamics, changes in fish catch, and the economic benefits of recreational fishing. This will be done by developing trout population models using observational data, literature estimates, and existing models.",
      "409": "The main idea is that Project Vikela is using artificial intelligence (AI) to detect illegal rhino horn in airplane luggage X-Ray scanners. The goal is to prevent the smuggling of rhino horn by utilizing advanced technology.",
      "228": "The Email Analytics application allows users to analyze email data obtained legally. It uses AI to classify spam messages, extract information about names, organizations, and locations, and includes machine translation capabilities.",
      "36": "The main idea of the response is that there is a system called Intelligent Ticket Routing that automatically routes BMC Remedy tickets to the appropriate work groups. This system utilizes multiple technologies and tools such as Python, JupyterHub, scikit-learn, GitLab, Flask, Gunicorn, Nginx, and ERMS.",
      "423": "Automated eye movement analysis using artificial intelligence can help improve the accuracy and quality of diagnostic predictions for neurological diseases such as traumatic brain injury, Parkinson's, and stroke. This technology uses previously collected data to screen for markers of these diseases.",
      "422": "This response suggests that artificial intelligence can be used by health professionals to assess lung function in both healthy individuals and those with diseases. It mentions that the AI can help identify predictors of normal and abnormal lung function as well as sleep parameters.",
      "223": "The main idea is that security analysts in Security Operations Centers receive large amounts of log data and use manual and automatic methods to detect and correlate potential cyber attacks. However, these methods are not always comprehensive, so analysts use automated tooling with mathematically and probabilistically based models to refine alerts and detect anomalies in a timely manner.",
      "226": "HSI uses Artificial Intelligence to normalize and correct data entry errors, identify purposeful misidentification, and connect information across datasets. This streamlines the process of investigations and reduces the number of resource hours needed. The services provided include normalizing addresses, inferring ID types, categorizing name parts, and validating phone numbers. These services are part of the Repository for Analytics in a Virtualized Environment (RAVEn), which supports ICE's mission to enforce and investigate violations of U.S. laws.",
      "22": "The Landscape Change Monitoring System (LCMS) is a data system created by the USDA Forest Service that uses remote sensing to map and monitor changes in vegetation canopy cover, land cover, and land use. It uses a supervised classification process to analyze temporal change classifications and training data to identify areas of vegetation gain, loss, and changes in land cover and use.",
      "312": "The main idea of the response is that text to speech conversion can be enhanced through the use of neural networks, resulting in more realistic human-sounding applications. This is achieved by utilizing natural language processing models.",
      "165": "The main idea in this response is that CMS is using a Security Data Lake to modernize its load-extract-load-transform (L-ETL) pipelines and data tooling. This will enhance Agency security by bringing together more system, telemetry, and program data in one place with a unifying governance model. While there is no ML/AI work being done currently, the goal is to build a modern data platform that will allow for machine learning model development in the future.",
      "26": "The Cropland Data Layer (CDL) uses a machine learning algorithm to classify the type of crop or activity in each 30 square meter pixel on the ground using satellite-based sensors. The algorithm is trained on USDA's Farm Services Agency data and other sources to ensure accuracy. The CDL has been produced since 2008 and is highly accurate for commodities like corn and soybeans.",
      "372": "The TOPIQ GEC A&R's TOPIQ tool is designed to classify text into topics for analyst review and interpretation. It utilizes Latent Dirichlet Allocation (LDA), a natural language processing technique, to identify topics within a collection of documents and determine the probability of each document belonging to a specific topic.",
      "267": "The Seabird Studies Team at the Western Ecological Research Center conducted aerial surveys of the ocean off central and southern California to count and classify marine birds and mammals. To process the large volume of images, they used machine learning techniques and created a labeled training dataset. They are currently reviewing the model's output and will generate maps of species distribution and abundance to inform planning for offshore wind energy development.",
      "448": "The study used machine learning to analyze patient data from 2001 to 2015 to predict surgery in Crohn's disease patients. The analysis focused on patient demographics, medication use, and laboratory values to model future surgical outcomes within one year.",
      "170": "The response describes an artificial intelligence-based deduplication algorithm that is used to identify duplicate reports in the FDA Adverse Event Reporting System (FAERS). The algorithm processes both structured and unstructured data, extracts relevant clinical features, and uses a probabilistic record linkage approach to score pairs of reports. The algorithm aims to facilitate the identification of potential duplicate reports during case series evaluation for safety concerns.",
      "437": "Machine learning algorithms are being used to automatically detect seizures without the need for human intervention. These algorithms analyze EEG and video data from a VHA epilepsy monitoring unit to identify and classify seizure activity.",
      "119": "This project aims to develop passive instrumentation to measure permanent strains caused by radiation and extract important parameters using modeling, simulation, and machine learning algorithms. The researchers plan to conduct an irradiation experiment using anisotropic materials to understand the directional deformation caused by neutron radiation. The results will be used to predict the material's response in future applications as a probe material.",
      "337": "The Duplicate Identification Process (DIP) aims to assist users in efficiently identifying and marking duplicate cases, thereby reducing the time spent on reviewing cases for hearings. DIP utilizes image recognition technology powered by artificial intelligence software to accurately identify duplicates according to the policy set by the Social Security Administration (SSA).",
      "355": "The Department's eRecords archive uses machine learning models to enhance metadata and aid in record discovery and review. These models include entity extraction, sentiment analysis, classification, and document type identification.",
      "74": "This project aims to study the distribution and ecology of green sea turtles in southern California, specifically in the La Jolla Cove area. It involves engaging with local photographers to collect underwater images of the turtles, which are then analyzed using facial recognition software to identify individual turtles. Through this method, researchers can gather information on population size, residency patterns, and foraging habits of the green turtles.",
      "338": "The main idea of the response is that handwriting recognition from forms AI is used to perform OCR (Optical Character Recognition) on handwritten entries on specific standard forms. This use case supports both Robotic Process Automation efforts and can also be used as a standalone application.",
      "78": "The response discusses the investigation of replacing unstructured wave models in the Great Lakes with two AI models: a Recurrent Neural Network (RNN) and a boosted ensemble decision tree. These models were trained on two decades of wave observations in Lake Erie and compared to the current operational wave model.",
      "180": "The Pango nomenclature, known as Pango lineages, is being used globally to track the transmission and spread of SARS-CoV-2 and its variants. Researchers and public health agencies can access and analyze the sequence data using the Pango lineage classifications. The tool requires conda on a MacOS or Linux system and FASTA-formatted sequence data, and it uses a classification tree called PangoLEARN to group similar sequences for lineage assignment within NCBI Virus.",
      "138": "The main idea is that acquisition analytics uses detailed transaction data to classify each transaction within the Government-wide Category Management Taxonomy. This helps in organizing and managing government acquisitions more effectively.",
      "389": "The main idea of the response is that machine learning techniques, specifically deep learning models, can be used to predict head kinematics in vehicle crashes using videos. This is useful when there are no sensors available or when sensor data is of low quality, and the output of the model can be used to predict the likelihood of injury based on angular velocity.",
      "45": "The Fisheries Electronic Monitoring Library (FEML) is a centralized database that stores electronic monitoring (EM) data pertaining to marine life. It serves as a repository for this information.",
      "93": "The project aims to use artificial intelligence and Monte Carlo algorithms to improve the efficiency and reliability of computational simulations for estimating low failure probabilities in advanced reactor technologies. By reducing the number of finite element evaluations, the project will enable the nuclear engineering community to conduct probabilistic failure analyses and uncertainty quantification studies more efficiently in the design and optimization of these technologies.",
      "193": "The National Institutes of Health (NIH) has developed a virtual assistant chat bot to help users find grant-related information using open educational resources (OER). This chat bot will provide assistance in navigating the vast amount of grant information available through the NIH.",
      "263": "The project involves using AI to automate the detection and classification of wildlife from aerial imagery. The first stage is a detector that identifies wildlife, while the second stage is a classification algorithm that categorizes the wildlife. The project uses various tools and databases to develop and train the algorithms and store the annotated data and image metadata.",
      "68": "The VOLCAT is an application system that uses AI-powered satellite applications to detect, track, characterize, and forecast hazardous volcanic events, particularly volcanic ash which is a major aviation hazard. The goal of the project is to further develop the VOLCAT products and transition them to the NESDIS Common Cloud Framework to meet new International Civil Aviation Organization requirements.",
      "350": "The Village Monitoring System program utilizes AI and machine learning to analyze moderate resolution commercial satellite imagery on a daily basis. By focusing on the near-infrared band, the program can detect anomalies or unusual patterns.",
      "24": "The main idea of the response is that machine learning models are being used to map and monitor forest mortality and defoliation across the United States. These models use training data from various sources and can process the output into vector polygons.",
      "395": "The main idea is that the NLU model will be integrated into the Automated Collections IVR (ACI) menu. It will analyze customer speech input and determine the intent, guiding the taxpayer to the appropriate call path based on that intent.",
      "436": "The main ideas in the response are that AI can be used to improve the accuracy of provider directory data and align it with the system of record. AI can also be used for intelligent identity resolution, linking, clinical decision support, discrepancy detection, and resolution. Additionally, AI adapters can be used for inference, and AI has long-term storage capabilities for machine learning and business intelligence applications.",
      "362": "Fast Text is an AI approach that helps identify similar terms and phrases based on a root word. It supports A&R in creating strong search queries for data collection.",
      "136": "The response highlights that the EPA's Office of Compliance and the University of Chicago collaborated to create a proof-of-concept aimed at enhancing the enforcement of environmental regulations through facility inspections. Through the use of predictive analytics, the initiative achieved a significant 47% improvement in identifying violations of the Resource Conservation and Recovery Act.",
      "270": "The main idea is that the study aims to map benthic algae along the Buffalo National River in northern Arkansas using orthophotos and multispectral images. The researchers collected field data to train a classification algorithm that can distinguish between different levels of algal density.",
      "221": "The main idea of the response is that malware reverse engineering is crucial for CISA's cyber defense mission. Threat Focused Reverse Engineering (TFRE) is a method that combines advanced engineering, formal methods, and deep learning techniques to improve cyber threat intelligence. The use of scalable, automated tools is necessary to disrupt sophisticated adversaries' malware development lifecycle, and new techniques are needed to target adversaries, support analysts, and create advanced tools for end users. TFRE includes tool hardening, enhanced computational abilities, understanding of deployment environments, and other important capabilities.",
      "6": "The response discusses the concept of approximate string or fuzzy matching, which is used to automate the process of matching similar but not identical text in administrative documents. This matching algorithm helps classify similar strings into a single category, reducing the need for manual error-checking and information duplication.",
      "244": "The main idea of the response is that artificial intelligence and machine learning can be used to improve the accuracy and efficiency of analyzing high-resolution photogrammetric data obtained from unmanned aerial systems (UAS). By developing a standard reference protocol and using these technologies, it will be possible to unlock the potential information in the data and provide detailed analysis of Reclamation's assets, leading to better-informed decision making.",
      "1": "The main idea is to detect pre-symptomatic citrus trees infected with Huanglongbing (HLB) by identifying pixels in multispectral and thermal imagery that have the signature of HLB infection. This method allows for the detection of HLB before visible symptoms appear on the citrus trees.",
      "285": "The main idea of the response is that a system is being developed to predict flood flow metrics for stream reaches based on watershed characteristics and long-term meteorological data. The system will use gage data from the Delaware River Basin and the Colorado River Basin to train models that can estimate flood flow metrics in ungaged reaches. The current focus is on minimally altered catchments, but future years may include predictions for altered catchments. The models will be built using R packages on the USGS Tallgrass supercomputer.",
      "357": "The response mentions a prototype system that collects and analyzes daily media clips reports from around 70 Embassy Public Affairs Sections. This system is likely designed to help with global audience segmentation and understanding of different public affairs sections' media coverage.",
      "114": "This project aims to develop a simulation framework that combines high-fidelity physics models with grid monitoring data to make real-time decisions for integrated energy systems (IES) operation. The framework will use learning-based algorithms to detect and respond to component contingencies caused by extreme events like cyber-attacks or extreme weather, in order to mitigate their impacts.",
      "328": "The main idea of the response is that the anomalous iClaim predictive model is a machine learning model used to identify high-risk iClaims. These claims are then sent for further review before any further action is taken.",
      "313": "The main idea is to use custom natural language processing models to determine if a physician's note contains causal language. This process is part of claims document processing.",
      "13": "Westat held a competition to discover efficient ways of connecting USDA nutrition information with a large dataset of 750K food items. Participants used various AI techniques like NLP, random forest, and semantic matching to achieve this task.",
      "214": "The AI Security and Robustness Frameworks, processes, and testing tools have been developed to govern the acquisition, development, deployment, and maintenance of AI technologies. These tools, which use Machine Learning and Natural Language Processing, help ensure the trustworthy, robust, and secure operation of AI systems by speeding up data processing and enhancing the assessment of AI technology within the agency.",
      "131": "The response discusses the use of big data, artificial intelligence, and machine learning technology to analyze phasor measurement unit data. The goal is to identify and improve existing knowledge, as well as discover new insights and tools for better grid operation and management.",
      "233": "The project aims to create a machine learning model that can predict the approval of I-539 applications through eProcessing. This has the potential to enhance the efficiency of the approval process and improve the overall experience for applicants.",
      "56": "The response states that deep learning algorithms have been developed to automate the identification of right whales in photos. These algorithms have been expanded to include different viewpoints and body parts, and are now being used on the Flukebook platform for both North Atlantic and southern right whales. Additionally, a paper about this system is currently under review at Mammalian Biology.",
      "90": "This research aims to develop a digital twin of a centrifugal contactor system in the nuclear fuel cycle. The digital twin will receive data from sensors, simulate the chemical separations component, and use machine learning to analyze the data for anomalies, failures, and trends. The research will also involve the use of advanced artificial intelligence and data analysis techniques guided by a team of nuclear safeguards experts.",
      "421": "This project aims to detect acute kidney injury (AKI) using artificial intelligence in collaboration with Google DeepMind. The AI system can identify AKI, ranging from minor loss of kidney function to complete kidney failure, and can also detect AKI caused by other illnesses.",
      "323": "The main idea is that an open source large language model is used to summarize case recording documents that do not contain any personal identifiable information or sensitive data. The process involves human note takers reviewing the summaries, and the model is not hosted in the DOL technical environment.",
      "65": "The main ideas in this response are that CoralNet is a software used for annotating benthic photo quadrats using machine vision point classification. The development of classifiers has reduced the need for human annotation and there is ongoing development and improvement of CoralNet.",
      "176": "Splunk is an IT system monitoring software that uses machine learning to collect and analyze system logs from various IT infrastructure systems and endpoints. It helps with auditing and monitoring tasks.",
      "289": "The main idea of this response is that a multi-task deep learning model was developed to predict daily average streamflow and daily average stream water temperature. The model used meteorological variables as input data and a multi-task scaling factor to control the contribution of the auxiliary variable's error. The training data consisted of streamflow and water temperature observations collected by the USGS and made available through the NWIS and CAMELS dataset. The models were developed using Python, TensorFlow, and Snakemake.",
      "428": "Researchers are using machine learning techniques to improve diagnostic error detection and classification of protein electrophoresis text. They are collecting true/false positive annotations through chart review and constructing a vector embedding of patient records to retrieve similar unlabeled records. The aim is to use machine learning as a filter to improve specificity after rules-based retrieval, focusing on high-value structured data relevant to stroke risk and potentially prior text notes.",
      "11": "The NAL Automated indexing Cogito software utilizes artificial intelligence to automatically annotate around 500,000 peer-reviewed journal articles each year. It specifically uses the National Ag Library Thesaurus concept space to annotate metadata in the Library's bibliographic citation database, including AGRICOLA, PubAg, and Ag Data Commons.",
      "258": "This study aims to develop an AI system that can identify individual fish and detect diseases from images. If successful, this system could replace traditional methods used for estimating fish abundance and movement, leading to cost reductions for fisheries managers. Additionally, disease detection from images could offer new ways to assess fish health status and trends.",
      "97": "The approach described in the response utilizes millimeter wave beam directionality and autonomous beam scheduling to support secure spectrum sharing for 5G and ensure optimal performance for base stations. Measurements and predictive analytics are used to develop autonomous beam scheduling algorithms, which will benefit mission critical communications, emergency response operations, and secure communication for critical infrastructure without the need for expensive licensed bands.",
      "265": "The ML-Mondays course focuses on the applications of deep learning in image analysis, particularly in image segmentation, classification, and object detection. The course utilizes Python, Keras, and Tensorflow ML libraries, providing software, data, documentation, slides, and a website for further information.",
      "113": "The project aims to develop a deep reinforcement learning approach that can effectively manage distributed or tightly coupled multi-agent systems in energy systems. This approach will utilize deep neural networks for system representation, modeling, and learning, allowing for complex optimization of nonlinear systems over various timescales.",
      "207": "The response describes the use of geospatial imagery and annotation through Synthetic Aperture Radar (SAR) satellites, which can capture images of any location on Earth regardless of cloud cover or time of day. This technology utilizes AI, including machine vision and object detection, to identify airframes, military vehicles, and marine vessels, as well as detect changes for disaster response missions.",
      "315": "The main idea is that there is a custom machine learning model that can extract data from complex forms and tag the data entries to field headers. This model takes a document or scanned image of the form as input and produces a JSON response with key/value pairs extracted by running the form through the trained model.",
      "231": "The Facial Recognition Service is utilized by HSI agents and analysts to identify individuals involved in various crimes such as child exploitation, human rights violations, and war crimes. It is a part of the DHS HSI Innovation Lab project known as RAVEn, which helps support ICE's mission to enforce and investigate violations of U.S. laws. RAVEn also enables the use of analytical tools to analyze trends and identify criminal patterns as needed by HSI.",
      "239": "The main idea of the response is that topic modeling on Request For Evidence (RFE) data sets involves creating models that can identify lists of topics and documents related to each topic. Topic modeling is a useful tool for organizing, understanding, searching, and summarizing text data, as it helps in discovering hidden themes in a collection and classifying documents based on these themes.",
      "396": "The project is evaluating the effectiveness of training a multilingual BERT model on IRS corpora and using it to evaluate software translation of IRS content. The evaluation will use COMET, ROGUE, and BLEU measures, and will also assess the model's performance in classifying English-Only and Spanish-Only content.",
      "47": "The main idea of the response is that AI-based automation of acoustic detection of marine mammals is important for adapting mitigation measures in response to climate change. The INSTINCT software has been developed for training and deploying machine learning models for this purpose, and it has been successfully used in several analyses. However, further development and integration of AI methods require a skilled operator familiar with INSTINCT, machine learning, and the acoustic repertoire of Alaska region marine mammals.",
      "10": "The ARS Project Mapping NLP allows national program leaders to analyze and cluster research project plans, providing them with an interactive dashboard to identify synergies and patterns within and across different ARS research program portfolios. This tool aims to enhance collaboration and coordination among different research programs.",
      "371": "The SentiBERTIQ GEC A&R is an AI tool that uses deep contextual analysis to identify and extract subjective information from text. It was trained on a large dataset of labeled tweets in multiple languages and can assign sentiment and confidence intervals to text documents.",
      "288": "The main ideas in the response are: \n1) A model has been developed to predict daily dissolved oxygen concentrations in stream locations using meteorological inputs and static catchment attributes. \n2) The model is trained using dissolved oxygen concentrations collected by the USGS and made available through the National Water Information System. \n3) The work is being conducted using Python and R, with deep learning models written in TensorFlow, data preparation in R, and the modeling workflow scripted via Snakemake.",
      "251": "This project aims to classify walrus haulout camera trap images using codes that were previously developed for wildlife underpass camera trap image classification. The system is able to determine the probability of an image containing walruses and various human disturbances, such as boats and aircraft. Training, validation, and testing datasets with human-assigned labels are used to train and evaluate the models, which can then be used to predict classes on unlabeled images from ongoing camera monitoring efforts. The training process utilizes a convolutional neural network (CNN) approach based on TensorFlow and is performed on the USGS Tallgrass supercomputer.",
      "370": "The response describes a deep learning model called Deepfake Detector that can classify an image as either real or fake based on the presence of a person's face. It specifically identifies deepfakes, which are synthetically generated faces often created using Generative Adversarial Networks (GANs).",
      "149": "The main idea of this response is that relevancy tailoring involves adjusting the ranking of search results to ensure that the most relevant results are displayed at the top of the list. This process helps users find the most useful and accurate information quickly and easily.",
      "75": "The response states that there is a project to develop automated machine learning tools for classifying the species identity of toothed whales and dolphins using acoustic recordings. The tools will be used to analyze long-term recordings from passive acoustic moored instruments in the Gulf of Mexico to study environmental processes affecting marine mammal density and distribution. The project is funded from June 2018 to May 2021.",
      "76": "The main idea of the response is that the NOAA Fisheries Alaska Fisheries Science Center's Marine Mammal Laboratory conducts annual aerial surveys to monitor the endangered western Steller sea lion population in Alaska. They currently use manual counting methods but are working with Kitware to develop automated detection and image registration pipelines to improve the process. This data is important for understanding the species and ecosystem and informing sustainable fishery management decisions.",
      "122": "This research combines machine learning techniques with microscopy to identify and correlate microstructural features in a multiphase alloy that has high strength and fracture toughness. The goal is to develop a machine learning tool that can be used to identify key microstructural features and correlate them with mechanical properties in different alloys.",
      "101": "The project developed a framework and process to translate industrial control system features into a machine-readable format for use with automated cyber tools. The research also examined current and evolving standards for usability with diverse grid architectures and aims to prioritize future research steps for automated threat response and improved cyber incident consequence models. Additionally, the project aims to enhance national capabilities for sharing actionable threat intelligence at machine speed.",
      "394": "The main idea is that the Natural Language Understanding (NLU) model will be integrated into the eGain intent engine. This NLU will analyze customer typed text input and match it to a specific intent, allowing it to provide the relevant knowledge article in response.",
      "400": "The Line Anomaly Recommender use case aims to find a model that combines two recommender system models in order to evaluate compliance risk and detect abnormal tax returns and line-item values. The pipeline capabilities provided by this model can enhance the IRS LB&I reviewers' understanding with the help of advanced deep learning techniques for identifying anomalies.",
      "133": "The main idea of the response is to explore the use of big data, AI, and machine learning on PMU data to enhance power system resilience. The goal is to improve existing knowledge, discover new insights, and develop tools for better grid operation and management.",
      "37": "The main idea of this response is that predictive maintenance can have an impact on infrastructure items. It mentions several tools and technologies that are used in the process, such as einblick, mysql, python, linux, and tableau.",
      "205": "The response explains that Data and Entity Resolution is a process that uses Machine Learning to merge and identify connections between different data sources. It also mentions that there is a user-friendly tool available for non-technical users to train the models continuously.",
      "302": "The researchers used a machine learning approach to develop a ground motion model (GMM) using simulated ground motions from the Southern California CyberShake study. They found that their synthetic-based GMM had similar results to empirically based GMMs derived from a global data set and records of a recent earthquake, suggesting that machine learning can effectively utilize synthetic data to guide future parameterization of GMMs.",
      "48": "The main ideas of the response are: 1) The project aims to develop an image library of landed catch from optical survey data in the Gulf of Mexico, 2) The project plans to use machine learning and deep learning techniques to automatically identify and count species from underwater imagery, and 3) The project also aims to develop algorithms that can process imagery in near real time and transfer the information to a central database.",
      "2": "The main idea of the response is that high throughput phenotyping techniques can be used in citrus orchards to monitor the health of the orchard. This involves locating, counting, and categorizing citrus trees in order to assess their overall well-being.",
      "115": "The use of computer vision techniques for processing satellite imagery has improved in recent years, making it possible to analyze critical infrastructure and interdependency data more effectively. By combining advanced computer vision techniques with a functional taxonomic approach to critical infrastructure and unique geo-spatial and dependency datasets, researchers can achieve innovative and state-of-the-art image processing results that enhance national critical infrastructure security and defense capabilities.",
      "152": "The suggestion is to display related searches that could offer the user additional valuable information. This feature aims to enhance the user's experience and provide them with more relevant content.",
      "359": "GPATools and GPAIX are production systems developed by GPA for testing messages at a large scale across different foreign sub-audiences. The goal is to determine the most effective way to reach and engage with specific target audiences.",
      "319": "The main idea of the response is that electronic records management is meeting the metadata standards set by NARA for permanent federal documents through the use of AI. This is achieved by using AI to identify data within the documents and also using natural language processing (NLP) to classify and summarize the documents.",
      "190": "The main idea of the response is that RCDC is an electronic tool that uses AI/NLP to categorize projects based on grant applications, R&D contracts, intramural projects, and inter-agency agreements. It does this by identifying concepts in the extracted text from the source project, person, or publication, normalizing the text, extracting concepts and matching them to the RCDC thesaurus. The system then ranks the concepts based on their frequency of occurrence and outputs the projects into their respective areas of science.",
      "301": "The main idea of the response is that machine learning is being applied to predict ground shaking during earthquakes based on initial observations from seismic stations. The initial test dataset is from an area of induced seismicity in Oklahoma, but future datasets will include seismic data from California and possibly Japan. The plan is to eventually transition from running the codes on a desktop to a cloud computing platform like AWS.",
      "57": "The main idea of the response is that there is a development of fast and accurate neural network longwave (LW) and shortwave (SW) radiations for the Global Forecast System (GFS) and Global Ensemble Forecast System (GEFS). The success and stability of this approach have been demonstrated in previous versions of GFS, and it will now be extended to the current versions of GFS and GEFS.",
      "217": "The Cyber Sentry program monitors critical infrastructure networks and uses advanced anomaly detection and machine learning to analyze cyber-physical data from IT and OT networks, including ICS/SCADA. The Critical Infrastructure Anomaly Alerting model assists threat hunting analysts by providing AI-assisted processing of this information.",
      "242": "The response states that Reclamation, along with partners, conducted a year-long evaluation of streamflow forecasting technologies and held a prize competition focused on 10-day streamflow forecasts. The top performing forecast product was from UpstreamTech, an AI/ML forecasting company, and several competitors from the prize competition also performed well. Reclamation plans to further evaluate the UpstreamTech forecast products and other top performers from the competition.",
      "25": "The Land Change Analysis Tool (LCAT) uses a random forest machine learning classifier to create detailed land cover maps from aerial and satellite imagery. They generate training data using a web application and process the data using a large docker cluster. The results are made publicly available through an image service, and they have already mapped a significant amount of land and generated a large number of training samples.",
      "53": "The main idea of the response is that machine learning techniques, including simple neural networks and deep learning techniques, are used with NCEP models to predict precipitation and temperature over the contiguous United States (CONUS) for the first five weeks. These techniques are employed to provide drought outlooks.",
      "245": "The project aims to use photogrammetric products to analyze and map cracks on Reclamation facilities. This process, which has traditionally been time-consuming and required difficult access, can now be done using drones or other devices. By implementing a standardized protocol and utilizing machine learning and AI, the collected data will be used to make informed decisions about Reclamation assets.",
      "110": "The main idea of this response is that the project aims to develop machine learning methodologies to assess the resilience of integrated energy systems and their vulnerabilities to threats. This analysis will help understand the impact of microreactors and distributed energy resources on the reliability and resiliency of energy systems.",
      "412": "AI technology was used in Serbia to predict bed occupancy at hospitals, with a median error of around 20%. This proof-of-concept model was developed to demonstrate the value of AI and will be followed by a focus on waiting list optimization for scheduled imaging diagnostics services as part of the national AI strategy.",
      "435": "This response states that machine learning prediction models are being used to evaluate risk factors for opioid use disorder (OUD) and overdose in Post-9/11 Veterans. Various modeling approaches are being employed to develop predictor profiles for OUD and overdose.",
      "177": "The COVID-19 Pandemic Vulnerability Index Dashboard is a tool that provides risk profiles for every county in the United States. It generates PVI scorecards that summarize and visualize the overall disease risk based on the latest data, enabling users to assess the vulnerability of different areas to the COVID-19 pandemic.",
      "453": "This pilot project aims to extract family medical history data from patient records of African American Veterans aged 45-50. The goal is to identify individuals who are at risk of prostate cancer but have not undergone screening for this disease.",
      "325": "The Bureau of Labor Statistics (BLS) receives bulk data from corporations regarding the cost of goods and services they provide. To process this data efficiently, BLS is using machine learning to label the data with Entry Level Item (ELI) codes based on word frequency counts in item descriptions. Logistic regression is used to estimate the probability of each item being classified, and any classifications with low probabilities are flagged for human review.",
      "88": "Aidan FSA is a virtual assistant that utilizes natural language processing to provide information and answer commonly asked questions about financial aid. Over the span of two years, Aidan has assisted over 2.6 million customers and processed more than 11 million user messages.",
      "218": "Cyber incident handling specialists use advanced automation tools that leverage Machine Learning and Natural Language Processing to process and filter data received from various threat intelligence and cyber incident channels. These tools assist in increasing the accuracy and relevance of data presented to human analysts and decision-makers, as well as aggregating information in reports for further analysis.",
      "8": "The main idea of the response is that artificial intelligence (AI) techniques are used for correlative statistical analysis, specifically in modeling predictive relationships between variables. The response mentions various modeling approaches, such as random forest, artificial neural networks, k-nearest neighbor clustering, and support vector machines, that are commonly used for statistical prediction.",
      "128": "The main idea is to explore the use of big data, artificial intelligence, and machine learning technology on PMU data in order to improve existing knowledge and discover new insights for better grid operation and management.",
      "286": "The main idea of this response is that a process-guided deep learning model has been developed to predict lake water temperatures. The model is trained using a two-stage process, with pre-training using process-based modeling outputs and then fine-tuning using lake temperature observations. The models are designed to fit observations and conserve energy, and the software used for modeling is the General Lake Model (GLM version 2) software.",
      "185": "The main idea of the response is that SingleCite is an automated algorithm that improves single citation search in PubMed. It establishes a query-document mapping by using a regression function to predict the probability of a retrieved document being the target. SingleCite has shown superior performance in benchmarking experiments and is able to rescue queries that would otherwise fail.",
      "141": "The main idea is that Key KPI Forecasts for GWCM takes historical data to create near-term forecasts for the upcoming fiscal year. The pilot program is currently focused on total agency/category spend and if successful, the same methodology can be applied to other KPIs.",
      "271": "The response discusses the importance of understanding the changes in sub-surface drainage (tile drains) over time in order to analyze the effects on streamflow and water quality. The method proposed involves using satellite imagery to delineate tile drains and create an up-to-date geospatial layer. The process involves using a UNet model trained on panchromatic images and a combination of python scripting and Jupyter notebook.",
      "351": "The Conflict Observatory program uses AI and machine learning to analyze satellite imagery and document war crimes and abuses in Ukraine. One of its main functions is to conduct automated damage assessments of various buildings, including critical infrastructure, hospitals, schools, and crop storage facilities.",
      "112": "This project aimed to improve probabilistic risk assessment by using a support vector machine and PRA software to automatically detect vulnerabilities in system design and identify previously unknown issues. This approach eliminates the need for training data that would typically only be available after system failures occur, reducing human error and costs.",
      "236": "The Person-Centric Identity Services (PCIS) aims to be a trusted source of biographical and biometric information for individuals' immigration history. The de-duplication model helps merge data from different systems to create a complete picture of a person, using machine learning to identify and match records with high accuracy. This allows PCIS to gather an individual's immigration history efficiently without the need for extensive research across multiple systems.",
      "404": "The Media Early Warning System (MEWS) aims to identify narratives and trends in social media by detecting alterations in images and videos. The purpose of this system is to counteract malign narratives by monitoring and addressing them in a timely manner.",
      "92": "The main idea of this research is to develop and validate scalable models that can make predictions and decisions faster than real-time. The focus is on achieving autonomous operation of microreactors through a hybrid modeling approach that combines physics-based and artificial intelligence techniques. Additionally, a distributed anticipatory control strategy will be developed to analyze the risk of cascading failures when deploying emerging reactors in a full feeder microgrid.",
      "111": "This research project aims to use generative adversarial networks to automate the training of electromagnetic-based anomaly detection systems for legacy industrial control systems devices and Industrial Internet of Things. By doing so, it would reduce the manual labor and operational costs associated with protecting legacy control systems from intrusion.",
      "54": "The EcoCast is an operational tool that uses boosted regression trees to model the distribution of swordfish and bycatch species in the California Current. It is designed to reduce bycatch and support sustainable fisheries by providing dynamic ocean management.",
      "167": "The main idea of this response is to prioritize alerts produced by the Fraud Prevention System based on the forecasted time needed to work on them. The inputs for this prioritization include Medicare Claims data, TPE Data, and Jurisdiction information, and the output is the forecasted time needed to work on each alert using various machine learning algorithms.",
      "66": "This project focuses on the automated detection of hazardous low clouds to ensure safe and efficient transportation. It involves maintaining and sustaining the operational GOES-R fog/low stratus products, which are derived from satellite imagery and machine learning. These products are regularly used by the NWS Aviation Weather Center and Weather Forecast Offices.",
      "124": "The Grid Resilience and Intelligence Platform (GRIP) utilizes artificial intelligence (AI) to create metrics that measure the effects of extreme weather events on the power grid. By analyzing utility data and utilizing physical models, GRIP can predict the potential grid impacts caused by major storms.",
      "178": "The National Institute of General Medical Sciences has developed a system called NIGMS ASSIST, which utilizes artificial intelligence and natural language processing to provide relevant data to program staff. The system includes modules for identifying investigators and matching program officers based on scientific data input. It is supported by Oracle, SQL server, and Python analytics.",
      "160": "The Chatbot (text) is designed to help the Security team by automating email responses to general physical security questions. This allows the help desk team to focus on addressing more complex issues for employees and contractors.",
      "426": "The Digital Command Center is a system that aims to gather all data within a medical center and use predictive and prescriptive analytics to help leaders improve the performance of the hospital. By consolidating information and applying advanced analytics, the system enables better optimization and decision-making.",
      "452": "The Medtronic GI Genius is a technology that uses artificial intelligence to assist in the detection of colon polyps. It is designed to improve the accuracy and effectiveness of colonoscopy procedures by providing real-time analysis and highlighting potential polyps for further examination.",
      "378": "The use of machine learning software has been successful in analyzing camera images of a wind sock to accurately determine surface wind speed and direction in remote areas without weather observing sensors. This AI capability proves to be a reliable method for obtaining crucial weather information in inaccessible locations.",
      "129": "The response discusses the use of big data, AI, and machine learning technology in analyzing PMU data to enhance grid operation and management. The goal is to improve existing knowledge, uncover new insights, and develop tools for better grid management.",
      "318": "The response highlights the use of AI technology for validating official documents. It specifically focuses on the detection of mismatched addresses and garbled text in letters sent to benefits recipients.",
      "100": "The Resilient Attack Interceptor for Intelligent Devices approach aims to develop external monitoring methods to safeguard industrial internet of things devices. This will be done by analyzing naturally occurring physical aspects and detecting any abnormal functionality that may indicate a potential attack.",
      "416": "NASA SERVIR is using artificial intelligence to predict harmful algae blooms in Lake Atitl\u00e1n, Guatemala. The system uses machine learning and data from Earth observations and weather models to provide daily forecasts, which are used by Lake Authorities to inform their Harmful Algal Blooms Alert System. The project is supported by National Geographic and Microsoft.",
      "457": "The response discusses the use of an AI called social determinants of health extractor to identify social determinants of health (SDOH) information from clinical notes. These extracted variables can then be used in health-related analysis to determine if SDOH can contribute to disease risks or healthcare inequality.",
      "295": "The main idea of the response is that the researchers are using a neural network to differentiate between exposed bare rock and soil covered areas in land cover classification. They have trained and tested the neural network using a dataset from the Sierra Nevada Mountains and are aiming to create a machine learning approach to accurately map soil vs. rock-covered areas for various applications such as landslide hazard mapping and calculating water fluxes.",
      "215": "The main idea of the response is that AIS Automated Scoring & Feedback (AS&F) uses descriptive analytics to classify indicators of compromise (IOCs) based on organizational-centric intelligence data. It determines if an indicator is present in a known-good list, if there are sightings of the indicator, if it has been verified by an analyst, and if there are other reports about the indicator. AIS participants can use the opinion and confidence values to filter and prioritize actions and investigations.",
      "134": "The study used a random forest model to predict the probability of a chemical being associated with different exposure pathways. They then created a consensus model that combined multiple predictors of exposure to estimate intake rates for a large number of chemicals, even with limited exposure information. The approach identified certain chemicals with potentially high intake rates, while also providing confidence intervals for the estimated intake rates of other compounds.",
      "19": "The CLT knowledge database is an information system that uses data aggregator bots to search the internet for relevant cross-laminated timber (CLT) information. It has cataloged over 3,600 publications on various aspects of CLT and aims to foster collaboration among stakeholders and support the increasing use of mass timber, benefiting forest health.",
      "344": "A/LM plans to develop AI/ML models to detect potential fraud or malfeasance in their Integrated Logistics Management System (ILMS). These models will focus on key supply chain functions like Asset Management, Procure-to-Pay, and Fleet Management to enhance existing risk analytics.",
      "399": "The main idea is that LB&I (Large Business and International) Text Analytics has developed TaxBERT, a tax domain-specific BERT model, by training it using a large number of tax-related documents. This model can be used for targeted analytics in the tax domain.",
      "254": "The main idea of this response is that a system is being developed to detect and count individual walruses in drone imagery. The system will use convolutional neural networks trained on a supercomputer to identify and create bounding boxes around the walruses. This will support population research conducted by the Alaska Science Center.",
      "294": "The research is focused on using artificial neural networks to identify surface water in different areas by training them with annotated hydrography data. The input training data includes various types of remotely sensed data and surface flow models. The researchers are utilizing open-source tools in a high-performance computing environment for their work.",
      "342": "The company developed a machine learning model called Product Service Code Automation ML Model A/LM. This model is designed to scan unstructured procurement data entered by users, such as requisition titles and line descriptions, and automatically detect the types of commodities and services being purchased. The purpose of this model is to improve the categorization of procurement items.",
      "339": "The Quick Disability Determinations (QDD) process uses a computer-based predictive model to identify cases where a positive disability determination is likely and medical evidence is easily accessible. By identifying these cases early on, the Social Security Administration can prioritize them and expedite the processing. The Agency continually updates and improves the QDD model to better identify strong candidates for faster processing.",
      "385": "The response describes a deep neural network called DeepCNet that can identify and classify various features related to railroad tracks, such as fasteners and ties. The network is used for \"change detection\" applications, where it can detect and notify any changes in the track's status or between different inspections based on geolocation.",
      "189": "The response explains that the RPAB is responsible for assigning program classifications to grant applications submitted to NIAID. They currently manually assign approximately 6,000+ grant applications, but the AI project aims to automate this process by categorizing the applications into their respective Program Class Codes (PCCs).",
      "9": "The 4% Repair Dashboard is a model that analyzes descriptions of expenses related to repairs and maintenance. It uses keywords in context to classify expenses as either \"repair\" or \"not repair.\"",
      "39": "The B2B matchmaking system uses algorithms and AI technology to analyze data about event participants and identify suitable matches based on their specific needs and available opportunities. It generates suggested B2B matches and provides a match strength scorecard as an output.",
      "155": "The main idea is that a chatbot is an interactive interface that can understand and respond to queries in real time using natural language processing. It is capable of understanding plain language and providing appropriate responses.",
      "243": "The goal of this study was to investigate whether advancements in machine learning, particularly deep learning with convolutional neural networks, can enhance the mapping of seasonal and temporary wetlands and floodplains using high-resolution remote sensing data. If successful, these improved mappings could be used to manage protected species and provide valuable information for decision-making in operations and planning.",
      "224": "The DHS OCHCO is using Text Analytics for Survey Responses (TASR) to analyze and extract important topics/themes from open-ended survey responses. These results are then used by DHS Leadership to improve employee satisfaction and meet their basic needs.",
      "31": "The main idea of the response is that machine learning was used to analyze a large amount of data, including over 20 million records of soils data and 20,000 text documents of ecological state and transition information, in order to create ecological site descriptions.",
      "433": "Machine learning is being used to predict veterans' suicidal thoughts after they leave the military. The prediction is based on data collected through a web-based survey that tracks veterans' experiences within the first three years of leaving military service.",
      "415": "The main idea of the response is that NASA SERVIR's GEOGloWS ECMWF Streamflow Service (GESS) uses machine learning techniques to bias correct historical flow data. The service serves as a platform for collaboration and engagement among different sectors to provide actionable water information. The application of Earth Observations (EO) has been a significant element in creating a system that forecasts flow on every river worldwide and provides a 40-year simulated historical flow.",
      "168": "The Provider Education 90 Day program aims to analyze the claim submission patterns of healthcare providers before and after their education. It uses Medicare Claims data, TPE data, and jurisdiction information to review and identify any statistical changes in their claim submissions. The output of the program is a comprehensive assessment of the providers' claim submission patterns.",
      "309": "Form Recognizer for Benefits Forms is a custom machine learning model that can extract data from complex forms and tag the data entries to field headers. By inputting a document or scanned image of the form, the model generates a JSON response that includes key/value pairs extracted using the custom trained model.",
      "153": "The main idea is that auto tagging is a process of suggesting content tags automatically by evaluating how existing content is tagged using machine-driven algorithms. This approach eliminates the need for manual tagging and allows for more efficient categorization of content.",
      "107": "The main idea of the response is that the team believes that artificial intelligence can be used to predict events by integrating data from test bed sensors and physics-based models. They also aim to develop a framework for future digital twins by integrating software, AI, and sensor data, and to train AI models on determining important attributes for intelligent autonomous control and cybersecurity in digital twins.",
      "80": "The response discusses the use of CNN (Convolutional Neural Network) to identify objects of a specific size in side scan imagery. By presenting users with a probability, the automation of contact picking in the field becomes possible. Side scan imagery, being a one-channel intensity image, is suitable for basic CNN techniques.",
      "275": "The National Landcover database (NLCD) uses artificial intelligence and machine learning to generate landcover data for all 50 states. This data is used by various users and federal agencies to estimate wildlife habitat, urban runoff, population growth, and other related factors.",
      "43": "The Market Diversification Toolkit is a tool that uses current trade patterns to identify potential new export markets for users. It applies a machine learning algorithm to compare and recommend markets that should be considered for further market research. Users can customize the tool's indicators and export the data for further analysis.",
      "293": "The main focus of this work is to develop expertise and resources for Explainable AI (XAI) in WMA PUMP Projects. The goal is to develop models that can predict stream temperature, discharge, dissolved oxygen, and other characteristics, and provide interpretable metrics that help understand the reasons behind the predictions and the physical processes captured by the models.",
      "406": "The main idea of the response is that Machine Learning for Peace Objective 1 is a part of the Illuminating New Solutions and Programmatic Innovations for Resilient Spaces (INSPIRES) initiative. It involves program activities and has a dedicated website for further information.",
      "116": "This response highlights the use of physics-based multi-scale modeling and AI techniques to speed up nuclear materials research and qualification. By applying AI to combinatorial-based materials research, the focus can be narrowed down to a smaller number of candidates with the desired properties.",
      "137": "The Solicitation Review Tool (SRT) uses SAM.gov data to compile a database of Information and Communications Technology (ICT) solicitations. It then applies machine learning algorithms, starting with a Natural Language Processing model, to determine if a solicitation contains compliance language. Agencies are asked to validate the SRT predictions, and random manual reviews are conducted by GSA monthly.",
      "248": "The Level 1 surveys obtained from BSEE provide information on the condition of well platforms, including the coating and structural condition. These reports are used to assess safety concerns and determine if additional audits are needed. An automated screening system that can identify areas with excessive corrosion could significantly speed up the report processing time.",
      "154": "The main idea of the response is that the speaker is suggesting the implementation of spelling corrections and reformatted search queries based on Google Analytics data.",
      "109": "The main idea of this project is to develop a framework for automated malware analysis using dynamic sandboxes. The framework aims to provide capabilities for analyzing industrial control system malware, outputting results in a machine-readable format, and sharing threat information. The ultimate goal is to enable further analysis through machine learning and facilitate timely and automated analysis of malware samples.",
      "321": "The main idea of the response is that there is a need for automatic processing of continuation of benefits forms in order to extract pre-defined selection boxes. This suggests that there is a desire to streamline the process of extracting specific information from these forms using automated methods.",
      "95": "The main ideas are that the project aims to address the efficient use of limited experimental data for training and demonstrating nuclear digital twins (NDTs). This involves developing sparse data reconstruction methods and using NDT models to determine the sensor requirements for demonstration experiments. The project also highlights the importance of leveraging sparse sensing and sparse learning for stronger prediction, diagnostics, and prognostics capabilities.",
      "382": "The response explains that the team at George Mason University collaborated with AVS employees to use Natural Language Processing (NLP) and Machine Learning to predict JASC codes from narrative descriptions in safety difficulty reports (SDR). This method can be used to verify the accuracy of SDR entries or assign codes when they are missing.",
      "425": "CuraPatient is a remote tool powered by AI that enables patients to effectively manage their health conditions without needing to visit a healthcare provider. The tool provides features such as health tracking, program enrollment, insurance management, and appointment scheduling.",
      "184": "The main idea of this response is that PubMed has developed a new relevance search algorithm called Best Match in order to help users find the most relevant papers in the rapidly growing field of biomedical literature. The algorithm uses machine-learning technology and user feedback to improve retrieval performance and provide an improved user experience.",
      "429": "The main idea is that Behavidence is a mental health tracking app specifically designed for veterans. The app analyzes the phone usage of veterans and compares it to a digital phenotype of individuals who have confirmed mental health conditions.",
      "173": "The BHW Community Need Analysis Platform is being developed to assess the healthcare needs of a population in primary care with behavioral health integration. It uses a machine learning-based automated clustering engine to analyze relevant datasets and provide dynamic assessments. The output of this tool will be used in the evaluation process for grant proposals for the Notice of Funding Opportunity (NOFO).",
      "222": "The Operations Center in CISA utilizes an artificial intelligence-powered dashboard to assist duty officers and analysts in understanding ongoing operational activities. This AI system combines real-time event data, historical cybersecurity information, and previous response activity to suggest appropriate actions and engagement strategies with other government entities and critical infrastructure owners based on potential impacts to national critical functions.",
      "253": "The main idea of this response is that a system is being developed to identify individual mountain lions using facial images. The system will use a convolutional neural network architecture and will help researchers mark and estimate the population of mountain lions.",
      "188": "The National Library of Medicine has developed NLM-Chem, an automatic tool for finding chemical names in biomedical literature. This tool aims to improve the efficiency of chemical indexing by replacing manual indexing by expert indexers. The tool has been tested on evaluation datasets and will be integrated into the production MEDLINE indexing pipeline.",
      "77": "The main idea of the response is that researchers are trying to detect and identify branded Steller sea lions from remote camera images in the western Aleutian Islands. The purpose of this is to make the photo processing more efficient and reduce the amount of effort needed to review the images.",
      "268": "The Fouling Identification Neural Network (FINN) is an end-to-end system that uses supervised learning to predict and detect sensor fouling at USGS stream gages. The system operates in real-time on Amazon Web Services, providing predictions every 30 minutes based on raw data from the USGS AQUARIUS database. The system produces values indicating the likelihood of current fouling and the likelihood of fouling occurring in the next 24 hours, and these values are displayed on a Tableau dashboard connected to AWS.",
      "278": "The Fish and Climate Change Database (FiCli) is a database that compiles peer-reviewed literature on the impact of climate change on inland fishes globally. The creators are looking to automate parts of the review process to make it more efficient in updating and maintaining the database.",
      "241": "Reclamation has conducted two year-long prize competitions to develop data-driven methods for predicting temperature and precipitation over a 2-6 week period in the western US. Participants in these competitions outperformed forecasts from NOAA, and Reclamation is now collaborating with Scripps Institute of Oceanography to refine and pilot the most promising methods. Improving sub-seasonal forecasts can have a significant impact on water management outcomes.",
      "46": "Passive acoustic analysis using machine learning is being used to detect and classify the signals emitted by beluga whales in Cook Inlet, AK. The results of this analysis are being used to understand the seasonal distribution, habitat use, and impact of human disturbance on these whales. The project also aims to expand its analysis to other cetacean species and anthropogenic noise.",
      "336": "The main idea of the response is that IMAGEN is an IT modernization product that will provide tools and services to improve the efficiency and consistency of disability determinations and decisions. It will transform text to data and leverage machine learning technologies to support other agency initiatives such as fraud prevention.",
      "201": "The main idea is that the ICAD system uses automated software called Matroid to analyze and annotate photographs taken by field imaging equipment. The software determines if the images contain human subjects and can also recognize objects, people, and events in any image or video stream. The goal is to expand the software's capabilities to include vehicles and subjects with long-arm rifles, while excluding items of little interest such as animals.",
      "79": "The response discusses the use of k-means clustering to identify consistent wave systems in terms of spatial and temporal aspects. This postprocessing technique has been evaluated and implemented into operations by NWS marine forecasters nationwide as of February 3, 2021.",
      "386": "The response describes a system that uses deep learning computer vision algorithms to analyze the particle size grading of crushed aggregate. It takes images of ballast cross sections as input and produces a ballast fouling index as output.",
      "162": "The main idea of this response is that Predictive Intelligence (PI) is used in the Quality Service Center (QSC) to assign incidents. The solution analyzes the short description provided by the end user and assigns the ticket to the appropriate assignment group based on previously submitted incidents. The solution is re-trained every 3-6 months with incident data.",
      "299": "The USGS National Earthquake Information Center has used deep learning to enhance their earthquake monitoring system. By training AI models to analyze waveform data, they have improved automatic earthquake detection and characterization. The models utilized a training dataset that combined the NEIC's earthquake catalog with archived waveform recordings, and were developed using Python, Keras, and Tensorflow.",
      "161": "The Feedback Analysis Solution (FAS) is a system that uses publicly available data to review and analyze public comments and other information from stakeholders. It utilizes Natural Language Processing (NLP) and machine learning (ML) tools to aggregate and sort comments, identify duplicates, and extract topics, themes, and sentiment from the dataset.",
      "23": "The response states that there are various courses available that focus on teaching software and scripting for machine learning in geospatial and remote sensing. These courses cover topics like change detection, using software packages like eCognition and Google Earth Engine, and utilizing Collect Earth Online.",
      "300": "The researchers developed ground-motion models for peak ground acceleration (PGA) and peak ground velocity (PGV) using a gradient boosting method. They found that the optimal model for predicting PGA and PGV uses four explanatory variables: M, Rjb, VS30, and Ztor. The reduction in total variability is primarily due to the inclusion of source parameters as explanatory variables.",
      "282": "The researchers are developing a machine learning model to predict the location of the salt front in the Delaware River Estuary. The model will use data on river discharge, tidal forcings, and meteorological data from various points in the estuary. The model will be compared with a process-based hydrodynamic model, COAWST, and is being built using tools from pyTorch.",
      "276": "ARIES is an international research project that uses semantics and machine reasoning to enable AI-assisted modeling of human-natural systems. It aims to create a seamless knowledge commons of scientific artifacts that can be easily accessed and utilized by humans and machines through the linked data paradigm and artificial intelligence. The project's software, k.LAB, supports the creation and maintenance of a distributed semantic web platform for storing and connecting scientific information.",
      "451": "This study focuses on using artificial intelligence models to enhance the clinical management of colorectal polyps. The models analyze video frames from colonoscopy videos to identify the presence of polyps and predict their likelihood of being cancerous.",
      "360": "The SMART system on OpenNet has integrated AI capabilities to perform various tasks such as entity extraction, sentiment analysis, keyword extraction, and historical data analysis. These capabilities are used to identify objects within cables, analyze the sentiment in cables, extract keywords related to topics in cables, and provide recommendations for addressees and passlines when composing cables.",
      "403": "The SBSE Issue Recommender has developed an AI-based recommender system that can detect potential non-compliance issues. This system improves the efficiency and scalability of training returns selection and field work processes.",
      "148": "The main idea of the response is that the virtual agent, named SAM, uses manual learning and natural language processing to understand customer needs and provide appropriate responses. It is part of the IAE FSD CCAI system.",
      "158": "The National Center for Health Statistics (NCHS) Data Linkage Program has incorporated the Sequential Coverage Algorithm (SCA) into their linkage programs. This supervised machine learning algorithm is used to create blocking groups or joining methods for large datasets, enhancing the efficiency of the blocking process.",
      "346": "The response explains the process of using a Natural Language Processing (NLP) model and Intelligent Character Recognition (ICR) to extract values from the JF-62 form for within grade increase payroll actions. After that, Robotic Process Automation (RPA) is used to validate the data, create a formatted file, and proceed with approval and processing.",
      "33": "The main idea of the response is that neural networks and AI technologies are being used to identify and detect no-changes in digital imagery for the NRI program. This suggests that advanced technologies are being utilized to analyze and monitor national resources.",
      "306": "The Complaint Lead Value Probability Threat Intake Processing System (TIPS) database employs artificial intelligence algorithms to efficiently identify and process actionable tips. By prioritizing immediate threats through AI triage, the system assists FBI field offices and law enforcement in responding to the most serious threats promptly. Tips with the highest algorithm score receive priority for human review.",
      "81": "The Institute for Telecommunication Sciences (ITS) is using AI, specifically a convolutional neural network (CNN), to automatically identify and classify clutter obstructed radio frequency propagation paths. Clutter refers to vegetation, buildings, and other structures that cause radio signal loss. The CNN is trained using lidar data and radio frequency propagation measurements, and can predict clutter classification labels for new radio path lidar data.",
      "220": "The use of advanced automation tools, such as Machine Learning and Natural Language Processing, is crucial for vulnerability analysts to process and aggregate data from various reporting channels. These tools improve the accuracy and relevance of the filtered information, making it easier for human analysts and decision-makers to analyze and make informed decisions. Additionally, Machine Learning techniques aid in aggregating information from databases like KEV and CVE for further analysis and presentation.",
      "290": "The study proposes a method called meta-transfer learning to predict water temperature dynamics in unmonitored lakes. Different model types, including process-based models, neural networks, and process-guided neural networks, were trained on well-observed lakes and used to make predictions in unobserved lakes. The results showed that process-guided deep learning models performed better in transferring knowledge than process-based and pure machine learning approaches.",
      "42": "The AD/CVD program investigates allegations of dumping and countervailing duties. Self-initiation allows the ITA to monitor trade patterns and start investigations before harmed US entities are even aware of the harm. This proactive approach helps identify and address potential offenses more efficiently.",
      "51": "FathomNet is a platform that offers training data for machine learning algorithms to analyze visual data. They have used interns and college class curriculums to annotate and localize imagery from NOAA videos, which helps in training their own algorithms.",
      "345": "ILMS has created an automated support desk assistant using ServiceNow Virtual Agent in order to make interactions with the support desk easier for customers and to reduce the workload of support desk agents by resolving simple issues. This system aims to streamline support desk operations and minimize costs.",
      "86": "The response describes an Enriched Citation Data dissemination system that can identify references or prior art cited in patent application office actions. The system can extract information from unstructured office actions and provide it through a structured API, including bibliographic information, cited claims, and relevant sections relied upon by the examiner.",
      "391": "The response states that PHMSA plans to use ChatGPT, an artificial intelligence system, to support the rulemaking processes. ChatGPT will be used to analyze the sentiment and relevance of comments on proposed rules, provide a synopsis of the comments, catalog them, and identify duplicate comments. This is expected to bring efficiency, reduce effort, and enable scalability in handling public scrutiny or interest in rulemaking.",
      "197": "The NIH Office of Portfolio Analysis has created a neural network method called word2vec OPA for analyzing scientific content. This approach converts words in scientific texts into numbers and summarizes documents based on their semantic meaning. The method is customizable for different types of scientific texts, such as grants and articles.",
      "424": "Automatic speech transcription engines are being used to analyze the cognitive decline of older VA patients by transcribing their digitally recorded speech responses using artificial intelligence-based technology. This eliminates the need for manual transcription of patient speech, making it easier to score neuropsychological tests.",
      "200": "The AI for autonomous situational awareness system aims to detect and track illicit cross-border traffic using IoT sensor kits in remote locations. It utilizes motion image/video systems enhanced with Artificial Intelligence to detect vehicles and determine their direction, with high-resolution cameras capturing images upon motion sensor triggers. The captured images are then processed by AI models to classify objects and provide imagery for re-identification, creating a low-cost and low-power system for covert detection and situational awareness.",
      "225": "RelativityOne is a document review platform that helps streamline the process of reviewing and producing large volumes of documents in various legal contexts, such as litigation and FOIA requests. It aims to improve efficiency and effectiveness in these tasks.",
      "123": "The research aims to develop a methodology that combines machine learning models, ion irradiation and creep testing techniques, and advanced characterization to understand the relationship between alloy composition, thermomechanical processing, microstructure, and swelling and creep behavior. The project aims to provide a rapid development process for in-core materials and important information on alloy design for optimized swelling and creep behavior for advanced reactor development.",
      "388": "Automated delay detection using voice processing is necessary to accurately track and account for delays in air traffic control (ATC) and aircraft interactions. The current reporting system lacks the ability to detect certain delay events like vectoring, and voice detection would enable automated detection of these events.",
      "348": "Conflict Forecasting CSO/AA is working on creating forecasting models to predict conflict outcomes such as interstate war, mass mobilization, and mass killings. These models utilize open-source data on political, social, and economic factors and employ statistical AI techniques like machine learning and clustering methods.",
      "274": "The main objective of this project is to use deep learning tools to extract and recognize terrain features. The focus is on developing techniques to detect and identify various characteristics of the terrain using advanced technology.",
      "91": "The main idea is that a multi-sensor data science system will be developed to analyze solvent extraction processes. The system will use non-traditional and traditional measurement sources, along with machine learning techniques, to discover signals and improve target metals recovery, identify process faults, account for special nuclear material, and make real-time decisions.",
      "164": "The Rapid Authority to Operate (ATO) System uses natural language processing (NLP) to analyze system security plans and identify commonly used technology components in Federal Information Security Management Act (FISMA) systems. This helps the Centers for Medicare and Medicaid Services (CMS) identify similar approaches to solving control areas within the Acceptable Risk Safeguards (ARS) and streamline the generation of system security plans for new systems.",
      "151": "The main idea of the response is that there is a feature or tool that automatically suggests or fills in queries as they are being typed. This suggests that the system or platform has some sort of predictive or auto-fill functionality to assist users in typing their queries more quickly or accurately.",
      "156": "The response states that MedCoder uses ICD-10 codes to match the cause of death descriptions provided on death certificates. This includes codes for both the underlying cause and contributing causes of death.",
      "384": "The Offshore Precipitation Capability (OPC) uses various data sources including weather radar, lightning networks, satellite, and numerical models to create a radar-like representation of precipitation. By applying machine learning techniques using extensive satellite and model data, OPC enhances the accuracy of identifying and predicting the location and intensity of precipitation areas.",
      "212": "The Cybersecurity and Infrastructure Security Agency (CISA) uses advanced analytics and forensic specialists to investigate cyber events in government departments and agencies, as well as other partners. These specialists use artificial intelligence tools to analyze data and detect anomalies and potential threats more efficiently.",
      "281": "The main idea of the response is that a system is being developed to predict specific conductance (SC) in inland stream reaches in the Delaware River Basin (DRB). The system will use watershed characteristics, land use, and meteorological data to make predictions in locations and time periods where data is not available. The model will be built using pyTorch on the USGS Tallgrass supercomputer.",
      "87": "The Inventor Search Assistant (iSAT) Service is designed to assist inventors in conducting a novelty search by providing them with relevant documents, figures, and classification codes based on a short description of their invention. The system generates a user-selectable list of recommended resources to help inventors get started with their research.",
      "171": "The Opioid Data Warehouse has developed a system called Term Identification and Novel Synthetic Opioid Detection and Evaluation Analytics. This system utilizes social media and forensic chemistry data to identify new references to drug products in social media text. It uses the FastText library to create vector models of known NSO-related terms, providing similarity scores and expected prevalence estimates for future data gathering efforts.",
      "455": "Artificial intelligence is being used to interpret eye images and assist in triaging eye patients in telehealth. By analyzing retina photos, it can assess health risks and improve the diagnosis of conditions like glaucoma, macular degeneration, and diabetic retinopathy.",
      "326": "The Expenditure Classification Autocoder is a custom machine learning model that is used to assign expense descriptions from survey respondents to specific expense categories known as item codes. This model helps automate the process of classification and categorization of expenses for analysis and reporting purposes.",
      "174": "The main idea is that AI and machine learning can be used to classify and categorize scientific concepts. This is done by using a text classification model and concept extraction on publications and grants abstracts, resulting in category labels and a list of concepts.",
      "4": "The main idea is the development of a system that can automatically detect and map host plants using ground-level imagery. The focus is on generating maps specifically for target trees using streetview images.",
      "445": "Artificial intelligence is being used to predict how veterans with irritable bowel disease will respond to thiopurines, using data from the Computerized Patient Record System (CPRS) and Corporate Data Warehouse (CDW). This technology aims to improve the treatment outcomes for these individuals.",
      "441": "The Medication Safety (MedSafe) Clinical Decision Support (CDS) system utilizes VA electronic clinical data to analyze the current clinical management of diabetes, hypertension, and chronic kidney disease. It then provides evidence-based recommendations to primary care providers based on patient-specific information such as comorbidities, laboratory test results, medications, and history of adverse drug events. The system uses knowledge bases and an automated execution engine to generate these patient-specific recommendations.",
      "192": "The Internal Referral Module (IRM) NLP module automatically refers grant applications to Program Officers based on an analysis of the applications' title, abstract, specific aims, and Public Health Relevance. This process has been highly accurate and has successfully eliminated the referral bottleneck.",
      "264": "This project aims to predict the thickness of the regolith layer in the Delaware River Basin by utilizing data collected from private well drillers. By training a Random Forest model, the researchers hope to create a data product that can be used to support groundwater and hydrologic modeling in the basin.",
      "269": "The researchers are using high frequency satellite images to estimate water depth in river channels. They are able to improve accuracy by averaging multiple scenes collected on the same day or within a couple of days. They have also developed a neural network regression approach for this purpose, using field measurements of water depth from five different rivers as training data. The method is implemented in MATLAB using the Deep Learning Toolbox.",
      "5": "The response discusses the process of standardizing cut flower business names for message set data using natural language processing. It explains that data is cleaned by removing punctuation to make it easier to match and then calculates cosine similarity to find similar terms, ultimately providing the results.",
      "209": "The RVSS Legacy Overhauled System Project (INVNT) has developed software called Video Computer Aided Detection (VCAD) that allows users to create and share vision detectors. These detectors are trained computer vision models that can recognize objects, people, and events in images or videos. The software provides various reports and alert notifications to help users identify important events and trends, and it also offers an API and language-specific clients for integration with other CBP applications.",
      "287": "The response states that a system is being developed to predict lake water temperature based on lake characteristics. The system will use lake temperature observations, meteorological data, and lake characteristics as training data to develop models using Python packages such as PyTorch on the USGS Tallgrass supercomputer.",
      "63": "The given response describes a machine learning product called First Guess Excessive Rainfall Outlook. This product is designed to provide a first estimate of excessive rainfall outlook based on atmospheric variables learned from the ERO (Excessive Rainfall Outlook). It specifically focuses on predicting excessive rainfall for the Day 4-7 time frame.",
      "206": "The use of third-party global trade data enhances investigations into targeted entities by providing additional information and network analysis on trade flows and associated risks. AI/ML models are utilized to manage the data and perform various functions to support the software's knowledge graph and user interface.",
      "108": "This project aims to develop a machine learning system that can effectively detect 5G attacks, including zero-day attacks. The system will have high classification speed and accuracy, and it will use field programmable gate array based deep autoencoders to address the vulnerability to zero-day attacks.",
      "272": "The response discusses a model that accurately classifies waterfowl behavior into 8 different life history states using GPS relocations and potentially habitat data. This tool can help waterfowl researchers and managers quickly assess and notify important events in real-time, improving outcomes and reducing costs.",
      "144": "The main idea of the response is that CALI is an automated machine learning tool that is used to evaluate vendor proposals against solicitation requirements in order to support the Source Selection process. It processes and analyzes documents in four key areas and allows evaluation members to review and submit evaluation results. CALI is currently being trained with sample data from the EULAs under the Multiple Award Schedule program.",
      "198": "The NIH developed a disambiguation solution to accurately link researchers to their grants and publications. They used a neural network model trained on ORCID identifiers to determine if author-publication pairs refer to the same person, considering factors such as institutional affiliation, co-authorship, and article-affiliated Medical Subject Heading terms.",
      "49": "The main idea of the response is that the use of VIAME for automated identification of reef fish is being fast-tracked. Image libraries are being compiled to create automated detection and classification models for the SEAMAP Reef Fish Video survey. The models are performing well, and automated analysis will be incorporated into the video reads in the spring as part of a supervised annotation process.",
      "298": "The response discusses the use of Artificial Neural Networks (ANNs) to enhance earthquake ground-motion models. The model utilizes data on location, magnitude, and local geological structure to estimate peak ground-motion from earthquakes. The model was built using Python, specifically Keras with TensorFlow.",
      "398": "The main idea of Large Partnership Compliance is to use a machine learning model to analyze partnership data and assess the risk of potential non-compliance. This model helps in categorizing and scoring the data based on the level of risk involved.",
      "402": "The IRS has developed a web app that uses a machine learning model to predict when procurement requests will become signed contracts. The tool provides valuable insight for the IRS and other federal agencies on when contracts are likely to be signed, potentially impacting $600 billion in government contracts.",
      "40": "The response mentions the implementation of a chatbot pilot embedded into trade.gov to assist clients with frequently asked questions, locating information, suggesting events and services. Clients would interact with the chatbot by asking questions or responding to prompts, and the chatbot would scan content libraries and input from staff to provide relevant answers and suggestions based on the client's persona.",
      "85": "The response states that an AI retrieval system is being used for trademark design coding and image search. The purpose of this system is to help examiners identify similar trademark images, suggest the correct assignment of design codes, and determine the potential acceptability of goods and services. The system is expected to use both incoming and registered trademark images to output design codes and related images.",
      "83": "The main idea of the response is that there is an AI system being developed to enhance patent search tools for examiners. This system can analyze published and unpublished applications and suggest additional areas to search for relevant documents, allowing users to sort the recommendations based on similarity to specific concepts.",
      "14": "The Comment Analysis pilot has demonstrated that a tool utilizing Natural Language Processing (NLP) can assist in the regulatory comment analysis process. The tools developed help reviewers identify comment topics and themes, as well as group similar comments together. These tools provide efficiency and cost savings for government agencies by streamlining the comment processing and reducing duplicated efforts.",
      "341": "A bot was developed to automate data entry in the Federal Procurement Data System (FPDS), reducing workload for procurement staff and improving compliance with DATA Act reporting. Another bot was developed to automate closeout reminders for federal assistance grants, and plans are underway to automate receiving report validation and customer service inbox monitoring.",
      "430": "The response states that there is an IRB-approved study that intends to use machine learning tools to predict the health outcomes of Veterans Affairs (VA) patients. The study will specifically focus on predicting Alzheimer's disease, rehospitalization, and Chlostridioides difficile infection.",
      "444": "A machine learning model is being utilized to forecast the progression of hepatitis C virus in veterans. This model aims to predict the course of the disease and potentially help in developing effective treatment plans.",
      "172": "The main ideas in this response are that an AI chatbot has been developed and deployed for HRSA EHBs (Electronic Handbooks) grantees. The chatbot allows grantees to communicate using natural conversational expressions and provides knowledge- and action-based responses. It is integrated with existing EHBs application UI and Salesforce for automated ticket creation, and has the ability to improve its responses over time.",
      "381": "The MARS program is working on developing a safety case for reducing separation standards between PBN routes in terminal airspace, which could help deconflict airports in high-demand areas. To build collision risk models, they need to identify rare events where aircraft fail to navigate procedures correctly, and prior work has used Machine Learning to filter incident data and identify similar events on departure procedures.",
      "262": "The project aims to use a large dataset of rapid habitat assessment data collected in the Chesapeake Bay Watershed to predict stream habitat conditions for unmeasured stream reaches in the region. The model can generate predictions for multiple aspects of physical habitat condition and can be updated quickly with new data.",
      "392": "The main idea of this response is to build and evaluate a multiple linear regression model to predict whether an inventory item will be received before or after the need by date. The goal is to determine the likelihood of receiving items on time in the future.",
      "280": "The main idea of the response is that species distribution models have been developed for 271 fluvial fish species in their native ranges in the conterminous United States. Boosted Regression Tree (BRT) models were used to predict the presence or absence of each species in stream segments based on landscape data and anthropogenic impacts. R Version 4.0.2 or newer with specific packages were used for modeling.",
      "70": "The main idea of the response is that BANTER is a machine learning acoustic event classifier. It uses a hierarchical random forest approach and is supervised in nature.",
      "439": "The study uses machine learning to create models that can predict the decision-making process of perfusionists during critical situations in cardiac surgery. The findings could potentially lead to the development of computerized tools that can enhance patient safety and improve surgical outcomes in the operating room.",
      "387": "The development of predictive analytics using Autonomous Track Geometry Measurement System (ATGMS) data involves using machine-learning processes to analyze, predict, and report track locations of concern. By leveraging track geometry measurements and exceptions, an inspection report is generated that includes the trending of track geometry measures and the time to failure, helping with maintenance and safety limits.",
      "279": "A collaboration between USGS, USFWS, and the University of Michigan is developing a machine learning model (MLM) that can analyze terabytes of hydroacoustic data on fish movement in restored coastal wetlands more efficiently. The model will identify, track, and quantify fish movement by reading sonar image files, converting them to a universal file format, and using TensorFlow-based convolutional neural networks for object detection. The model's output will provide valuable information for wetland managers and researchers in estimating fish habitat use and supporting the restoration of coastal wetland habitats.",
      "146": "The main idea is that the introduction of a chatbot will help the GSA FAS NCSC streamline customer experience and automate answering commonly asked questions. This will reduce the need for live chat agents and allow resources to be dedicated to other customer service initiatives, while still giving customers the option to connect with a live agent if they prefer.",
      "52": "The researchers propose using Artificial Neural Networks (ANN) to enhance the accuracy of Week 3-4 precipitation and temperature forecasts in the Climate Forecast System (CFS). By incorporating ANN into the forecasting model, they aim to improve the outlooks for these weather variables.",
      "106": "This research aims to improve the assessment of the security of machine learning and artificial intelligence systems through reverse engineering, exploitation, risk assessment, and vulnerability remediation. By addressing gaps in understanding and developing risk evaluation metrics, this research can contribute to better cybersecurity practices in the field of AI.",
      "450": "This study aimed to determine if deep learning recurrent neural network models using raw longitudinal data from electronic health records were more effective than conventional regression models in predicting the risk of hepatocellular carcinoma in patients with hepatitis C-related cirrhosis. The study analyzed data from patients in the national Veterans Health Administration with at least 3 years of follow-up after their cirrhosis diagnosis.",
      "405": "The University of California, Berkeley is creating a machine learning model to analyze gender differentiated credit scoring for Rappicard customers in Mexico. They aim to compare this model with Rappi's current method to evaluate if a gender differentiated approach can improve women's access to credit.",
      "99": "The response discusses the limitations of typical contingency analysis for power utilities and introduces a new approach using a machine learning framework and resilience-chaos plots. This new method reduces computational expense and can accurately discover n-2 contingencies by 50%.",
      "61": "The main idea of the response is that there is continued development and support for a multispectral aerial imaging payload that can run detection models in real-time. The goal is to reduce the amount of data and processing time, in order to expedite the analysis and population assessment for arctic mammals.",
      "7": "The main idea is that machine learning models can be trained to automatically read file attachments and extract information, such as form fields, to save it in an Excel format. This helps program managers who receive numerous PDF email attachments daily, as manually opening and copying the information is time-consuming. The use of artificial intelligence in document processing and information extraction enables automation in this task.",
      "186": "The National Institutes of Health (NIH) NLM has developed a machine-learning method to disambiguate author names in PubMed queries. The method uses agglomerative clustering to group papers belonging to the same authors, resulting in higher accuracy than other methods. This disambiguation method has been integrated into PubMed to improve author name searches.",
      "283": "The researchers developed a machine learning model called the recurrent graph convolutional network (RGCN) to predict water temperature in the Delaware River Basin. They trained the RGCN using predictions from a process-based model that predicts stream flow and temperature called the Precipitation Runoff Modeling System with the coupled Stream Network Temperature Model (PRMS-SNTemp).",
      "330": "The Rep Payee Misuse Model is a machine learning model that predicts the likelihood of representative payees misusing resources. It identifies cases that require further examination by a technician, potentially helping to prevent misuse of funds.",
      "232": "The I-485 Family Matching system uses artificial intelligence to match family members to their underlying I-485 petitions, which can be difficult due to limited available data. It aims to improve the reliability of matching by leveraging AI and can also help identify and group I-485s filed by family members and gather related forms for faster and more accurate processing.",
      "21": "TreeMap 2016 is a model that matches forest plot data to a grid, providing a detailed representation of the forests in the United States. It is being used in various sectors for projects such as fuel treatment planning and estimating carbon resources. The model utilizes a machine-learning algorithm and incorporates various predictor variables such as forest cover, height, topography, and disturbance history.",
      "213": "The main ideas in the response are that Advanced Network Anomaly Alerting Threat hunting and Security Operations Center (SOC) analysts receive large amounts of data from the National Cybersecurity Protection System's (NCPS) Einstein sensors. They use a combination of manual and automated techniques to detect network attacks and refine their alerts, leveraging mathematical and probabilistic models to ensure timely and accurate detection of anomalies.",
      "408": "The main idea of the response is that a social innovation lab for a machine vision program will be established in Morogoro, Tanzania, to address agricultural problems faced by farmers in the region. The project aims to develop experts who can use machine vision to solve problems related to disease detection, weed classification, pest detection, crop seedlings, and crop vigor estimation. This will contribute to the improvement of agricultural practices and help farmers mitigate problems and improve crop performance.",
      "250": "This software system uses wildlife camera trap images to classify them into different taxonomic classes based on the species present in each image. By developing AI systems that can accurately perform this task, it can reduce the costs and increase the volume of data for analysis. The system uses a convolutional neural network approach and is trained on the USGS Tallgrass supercomputer.",
      "118": "The main idea of the response is that the project developed a method to analyze radiation spectra using deep learning, which can overcome the weaknesses of existing spectroscopic techniques and enhance difficult measurements. The method was tested and operated on the International Space Station's supercomputer, demonstrating its performance in low-wattage computing situations and hazardous radiological environments.",
      "169": "The main idea is that ASSIST4Tobacco is a new tool that uses semantic indexing and artificial intelligence to search tobacco authorization applications. It utilizes a language model to understand relationships between words and concepts in the text, enabling more thorough search capabilities.",
      "259": "The RISE project aims to create a camera system that can be integrated into the USGS Water Mission Area's streamgage monitoring network. This system will not only capture images and videos, but also use AI/ML modeling techniques to generate time-series data of surface water levels from still camera images.",
      "181": "The response discusses the use of Support Vector Machines (SVM) in providing MeSH CheckTags to the NLM Medical Text Indexer (MTI) program. These CheckTags are a small set of MeSH Descriptors that indicate Species, Sex, and Age in MEDLINE articles. SVM machine learning algorithm is used to provide confidence scores for these CheckTags.",
      "104": "The main idea of this response is that the project aims to research and implement machine learning and artificial intelligence algorithms for signal decomposition in order to detect false data injection in physical processes. The project also aims to develop an advanced library that combines these algorithms with high-fidelity model comparisons for improved detection of malicious tampering.",
      "303": "The main idea of this response is that the researchers are testing a machine learning model called Generalized Phase Detection (GPD) to improve the earthquake catalog of the Southern California Seismic Network. The model uses seismic data from multiple stations to detect and pick the arrival times of P and S waves, which are then used to estimate earthquake locations, origin times, and magnitudes. The researchers are also developing a cloud-native software architecture to apply the GPD model in real-time using Amazon Web Services.",
      "84": "The given response discusses the use of AI in a CPC classification system. This system helps in categorizing patent applications based on the cooperative patent classification scheme, assigning work, and recommending symbols for AI search. Additionally, it mentions the use of a back-office processing system that takes incoming patent applications as input and provides classification symbols as output.",
      "317": "The DOL (Department of Labor) has implemented a chatbot assistant on their intranet websites to provide answers to common procurement questions and specific contract inquiries. This chatbot aims to assist employees in finding information quickly and efficiently.",
      "135": "The records management technology team is utilizing machine learning to forecast the retention schedule for records. This model will be integrated into a records management application to assist users in applying the appropriate retention schedules for new records.",
      "419": "The artificial intelligence coach in cardiac surgery helps identify misalignment in team members' mental models during complex healthcare tasks, particularly in safety-critical domains like aviation and healthcare. By identifying model misalignment, the coach can assist in improving teamwork and enhancing human cognition in the operating room.",
      "28": "The response propensity scores for the Census of Agriculture (COA) are calculated using random forest models that analyze historical data, control data, and other survey data. These scores aid in identifying the most effective methods for data collection.",
      "304": "The researchers used deep learning approaches to analyze the 2020-2021 earthquake sequence in southwestern Puerto Rico. They employed various deep learning models, such as EQTransformer, EikoNet, and HypoSVI, to detect earthquakes, determine their location, and understand the fault system and triggering mechanisms. These machine learning methods provided more data on small earthquakes and improved depth estimates, allowing for a better understanding of the active faults and physical processes involved.",
      "418": "The main idea of the response is that there is an artificial intelligence physical therapy app that serves as a support tool for physical therapy. The app is capable of analyzing data from wearable sensors and providing feedback to the physical therapist in a format that can be easily understood.",
      "73": "The response mentions the use of an LSTM model to forecast ONI values in the tropical Pacific up to one year in advance. There is also a plan to improve these forecasts by adding a CNN layer that utilizes reforecast data.",
      "368": "The main idea of the response is that topic modeling is a technique used to cluster text into themes based on the frequency of used words in documents. This technique has been applied to both digital media articles and social media posts, and it can be implemented using Python libraries.",
      "316": "The main idea is that inspectors can use Hololens AI to visually inspect high and unsafe areas without putting themselves in danger. This technology allows them to view and assess these areas from a safe location.",
      "202": "The Autonomous Aerostat Aerostat capability utilizes three tethers and advanced weather sensors to autonomously launch and recover aerostats based on weather conditions. This eliminates the need for on-site staff and allows for autonomous operation, saving time and manpower.",
      "32": "The Conservation Effects Assessment Project aims to determine the conservation benefits at the field level. It achieves this by utilizing farmer survey data, APEX modeling results, and environmental data to predict these benefits.",
      "175": "The response explains that there is a tool being developed that uses natural language processing to classify grant applications for review assignment purposes. This tool aims to streamline the process of categorizing grant applications based on their subject matter.",
      "252": "The USGS Amphibian and Reptile Monitoring Initiative (ARMI) aims to help reverse amphibian population declines by providing scientific information to managers. They are using acoustic monitoring of amphibian vocalizations, but the process of reviewing and identifying species vocalizations is time-consuming. To address this issue, they plan to develop convolutional neural networks (CNNs) that can classify species vocalizations in audio recordings, starting with bullfrog vocalizations as a prototype project. They will use the TensorFlow Python API and train the models on the USGS Tallgrass supercomputer.",
      "216": "The main idea of the response is that the Automated PII Detection and Human Review Process uses analytics and natural language processing to automatically detect potential personally identifiable information (PII) in submissions. If PII is flagged, it is reviewed by analysts who can confirm or deny its identification and redact it if necessary. The system learns from feedback and helps ensure compliance with privacy requirements.",
      "204": "The Autonomous Surveillance Towers by Anduril are equipped with artificial intelligence technology that allows them to detect, identify, and track items of interest without the need for a dedicated operator. These towers are easily deployable and can be relocated in less than a day by a small team. The system is solar-powered with battery backup and has a hybrid command and control capability accessible through various devices. The tower scans constantly, with the radar detecting and recognizing movement, and the camera slewing autonomously to the object of interest. The system alerts the user and tracks the object autonomously, providing near real-time photos that can be accessed through the User Interface.",
      "432": "The response discusses a model for precision medicine that can be used as a diagnostic and predictive tool for PTSD and suicidality. This model aims to interpret real-time inputs to anticipate episodes of PTSD and suicidality, provide early and accurate diagnosis, and gain a deeper understanding of the effects of stress on the onset of PTSD, particularly in extreme situations.",
      "240": "The Land Use Plan Document and Data Mining and Analysis R&D project aims to uncover patterns and conflicts in resource management planning rules by analyzing unstructured planning documents. The project's outputs help identify proposed action locations that require exclusion, restrictions, or stipulations based on the conflicts found in the planning documents.",
      "292": "The response discusses a process for predicting daily average stream temperature using meteorological drivers in the Delaware River Basin. The training data used are water temperature observations collected by the UGSS. The focus is on developing a custom loss function to account for the influence of groundwater on stream temperature by considering the phase lag and amplitude dampening effect of groundwater.",
      "132": "This response suggests using big data, artificial intelligence, and machine learning to analyze phasor measurement unit data in order to enhance grid operation and management. The goal is to identify and enhance existing knowledge while also discovering new insights and tools for improved efficiency.",
      "373": "The Text Similarity capability of GEC A&R identifies texts that are identical or very similar by calculating their cosine similarity. These texts are then grouped together based on their high cosine similarity and made available for analysts to review in more detail.",
      "227": "Systran's machine translation service, previously known as Language Translator, offers translation for over 100 language combinations. The Innovation Lab currently has licenses for translating various languages, including Chinese, Spanish, Arabic, and more, into English. Systran can translate plain text, word documents, and PDFs, and provides a web-based UI and API endpoint for easy access.",
      "194": "The Grants Analytics Portal is a tool that utilizes AI to provide HHS OIG staff with efficient access to grants data. It allows them to quickly find relevant findings, compare data between different divisions, identify trends, and assess potential anomalies in grantees.",
      "331": "The CDR (Continuing Disability Review) Model is based on machine learning and aims to identify disability cases that have a higher chance of medical improvement. It uses this information to flag these cases for a review to assess if the individuals still qualify for disability benefits.",
      "34": "The main idea of the response is that an Artificial Intelligence (AI) solution, which combines Robotic Process Automation with AI/ML models, is being used to address the issue of spam and marketing emails that appear in civil rights complaints email channels. The solution aims to automatically classify and remove these unwanted emails, as they make up a significant portion of incoming OASCR emails.",
      "367": "The main idea of the response is that Optical Character Recognition (OCR) can be used to extract text from images using standard Python libraries. The response also mentions that the inputs for this process have been websites, indicating that data can be collected from websites and the text can be extracted from images on those websites.",
      "89": "This project focuses on developing theories and algorithms for reducing scientific data in workflows. The reduction is driven by specific objectives and involves various models, including data-driven AI models.",
      "379": "The main idea of ROMIO is to assess the possibility of sending convective weather information to aircraft flying over the ocean and remote areas. This is achieved by using converted weather satellite data, lightning and weather prediction model data to identify areas of thunderstorm activity and cloud top heights. Artificial intelligence is also employed to enhance the accuracy of the output by comparing it with ground truth data from previous activity.",
      "434": "PredictMod is an artificial intelligence system that analyzes the gut microbiome to determine if it can make predictions about diabetes. It utilizes AI technology to identify possible correlations between the gut microbiome and the development of diabetes.",
      "383": "The AVS International office needs to comply with ICAO Standards and Recommended Practices (SARPs) and must find means of compliance evidence scattered across thousands of pages of documents. The Regulatory Compliance Mapping Tool (RCMT) processes these documents through Natural Language Processing (NLP) to extract the meaning of the text and uses a recommender system to establish matches between the SARPs and FAA text.",
      "291": "This study uses meteorological data to predict stream temperature in the Delaware River Basin. The researchers compare the performance of two deep learning models that incorporate process guidance through pretraining on process-based modelling outputs, in order to understand their limitations in accurately predicting stream temperature under changing climate and precipitation conditions.",
      "456": "The main idea is that national VHA administrative data is being used to develop tools that can predict the risk of esophageal adenocarcinoma using electronic health records.",
      "343": "The company A/LM plans to utilize the ILMS transactional data and planned transactions to create customized user experiences and analytics that cater to the specific needs of the users. By analyzing real system actions and clicks, they aim to gather valuable insights that can simplify user interactions and reduce the time taken to complete daily tasks.",
      "414": "In Indonesia, artificial intelligence (AI) technology will be utilized to create a forecasting model for tuberculosis (TB) drugs. This model aims to improve the accuracy of annual quantification exercises for the Ministry of Health (MoH) by integrating national data through the SatuSehat platform.",
      "366": "The main idea of the given response is to use k-means clustering to categorize countries into tiers based on data collected from open source and bureau sources. This approach allows for the grouping of countries based on similar characteristics or variables.",
      "347": "The response explains that the Bureau of Conflict and Stabilization Operations conducted a pilot project using a technology service called Sealr to verify the delivery of foreign assistance to conflict-affected areas where neither the U.S. Department of State nor their partner could access. Sealr utilizes blockchain encryption and artificial intelligence to secure and detect tampering of photographs taken on smartphones, making it a useful tool for remote monitoring of foreign assistance in dangerous or inaccessible areas.",
      "187": "The National Library of Medicine has developed an automatic tool called NLM-Gene to assist in the manual process of gene indexing in biomedical literature. The tool uses natural language processing and deep learning methods to find gene names. It has been tested on evaluation datasets and will be integrated into the MEDLINE indexing pipeline.",
      "145": "USAGov and USAGov en Espa\u00f1ol gather qualitative data from various sources such as survey comments, web searches, and call center chat transcripts. This data is classified by topic to identify areas that require product updates or enhancements.",
      "307": "The Office of Records Management Policy has developed an Intelligent Records Consolidation Tool that uses AI and Natural Language Processing to assess the similarity of records schedules. The tool generates clusters of similar items, reducing the time spent on manual review by the Records Manager. The tool also provides recommendations for schedule consolidation and can be applied to other domains that require text similarity analysis.",
      "16": "The Nutrition Education & Local Access Dashboard aims to provide a visual representation of FNS nutrition support at the county level, including nutrition education and local food access. The dashboard includes a clustering script that groups states based on various characteristics, enabling users to identify similar states for potential partnerships.",
      "58": "The main idea in this response is the development of NN (Neural Network) training software for the new generation of NCEP (National Centers for Environmental Prediction) models. The goal is to optimize the NCEP EMC (Environmental Modeling Center) Training and Validation System to effectively handle the high spatial resolution model data generated by these new operational models.",
      "277": "The researchers used both manual and machine learning methods to analyze a large amount of literature on global inland fisheries. Their goal was to understand the impact of human-driven environmental changes on these fisheries and develop a risk index to assess the level of stressors they face.",
      "305": "The DEA's Special Testing and Research Laboratory employs AI and machine learning techniques to classify the geographic origin of samples in their Heroin and Cocaine signature programs. They use statistical analysis tools to automatically detect anomalies and low confidence results.",
      "255": "The PROSPER modeling framework uses sparse streamflow observation data and hydroclimatic data to predict the annual probability of streamflow permanence at different resolutions. The models were developed using various tools and resources, including FCPGTools, R, and USGS HPC resources.",
      "320": "The main idea of the response is the automatic analysis of recorded calls made to Benefits Advisors in the DOL Interactive Voice Response (IVR) center. This analysis likely involves evaluating the content and quality of the calls to gain insights and improve the efficiency or effectiveness of the service provided by the Benefits Advisors.",
      "324": "The OEWS Occupation Autocoder is a tool that reads job titles in state submitted response files and assigns Standard Occupational Classification (SOC) codes along with their probabilities as recommendations for human coders. These codes above a certain threshold are then appended to the response files and sent back to states to assist with their SOC code assignment."
    }
  },
  "meta": {
    "cost": 0.786948,
    "tokens": 393474,
    "calls": 1658
  },
  "explainations": "{\"healthcare\":{\"0\":\"None\",\"1\":\"The theme \\\"healthcare\\\" is relevant in the given text because it mentions the Medicare Part D Subsidy Model. Medicare Part D is a government program that provides prescription drug coverage to eligible individuals, particularly senior citizens. The text states that machine learning is utilized to identify cases that may have incorrect Medicare Part D subsidies. This implies that the text is discussing a process or system related to healthcare and specifically to Medicare Part D subsidies. The mention of technicians reviewing the flagged cases further supports the relevance of the healthcare theme, as technicians would likely be involved in the healthcare industry.\",\"2\":\"None. The text does not mention healthcare or any related topics. It focuses on the use of social media listening and machine learning to analyze social media posts in Nigeria.\",\"3\":\"None\",\"4\":\"None\",\"5\":\"None\",\"6\":\"None\",\"7\":\"None\",\"8\":\"None\",\"9\":\"None\",\"10\":\"None\",\"11\":\"The theme \\\"healthcare\\\" is relevant in the given text. The text discusses researchers utilizing artificial intelligence to analyze brain imaging and electrophysiological data for identifying patterns of dementia. Additionally, it mentions investigating the potential of these imaging modalities as biomarkers for different types of dementia and epilepsy disorders, with the assistance of retrospective chart reviews conducted by the VA. This demonstrates the importance of healthcare in terms of diagnosing and understanding neurological disorders.\",\"12\":\"None\",\"13\":\"None\",\"14\":\"None\",\"15\":\"None\",\"16\":\"None\",\"17\":\"None\",\"18\":\"None\",\"19\":\"The theme \\\"healthcare\\\" is relevant in the given text. The text discusses the use of a machine learning model to evaluate treatment policies for patients with hepatitis C virus. This implies that the text is focused on healthcare and specifically addresses the management and treatment of individuals with this particular virus.\",\"20\":\"None\",\"21\":\"None\",\"22\":\"None\",\"23\":\"None\",\"24\":\"None\",\"25\":\"None\",\"26\":\"None\",\"27\":\"None\",\"28\":\"None\",\"29\":\"None\",\"30\":\"None\",\"31\":\"None\",\"32\":\"None\",\"33\":\"None\",\"34\":\"The text is relevant to the theme of healthcare. It discusses MetaMap, a program that allows access to the concepts in the unified medical language system (UMLS) Metathesaurus from biomedical text. This program uses natural language processing (NLP) to link the text of biomedical literature to the knowledge and synonymy relationships in the Metathesaurus. This technology is used in the healthcare field to improve the understanding and indexing of biomedical literature, which is crucial for research, diagnosis, and treatment.\",\"35\":\"None\",\"36\":\"None\",\"37\":\"None\",\"38\":\"None\",\"39\":\"None\",\"40\":\"The theme \\\"healthcare\\\" is relevant in the text above. The text discusses a study conducted on ulcerative colitis patients and their likelihood of achieving corticosteroid-free remission with the use of Vedolizumab. This indicates a focus on healthcare, specifically in terms of treatment options for ulcerative colitis. The study aims to predict the effectiveness of the medication and identifies the use of predictive models based on patient data. Therefore, the theme of healthcare is clearly present in the text.\",\"41\":\"None\",\"42\":\"The theme \\\"healthcare\\\" is relevant in the text above because it discusses how the National Institute of General Medical Sciences (NIGMS) has developed a method to automate the referral of grant applications. This automation process aims to streamline the grant assignment process, ultimately impacting the funding and support provided to healthcare-related projects. Additionally, the collaboration with the Electronic Records Administration group and the incorporation of this technique into the Internal Referral Module demonstrates the potential impact on the broader healthcare community, specifically the National Institutes of Health (NIH).\",\"43\":\"None\",\"44\":\"None\",\"45\":\"None\",\"46\":\"None\",\"47\":\"None\",\"48\":\"None\",\"49\":\"None\",\"50\":\"None\",\"51\":\"None\",\"52\":\"None\",\"53\":\"None. The text does not mention anything directly related to healthcare or any aspect of healthcare. It focuses on the development of a classifier using a Convolutional Neural Network (CNN) for article selection.\",\"54\":\"None\",\"55\":\"The theme \\\"healthcare\\\" is relevant in the text because it discusses how a tool can utilize electronic health records to predict various health outcomes such as suicide death, opioid overdose, and decompensated outcomes of chronic diseases. It highlights the use of technology and data analysis in healthcare to generate predictions and improve patient care.\",\"56\":\"None\",\"57\":\"None\",\"58\":\"None\",\"59\":\"The theme \\\"healthcare\\\" is relevant in the given text because it mentions the Priority Score Model, which is a system used in the healthcare industry. The model utilizes data such as Medicare Claims data to rank providers within the Fraud Prevention System (FPS), which is a healthcare-related system aimed at preventing fraudulent activities. Therefore, the text is relevant to the theme \\\"healthcare.\",\"60\":\"None\",\"61\":\"The theme \\\"healthcare\\\" is not relevant in the given text. The text primarily discusses the National Center for Health Statistics (NCHS) creating a model to detect item nonresponse in open-text survey data. It focuses on improving survey data and questionnaire design rather than healthcare-related topics. Therefore, the text is not relevant to the theme \\\"healthcare.\",\"62\":\"None\",\"63\":\"None\",\"64\":\"None\",\"65\":\"None\",\"66\":\"None\",\"67\":\"None\",\"68\":\"The theme \\\"healthcare\\\" is relevant in the given text because it discusses an AI system called Nediser that assists radiologists in analyzing X-ray properties. This technology is directly related to healthcare as it aims to improve the efficiency and accuracy of radiology diagnostics, ultimately benefiting patient care.\",\"69\":\"None\",\"70\":\"None\",\"71\":\"None\",\"72\":\"None\",\"73\":\"None\",\"74\":\"None\",\"75\":\"None\",\"76\":\"None\",\"77\":\"None\",\"78\":\"None\",\"79\":\"None. The text does not mention healthcare or any related concepts. It primarily focuses on the development of a machine learning-based system to detect attacks in 5G networks, with an emphasis on enhancing security for mission-critical applications such as automated vehicles, drones, and emergency response operations.\",\"80\":\"None\",\"81\":\"The theme of healthcare is relevant in the text because it discusses the use of machine learning in predicting the likelihood of treatment interruption among people living with HIV in Nigeria. This use of technology in healthcare aims to provide more intensive support to patients at high risk of interrupting treatment. Additionally, a qualitative assessment was conducted to understand healthcare workers' perception of machine learning and identify the additional support needed for incorporating it into their routine work.\",\"82\":\"None\",\"83\":\"None\",\"84\":\"None\",\"85\":\"None\",\"86\":\"None\",\"87\":\"None\",\"88\":\"The theme \\\"healthcare\\\" is relevant in the text because it discusses the use of machine learning to improve the treatment of peripheral artery disease (PAD) in patients. This technology is being used to analyze biomechanics data and identify specific gait signatures in PAD patients. It also evaluates the effectiveness of using limb acceleration measurements to model important biomechanics measures from PAD data. Thus, the text directly relates to healthcare and the application of technology in improving patient outcomes.\",\"89\":\"None\",\"90\":\"None\",\"91\":\"The theme \\\"healthcare\\\" is relevant in the given text. The text mentions the VA-DoE Suicide Exemplar project, which is focused on using artificial intelligence to enhance the VA's capacity to identify veterans who are at risk of suicide. This project falls within the scope of healthcare as it aims to address mental health issues and provide better support and care for veterans. Additionally, the project involves partnerships with the Department of Energy, indicating collaboration between healthcare and technology sectors to improve healthcare outcomes.\",\"92\":\"None\",\"93\":\"None\",\"94\":\"None\",\"95\":\"None\",\"96\":\"None\",\"97\":\"None\",\"98\":\"The theme \\\"healthcare\\\" is relevant in the given text. The text discusses the SoKat Suicide Ideation Engine (SSIE), a tool that utilizes natural language processing (NLP) to detect suicidal thoughts among veterans. This tool is specifically designed to improve mental health care for veterans by analyzing survey data collected by the Office of Mental Health Veteran Crisis Line support team. Therefore, the text highlights the relevance of healthcare in addressing mental health issues among veterans.\",\"99\":\"None\",\"100\":\"None\",\"101\":\"None\",\"102\":\"None\",\"103\":\"None\",\"104\":\"None\",\"105\":\"None\",\"106\":\"The theme \\\"healthcare\\\" is relevant in the text because it discusses the utilization of AI technology to create a model for distributing COVID-19 vaccines more efficiently. This demonstrates the application of healthcare technology in addressing the current pandemic. Additionally, the model prioritizes areas with high COVID-19 cases and pregnant\\/breastfeeding women, highlighting the importance of healthcare considerations in vaccine distribution.\",\"107\":\"None\",\"108\":\"None\",\"109\":\"The theme \\\"healthcare\\\" is relevant in the given text because the AICURE mobile application is designed to track and ensure adherence to prescribed medication in clinical or pharmaceutical drug studies. This application plays a role in healthcare by using artificial intelligence to monitor and analyze patient behavior, providing accurate data to sponsors. It ultimately contributes to improving patient care and the effectiveness of medication in healthcare settings.\",\"110\":\"None\",\"111\":\"None\",\"112\":\"None\",\"113\":\"None\",\"114\":\"The theme of healthcare is relevant in the given text. The text discusses a study that aims to predict hospitalization and corticosteroid use as indicators of irritable bowel disease (IBD) flare-ups. This study directly relates to healthcare as it focuses on understanding and predicting the occurrence of flare-ups in patients with IBD. The researchers utilized data from over 20,000 patients from the Veterans Health Administration, which further emphasizes the healthcare aspect of the study. Additionally, the use of random forest models to analyze longitudinal lab data and other factors highlights the application of healthcare analytics in predicting and managing IBD flare-ups.\",\"115\":\"The theme \\\"healthcare\\\" is relevant in the given text. The text mentions a research study that utilizes a randomized trial and artificial intelligence to detect colon polyps. This study has received approval from the VA (Veterans Affairs) and IRB (Institutional Review Board). This indicates the involvement of healthcare institutions and the significance of healthcare in conducting and approving such research studies.\",\"116\":\"None\",\"117\":\"None\",\"118\":\"The theme \\\"healthcare\\\" is not relevant in the text above. None of the information provided directly relates to healthcare or the delivery of healthcare services. Instead, the text focuses on the development of a machine learning system by the NIH Office of Portfolio Analysis that predicts the likelihood of a scientific paper being cited by a future clinical trial or guideline. The text primarily discusses the assessment and prediction of translational progress in biomedicine based on early reactions from the scientific community.\",\"119\":\"None\",\"120\":\"None\",\"121\":\"None\",\"122\":\"None\",\"123\":\"None\",\"124\":\"None\",\"125\":\"None\",\"126\":\"The theme \\\"healthcare\\\" is relevant in the text because it discusses how automated eye movement analysis using artificial intelligence can enhance diagnostic predictions for neurological diseases. This technology has the potential to improve the accuracy and quality of healthcare by screening for markers of conditions like traumatic brain injury, Parkinson's, and stroke.\",\"127\":\"The theme \\\"healthcare\\\" is relevant in the text because it discusses how artificial intelligence can be utilized by health professionals to assess lung function. It highlights the potential of AI in identifying predictors of normal and abnormal lung function, as well as sleep parameters, which can be crucial in healthcare settings. Therefore, the text is relevant to the theme of healthcare.\",\"128\":\"None\",\"129\":\"None\",\"130\":\"None\",\"131\":\"None\",\"132\":\"None\",\"133\":\"None\",\"134\":\"None\",\"135\":\"None\",\"136\":\"The theme \\\"healthcare\\\" is relevant in the text above as it discusses the use of machine learning to analyze patient data in order to predict surgery outcomes for Crohn's disease patients. This demonstrates the application of healthcare technology and data analysis to improve patient care and surgical decision-making.\",\"137\":\"The theme of healthcare is relevant in the given text. The text discusses an artificial intelligence-based deduplication algorithm that is specifically designed to identify duplicate reports in the FDA Adverse Event Reporting System (FAERS). The algorithm processes clinical data, extracts relevant features, and uses a probabilistic record linkage approach to score pairs of reports. The purpose of this algorithm is to aid in the identification of potential duplicate reports during the evaluation of case series for safety concerns. Therefore, the text directly relates to the healthcare theme as it focuses on improving the efficiency and accuracy of healthcare data analysis.\",\"138\":\"The theme \\\"healthcare\\\" is relevant in the text above. It talks about the use of machine learning algorithms in detecting seizures without human intervention. This application of technology in healthcare demonstrates how advancements in machine learning can contribute to improving medical diagnosis and patient care in the field of epilepsy monitoring.\",\"139\":\"None\",\"140\":\"None\",\"141\":\"None\",\"142\":\"None\",\"143\":\"None\",\"144\":\"None\",\"145\":\"None. The text does not mention healthcare or any related concepts. It focuses on the Pango nomenclature and how it is used to track the transmission and spread of SARS-CoV-2 and its variants.\",\"146\":\"None\",\"147\":\"None. The text does not mention healthcare at all. It focuses on the use of machine learning techniques to predict head kinematics in vehicle crashes and the likelihood of injury, but it does not address healthcare directly.\",\"148\":\"None\",\"149\":\"None\",\"150\":\"The theme of healthcare is not relevant in the given text. The text discusses the National Institutes of Health (NIH) developing a virtual assistant chat bot to assist users in finding grant-related information. The focus is on providing assistance in navigating grant information, not on healthcare.\",\"151\":\"None\",\"152\":\"None\",\"153\":\"None\",\"154\":\"None\",\"155\":\"None\",\"156\":\"The theme \\\"healthcare\\\" is not relevant in the given text. The text primarily discusses the use of AI in improving data accuracy, identity resolution, clinical decision support, discrepancy detection, and storage capabilities for machine learning and business intelligence applications. While these applications may have potential relevance in healthcare, the text does not specifically mention any healthcare context or provide any direct connection to healthcare-related issues or concerns. Therefore, the theme \\\"healthcare\\\" is None in this text.\",\"157\":\"None\",\"158\":\"None\",\"159\":\"None\",\"160\":\"None\",\"161\":\"None\",\"162\":\"None\",\"163\":\"None\",\"164\":\"None\",\"165\":\"None\",\"166\":\"None\",\"167\":\"None\",\"168\":\"The theme \\\"healthcare\\\" is relevant in the text above. The text discusses the use of custom natural language processing models to analyze physician's notes in the context of claims document processing. This implies that the analysis of healthcare-related information, particularly physician's notes, is being performed to ensure accuracy and quality in healthcare claims.\",\"169\":\"None\",\"170\":\"None\",\"171\":\"None\",\"172\":\"None\",\"173\":\"None\",\"174\":\"None\",\"175\":\"The theme \\\"healthcare\\\" is relevant in the text. The text discusses a project that aims to detect acute kidney injury (AKI) using artificial intelligence. This highlights the application of technology in healthcare to improve the detection and diagnosis of a specific medical condition. Additionally, the mention of collaborating with Google DeepMind indicates the involvement of a major technology company in the healthcare domain. Overall, the text emphasizes the relevance of healthcare and technology coming together to address the issue of acute kidney injury.\",\"176\":\"None\",\"177\":\"None\",\"178\":\"None\",\"179\":\"None\",\"180\":\"The theme \\\"healthcare\\\" is relevant in the text above. The researchers are using machine learning techniques to improve the detection and classification of protein electrophoresis text, which is a diagnostic tool commonly used in healthcare. They are collecting annotations through chart review to train the machine learning model, with the aim of improving specificity in identifying stroke risk and relevant prior text notes in patient records. Therefore, the text is relevant to the theme of healthcare.\",\"181\":\"None\",\"182\":\"None\",\"183\":\"None\",\"184\":\"None\",\"185\":\"None\",\"186\":\"None\",\"187\":\"None\",\"188\":\"None\",\"189\":\"None\",\"190\":\"None\",\"191\":\"None\",\"192\":\"None\",\"193\":\"None\",\"194\":\"None\",\"195\":\"None\",\"196\":\"None\",\"197\":\"None\",\"198\":\"None\",\"199\":\"None\",\"200\":\"None\",\"201\":\"None\",\"202\":\"None\",\"203\":\"None\",\"204\":\"None\",\"205\":\"None\",\"206\":\"None\",\"207\":\"None\",\"208\":\"None\",\"209\":\"None\",\"210\":\"None\",\"211\":\"None\",\"212\":\"None\",\"213\":\"None\",\"214\":\"None\",\"215\":\"None\",\"216\":\"None\",\"217\":\"None\",\"218\":\"None\",\"219\":\"None\",\"220\":\"None\",\"221\":\"None\",\"222\":\"None\",\"223\":\"The theme of healthcare is relevant in the given text. The text mentions the use of AI technology in Serbia to predict bed occupancy at hospitals. This application of AI technology in healthcare is directly related to the theme of healthcare. Additionally, the text mentions the focus on waiting list optimization for scheduled imaging diagnostics services as part of the national AI strategy, further highlighting the relevance of healthcare in the text.\",\"224\":\"The theme \\\"healthcare\\\" is relevant in the text provided. The text discusses the use of machine learning prediction models to evaluate risk factors for opioid use disorder (OUD) and overdose in Post-9\\/11 Veterans. This topic falls under the domain of healthcare as it pertains to the analysis and prediction of health-related outcomes, specifically related to opioid addiction and overdose.\",\"225\":\"The theme of \\\"healthcare\\\" is relevant in the given text because it discusses the COVID-19 Pandemic Vulnerability Index Dashboard, which is a tool designed to assess the vulnerability of different areas to the COVID-19 pandemic. This tool provides risk profiles for every county in the United States, allowing users to analyze and understand the disease risk in various areas. By providing this information, the tool aids in healthcare decision-making and resource allocation to combat the pandemic effectively.\",\"226\":\"The theme \\\"healthcare\\\" is relevant in the given text. The text discusses a pilot project that focuses on extracting family medical history data from patient records of African American Veterans aged 45-50. The goal of this project is to identify individuals who are at risk of prostate cancer but have not undergone screening for the disease. This shows a clear connection to healthcare as the project aims to improve the identification and screening of individuals at risk for a specific health condition.\",\"227\":\"None\",\"228\":\"None\",\"229\":\"None\",\"230\":\"None\",\"231\":\"None\",\"232\":\"None\",\"233\":\"None. The text does not mention healthcare or any related topics. It specifically discusses SingleCite, an algorithm for improving single citation search in PubMed.\",\"234\":\"None\",\"235\":\"None\",\"236\":\"The theme of healthcare is not directly relevant in the given text. The text primarily discusses the Conflict Observatory program, which utilizes AI and machine learning to analyze satellite imagery and document war crimes and abuses in Ukraine. The program's main focus is on conducting automated damage assessments of various buildings, including critical infrastructure, hospitals, schools, and crop storage facilities. While the mention of hospitals indicates the importance of healthcare infrastructure in conflict situations, the text does not provide any specific information or analysis related to healthcare. Therefore, the theme of healthcare is not directly relevant in this text.\",\"237\":\"None\",\"238\":\"None\",\"239\":\"None\",\"240\":\"None\",\"241\":\"None\",\"242\":\"None\",\"243\":\"The theme \\\"healthcare\\\" is not relevant in the given text. The text primarily focuses on the prioritization of alerts produced by the Fraud Prevention System based on various data inputs and machine learning algorithms. It does not mention any specific healthcare-related concerns or activities.\",\"244\":\"None\",\"245\":\"None\",\"246\":\"The theme \\\"healthcare\\\" is not relevant in the given text. This text primarily discusses the National Institute of General Medical Sciences' system called NIGMS ASSIST, which utilizes artificial intelligence and natural language processing to provide relevant data to program staff. Although this system may have applications in the healthcare field, the text does not explicitly mention any healthcare-related context or examples. Therefore, the theme \\\"healthcare\\\" is not relevant in this text.\",\"247\":\"None\",\"248\":\"The theme \\\"healthcare\\\" is relevant in the text because it discusses the Digital Command Center, a system designed to improve the performance of a medical center. The system aims to gather all data within the medical center and use predictive and prescriptive analytics to help leaders make better decisions and optimize the hospital's operations. This directly relates to the healthcare industry and the importance of utilizing technology and data analytics to improve healthcare outcomes.\",\"249\":\"The theme \\\"healthcare\\\" is relevant in the text above because it discusses a medical technology, the Medtronic GI Genius, which is used to assist in the detection of colon polyps. This technology aims to improve the accuracy and effectiveness of colonoscopy procedures, which are a crucial aspect of healthcare for the early detection and prevention of colon cancer. Therefore, the theme of healthcare is directly associated with the discussion of this medical device.\",\"250\":\"None\",\"251\":\"None\",\"252\":\"None\",\"253\":\"None\",\"254\":\"None\",\"255\":\"The theme of healthcare is relevant in the given text. The text specifically talks about the use of an AI tool to extract social determinants of health (SDOH) information from clinical notes. This information can be utilized in health-related analysis to understand if SDOH can play a role in disease risks or healthcare inequality. Therefore, the text directly relates to the healthcare field and the use of technology to gather important data for analysis.\",\"256\":\"None\",\"257\":\"None\",\"258\":\"None\",\"259\":\"None\",\"260\":\"None\",\"261\":\"None\",\"262\":\"None\",\"263\":\"None\",\"264\":\"None\",\"265\":\"The theme \\\"healthcare\\\" is not relevant in the given text. The text primarily focuses on the Quick Disability Determinations (QDD) process and how it uses a computer-based predictive model to identify cases for expedited processing by the Social Security Administration. The text does not mention any specific healthcare-related issues or medical conditions. Therefore, the theme of healthcare is not applicable in this context.\",\"266\":\"None\",\"267\":\"None. The text does not mention healthcare or any related topics. It focuses on the RPAB's responsibility for assigning program classifications to grant applications, specifically in the context of the NIAID.\",\"268\":\"None\",\"269\":\"None\",\"270\":\"None\",\"271\":\"None\",\"272\":\"None\",\"273\":\"None\",\"274\":\"The theme \\\"healthcare\\\" is relevant in the given text. The text discusses the use of machine learning to predict veterans' suicidal thoughts after they leave the military. This indicates a concern for the mental health and well-being of veterans and the need for healthcare interventions to address their potential struggles. Furthermore, the data collected through the web-based survey highlights the importance of healthcare professionals in monitoring veterans' experiences and providing necessary support during their transition period.\",\"275\":\"None\",\"276\":\"The theme \\\"healthcare\\\" is relevant in the given text. The text specifically mentions the Provider Education 90 Day program, which aims to analyze the claim submission patterns of healthcare providers. It utilizes Medicare Claims data, TPE data, and jurisdiction information to review and identify any statistical changes in their claim submissions. The purpose of this program is to assess and understand the healthcare providers' claim submission patterns, indicating a direct link to the theme of healthcare.\",\"277\":\"None\",\"278\":\"None\",\"279\":\"None\",\"280\":\"None\",\"281\":\"None\",\"282\":\"None\",\"283\":\"None\",\"284\":\"None\",\"285\":\"None\",\"286\":\"None\",\"287\":\"None\",\"288\":\"None\",\"289\":\"None\",\"290\":\"None\",\"291\":\"None\",\"292\":\"None\",\"293\":\"The theme of \\\"healthcare\\\" is relevant in the given text. The text describes CuraPatient, an AI-powered remote tool that allows patients to manage their health conditions without visiting a healthcare provider. This tool provides various healthcare-related features like health tracking, program enrollment, insurance management, and appointment scheduling. Therefore, it directly relates to the theme of healthcare by offering digital solutions for managing health and healthcare-related tasks.\",\"294\":\"The theme \\\"healthcare\\\" is not relevant in the given text. The text discusses the development of a new search algorithm called Best Match by PubMed to enhance the retrieval of relevant papers in the field of biomedical literature. Although the algorithm is utilized for healthcare-related research, the text itself does not directly discuss healthcare or its implications.\",\"295\":\"The theme \\\"healthcare\\\" is relevant in the text because it mentions a mental health tracking app designed for veterans. The app aims to analyze phone usage and compare it to a digital phenotype of individuals with confirmed mental health conditions. This indicates a focus on monitoring and addressing mental health issues within the veteran community, which falls under the healthcare domain.\",\"296\":\"The theme of healthcare is relevant in the given text. The text discusses the development of the BHW Community Need Analysis Platform, which aims to assess the healthcare needs of a population specifically in primary care with behavioral health integration. The platform utilizes a machine learning-based automated clustering engine to analyze relevant datasets and provide dynamic assessments. The output generated by this tool will then be used in the evaluation process for grant proposals related to the Notice of Funding Opportunity (NOFO). Therefore, the text clearly highlights the importance of healthcare and its relevance in addressing the needs of the target population.\",\"297\":\"None\",\"298\":\"None\",\"299\":\"None. The theme \\\"healthcare\\\" is not relevant in this text. The text primarily discusses the development of NLM-Chem, an automatic tool for finding chemical names in biomedical literature, and its aim to improve the efficiency of chemical indexing. There is no direct mention or connection to healthcare or healthcare services in the text.\",\"300\":\"None\",\"301\":\"None\",\"302\":\"None\",\"303\":\"None\",\"304\":\"None\",\"305\":\"None\",\"306\":\"None\",\"307\":\"None\",\"308\":\"None\",\"309\":\"None\",\"310\":\"None\",\"311\":\"None\",\"312\":\"None\",\"313\":\"None\",\"314\":\"None\",\"315\":\"None\",\"316\":\"The theme \\\"healthcare\\\" is relevant in this text. The text discusses the use of artificial intelligence models to improve the clinical management of colorectal polyps. It specifically mentions analyzing video frames from colonoscopy videos to detect polyps and predict their potential for being cancerous. This application of artificial intelligence in healthcare demonstrates the relevance of the theme \\\"healthcare\\\" in the text.\",\"317\":\"None\",\"318\":\"None\",\"319\":\"None\",\"320\":\"The theme of healthcare is not relevant in the given text. The text primarily focuses on the National Center for Health Statistics (NCHS) Data Linkage Program and its use of the Sequential Coverage Algorithm (SCA) to improve the efficiency of the blocking process for large datasets. There is no direct mention or connection to healthcare services or patient care in the text.\",\"321\":\"None\",\"322\":\"None\",\"323\":\"None\",\"324\":\"None\",\"325\":\"None\",\"326\":\"None\",\"327\":\"None\",\"328\":\"None\",\"329\":\"None\",\"330\":\"None\",\"331\":\"None\",\"332\":\"None\",\"333\":\"The theme \\\"healthcare\\\" is relevant in the given text. The text discusses the use of automatic speech transcription engines to analyze the cognitive decline of older VA patients. This application of technology in healthcare aims to transcribe the recorded speech responses of patients, thus eliminating the need for manual transcription. This advancement can make it easier to score neuropsychological tests, which are frequently used to assess cognitive health in healthcare settings. Therefore, the theme of \\\"healthcare\\\" is clearly relevant in this text.\",\"334\":\"None\",\"335\":\"None\",\"336\":\"None\",\"337\":\"None\",\"338\":\"None\",\"339\":\"None\",\"340\":\"None\",\"341\":\"The theme \\\"healthcare\\\" is not relevant in the given text. The text primarily discusses the Rapid Authority to Operate (ATO) System, which utilizes natural language processing (NLP) to analyze system security plans and identify commonly used technology components in Federal Information Security Management Act (FISMA) systems. It mentions how this system helps the Centers for Medicare and Medicaid Services (CMS) identify similar approaches to solving control areas within the Acceptable Risk Safeguards (ARS) and streamline the generation of system security plans for new systems. However, it does not directly relate to healthcare itself, but rather focuses on the management of information security in federal systems.\",\"342\":\"None\",\"343\":\"The theme \\\"healthcare\\\" is relevant in the given text. The text mentions the use of ICD-10 codes by MedCoder to match the cause of death descriptions provided on death certificates. This suggests that healthcare professionals or organizations, such as MedCoder, are involved in the process of accurately identifying and documenting causes of death.\",\"344\":\"None\",\"345\":\"None\",\"346\":\"None\",\"347\":\"None\",\"348\":\"The theme of healthcare is not relevant in the given text. The text primarily discusses the Opioid Data Warehouse's system called Term Identification and Novel Synthetic Opioid Detection and Evaluation Analytics, which focuses on utilizing social media and forensic chemistry data to identify new references to drug products in social media text. The system utilizes the FastText library to create vector models of known NSO-related terms, providing similarity scores and expected prevalence estimates for future data gathering efforts. Although the text relates to drug detection and analysis, it does not directly address healthcare as a theme.\",\"349\":\"The theme \\\"healthcare\\\" is relevant in the given text. The text discusses how artificial intelligence is utilized in healthcare to interpret eye images and assist in triaging eye patients through telehealth. By analyzing retina photos, AI can assess health risks and enhance the diagnosis of various eye conditions such as glaucoma, macular degeneration, and diabetic retinopathy.\",\"350\":\"None\",\"351\":\"None\",\"352\":\"None\",\"353\":\"The theme of healthcare is relevant in the given text. It discusses the use of artificial intelligence in predicting the response of veterans with irritable bowel disease to thiopurines. This technology is aimed at improving the treatment outcomes for these individuals, highlighting the relevance of healthcare in the text.\",\"354\":\"The theme of healthcare is relevant in the text because it discusses the Medication Safety (MedSafe) Clinical Decision Support (CDS) system which analyzes the clinical management of diabetes, hypertension, and chronic kidney disease. This system provides evidence-based recommendations to primary care providers based on patient-specific information such as comorbidities, laboratory test results, medications, and history of adverse drug events. This demonstrates how healthcare is being improved through the use of technology and data analysis.\",\"355\":\"The theme \\\"healthcare\\\" is not relevant in the given text. This text primarily discusses the Internal Referral Module (IRM) NLP module, which automatically refers grant applications to Program Officers based on an analysis of various factors such as the applications' title, abstract, specific aims, and Public Health Relevance. The text does not provide any information or discussion related to healthcare itself, its challenges, or any specific healthcare-related issues. Therefore, the theme \\\"healthcare\\\" is not relevant in this context.\",\"356\":\"None\",\"357\":\"None\",\"358\":\"None\",\"359\":\"None\",\"360\":\"None\",\"361\":\"None\",\"362\":\"None\",\"363\":\"None\",\"364\":\"None\",\"365\":\"None\",\"366\":\"The theme of healthcare is not relevant in the given text. The text primarily discusses the disambiguation solution developed by the NIH to accurately link researchers to their grants and publications. It focuses on the use of a neural network model trained on ORCID identifiers to determine if author-publication pairs refer to the same person, taking into account factors such as institutional affiliation, co-authorship, and article-affiliated Medical Subject Heading terms. While the text involves research and publications, it does not directly relate to healthcare or medical treatment.\",\"367\":\"None\",\"368\":\"None\",\"369\":\"None\",\"370\":\"None\",\"371\":\"None\",\"372\":\"None\",\"373\":\"None\",\"374\":\"None\",\"375\":\"None\",\"376\":\"The theme \\\"healthcare\\\" is relevant in the given text. The text discusses an IRB-approved study that aims to utilize machine learning tools to predict the health outcomes of Veterans Affairs (VA) patients. The study specifically focuses on predicting Alzheimer's disease, rehospitalization, and Chlostridioides difficile infection. This demonstrates the relevance of the healthcare theme as it highlights the application of advanced technology in healthcare settings to improve patient outcomes and address specific medical conditions.\",\"377\":\"The theme \\\"healthcare\\\" is relevant in the given text. This is because the text discusses the use of a machine learning model in predicting the progression of hepatitis C virus in veterans. This application of machine learning in healthcare demonstrates the relevance of the healthcare theme in the text.\",\"378\":\"None. The text does not mention healthcare or any related topics. It focuses on the development and deployment of an AI chatbot for HRSA EHBs grantees, which is unrelated to the theme of healthcare.\",\"379\":\"None\",\"380\":\"None\",\"381\":\"None\",\"382\":\"None\",\"383\":\"None\",\"384\":\"The theme \\\"healthcare\\\" is relevant in the text above. The text discusses the use of machine learning to predict the decision-making process of perfusionists during cardiac surgery. This has direct implications for healthcare as it can potentially lead to the development of computerized tools that can improve patient safety and surgical outcomes in the operating room.\",\"385\":\"None\",\"386\":\"None\",\"387\":\"None\",\"388\":\"None\",\"389\":\"None\",\"390\":\"The theme of healthcare is relevant in the text above. The text discusses a study that utilizes deep learning recurrent neural network models to predict the risk of hepatocellular carcinoma in patients with hepatitis C-related cirrhosis. The study analyzes data from patients in the national Veterans Health Administration, specifically focusing on electronic health records. Therefore, the text is directly related to the healthcare field and the prediction of risks associated with a specific disease.\",\"391\":\"None\",\"392\":\"None\",\"393\":\"None\",\"394\":\"None\",\"395\":\"The theme \\\"healthcare\\\" is not relevant in the given text. The text primarily discusses the National Institutes of Health (NIH) NLM's development of a machine-learning method to disambiguate author names in PubMed queries. It mentions the use of agglomerative clustering to group papers belonging to the same authors and how this method has been integrated into PubMed to improve author name searches. However, it does not directly relate to healthcare, patient care, medical treatments, or any other healthcare-related topics.\",\"396\":\"None\",\"397\":\"None\",\"398\":\"None\",\"399\":\"None\",\"400\":\"None\",\"401\":\"None\",\"402\":\"None\",\"403\":\"None\",\"404\":\"None\",\"405\":\"None\",\"406\":\"The theme \\\"healthcare\\\" is not relevant in the given text. This text primarily discusses the use of Support Vector Machines (SVM) and MeSH CheckTags in the NLM Medical Text Indexer (MTI) program. It focuses on machine learning algorithms and providing confidence scores for specific MeSH Descriptors in MEDLINE articles. Although the topic of MeSH Descriptors and MEDLINE articles can be related to healthcare, the text itself does not extensively discuss healthcare or its implications.\",\"407\":\"None\",\"408\":\"None\",\"409\":\"None\",\"410\":\"None\",\"411\":\"None\",\"412\":\"The theme \\\"healthcare\\\" is relevant in the given text as it specifically mentions complex healthcare tasks and the operating room. It highlights the use of an artificial intelligence coach in cardiac surgery to improve teamwork and enhance human cognition in healthcare settings. This indicates the importance of healthcare and the application of technology in improving healthcare outcomes.\",\"413\":\"None\",\"414\":\"None\",\"415\":\"The theme of healthcare is relevant in the given text. The text discusses an artificial intelligence physical therapy app that supports physical therapy. This app analyzes data from wearable sensors, which can be considered a healthcare technology. Additionally, the app provides feedback to the physical therapist, which can be beneficial in improving the quality of healthcare provided to the patients. Therefore, healthcare is relevant in this context.\",\"416\":\"None\",\"417\":\"None\",\"418\":\"None\",\"419\":\"None\",\"420\":\"None\",\"421\":\"None\",\"422\":\"None\",\"423\":\"None\",\"424\":\"None\",\"425\":\"The theme of healthcare is relevant in the text above. The text discusses a model for precision medicine that focuses on diagnosing and predicting PTSD and suicidality. This model aims to provide early and accurate diagnosis, which is a crucial aspect of healthcare. Additionally, the model seeks to gain a deeper understanding of the effects of stress on the onset of PTSD, which is also related to healthcare as it involves mental health and well-being.\",\"426\":\"None\",\"427\":\"None\",\"428\":\"None\",\"429\":\"None\",\"430\":\"None\",\"431\":\"None. The text does not mention healthcare or any related aspects. It focuses on a tool called the Grants Analytics Portal that is used by the HHS OIG staff to access grants data and analyze it for various purposes.\",\"432\":\"The theme \\\"healthcare\\\" is relevant in the text provided. The text discusses the CDR (Continuing Disability Review) Model, which utilizes machine learning to identify disability cases that have a higher likelihood of medical improvement. This model is used to flag such cases for a review to determine if the individuals still meet the criteria for disability benefits. Thus, the text directly pertains to the healthcare system's evaluation and assessment of individuals' health conditions and their eligibility for disability benefits.\",\"433\":\"None\",\"434\":\"None\",\"435\":\"None\",\"436\":\"None\",\"437\":\"The theme \\\"healthcare\\\" is relevant in the text because it discusses the application of artificial intelligence in analyzing the gut microbiome to make predictions about diabetes. This shows the connection between healthcare and the use of technology to better understand and potentially prevent or manage diseases.\",\"438\":\"None\",\"439\":\"None\",\"440\":\"The theme of healthcare is relevant in the text as it discusses the use of national VHA administrative data and electronic health records to develop tools for predicting the risk of esophageal adenocarcinoma. This shows the application of healthcare data and technology in improving the accuracy of risk assessment for a specific medical condition.\",\"441\":\"None\",\"442\":\"The theme \\\"healthcare\\\" is relevant in the given text. The text mentions the utilization of artificial intelligence technology in Indonesia to create a forecasting model for tuberculosis drugs. This initiative aims to improve the accuracy of annual quantification exercises for the Ministry of Health by integrating national data through the SatuSehat platform. This demonstrates the relevance of healthcare as the text discusses the use of technology and data integration to enhance the healthcare system specifically for tuberculosis treatment.\",\"443\":\"None\",\"444\":\"None\",\"445\":\"None. The theme \\\"healthcare\\\" is not relevant in the given text. The text discusses the development of a tool called NLM-Gene by the National Library of Medicine for gene indexing in biomedical literature. It mentions natural language processing and deep learning methods used by the tool, as well as its integration into the MEDLINE indexing pipeline. However, there is no direct mention or connection to healthcare or the provision of medical care services.\",\"446\":\"None\",\"447\":\"None\",\"448\":\"None\",\"449\":\"None\",\"450\":\"None\",\"451\":\"None\",\"452\":\"None\",\"453\":\"None\",\"454\":\"None\"},\"spatial\":{\"0\":\"The theme \\\"spatial\\\" is relevant in the text. The text mentions that a data-driven approach was used to create a prospectivity map for Clastic Dominated (CD) and Mississippi Valley Type (MVT) deposits in three countries. This approach involved loading the data into Uber's H3 cube, which is a spatial indexing system. Additionally, the models used in the approach, such as Weights of Evidence and Gradient-Boosting Machine models, are commonly used in spatial analysis. Therefore, the theme of spatial is relevant in this text.\",\"1\":\"None\",\"2\":\"None\",\"3\":\"None\",\"4\":\"None\",\"5\":\"None\",\"6\":\"None\",\"7\":\"None\",\"8\":\"The theme \\\"spatial\\\" is not relevant in the given text. The text primarily focuses on advancements in earthquake assessment and modeling using remote sensing and machine learning techniques. While the text mentions the improvement in prediction abilities and the production of images, maps, and products for post-earthquake assessment, it does not explicitly discuss the spatial aspects of these advancements. Thus, the theme \\\"spatial\\\" is not relevant in this context.\",\"9\":\"None\",\"10\":\"None\",\"11\":\"None\",\"12\":\"None\",\"13\":\"None\",\"14\":\"The theme \\\"spatial\\\" is relevant in the given text. The text mentions that the Coast Train dataset includes orthomosaic and satellite images of coastal, estuarine, and wetland environments. These images capture the spatial aspect of these areas, providing a visual representation of the physical layout and arrangement of the landscapes. Additionally, the dataset also includes thematic label masks, which further highlight the spatial characteristics of different features within these environments. The mention of over 1.2 billion labelled pixels representing more than 3.6 million hectares indicates the extensive spatial coverage of the dataset. Therefore, the theme of \\\"spatial\\\" is relevant in this text.\",\"15\":\"None\",\"16\":\"None\",\"17\":\"The theme \\\"spatial\\\" is relevant in the text above. This is evident through the mention of the Colorado River Basin, gridded meteorologic forcing data, and daily streamflow data. These elements indicate that the project involves analyzing and modeling hydrologic conditions in a specific geographic area. Additionally, the use of AWS, CHS, and USGS HPC systems suggests that spatial data and analysis are integral to the project's development and implementation.\",\"18\":\"None\",\"19\":\"None\",\"20\":\"None\",\"21\":\"None\",\"22\":\"The theme \\\"spatial\\\" is relevant in the given text. The text discusses the Coastal Change Analysis Program (C-CAP) and their use of geographic object-based image analysis and machine learning algorithms to classify coastal land cover from high-resolution imagery. This indicates that the analysis and classification of land cover are based on spatial data and the specific characteristics of the coastal areas. Additionally, the mention of using Landsat data and employing Classification and Regression Trees for data development in 2002 also relates to the spatial aspect of the analysis.\",\"23\":\"None\",\"24\":\"None\",\"25\":\"None\",\"26\":\"None\",\"27\":\"None\",\"28\":\"None\",\"29\":\"The theme \\\"spatial\\\" is relevant in the given text. The text mentions creating a database of spot elevations for summit locations in the contiguous United States. Spot elevations are specific points on a map that indicate the elevation above sea level. By extracting this information from historical topographic maps, the project aims to collect spatial data about the elevation of summit locations across the United States. Thus, the theme of \\\"spatial\\\" is relevant in this context.\",\"30\":\"None\",\"31\":\"None\",\"32\":\"The theme \\\"spatial\\\" is relevant in the text because the Water Mission Area Drought Prediction Project aims to create a method for predicting daily hydrologic drought in specific locations. The project will develop machine learning models calibrated on streamflow and meteorological data for these specific locations and then apply them to similar ungaged basins. This indicates that the project is concerned with the spatial aspect of drought prediction and the application of models across different geographic areas.\",\"33\":\"The theme \\\"spatial\\\" is relevant in the given text because it mentions the RMRS Raster Utility, a .NET library that specifically focuses on spatial modeling. The text states that this utility aims to streamline raster analysis, which involves analyzing and processing data in a grid format, commonly used in spatial analysis. Additionally, it mentions that the utility incorporates machine learning techniques, which can also be applied to spatial analysis tasks. Therefore, the theme of \\\"spatial\\\" is relevant in this text.\",\"34\":\"None\",\"35\":\"None\",\"36\":\"None\",\"37\":\"The theme \\\"spatial\\\" is not relevant in the given text. The text primarily focuses on the objectives of a project related to the detection and classification process of ice seals in aerial imagery. It discusses reducing false positive rates, maintaining high accuracy, and minimizing the need for post-survey review. However, it does not mention or involve any spatial elements or concepts.\",\"38\":\"None\",\"39\":\"The theme \\\"spatial\\\" is not relevant in the given text. The text primarily focuses on the goals of a project related to using timelapse images and creating a web-based platform for easy access and exploration of the images and data. The text does not mention anything related to spatial aspects or the physical arrangement of objects or locations.\",\"40\":\"None\",\"41\":\"None\",\"42\":\"None\",\"43\":\"None\",\"44\":\"The theme \\\"spatial\\\" is relevant in the text because NASA SERVIR is working on a project that involves utilizing satellite imagery to map informal settlements in major population centers. By using satellite imagery, they can analyze and visualize the spatial distribution of these settlements and assess their vulnerability. The project aims to enhance urban vulnerability assessment by understanding the spatial patterns and characteristics of these informal settlements. Therefore, the theme of spatiality plays a significant role in this text.\",\"45\":\"None\",\"46\":\"None\",\"47\":\"None\",\"48\":\"None\",\"49\":\"None\",\"50\":\"None\",\"51\":\"None\",\"52\":\"None\",\"53\":\"None\",\"54\":\"None\",\"55\":\"None\",\"56\":\"None\",\"57\":\"None\",\"58\":\"The theme \\\"spatial\\\" is relevant in the given text as it mentions the Ecosystem Management Decision Support System (EMDS), which operates within ArcGIS and QGIS. Both ArcGIS and QGIS are geographic information system (GIS) software that are specifically designed for spatial analysis and mapping. The use of these software indicates that the EMDS is focused on spatial data and analysis, emphasizing the spatial theme.\",\"59\":\"None\",\"60\":\"None\",\"61\":\"None\",\"62\":\"None\",\"63\":\"None\",\"64\":\"None\",\"65\":\"None\",\"66\":\"None\",\"67\":\"None\",\"68\":\"None\",\"69\":\"None\",\"70\":\"None\",\"71\":\"None\",\"72\":\"None\",\"73\":\"None\",\"74\":\"None\",\"75\":\"The theme \\\"spatial\\\" is relevant in the text because NOAA Coral Reef Watch uses remote sensing, modeling, and in situ data to gather information about coral reef ecosystems worldwide. This implies that they are concerned with the spatial distribution of coral reefs and how they are being affected by climate change and warming oceans. They provide early warnings and outlooks of stressful environmental conditions at targeted reef locations, indicating their focus on the spatial aspect of coral reef ecosystems.\",\"76\":\"None\",\"77\":\"None\",\"78\":\"None\",\"79\":\"None\",\"80\":\"None\",\"81\":\"None\",\"82\":\"None\",\"83\":\"None\",\"84\":\"The theme \\\"spatial\\\" is relevant in the text. The study discusses the application of machine learning and object-based image classification techniques to identify buildings, building loss, and defensible space in wildland-urban interface areas before and after a wildfire. By employing these methods, the study aims to map wildfire damage and assess the effectiveness of defensible space measures. The spatial aspect is central to this study as it involves analyzing the physical layout and arrangement of buildings and defensible spaces within the wildland-urban interface areas.\",\"85\":\"None\",\"86\":\"None\",\"87\":\"None\",\"88\":\"None\",\"89\":\"None\",\"90\":\"None\",\"91\":\"None\",\"92\":\"The theme of \\\"spatial\\\" is relevant in the text. The text mentions the use of satellite data and satellite imagery to analyze the long-term impacts of land-use and land-cover dynamics on surface water quality in Botswana's Limpopo River Basin. By using satellite data, the study will be able to determine the relationships between various factors such as land-use change, socioeconomic development indicators, climate change, and their effects on water quality and availability. Additionally, the study aims to develop empirical models for estimating water quality and mapping a water quality index, which involves analyzing and interpreting spatial data from in-situ measurements and satellite imagery.\",\"93\":\"None\",\"94\":\"None\",\"95\":\"None\",\"96\":\"None\",\"97\":\"None\",\"98\":\"None\",\"99\":\"None\",\"100\":\"The theme \\\"spatial\\\" is relevant in the text above. The text specifically talks about the detection and identification of aquatic weeds, which requires understanding their location and spatial distribution in aquatic environments. This indicates that spatial awareness is important in this context.\",\"101\":\"None\",\"102\":\"None\",\"103\":\"None\",\"104\":\"None\",\"105\":\"None\",\"106\":\"None\",\"107\":\"None\",\"108\":\"None\",\"109\":\"None\",\"110\":\"None\",\"111\":\"None\",\"112\":\"None\",\"113\":\"None\",\"114\":\"None\",\"115\":\"None\",\"116\":\"None\",\"117\":\"None\",\"118\":\"None\",\"119\":\"None\",\"120\":\"None\",\"121\":\"None\",\"122\":\"The theme \\\"spatial\\\" is not relevant in this text. The text primarily focuses on connecting data, developing models, and studying trout population dynamics, changes in fish catch, and the economic benefits of recreational fishing. There is no mention of spatial aspects such as location, distance, or physical arrangement, making the theme \\\"spatial\\\" not applicable in this context.\",\"123\":\"None\",\"124\":\"None\",\"125\":\"None\",\"126\":\"None\",\"127\":\"None\",\"128\":\"None\",\"129\":\"None\",\"130\":\"The theme \\\"spatial\\\" is relevant in the text above. The text mentions that the Landscape Change Monitoring System (LCMS) uses remote sensing to map and monitor changes in vegetation canopy cover, land cover, and land use. Remote sensing involves capturing data from a distance, usually through satellites or aircraft, and this data is typically spatial in nature, providing information about the location and distribution of features on the Earth's surface. The LCMS uses this spatial data to analyze temporal change classifications and identify areas of vegetation gain, loss, and changes in land cover and use. Therefore, the concept of space and spatial analysis is central to the functioning of the LCMS.\",\"131\":\"None\",\"132\":\"None\",\"133\":\"The theme \\\"spatial\\\" is relevant in the text because it discusses the use of satellite-based sensors to classify the type of crop or activity in each 30 square meter pixel on the ground. This implies that the text is discussing the spatial aspect of the cropland data and how it is being analyzed and classified based on its spatial location.\",\"134\":\"None\",\"135\":\"The theme \\\"spatial\\\" is relevant in the given text. The Seabird Studies Team conducted aerial surveys of the ocean off central and southern California, implying a focus on the spatial aspect of studying marine birds and mammals. Additionally, the team plans to generate maps of species distribution and abundance, further emphasizing the spatial theme as they analyze and interpret the data collected.\",\"136\":\"None\",\"137\":\"None\",\"138\":\"None\",\"139\":\"None\",\"140\":\"None\",\"141\":\"None\",\"142\":\"The theme \\\"spatial\\\" is relevant in the text above. The text discusses studying the distribution and ecology of green sea turtles in southern California, specifically in the La Jolla Cove area. This indicates that the researchers are interested in understanding the spatial aspects of where these turtles are located and how they move within this region. Additionally, the project involves collecting underwater images of the turtles, which implies an examination of their spatial presence and behavior underwater. The use of facial recognition software to identify individual turtles further highlights the spatial aspect of tracking and studying their movements. Therefore, the theme \\\"spatial\\\" is relevant in this text.\",\"143\":\"None\",\"144\":\"None\",\"145\":\"None\",\"146\":\"None\",\"147\":\"None\",\"148\":\"None\",\"149\":\"None\",\"150\":\"None\",\"151\":\"The theme \\\"spatial\\\" is relevant in the text above because it mentions the use of aerial imagery, which implies a connection to physical space. The project aims to automate the detection and classification of wildlife using AI, and this requires analyzing and understanding the spatial aspects of the aerial imagery. The algorithms need to identify and categorize wildlife based on their spatial location within the imagery. Additionally, the project also mentions the use of tools and databases to store annotated data and image metadata, which further emphasizes the spatial aspect of the project.\",\"152\":\"The theme \\\"spatial\\\" is relevant in the given text. The text mentions that the VOLCAT system uses AI-powered satellite applications to detect, track, and forecast hazardous volcanic events. This indicates that the system operates in a spatial context, utilizing satellite data to monitor and analyze volcanic activities occurring in different geographical locations. Additionally, the mention of volcanic ash as a major aviation hazard further emphasizes the spatial aspect, as it highlights the potential impact of the volcanic events on aviation routes and airspace.\",\"153\":\"The theme \\\"spatial\\\" is relevant in the given text. The text discusses the Village Monitoring System program, which utilizes AI and machine learning to analyze satellite imagery. This implies that the program is concerned with spatial data and the interpretation of patterns and anomalies in the imagery. The mention of \\\"moderate resolution commercial satellite imagery\\\" suggests that the program is working with spatial data at a certain level of detail. Therefore, the theme of space and spatial analysis is relevant to the text.\",\"154\":\"The theme \\\"spatial\\\" is relevant in the given text. The text mentions the use of machine learning models to map and monitor forest mortality and defoliation across the United States. In order to accomplish this, these models utilize training data from various sources and process the output into vector polygons. The concept of mapping and monitoring forest conditions involves spatial elements as it requires the representation and analysis of data within a specific geographic area. Therefore, the theme \\\"spatial\\\" is relevant in this text.\",\"155\":\"None\",\"156\":\"None\",\"157\":\"None\",\"158\":\"None\",\"159\":\"The theme \\\"spatial\\\" is relevant in the text as it discusses the study's objective of mapping benthic algae along the Buffalo National River in northern Arkansas. The use of orthophotos and multispectral images implies that the researchers are analyzing and interpreting spatial data to understand the distribution and density of benthic algae in the river. Additionally, the collection of field data to train a classification algorithm further emphasizes the spatial aspect of the study, as it involves gathering information from specific locations along the river to create a spatial model.\",\"160\":\"None\",\"161\":\"None\",\"162\":\"The theme \\\"spatial\\\" is not relevant in the given text. The text focuses on how artificial intelligence and machine learning can improve the analysis of high-resolution photogrammetric data obtained from unmanned aerial systems (UAS). It discusses the development of a standard reference protocol and the use of these technologies to unlock potential information in the data. The text does not mention anything related to spatial aspects or the physical arrangement of objects or places. Hence, the theme \\\"spatial\\\" is None in this context.\",\"163\":\"The theme \\\"spatial\\\" is relevant in the text. The text discusses using multispectral and thermal imagery to detect pre-symptomatic citrus trees infected with Huanglongbing (HLB). This implies that the detection process involves analyzing the spatial distribution of pixels in the imagery to identify the signature of HLB infection. By utilizing spatial information, the method can identify HLB before visible symptoms appear on the citrus trees.\",\"164\":\"The theme \\\"spatial\\\" is relevant in the text because it discusses the development of a system to predict flood flow metrics for stream reaches based on watershed characteristics. This implies that the system will consider the geographical and spatial aspects of the watershed to make accurate predictions. Additionally, the text mentions the use of gage data from the Delaware River Basin and the Colorado River Basin, which further emphasizes the spatial aspect of the analysis. The mention of \\\"ungaged reaches\\\" also suggests the consideration of different spatial locations within the river basins. Thus, the theme \\\"spatial\\\" is relevant in this text.\",\"165\":\"None\",\"166\":\"None\",\"167\":\"None\",\"168\":\"None\",\"169\":\"None\",\"170\":\"None\",\"171\":\"None\",\"172\":\"None\",\"173\":\"None\",\"174\":\"None\",\"175\":\"None\",\"176\":\"None\",\"177\":\"None\",\"178\":\"None\",\"179\":\"None\",\"180\":\"None\",\"181\":\"None\",\"182\":\"None\",\"183\":\"None\",\"184\":\"None\",\"185\":\"None\",\"186\":\"The theme \\\"spatial\\\" is relevant in the given text. The text discusses the use of geospatial imagery and annotation through Synthetic Aperture Radar (SAR) satellites. This technology allows for capturing images of any location on Earth, emphasizing the spatial aspect. The text also mentions the use of AI, including machine vision and object detection, to identify various objects in different spatial contexts, such as airframes, military vehicles, and marine vessels. Additionally, the mention of using this technology for disaster response missions further highlights the spatial relevance by detecting changes in specific locations.\",\"187\":\"None\",\"188\":\"None\",\"189\":\"None\",\"190\":\"None\",\"191\":\"None\",\"192\":\"None\",\"193\":\"None\",\"194\":\"None\",\"195\":\"None. The theme \\\"spatial\\\" is not relevant in this text. The text primarily focuses on the classification of walrus haulout camera trap images using codes and neural networks. It does not discuss or mention anything related to spatial aspects or locations.\",\"196\":\"None\",\"197\":\"None\",\"198\":\"None\",\"199\":\"The theme \\\"spatial\\\" is not relevant in the given text. The text primarily focuses on the activities and methods used by the NOAA Fisheries Alaska Fisheries Science Center's Marine Mammal Laboratory to monitor the western Steller sea lion population. It discusses the use of aerial surveys, manual counting methods, and the development of automated detection and image registration pipelines. The text does not directly address any spatial aspects such as location, distance, or physical arrangement. Therefore, the theme \\\"spatial\\\" is not relevant in this context.\",\"200\":\"None\",\"201\":\"None\",\"202\":\"None\",\"203\":\"None\",\"204\":\"None\",\"205\":\"None\",\"206\":\"None\",\"207\":\"None\",\"208\":\"The theme \\\"spatial\\\" is relevant in the text above. This is evident as the project's main ideas involve developing an image library of landed catch from optical survey data in the Gulf of Mexico, using machine learning and deep learning techniques to identify species from underwater imagery, and developing algorithms to process imagery in near real time. All of these activities require a focus on spatial aspects, such as the location of the catch, the underwater imagery, and the transfer of information to a central database.\",\"209\":\"The theme \\\"spatial\\\" is relevant in the text above. The text mentions the use of high throughput phenotyping techniques in citrus orchards to monitor the health of the orchard. This implies that the techniques involve locating, counting, and categorizing citrus trees, which requires an understanding of the spatial arrangement and distribution of the trees in the orchard. Therefore, the theme of \\\"spatial\\\" is relevant in this context.\",\"210\":\"The theme \\\"spatial\\\" is relevant in the given text. The text mentions the use of computer vision techniques for processing satellite imagery, which involves analyzing critical infrastructure and interdependency data. This implies that the data being processed has a spatial component as it is derived from satellite imagery. Additionally, the text mentions the use of unique geo-spatial datasets, further emphasizing the relevance of the spatial theme in the context of analyzing critical infrastructure and enhancing national security.\",\"211\":\"None\",\"212\":\"None\",\"213\":\"None\",\"214\":\"None\",\"215\":\"The theme \\\"spatial\\\" is relevant in the text above. The text discusses the application of machine learning to predict ground shaking during earthquakes based on initial observations from seismic stations in different locations. It mentions seismic data from Oklahoma, California, and Japan, indicating the spatial aspect of the subject. Additionally, it talks about the transition from running the codes on a desktop to a cloud computing platform, which also involves a spatial shift in terms of data processing and storage.\",\"216\":\"None\",\"217\":\"None\",\"218\":\"None\",\"219\":\"The theme \\\"spatial\\\" is relevant in the given text. It is evident from the use of phrases such as \\\"detailed land cover maps,\\\" \\\"aerial and satellite imagery,\\\" \\\"mapping a significant amount of land,\\\" and \\\"image service.\\\" These indicate that the text discusses the analysis and classification of land cover based on geographic or spatial data.\",\"220\":\"None\",\"221\":\"The theme of \\\"spatial\\\" is relevant in the given text. This is evident from the mention of using photogrammetric products to analyze and map cracks on Reclamation facilities. Photogrammetry is a technique used to measure and analyze the spatial properties of objects from photographs. Additionally, the text highlights the use of drones or other devices to carry out this spatial analysis, indicating the importance of spatial data collection. By implementing a standardized protocol and utilizing machine learning and AI, the collected spatial data will be used to make informed decisions about Reclamation assets. Therefore, the theme of \\\"spatial\\\" is relevant in this text.\",\"222\":\"None\",\"223\":\"None\",\"224\":\"None\",\"225\":\"The theme \\\"spatial\\\" is relevant in the given text because the COVID-19 Pandemic Vulnerability Index Dashboard provides risk profiles for every county in the United States. Counties represent different areas within the country, and by generating PVI scorecards and visualizing the overall disease risk based on the latest data, the tool allows users to assess the vulnerability of these different areas to the COVID-19 pandemic. The spatial aspect is crucial in understanding and comparing the vulnerability of various counties across the United States.\",\"226\":\"None\",\"227\":\"None\",\"228\":\"None\",\"229\":\"None\",\"230\":\"None\",\"231\":\"None\",\"232\":\"None\",\"233\":\"None\",\"234\":\"None\",\"235\":\"The theme \\\"spatial\\\" is relevant in the given text. The text discusses the use of satellite imagery to create a geospatial layer for understanding the changes in sub-surface drainage over time. This means analyzing the spatial distribution of tile drains and their impact on streamflow and water quality. The use of a UNet model trained on panchromatic images and python scripting further emphasizes the importance of spatial analysis in this context.\",\"236\":\"The theme \\\"spatial\\\" is relevant in the text as it discusses the use of satellite imagery by the Conflict Observatory program to analyze and document war crimes and abuses in Ukraine. By utilizing AI and machine learning, the program conducts automated damage assessments of various buildings, including critical infrastructure, hospitals, schools, and crop storage facilities. The analysis of satellite imagery and the assessment of different spatial locations are essential in understanding the extent of the damage and identifying areas affected by war crimes and abuses.\",\"237\":\"None\",\"238\":\"None\",\"239\":\"None\",\"240\":\"None\",\"241\":\"None\",\"242\":\"The theme \\\"spatial\\\" is relevant in the text above. This is because the text discusses the EcoCast, which is an operational tool that models the distribution of swordfish and bycatch species. By modeling their distribution, the tool considers the spatial aspect of where these species are located in the California Current. Additionally, the tool aims to reduce bycatch and support sustainable fisheries by providing dynamic ocean management, which involves considering the spatial patterns and movements of these species. Thus, the concept of spatiality is directly related to the topic discussed in the text.\",\"243\":\"None\",\"244\":\"The theme \\\"spatial\\\" is relevant in the given text. The text mentions the use of satellite imagery for the automated detection of hazardous low clouds. Satellite imagery is a spatial technology that allows for the observation and analysis of the Earth's surface from a distance. The mention of the NWS Aviation Weather Center and Weather Forecast Offices also suggests that spatial information and analysis are integral to their work in monitoring and forecasting weather conditions for transportation purposes. Therefore, the theme of \\\"spatial\\\" is relevant in this text.\",\"245\":\"None\",\"246\":\"None\",\"247\":\"None\",\"248\":\"None\",\"249\":\"None\",\"250\":\"None\",\"251\":\"None\",\"252\":\"None\",\"253\":\"None\",\"254\":\"The theme \\\"spatial\\\" is not relevant in the given text. The text primarily focuses on the use of artificial intelligence to predict harmful algae blooms in Lake Atitl\\u00e1n, Guatemala, and the collaboration between NASA SERVIR, National Geographic, and Microsoft. There is no mention or discussion of spatial concepts or the spatial relationships between objects or locations.\",\"255\":\"None\",\"256\":\"The theme \\\"spatial\\\" is relevant in the text because it discusses the use of a neural network to accurately map soil vs. rock-covered areas. This involves analyzing the spatial distribution of these areas in land cover classification. The researchers are specifically using a dataset from the Sierra Nevada Mountains to train and test the neural network, which further emphasizes the relevance of the spatial theme in understanding the geographical distribution of soil and rock-covered areas.\",\"257\":\"None\",\"258\":\"None\",\"259\":\"None\",\"260\":\"None\",\"261\":\"None\",\"262\":\"None\",\"263\":\"The theme \\\"spatial\\\" is relevant in the given text. This can be seen through the mention of different areas, which implies a spatial context. The research is focused on identifying surface water in these areas using artificial neural networks trained with annotated hydrography data. Additionally, the input training data includes various types of remotely sensed data, which further emphasizes the spatial aspect by capturing information from different locations. The use of open-source tools in a high-performance computing environment also suggests a spatial focus as these tools are likely used to analyze and process large spatial datasets. Therefore, spatial analysis and understanding are important aspects of the research described in the text.\",\"264\":\"None\",\"265\":\"None\",\"266\":\"The theme \\\"spatial\\\" is relevant in the given text. This is because the text discusses a deep neural network called DeepCNet that is capable of identifying and classifying various features related to railroad tracks based on their spatial characteristics. The network is used for \\\"change detection\\\" applications, where it can detect and notify any changes in the track's status or between different inspections based on geolocation, which again emphasizes the importance of spatial information in the context of the text.\",\"267\":\"None\",\"268\":\"None\",\"269\":\"None\",\"270\":\"None\",\"271\":\"The theme \\\"spatial\\\" is relevant in the text. The text discusses the use of high-resolution remote sensing data and machine learning techniques to enhance the mapping of wetlands and floodplains. By using these advancements, the goal is to create improved mappings that can be used for managing protected species and decision-making in operations and planning. The focus on mapping and spatial data highlights the relevance of the theme \\\"spatial\\\" in this text.\",\"272\":\"None\",\"273\":\"None\",\"274\":\"None\",\"275\":\"The theme \\\"spatial\\\" is not relevant in the given text. This text primarily focuses on the use of machine learning techniques and Earth Observations (EO) to bias correct historical flow data and forecast flow on every river worldwide. While the text mentions the global coverage of the system, it does not discuss spatial relationships or the physical arrangement of objects or places. Therefore, the theme \\\"spatial\\\" is None.\",\"276\":\"None\",\"277\":\"None\",\"278\":\"None\",\"279\":\"None\",\"280\":\"None\",\"281\":\"The theme \\\"spatial\\\" is relevant in the given text. The text discusses the National Landcover database (NLCD), which utilizes artificial intelligence and machine learning to generate landcover data for all 50 states. This data is used by various users and federal agencies to estimate wildlife habitat, urban runoff, population growth, and other related factors. The concept of spatial refers to the organization and arrangement of physical entities in a particular area or space. In this case, the NLCD's landcover data provides information about the spatial distribution of different land types, which is crucial for analyzing and understanding wildlife habitats, urban development, and population growth patterns.\",\"282\":\"None\",\"283\":\"None\",\"284\":\"None. The theme \\\"spatial\\\" is not relevant in the given text. The text mainly discusses the Machine Learning for Peace Objective 1 and its relation to the INSPIRES initiative, program activities, and a dedicated website. There is no mention of any spatial aspects or connections to physical locations or spaces.\",\"285\":\"None\",\"286\":\"None\",\"287\":\"None\",\"288\":\"None\",\"289\":\"None\",\"290\":\"None\",\"291\":\"None\",\"292\":\"None\",\"293\":\"None\",\"294\":\"None\",\"295\":\"None\",\"296\":\"None\",\"297\":\"None\",\"298\":\"None\",\"299\":\"None\",\"300\":\"The theme \\\"spatial\\\" is not relevant in the given text. The text focuses on the main idea of researchers trying to detect and identify branded Steller sea lions from remote camera images. It discusses the purpose of this activity, which is to make the photo processing more efficient and reduce effort. However, there is no mention or connection to any spatial aspects or themes in the text. Hence, the relevance to the theme \\\"spatial\\\" is None.\",\"301\":\"None\",\"302\":\"None\",\"303\":\"None\",\"304\":\"The theme \\\"spatial\\\" is relevant in the text. The text discusses the use of passive acoustic analysis and machine learning to detect and classify the signals emitted by beluga whales in Cook Inlet, AK. By analyzing the signals, the project aims to understand the seasonal distribution and habitat use of these whales. This implies a focus on the spatial aspect of the whales' behavior and their interaction with their environment. Additionally, the project also intends to expand its analysis to other cetacean species and anthropogenic noise, suggesting a broader spatial scope in studying the impact of human disturbance on marine mammals.\",\"305\":\"None\",\"306\":\"The theme \\\"spatial\\\" is not relevant in the given text. The text primarily focuses on the ICAD system and its automated software called Matroid, which analyzes and annotates photographs. The text mentions the software's ability to recognize objects, people, and events in images or videos. It also discusses the goal of expanding the software's capabilities to include vehicles and subjects with long-arm rifles while excluding animals. However, the text does not provide any information or discussion related to the spatial aspect or location of these objects, events, or subjects. Thus, the theme \\\"spatial\\\" is not applicable in this context.\",\"307\":\"The theme \\\"spatial\\\" is relevant in the given text. The text mentions the use of k-means clustering to identify consistent wave systems in terms of spatial and temporal aspects. This implies that the analysis is being conducted to understand the spatial distribution of wave systems. Additionally, the fact that this technique has been implemented by NWS marine forecasters nationwide further emphasizes the relevance of the spatial aspect in the text.\",\"308\":\"None\",\"309\":\"None\",\"310\":\"None\",\"311\":\"None\",\"312\":\"The theme \\\"spatial\\\" is relevant in the given text. The text mentions courses that focus on teaching software and scripting for machine learning in geospatial and remote sensing. It talks about topics such as change detection, using software packages like eCognition and Google Earth Engine, and utilizing Collect Earth Online. All of these references indicate a connection to spatial analysis and the use of spatial data.\",\"313\":\"The theme \\\"spatial\\\" is not relevant in the given text. The text primarily focuses on the development of ground-motion models and the inclusion of certain explanatory variables to predict peak ground acceleration (PGA) and peak ground velocity (PGV). It does not discuss any spatial aspects or concepts related to the physical space or location. Therefore, the theme of \\\"spatial\\\" is not applicable here.\",\"314\":\"The theme \\\"spatial\\\" is relevant in the text because it discusses the prediction of the location of the salt front in the Delaware River Estuary. The researchers are using data from various points in the estuary, such as river discharge, tidal forcings, and meteorological data, to develop a machine learning model. They are also comparing their model with a process-based hydrodynamic model, COAWST. The use of different data points and the comparison of models indicate the importance of spatial analysis in this research.\",\"315\":\"None\",\"316\":\"None\",\"317\":\"None\",\"318\":\"None\",\"319\":\"None\",\"320\":\"None\",\"321\":\"None\",\"322\":\"None\",\"323\":\"None\",\"324\":\"The theme \\\"spatial\\\" is relevant in the given text. This is because the text discusses the use of AI, specifically a convolutional neural network (CNN), to identify and classify clutter obstructed radio frequency propagation paths. Clutter in this context refers to vegetation, buildings, and other structures that cause radio signal loss. The CNN is trained using lidar data, which is a remote sensing method that measures distances to objects using laser light, and radio frequency propagation measurements. Therefore, the spatial aspect of the data is crucial in understanding and predicting clutter classification labels for new radio path lidar data.\",\"325\":\"None\",\"326\":\"None\",\"327\":\"None\",\"328\":\"None\",\"329\":\"None\",\"330\":\"None\",\"331\":\"None\",\"332\":\"None\",\"333\":\"None\",\"334\":\"None\",\"335\":\"None\",\"336\":\"None\",\"337\":\"None\",\"338\":\"None\",\"339\":\"The theme \\\"spatial\\\" is relevant in the given text. The text discusses using deep learning tools to extract and recognize terrain features, which implies a focus on analyzing and understanding the spatial aspects of the terrain. By developing techniques to detect and identify various characteristics of the terrain, the text emphasizes the importance of spatial understanding and analysis.\",\"340\":\"None\",\"341\":\"None\",\"342\":\"None\",\"343\":\"None\",\"344\":\"The theme \\\"spatial\\\" is relevant in the text above. This is because the Offshore Precipitation Capability (OPC) focuses on using various data sources to create a radar-like representation of precipitation. This radar-like representation helps in identifying and predicting the location and intensity of precipitation areas. The use of data from weather radar, lightning networks, satellite, and numerical models emphasizes the importance of spatial analysis and understanding the spatial distribution of precipitation. Therefore, the theme \\\"spatial\\\" is relevant in this text.\",\"345\":\"None\",\"346\":\"The theme \\\"spatial\\\" is relevant in the given text. The text discusses the development of a system to predict specific conductance (SC) in inland stream reaches in the Delaware River Basin (DRB). This indicates that the focus is on understanding and predicting the spatial variations of specific conductance in different locations within the DRB. The system will utilize various spatial factors such as watershed characteristics, land use, and meteorological data to make predictions in areas where data is currently not available. Additionally, the mention of using pyTorch on the USGS Tallgrass supercomputer indicates the computational aspect of analyzing spatial data. Therefore, the theme of \\\"spatial\\\" is relevant in this text.\",\"347\":\"None\",\"348\":\"None\",\"349\":\"None\",\"350\":\"None\",\"351\":\"None\",\"352\":\"The theme \\\"spatial\\\" is relevant in the given text. The text discusses the development of a system that can automatically detect and map host plants using ground-level imagery. This implies a focus on analyzing and understanding the spatial aspects of the environment in order to identify and map the target trees accurately. Additionally, the use of streetview images also suggests the consideration of spatial information to generate maps. Therefore, the theme of \\\"spatial\\\" is relevant in this text.\",\"353\":\"None\",\"354\":\"None\",\"355\":\"None\",\"356\":\"None\",\"357\":\"The theme \\\"spatial\\\" is relevant in the given text. This is because the text discusses the use of high frequency satellite images to estimate water depth in river channels. The researchers are utilizing spatial data provided by satellite images to understand the spatial distribution of water depth in rivers. Additionally, the text mentions the use of field measurements from five different rivers as training data, which further emphasizes the spatial aspect of the research.\",\"358\":\"None\",\"359\":\"None\",\"360\":\"None\",\"361\":\"None\",\"362\":\"None\",\"363\":\"None\",\"364\":\"The theme \\\"spatial\\\" is relevant in the given text. The text mentions the use of GPS relocations to accurately classify waterfowl behavior. GPS relocations involve tracking the spatial movements of the waterfowl, which is directly related to the theme of \\\"spatial.\\\" Additionally, the text also suggests the potential use of habitat data, which further emphasizes the importance of spatial information in understanding and managing waterfowl behavior.\",\"365\":\"None\",\"366\":\"None\",\"367\":\"None\",\"368\":\"The theme \\\"spatial\\\" is relevant in the given text. The text discusses the use of Artificial Neural Networks (ANNs) to enhance earthquake ground-motion models. These models utilize data on location, magnitude, and local geological structure to estimate peak ground-motion from earthquakes. The use of spatial data, such as location and local geological structure, is crucial in developing accurate ground-motion models. Additionally, the mention of Python and TensorFlow implies that spatial data processing and analysis might have been involved in building the model.\",\"369\":\"None\",\"370\":\"None\",\"371\":\"None\",\"372\":\"None\",\"373\":\"None\",\"374\":\"None\",\"375\":\"None\",\"376\":\"None\",\"377\":\"None\",\"378\":\"None\",\"379\":\"None\",\"380\":\"The theme \\\"spatial\\\" is relevant in this text because it discusses using a large dataset to predict stream habitat conditions in the Chesapeake Bay Watershed. The use of spatial data is important in understanding the physical habitat condition of different stream reaches in the region. By analyzing the dataset, the model can generate predictions for multiple aspects of the physical habitat condition, which implies a spatial understanding of the area. Additionally, the ability to update the model quickly with new data suggests a continuous monitoring of the spatial changes in stream habitat conditions.\",\"381\":\"None\",\"382\":\"The theme \\\"spatial\\\" is relevant in the text above. This is because the text discusses the development of species distribution models for fluvial fish species in the United States based on landscape data and anthropogenic impacts. These models predict the presence or absence of each species in stream segments, which involves analyzing and understanding the spatial distribution of the species.\",\"383\":\"None\",\"384\":\"None\",\"385\":\"The theme \\\"spatial\\\" is relevant in the given text. The text discusses the use of Autonomous Track Geometry Measurement System (ATGMS) data to analyze and predict track locations of concern. This implies that the focus is on the spatial aspect of the track geometry measurements. The predictive analytics mentioned in the text involve understanding the spatial patterns and trends in track geometry measures, which helps in identifying areas that require maintenance and ensuring safety limits are met. Therefore, the theme of \\\"spatial\\\" is relevant in this context.\",\"386\":\"None\",\"387\":\"None\",\"388\":\"None\",\"389\":\"None\",\"390\":\"None\",\"391\":\"None\",\"392\":\"None\",\"393\":\"The theme \\\"spatial\\\" is not relevant in the given text. The text mainly focuses on the development and support of a multispectral aerial imaging payload for real-time detection models. It mentions the goal of expediting the analysis and population assessment for arctic mammals. However, it does not discuss or emphasize any spatial aspects or considerations related to the topic. Hence, the relevance of the theme \\\"spatial\\\" is None.\",\"394\":\"None\",\"395\":\"None\",\"396\":\"None\",\"397\":\"None\",\"398\":\"None\",\"399\":\"The theme \\\"spatial\\\" is relevant in the given text. The text discusses TreeMap 2016, a model that matches forest plot data to a grid, providing a detailed representation of the forests in the United States. The use of a grid and matching forest plot data to it indicates a focus on spatial analysis and representation. Additionally, the mention of predictor variables such as forest cover, height, topography, and disturbance history further emphasizes the spatial aspect of the model. Thus, the theme \\\"spatial\\\" is relevant in this text.\",\"400\":\"None\",\"401\":\"None\",\"402\":\"None\",\"403\":\"None\",\"404\":\"None\",\"405\":\"The theme \\\"spatial\\\" is relevant in the text. The text mentions that the RISE project aims to create a camera system that can be integrated into the USGS Water Mission Area's streamgage monitoring network. This indicates that the camera system will be used to monitor and capture images and videos of streamgages, which are typically located in different spatial locations. Additionally, the system will use AI\\/ML modeling techniques to generate time-series data of surface water levels from the captured images, further emphasizing the spatial aspect of the project.\",\"406\":\"None\",\"407\":\"None\",\"408\":\"The theme \\\"spatial\\\" is relevant in the text because it discusses the use of seismic data from multiple stations to detect and locate earthquakes in Southern California. The researchers are using a machine learning model to analyze the spatial information provided by the seismic data and estimate earthquake locations. Additionally, the text mentions the development of a cloud-native software architecture to apply the model in real-time, indicating the consideration of spatial aspects in the implementation of the technology.\",\"409\":\"None\",\"410\":\"None\",\"411\":\"None\",\"412\":\"None\",\"413\":\"None\",\"414\":\"The theme \\\"spatial\\\" is relevant in the text above. The researchers used deep learning models to analyze the earthquake sequence in southwestern Puerto Rico and determine the location of earthquakes. By understanding the fault system and triggering mechanisms, they were able to gain insights into the spatial distribution of earthquakes in the region. Additionally, the improved depth estimates provided a better understanding of the physical processes involved in the earthquakes.\",\"415\":\"None\",\"416\":\"None\",\"417\":\"None\",\"418\":\"None\",\"419\":\"None\",\"420\":\"None\",\"421\":\"None\",\"422\":\"None\",\"423\":\"None\",\"424\":\"None\",\"425\":\"None\",\"426\":\"The theme \\\"spatial\\\" is relevant in the given text. The text discusses the Land Use Plan Document and Data Mining and Analysis R&D project, which aims to analyze unstructured planning documents to uncover patterns and conflicts in resource management planning rules. By analyzing these documents, the project aims to identify proposed action locations that may require exclusion, restrictions, or stipulations based on the conflicts found. This analysis of locations and conflicts directly relates to the spatial aspect of resource management planning, as it involves identifying specific areas and their suitability for certain actions based on spatial factors.\",\"427\":\"None\",\"428\":\"None\",\"429\":\"None\",\"430\":\"None\",\"431\":\"None\",\"432\":\"None\",\"433\":\"None\",\"434\":\"None\",\"435\":\"None\",\"436\":\"None\",\"437\":\"None\",\"438\":\"None\",\"439\":\"None\",\"440\":\"None\",\"441\":\"None\",\"442\":\"None\",\"443\":\"None\",\"444\":\"None\",\"445\":\"None\",\"446\":\"None\",\"447\":\"None\",\"448\":\"The theme \\\"spatial\\\" is relevant in the given text. This is because the text discusses the Nutrition Education & Local Access Dashboard, which aims to provide a visual representation of FNS nutrition support at the county level. The use of a dashboard implies the presentation of information in a spatial format, allowing users to understand and analyze data based on geographical locations (counties). Additionally, the text mentions a clustering script that groups states based on characteristics, further emphasizing the spatial aspect of the information provided.\",\"449\":\"The theme \\\"spatial\\\" is relevant in the given text. The text discusses the development of NN training software for the new generation of NCEP models. The main goal is to optimize the NCEP EMC Training and Validation System to handle high spatial resolution model data. This indicates that spatial considerations, such as accurately representing and analyzing geographic or spatial information, are crucial in the development of the software and the models.\",\"450\":\"None\",\"451\":\"None\",\"452\":\"The theme \\\"spatial\\\" is not relevant in the given text. The text primarily discusses the PROSPER modeling framework and the tools and resources used to develop the models. It does not provide any specific information or context related to spatial aspects or locations. Therefore, the relevance of the theme \\\"spatial\\\" is None in this text.\",\"453\":\"None\",\"454\":\"None\"},\"wildfire\":{\"0\":\"None\",\"1\":\"None\",\"2\":\"None\",\"3\":\"None\",\"4\":\"None\",\"5\":\"None\",\"6\":\"None\",\"7\":\"None\",\"8\":\"None\",\"9\":\"None\",\"10\":\"None\",\"11\":\"None\",\"12\":\"None\",\"13\":\"None\",\"14\":\"None\",\"15\":\"None\",\"16\":\"None\",\"17\":\"None\",\"18\":\"None\",\"19\":\"None\",\"20\":\"None\",\"21\":\"None\",\"22\":\"None\",\"23\":\"None\",\"24\":\"None\",\"25\":\"None\",\"26\":\"None\",\"27\":\"None\",\"28\":\"None\",\"29\":\"None\",\"30\":\"None\",\"31\":\"None\",\"32\":\"None\",\"33\":\"None\",\"34\":\"None\",\"35\":\"None\",\"36\":\"None\",\"37\":\"None\",\"38\":\"None\",\"39\":\"None\",\"40\":\"None\",\"41\":\"None\",\"42\":\"None\",\"43\":\"None\",\"44\":\"None\",\"45\":\"None\",\"46\":\"None\",\"47\":\"None\",\"48\":\"None\",\"49\":\"None\",\"50\":\"None\",\"51\":\"None\",\"52\":\"None\",\"53\":\"None\",\"54\":\"None\",\"55\":\"None\",\"56\":\"None\",\"57\":\"None\",\"58\":\"None\",\"59\":\"None\",\"60\":\"None\",\"61\":\"None\",\"62\":\"None\",\"63\":\"None\",\"64\":\"None\",\"65\":\"None\",\"66\":\"None\",\"67\":\"None\",\"68\":\"None\",\"69\":\"None\",\"70\":\"None\",\"71\":\"None\",\"72\":\"None\",\"73\":\"None\",\"74\":\"None\",\"75\":\"None\",\"76\":\"None\",\"77\":\"None\",\"78\":\"None\",\"79\":\"None\",\"80\":\"None\",\"81\":\"None\",\"82\":\"None\",\"83\":\"None\",\"84\":\"The theme of \\\"wildfire\\\" is highly relevant in the given text. The text specifically discusses the application of machine learning and image classification techniques to identify buildings, building loss, and defensible space in wildland-urban interface areas before and after a wildfire. The study aims to use these methods to map wildfire damage and evaluate the effectiveness of defensible space measures. Therefore, the theme of \\\"wildfire\\\" is directly addressed and central to the text.\",\"85\":\"None\",\"86\":\"None\",\"87\":\"None\",\"88\":\"None\",\"89\":\"None\",\"90\":\"None\",\"91\":\"None\",\"92\":\"None\",\"93\":\"None\",\"94\":\"None\",\"95\":\"None\",\"96\":\"None\",\"97\":\"None\",\"98\":\"None\",\"99\":\"None\",\"100\":\"None\",\"101\":\"None\",\"102\":\"None\",\"103\":\"None\",\"104\":\"None\",\"105\":\"None\",\"106\":\"None\",\"107\":\"None\",\"108\":\"None\",\"109\":\"None\",\"110\":\"None\",\"111\":\"None\",\"112\":\"None\",\"113\":\"None\",\"114\":\"None\",\"115\":\"None\",\"116\":\"None\",\"117\":\"None\",\"118\":\"None\",\"119\":\"None\",\"120\":\"None\",\"121\":\"None\",\"122\":\"None\",\"123\":\"None\",\"124\":\"None\",\"125\":\"None\",\"126\":\"None\",\"127\":\"None\",\"128\":\"None\",\"129\":\"None\",\"130\":\"None\",\"131\":\"None\",\"132\":\"None\",\"133\":\"None\",\"134\":\"None\",\"135\":\"None\",\"136\":\"None\",\"137\":\"None\",\"138\":\"None\",\"139\":\"None\",\"140\":\"None\",\"141\":\"None\",\"142\":\"None\",\"143\":\"None\",\"144\":\"None\",\"145\":\"None\",\"146\":\"None\",\"147\":\"None\",\"148\":\"None\",\"149\":\"None\",\"150\":\"None\",\"151\":\"None\",\"152\":\"None\",\"153\":\"None\",\"154\":\"None. The theme \\\"wildfire\\\" is not relevant in the given text. The text discusses machine learning models used for mapping and monitoring forest mortality and defoliation, but it does not mention anything about wildfires.\",\"155\":\"None\",\"156\":\"None\",\"157\":\"None\",\"158\":\"None\",\"159\":\"None\",\"160\":\"None\",\"161\":\"None\",\"162\":\"None\",\"163\":\"None\",\"164\":\"None\",\"165\":\"None\",\"166\":\"None\",\"167\":\"None\",\"168\":\"None\",\"169\":\"None\",\"170\":\"None\",\"171\":\"None\",\"172\":\"None\",\"173\":\"None\",\"174\":\"None\",\"175\":\"None\",\"176\":\"None\",\"177\":\"None\",\"178\":\"None\",\"179\":\"None\",\"180\":\"None\",\"181\":\"None\",\"182\":\"None\",\"183\":\"None\",\"184\":\"None\",\"185\":\"None\",\"186\":\"None\",\"187\":\"None\",\"188\":\"None\",\"189\":\"None\",\"190\":\"None\",\"191\":\"None\",\"192\":\"None\",\"193\":\"None\",\"194\":\"None\",\"195\":\"None\",\"196\":\"None\",\"197\":\"None\",\"198\":\"None\",\"199\":\"None\",\"200\":\"None\",\"201\":\"None\",\"202\":\"None\",\"203\":\"None\",\"204\":\"None\",\"205\":\"None\",\"206\":\"None\",\"207\":\"None\",\"208\":\"None\",\"209\":\"None\",\"210\":\"None\",\"211\":\"None\",\"212\":\"None\",\"213\":\"None\",\"214\":\"None\",\"215\":\"None\",\"216\":\"None\",\"217\":\"None\",\"218\":\"None\",\"219\":\"None\",\"220\":\"None\",\"221\":\"None\",\"222\":\"None\",\"223\":\"None\",\"224\":\"None\",\"225\":\"None\",\"226\":\"None\",\"227\":\"None\",\"228\":\"None\",\"229\":\"None\",\"230\":\"None\",\"231\":\"None\",\"232\":\"None\",\"233\":\"None\",\"234\":\"None\",\"235\":\"None\",\"236\":\"None\",\"237\":\"None\",\"238\":\"None\",\"239\":\"None\",\"240\":\"None\",\"241\":\"None\",\"242\":\"None\",\"243\":\"None\",\"244\":\"None\",\"245\":\"None\",\"246\":\"None\",\"247\":\"None\",\"248\":\"None\",\"249\":\"None\",\"250\":\"None\",\"251\":\"None\",\"252\":\"None\",\"253\":\"None\",\"254\":\"None\",\"255\":\"None\",\"256\":\"None\",\"257\":\"None\",\"258\":\"None\",\"259\":\"None\",\"260\":\"None\",\"261\":\"None\",\"262\":\"None\",\"263\":\"None\",\"264\":\"None\",\"265\":\"None\",\"266\":\"None\",\"267\":\"None\",\"268\":\"None\",\"269\":\"None\",\"270\":\"None\",\"271\":\"None\",\"272\":\"None\",\"273\":\"None\",\"274\":\"None\",\"275\":\"None\",\"276\":\"None\",\"277\":\"None\",\"278\":\"None\",\"279\":\"None\",\"280\":\"None\",\"281\":\"None\",\"282\":\"None\",\"283\":\"None\",\"284\":\"None\",\"285\":\"None\",\"286\":\"None\",\"287\":\"None\",\"288\":\"None\",\"289\":\"None\",\"290\":\"None\",\"291\":\"None\",\"292\":\"None\",\"293\":\"None\",\"294\":\"None\",\"295\":\"None\",\"296\":\"None\",\"297\":\"None\",\"298\":\"None\",\"299\":\"None\",\"300\":\"None\",\"301\":\"None\",\"302\":\"None\",\"303\":\"None\",\"304\":\"None\",\"305\":\"None\",\"306\":\"None\",\"307\":\"None\",\"308\":\"None\",\"309\":\"None\",\"310\":\"None\",\"311\":\"None\",\"312\":\"None\",\"313\":\"None\",\"314\":\"None\",\"315\":\"None\",\"316\":\"None\",\"317\":\"None\",\"318\":\"None\",\"319\":\"None\",\"320\":\"None\",\"321\":\"None\",\"322\":\"None\",\"323\":\"None\",\"324\":\"None\",\"325\":\"None\",\"326\":\"None\",\"327\":\"None\",\"328\":\"None\",\"329\":\"None\",\"330\":\"None\",\"331\":\"None\",\"332\":\"None\",\"333\":\"None\",\"334\":\"None\",\"335\":\"None\",\"336\":\"None\",\"337\":\"None\",\"338\":\"None\",\"339\":\"None\",\"340\":\"None\",\"341\":\"None\",\"342\":\"None\",\"343\":\"None\",\"344\":\"None\",\"345\":\"None\",\"346\":\"None\",\"347\":\"None\",\"348\":\"None\",\"349\":\"None\",\"350\":\"None\",\"351\":\"None\",\"352\":\"None\",\"353\":\"None\",\"354\":\"None\",\"355\":\"None\",\"356\":\"None\",\"357\":\"None\",\"358\":\"None\",\"359\":\"None\",\"360\":\"None\",\"361\":\"None\",\"362\":\"None\",\"363\":\"None\",\"364\":\"None\",\"365\":\"None\",\"366\":\"None\",\"367\":\"None\",\"368\":\"None\",\"369\":\"None\",\"370\":\"None\",\"371\":\"None\",\"372\":\"None\",\"373\":\"None\",\"374\":\"None\",\"375\":\"None\",\"376\":\"None\",\"377\":\"None\",\"378\":\"None\",\"379\":\"None\",\"380\":\"None\",\"381\":\"None\",\"382\":\"None\",\"383\":\"None\",\"384\":\"None\",\"385\":\"None\",\"386\":\"None\",\"387\":\"None\",\"388\":\"None\",\"389\":\"None\",\"390\":\"None\",\"391\":\"None\",\"392\":\"None\",\"393\":\"None\",\"394\":\"None\",\"395\":\"None\",\"396\":\"None\",\"397\":\"None\",\"398\":\"None\",\"399\":\"None. The theme \\\"wildfire\\\" is not relevant in the given text. The text primarily discusses the TreeMap 2016 model and its use in matching forest plot data to a grid for purposes such as fuel treatment planning and estimating carbon resources. It mentions predictor variables related to forests, but there is no mention or connection to the theme of \\\"wildfire.\",\"400\":\"None\",\"401\":\"None\",\"402\":\"None\",\"403\":\"None\",\"404\":\"None\",\"405\":\"None\",\"406\":\"None\",\"407\":\"None\",\"408\":\"None\",\"409\":\"None\",\"410\":\"None\",\"411\":\"None\",\"412\":\"None\",\"413\":\"None\",\"414\":\"None\",\"415\":\"None\",\"416\":\"None\",\"417\":\"None\",\"418\":\"None\",\"419\":\"None\",\"420\":\"None\",\"421\":\"None\",\"422\":\"None\",\"423\":\"None\",\"424\":\"None. The text does not mention or discuss anything related to wildfires.\",\"425\":\"None\",\"426\":\"None\",\"427\":\"None\",\"428\":\"None\",\"429\":\"None\",\"430\":\"None\",\"431\":\"None\",\"432\":\"None\",\"433\":\"None\",\"434\":\"None\",\"435\":\"None\",\"436\":\"None\",\"437\":\"None\",\"438\":\"None\",\"439\":\"None\",\"440\":\"None\",\"441\":\"None\",\"442\":\"None\",\"443\":\"None\",\"444\":\"None\",\"445\":\"None\",\"446\":\"None\",\"447\":\"None\",\"448\":\"None\",\"449\":\"None\",\"450\":\"None\",\"451\":\"None\",\"452\":\"None\",\"453\":\"None\",\"454\":\"None\"},\"maritime\":{\"0\":\"None\",\"1\":\"None\",\"2\":\"None\",\"3\":\"None\",\"4\":\"None\",\"5\":\"None\",\"6\":\"None\",\"7\":\"None\",\"8\":\"None\",\"9\":\"None\",\"10\":\"None\",\"11\":\"None\",\"12\":\"None\",\"13\":\"None\",\"14\":\"The theme \\\"maritime\\\" is not relevant in the given text. This is because the text mentions the Coast Train dataset, which is a collection of orthomosaic and satellite images of coastal, estuarine, and wetland environments. While these environments may be related to the maritime domain, the text does not specifically discuss any maritime activities or concepts. Therefore, the theme \\\"maritime\\\" is not applicable in this context.\",\"15\":\"None\",\"16\":\"None\",\"17\":\"None\",\"18\":\"None\",\"19\":\"None\",\"20\":\"None\",\"21\":\"None\",\"22\":\"None\",\"23\":\"None\",\"24\":\"None\",\"25\":\"None\",\"26\":\"None\",\"27\":\"The theme \\\"maritime\\\" is relevant in the given text. The text discusses how integrated technologies, analytics, machine-assisted detection, and AI algorithms can enhance maritime detection and the sensor network. It specifically mentions improving the detection of illicit vessels in areas with high volumes of legitimate trade and recreational water vessel traffic. The use of AI algorithms and sharing of detections of Items of Interest (IoI) can also aid in tracking and maintaining these IoIs across multiple sensors. Therefore, the theme \\\"maritime\\\" is clearly present and significant in the text.\",\"28\":\"None\",\"29\":\"None\",\"30\":\"None\",\"31\":\"None\",\"32\":\"None\",\"33\":\"None\",\"34\":\"None\",\"35\":\"The theme \\\"maritime\\\" is relevant in the text above. The text discusses the use of robotic microscopes and machine learning algorithms to track and monitor phytoplankton, which are important for marine food webs. Phytoplankton are a significant part of the marine ecosystem, and changes in the ocean and climate can impact their communities. Therefore, understanding and monitoring phytoplankton in relation to ocean and climate variability is crucial for maritime research and conservation efforts.\",\"36\":\"None\",\"37\":\"None. The theme \\\"maritime\\\" is not relevant in this text. The text focuses on enhancing the detection and classification process of ice seals in aerial imagery, minimizing false positive rates, and reducing the need for post-survey review. It does not mention anything related to maritime activities or environments.\",\"38\":\"None\",\"39\":\"None\",\"40\":\"None\",\"41\":\"None\",\"42\":\"None\",\"43\":\"None\",\"44\":\"None\",\"45\":\"None\",\"46\":\"None\",\"47\":\"None\",\"48\":\"None\",\"49\":\"None\",\"50\":\"None\",\"51\":\"None\",\"52\":\"None\",\"53\":\"None\",\"54\":\"None\",\"55\":\"None\",\"56\":\"None\",\"57\":\"None\",\"58\":\"None\",\"59\":\"None\",\"60\":\"None\",\"61\":\"None\",\"62\":\"None\",\"63\":\"None\",\"64\":\"None\",\"65\":\"None\",\"66\":\"None\",\"67\":\"None\",\"68\":\"None\",\"69\":\"None\",\"70\":\"None\",\"71\":\"None\",\"72\":\"None\",\"73\":\"None\",\"74\":\"None\",\"75\":\"None\",\"76\":\"None\",\"77\":\"None\",\"78\":\"None\",\"79\":\"None\",\"80\":\"None\",\"81\":\"None\",\"82\":\"None\",\"83\":\"None\",\"84\":\"None\",\"85\":\"The theme \\\"maritime\\\" is relevant in the text above because the entire passage discusses the use of various technologies and systems to detect, identify, and track objects in a maritime environment. It mentions the utilization of surveillance towers, ocean data solutions, unmanned autonomous surface vehicles (ASV), and AI specifically for this purpose. The text also mentions the use of low-cost surveillance towers equipped with radars and cameras, as well as ruggedized ASVs powered by wind, solar, or onboard engines. These systems, along with the employment of AI\\/ML, aim to enhance surveillance and monitoring in the maritime domain, potentially aiding in interdictions or intelligence collection.\",\"86\":\"None\",\"87\":\"None\",\"88\":\"None\",\"89\":\"None\",\"90\":\"None\",\"91\":\"None\",\"92\":\"None\",\"93\":\"None\",\"94\":\"None\",\"95\":\"None\",\"96\":\"None\",\"97\":\"None\",\"98\":\"None\",\"99\":\"None\",\"100\":\"None\",\"101\":\"None\",\"102\":\"None\",\"103\":\"None\",\"104\":\"None\",\"105\":\"The theme \\\"maritime\\\" is relevant in the given text because the text specifically discusses VIAME, an open-source software toolkit designed for analyzing video and image data in the marine environment. It mentions that the software allows users to automatically annotate imagery related to the marine environment using deep-learning algorithms. Additionally, it highlights that VIAME is available for free to NOAA users and is supported by the NOAA Fisheries Office of Science and Technology, further emphasizing its relevance to the maritime theme.\",\"106\":\"None\",\"107\":\"None\",\"108\":\"None\",\"109\":\"None\",\"110\":\"None\",\"111\":\"None\",\"112\":\"None. The theme \\\"maritime\\\" is not relevant in the given text. The text primarily focuses on the use of machine learning algorithms for predicting and improving the detection of pests at the port of entry. It does not mention any specific maritime elements or connections to the maritime industry.\",\"113\":\"None\",\"114\":\"None\",\"115\":\"None\",\"116\":\"None\",\"117\":\"None\",\"118\":\"None\",\"119\":\"None\",\"120\":\"None\",\"121\":\"None\",\"122\":\"None\",\"123\":\"None\",\"124\":\"None\",\"125\":\"None\",\"126\":\"None\",\"127\":\"None\",\"128\":\"None\",\"129\":\"None\",\"130\":\"None\",\"131\":\"None\",\"132\":\"None\",\"133\":\"None\",\"134\":\"None\",\"135\":\"The theme \\\"maritime\\\" is relevant in the text because it discusses the activities carried out by the Seabird Studies Team, which involve conducting aerial surveys of the ocean off central and southern California. The team's objective is to count and classify marine birds and mammals, which are inherently associated with the maritime environment. Additionally, the text mentions that the team is reviewing the model's output to generate maps of species distribution and abundance, which further emphasizes the relevance of the maritime theme as it pertains to the ocean ecosystem.\",\"136\":\"None\",\"137\":\"None\",\"138\":\"None\",\"139\":\"None\",\"140\":\"None\",\"141\":\"None\",\"142\":\"The theme \\\"maritime\\\" is relevant in the given text. This is because the text focuses on studying the distribution and ecology of green sea turtles in southern California, particularly in the La Jolla Cove area. The project involves collecting underwater images of the turtles, which implies studying their behavior and habitat in the marine environment. The use of facial recognition software to identify individual turtles also suggests a connection to the maritime theme. Additionally, gathering information on residency patterns and foraging habits of the green turtles further emphasizes the relevance of the maritime theme as it pertains to their marine ecosystem.\",\"143\":\"None\",\"144\":\"None. The text does not have any relevance to the theme \\\"maritime.\\\" It solely discusses the investigation of replacing wave models in the Great Lakes with AI models and does not touch upon any maritime aspects.\",\"145\":\"None\",\"146\":\"None\",\"147\":\"None\",\"148\":\"The theme \\\"maritime\\\" is relevant in the text because it mentions the Fisheries Electronic Monitoring Library (FEML), which is a database that specifically stores electronic monitoring data related to marine life. This indicates that the focus of the information being stored in the database is related to maritime activities and the study of marine life. Therefore, the text aligns with the theme of \\\"maritime.\",\"149\":\"None\",\"150\":\"None\",\"151\":\"None\",\"152\":\"None\",\"153\":\"None\",\"154\":\"None\",\"155\":\"None\",\"156\":\"None\",\"157\":\"None\",\"158\":\"None\",\"159\":\"None\",\"160\":\"None\",\"161\":\"None\",\"162\":\"None\",\"163\":\"None\",\"164\":\"None\",\"165\":\"None\",\"166\":\"None\",\"167\":\"None\",\"168\":\"None\",\"169\":\"None\",\"170\":\"None\",\"171\":\"None\",\"172\":\"None\",\"173\":\"None. The theme \\\"maritime\\\" is not relevant in the given text. The text discusses deep learning algorithms used for identifying right whales in photos and their expansion to include different viewpoints and body parts. It also mentions the Flukebook platform and a paper under review at Mammalian Biology. However, there is no mention or connection to maritime themes or any specific references to the ocean or maritime activities.\",\"174\":\"None\",\"175\":\"None\",\"176\":\"None\",\"177\":\"None\",\"178\":\"None\",\"179\":\"None\",\"180\":\"None\",\"181\":\"None\",\"182\":\"None\",\"183\":\"None\",\"184\":\"None\",\"185\":\"None\",\"186\":\"The theme \\\"maritime\\\" is not relevant in the given text. The text primarily focuses on the use of geospatial imagery and annotation through Synthetic Aperture Radar (SAR) satellites, which can capture images of any location on Earth. While it mentions the detection of marine vessels as part of the technology's capabilities, it does not delve into any maritime-specific details or implications. Therefore, the relevance of the theme \\\"maritime\\\" is None in this context.\",\"187\":\"None\",\"188\":\"None\",\"189\":\"None\",\"190\":\"None\",\"191\":\"None. The theme \\\"maritime\\\" is not relevant in this text. The text primarily focuses on the importance of AI-based automation of acoustic detection of marine mammals and the need for a skilled operator, but it does not directly relate to the maritime theme.\",\"192\":\"None\",\"193\":\"None\",\"194\":\"None\",\"195\":\"The theme \\\"maritime\\\" is relevant in the text below because it mentions the classification of walrus haulout camera trap images. It states that the system is able to determine the probability of an image containing walruses and various human disturbances, such as boats and aircraft. This indicates that the presence of boats and aircraft in maritime environments is an important factor in the classification process.\",\"196\":\"None\",\"197\":\"None\",\"198\":\"The theme \\\"maritime\\\" is relevant in the text because it mentions the Gulf of Mexico, which is a maritime region. The text also talks about using acoustic recordings to study marine mammal density and distribution in the Gulf of Mexico, further emphasizing the maritime theme.\",\"199\":\"The theme \\\"maritime\\\" is relevant in the text because it specifically mentions the monitoring of the endangered western Steller sea lion population in Alaska. The text discusses how the NOAA Fisheries Alaska Fisheries Science Center's Marine Mammal Laboratory conducts aerial surveys to monitor these sea lions. This indicates a connection to the maritime theme as it involves studying and monitoring marine mammals in their natural habitat. Additionally, the text mentions that this monitoring is important for informing sustainable fishery management decisions, further highlighting the relevance of the maritime theme.\",\"200\":\"None\",\"201\":\"None\",\"202\":\"None\",\"203\":\"None\",\"204\":\"None\",\"205\":\"None\",\"206\":\"None\",\"207\":\"None\",\"208\":\"The theme \\\"maritime\\\" is not relevant in the given text. The text primarily discusses a project that aims to develop an image library of landed catch from optical survey data in the Gulf of Mexico. Although the project involves underwater imagery and the Gulf of Mexico is a maritime location, the focus is more on data processing, image recognition, and technology rather than maritime themes. Therefore, the theme \\\"maritime\\\" is None in this text.\",\"209\":\"None\",\"210\":\"None\",\"211\":\"None\",\"212\":\"None\",\"213\":\"None\",\"214\":\"None\",\"215\":\"None\",\"216\":\"None\",\"217\":\"None\",\"218\":\"None\",\"219\":\"None\",\"220\":\"None\",\"221\":\"None\",\"222\":\"None\",\"223\":\"None\",\"224\":\"None\",\"225\":\"None\",\"226\":\"None\",\"227\":\"None\",\"228\":\"None\",\"229\":\"None\",\"230\":\"None\",\"231\":\"None\",\"232\":\"None\",\"233\":\"None\",\"234\":\"None\",\"235\":\"None\",\"236\":\"None\",\"237\":\"None\",\"238\":\"None\",\"239\":\"None\",\"240\":\"None\",\"241\":\"None\",\"242\":\"The theme \\\"maritime\\\" is relevant in the text because it mentions the California Current, which is a marine current that flows along the western coast of North America. The text discusses the EcoCast tool, which is used to model the distribution of swordfish and bycatch species in the California Current. This implies that the tool is specifically designed for managing and monitoring marine resources in a maritime environment. Therefore, the theme \\\"maritime\\\" is relevant in this text.\",\"243\":\"None\",\"244\":\"None\",\"245\":\"None\",\"246\":\"None\",\"247\":\"None\",\"248\":\"None\",\"249\":\"None\",\"250\":\"None\",\"251\":\"None\",\"252\":\"None\",\"253\":\"None\",\"254\":\"None\",\"255\":\"None\",\"256\":\"None\",\"257\":\"None\",\"258\":\"None\",\"259\":\"None\",\"260\":\"None\",\"261\":\"None\",\"262\":\"None\",\"263\":\"None\",\"264\":\"None\",\"265\":\"None\",\"266\":\"None\",\"267\":\"None\",\"268\":\"None\",\"269\":\"None\",\"270\":\"None\",\"271\":\"None\",\"272\":\"None\",\"273\":\"None\",\"274\":\"None\",\"275\":\"None\",\"276\":\"None\",\"277\":\"None\",\"278\":\"None\",\"279\":\"None\",\"280\":\"None. The theme \\\"maritime\\\" is not relevant in this text. The text primarily focuses on the use of CNN to identify objects in side scan imagery, without any mention or connection to maritime-related topics.\",\"281\":\"None\",\"282\":\"None\",\"283\":\"None\",\"284\":\"None\",\"285\":\"None\",\"286\":\"None\",\"287\":\"The theme \\\"maritime\\\" is not relevant in the given text. The text focuses on the condition of well platforms, safety concerns, and the need for additional audits. It mentions an automated screening system that can identify areas with excessive corrosion to speed up report processing time. However, there is no mention of maritime elements or any direct connection to the maritime industry. Therefore, the theme \\\"maritime\\\" is not relevant in this text.\",\"288\":\"None\",\"289\":\"None\",\"290\":\"None\",\"291\":\"None\",\"292\":\"None\",\"293\":\"None\",\"294\":\"None\",\"295\":\"None\",\"296\":\"None\",\"297\":\"None\",\"298\":\"None\",\"299\":\"None\",\"300\":\"The theme \\\"maritime\\\" is not relevant in the given text. The text primarily focuses on researchers using remote camera images to detect and identify sea lions in the Aleutian Islands. While the Aleutian Islands are located in a maritime region, the text itself does not provide any information or discussion specifically related to maritime activities, environments, or themes. Therefore, the relevance to the theme \\\"maritime\\\" is None.\",\"301\":\"None\",\"302\":\"None\",\"303\":\"None\",\"304\":\"The theme \\\"maritime\\\" is relevant in the given text. The text mentions the use of passive acoustic analysis to detect and classify the signals emitted by beluga whales in Cook Inlet, AK. Cook Inlet is a body of water located in Alaska, which is a maritime region. Furthermore, the text discusses understanding the seasonal distribution, habitat use, and impact of human disturbance on these whales, all of which are related to their maritime environment. The mention of expanding the analysis to other cetacean species and anthropogenic noise also implies a focus on the maritime ecosystem.\",\"305\":\"None\",\"306\":\"None\",\"307\":\"The theme \\\"maritime\\\" is relevant in the given text because it mentions the use of k-means clustering to identify consistent wave systems. Waves are a phenomenon commonly associated with the maritime environment, specifically the ocean. Additionally, it mentions the implementation of this technique by NWS marine forecasters, which indicates its relevance to maritime forecasting and operations.\",\"308\":\"None\",\"309\":\"None\",\"310\":\"None\",\"311\":\"None\",\"312\":\"None\",\"313\":\"None\",\"314\":\"None. The theme \\\"maritime\\\" is not relevant in this text. The text discusses the development of a machine learning model to predict the location of the salt front in the Delaware River Estuary. It mentions data on river discharge, tidal forcings, and meteorological data, as well as the use of a process-based hydrodynamic model and tools from pyTorch. There is no direct connection to maritime themes such as ships, navigation, or seafaring activities.\",\"315\":\"None\",\"316\":\"None\",\"317\":\"None\",\"318\":\"None\",\"319\":\"None\",\"320\":\"None\",\"321\":\"None\",\"322\":\"None\",\"323\":\"None\",\"324\":\"None\",\"325\":\"None\",\"326\":\"None\",\"327\":\"None\",\"328\":\"None. The theme \\\"maritime\\\" is not relevant in the given text. The text primarily discusses FathomNet, a platform that provides training data for machine learning algorithms using visual data. It mentions the use of interns and college class curriculums to annotate and localize imagery from NOAA videos. However, there is no direct mention or connection to the maritime theme.\",\"329\":\"None\",\"330\":\"None\",\"331\":\"None\",\"332\":\"None\",\"333\":\"None\",\"334\":\"None\",\"335\":\"None\",\"336\":\"None\",\"337\":\"None\",\"338\":\"None\",\"339\":\"None\",\"340\":\"None\",\"341\":\"None\",\"342\":\"None\",\"343\":\"None\",\"344\":\"None. The theme \\\"maritime\\\" is not relevant in the given text. This text primarily discusses the Offshore Precipitation Capability (OPC) and how it uses various data sources and machine learning techniques to enhance the accuracy of identifying and predicting precipitation areas. There is no direct connection to maritime-related aspects such as oceans, seas, ships, or navigation.\",\"345\":\"None\",\"346\":\"None\",\"347\":\"None\",\"348\":\"None\",\"349\":\"None\",\"350\":\"None\",\"351\":\"None\",\"352\":\"None\",\"353\":\"None\",\"354\":\"None\",\"355\":\"None\",\"356\":\"None\",\"357\":\"None\",\"358\":\"None\",\"359\":\"None\",\"360\":\"None\",\"361\":\"None\",\"362\":\"None\",\"363\":\"None\",\"364\":\"None\",\"365\":\"None\",\"366\":\"None\",\"367\":\"None\",\"368\":\"None\",\"369\":\"None\",\"370\":\"None\",\"371\":\"None\",\"372\":\"None\",\"373\":\"None\",\"374\":\"None\",\"375\":\"None\",\"376\":\"None\",\"377\":\"None\",\"378\":\"None\",\"379\":\"None\",\"380\":\"None\",\"381\":\"None\",\"382\":\"None\",\"383\":\"None\",\"384\":\"None\",\"385\":\"None\",\"386\":\"None\",\"387\":\"None\",\"388\":\"None\",\"389\":\"None\",\"390\":\"None\",\"391\":\"None\",\"392\":\"None\",\"393\":\"None\",\"394\":\"None\",\"395\":\"None\",\"396\":\"None\",\"397\":\"None\",\"398\":\"None\",\"399\":\"None\",\"400\":\"None\",\"401\":\"None\",\"402\":\"None\",\"403\":\"None\",\"404\":\"None\",\"405\":\"None\",\"406\":\"None\",\"407\":\"None\",\"408\":\"None\",\"409\":\"None\",\"410\":\"None\",\"411\":\"None\",\"412\":\"None\",\"413\":\"None\",\"414\":\"None\",\"415\":\"None\",\"416\":\"None\",\"417\":\"None\",\"418\":\"None\",\"419\":\"None\",\"420\":\"None\",\"421\":\"None\",\"422\":\"None\",\"423\":\"None\",\"424\":\"None\",\"425\":\"None\",\"426\":\"None\",\"427\":\"None\",\"428\":\"None\",\"429\":\"None\",\"430\":\"None\",\"431\":\"None\",\"432\":\"None\",\"433\":\"None\",\"434\":\"None\",\"435\":\"None\",\"436\":\"The theme \\\"maritime\\\" is not relevant in the given text. The text discusses the concept of ROMIO, which aims to provide convective weather information to aircraft flying over the ocean and remote areas. While the text mentions the use of converted weather satellite data and weather prediction models, it does not specifically focus on maritime or ocean-related aspects. Therefore, the theme \\\"maritime\\\" is None in this text.\",\"437\":\"None\",\"438\":\"None\",\"439\":\"None\",\"440\":\"None\",\"441\":\"None\",\"442\":\"None\",\"443\":\"None\",\"444\":\"None\",\"445\":\"None\",\"446\":\"None\",\"447\":\"None\",\"448\":\"None\",\"449\":\"None\",\"450\":\"None\",\"451\":\"None\",\"452\":\"None\",\"453\":\"None\",\"454\":\"None\"},\"cyber intelligence\":{\"0\":\"None\",\"1\":\"None\",\"2\":\"None\",\"3\":\"None\",\"4\":\"None\",\"5\":\"None\",\"6\":\"None\",\"7\":\"None\",\"8\":\"None\",\"9\":\"None\",\"10\":\"None\",\"11\":\"None\",\"12\":\"None\",\"13\":\"None\",\"14\":\"None\",\"15\":\"None\",\"16\":\"None\",\"17\":\"None\",\"18\":\"The theme of \\\"cyber intelligence\\\" is relevant in the given text. The text discusses the research objective of developing methods and technologies to enhance cybersecurity for industrial control systems (ICS) networks. The research involves analyzing captured communication signals to identify the protocol being used and employing machine learning to detect unknown protocols. This focus on analyzing and understanding communication signals demonstrates the utilization of cyber intelligence to enhance cybersecurity measures.\",\"19\":\"None\",\"20\":\"None\",\"21\":\"None\",\"22\":\"None\",\"23\":\"None\",\"24\":\"None\",\"25\":\"None\",\"26\":\"None\",\"27\":\"None\",\"28\":\"None\",\"29\":\"None\",\"30\":\"None\",\"31\":\"None\",\"32\":\"None\",\"33\":\"None\",\"34\":\"None\",\"35\":\"None\",\"36\":\"None\",\"37\":\"None\",\"38\":\"None\",\"39\":\"None\",\"40\":\"None\",\"41\":\"None\",\"42\":\"None\",\"43\":\"None\",\"44\":\"None\",\"45\":\"None\",\"46\":\"None\",\"47\":\"None\",\"48\":\"None\",\"49\":\"None\",\"50\":\"None\",\"51\":\"None\",\"52\":\"None\",\"53\":\"None\",\"54\":\"None\",\"55\":\"None\",\"56\":\"None\",\"57\":\"None\",\"58\":\"None\",\"59\":\"None\",\"60\":\"None\",\"61\":\"None\",\"62\":\"None\",\"63\":\"None\",\"64\":\"The theme of \\\"cyber intelligence\\\" is relevant in the given text. The text mentions the use of AI\\/ML models to analyze end user activity data and identify opportunities for improving workflows and application usage. This indicates the use of cyber intelligence techniques to gather and analyze data for optimizing processes and enhancing security. Additionally, the text mentions customization and automation of agency applications for greater connectivity and security, which also aligns with the theme of cyber intelligence.\",\"65\":\"None\",\"66\":\"None\",\"67\":\"None\",\"68\":\"None\",\"69\":\"None\",\"70\":\"The theme of \\\"cyber intelligence\\\" is relevant in the given text. The text discusses how the USDA (United States Department of Agriculture) has developed a natural language processing model to analyze text in procurement descriptions. This model is used to determine the likelihood of an award being IT-related and requiring an Acquisition Approval Request (AAR). The model calculates the probability of IT-relatedness for procurements without an AAR number in the Integrated Acquisition System (IAS). This use of natural language processing and probability calculation to analyze text in procurement descriptions and determine IT-relatedness demonstrates the relevance of \\\"cyber intelligence\\\" in the context of the text.\",\"71\":\"None\",\"72\":\"None\",\"73\":\"None\",\"74\":\"None\",\"75\":\"None\",\"76\":\"None\",\"77\":\"None\",\"78\":\"None\",\"79\":\"The theme of \\\"cyber intelligence\\\" is relevant in the given text. The text talks about developing a machine learning-based system that can detect attacks in the 5G cellular network. This indicates the importance of having intelligence and advanced technologies to monitor and protect against cyber threats in the digital realm.\",\"80\":\"None\",\"81\":\"None\",\"82\":\"None\",\"83\":\"The theme of \\\"cyber intelligence\\\" is relevant in the text because it discusses the use of AI algorithms to correlate information from multiple feeds in order to enhance the quality of externally shared information. The mention of AI learning and improving its efficiency, as well as the development of customized algorithms for continuous monitoring of threat actors' tactics, techniques, and procedures, highlights the focus on cyber intelligence in the text.\",\"84\":\"None\",\"85\":\"None\",\"86\":\"None\",\"87\":\"None\",\"88\":\"None\",\"89\":\"None\",\"90\":\"None\",\"91\":\"None\",\"92\":\"None\",\"93\":\"None\",\"94\":\"None\",\"95\":\"None\",\"96\":\"None\",\"97\":\"None\",\"98\":\"None\",\"99\":\"None\",\"100\":\"None\",\"101\":\"None\",\"102\":\"None\",\"103\":\"None\",\"104\":\"None\",\"105\":\"None\",\"106\":\"None\",\"107\":\"None\",\"108\":\"None\",\"109\":\"None\",\"110\":\"None\",\"111\":\"None\",\"112\":\"None\",\"113\":\"None\",\"114\":\"None\",\"115\":\"None\",\"116\":\"None\",\"117\":\"None\",\"118\":\"None\",\"119\":\"None\",\"120\":\"None\",\"121\":\"None\",\"122\":\"None\",\"123\":\"None\",\"124\":\"None\",\"125\":\"None\",\"126\":\"None\",\"127\":\"None\",\"128\":\"The theme of \\\"cyber intelligence\\\" is relevant in the given text. The text discusses how security analysts in Security Operations Centers utilize both manual and automated methods to detect and correlate potential cyber attacks. The mention of using automated tooling with mathematically and probabilistically based models highlights the application of cyber intelligence in refining alerts and detecting anomalies in a timely manner.\",\"129\":\"None\",\"130\":\"None\",\"131\":\"None\",\"132\":\"None\",\"133\":\"None\",\"134\":\"None\",\"135\":\"None\",\"136\":\"None\",\"137\":\"None\",\"138\":\"None\",\"139\":\"None\",\"140\":\"None\",\"141\":\"None\",\"142\":\"None\",\"143\":\"None\",\"144\":\"None\",\"145\":\"None\",\"146\":\"None\",\"147\":\"None\",\"148\":\"None\",\"149\":\"None\",\"150\":\"None\",\"151\":\"None\",\"152\":\"None\",\"153\":\"None\",\"154\":\"None\",\"155\":\"None\",\"156\":\"None\",\"157\":\"None\",\"158\":\"None\",\"159\":\"None\",\"160\":\"The theme \\\"cyber intelligence\\\" is relevant in the text because it discusses the importance of malware reverse engineering in CISA's cyber defense mission. It emphasizes the need for advanced engineering, formal methods, and deep learning techniques to improve cyber threat intelligence. It also mentions the use of scalable, automated tools to disrupt adversaries' malware development lifecycle. This demonstrates the relevance of cyber intelligence in analyzing and countering cyber threats.\",\"161\":\"None\",\"162\":\"None\",\"163\":\"None\",\"164\":\"None\",\"165\":\"None\",\"166\":\"The theme of \\\"cyber intelligence\\\" is relevant in the given text. The text mentions the use of learning-based algorithms to detect and respond to component contingencies caused by cyber-attacks. This implies that the project is focused on developing a simulation framework that utilizes cyber intelligence to make real-time decisions for integrated energy systems operation.\",\"167\":\"None\",\"168\":\"None\",\"169\":\"None\",\"170\":\"The theme \\\"cyber intelligence\\\" is relevant in the given text as it discusses the development and implementation of frameworks, processes, and testing tools for AI technologies. These tools utilize Machine Learning and Natural Language Processing, which are key components of cyber intelligence. The purpose of these tools is to enhance the assessment and operation of AI systems, making them more trustworthy, robust, and secure in handling data. Therefore, the theme of cyber intelligence is directly related to the text.\",\"171\":\"None\",\"172\":\"None\",\"173\":\"None\",\"174\":\"None\",\"175\":\"None\",\"176\":\"None\",\"177\":\"None\",\"178\":\"None\",\"179\":\"None\",\"180\":\"None\",\"181\":\"None\",\"182\":\"None\",\"183\":\"None\",\"184\":\"None\",\"185\":\"None\",\"186\":\"None\",\"187\":\"None\",\"188\":\"None\",\"189\":\"None\",\"190\":\"None\",\"191\":\"None\",\"192\":\"None\",\"193\":\"None\",\"194\":\"None\",\"195\":\"None\",\"196\":\"None\",\"197\":\"None\",\"198\":\"None\",\"199\":\"None\",\"200\":\"None\",\"201\":\"The theme of \\\"cyber intelligence\\\" is relevant in this text. The project mentioned in the text focuses on developing a framework and process to convert industrial control system features into a format that can be read by automated cyber tools. This indicates the use of cyber intelligence to enhance the capabilities of these tools. The research also examines current and evolving standards for usability with diverse grid architectures, suggesting the application of cyber intelligence in adapting to different systems. Furthermore, the project aims to prioritize future research steps for automated threat response and improved cyber incident consequence models, which highlights the importance of utilizing cyber intelligence in mitigating threats. Lastly, the project aims to enhance national capabilities for sharing actionable threat intelligence at machine speed, emphasizing the significance of cyber intelligence in real-time threat response and information sharing.\",\"202\":\"None\",\"203\":\"None\",\"204\":\"None\",\"205\":\"None\",\"206\":\"None\",\"207\":\"None\",\"208\":\"None\",\"209\":\"None\",\"210\":\"None\",\"211\":\"None\",\"212\":\"None\",\"213\":\"None\",\"214\":\"None\",\"215\":\"None\",\"216\":\"None\",\"217\":\"The theme \\\"cyber intelligence\\\" is relevant in the given text. The text describes the Cyber Sentry program that monitors critical infrastructure networks and utilizes advanced anomaly detection and machine learning to analyze cyber-physical data. It also mentions the Critical Infrastructure Anomaly Alerting model, which assists threat hunting analysts by providing AI-assisted processing of this information. These elements highlight the use of technology and artificial intelligence in gathering and analyzing data to enhance cybersecurity and protect critical infrastructure, thus demonstrating the relevance of the theme \\\"cyber intelligence.\",\"218\":\"None\",\"219\":\"None\",\"220\":\"None\",\"221\":\"None\",\"222\":\"None\",\"223\":\"None\",\"224\":\"None\",\"225\":\"None\",\"226\":\"None\",\"227\":\"None\",\"228\":\"None\",\"229\":\"The theme of \\\"cyber intelligence\\\" is relevant in the given text. It discusses how cyber incident handling specialists utilize advanced automation tools that employ Machine Learning and Natural Language Processing to process and filter data from different threat intelligence and cyber incident channels. These tools play a crucial role in enhancing the accuracy and relevance of the data presented to human analysts and decision-makers. Additionally, they help in aggregating information in reports for further analysis, which is an integral part of cyber intelligence activities.\",\"230\":\"None\",\"231\":\"None\",\"232\":\"None\",\"233\":\"None\",\"234\":\"None\",\"235\":\"None\",\"236\":\"None\",\"237\":\"The theme \\\"cyber intelligence\\\" is relevant in the given text. The text discusses how a support vector machine and PRA software are being utilized to automatically detect vulnerabilities in system design and identify previously unknown issues. This implies the use of advanced algorithms and technology to analyze and understand potential risks in a cyber system. Additionally, the text mentions the elimination of the need for training data that would typically be available after system failures occur, indicating the use of intelligent systems that can learn and detect vulnerabilities without relying on past incidents. Overall, the text highlights the application of cyber intelligence techniques to enhance probabilistic risk assessment in system design.\",\"238\":\"None\",\"239\":\"None\",\"240\":\"None\",\"241\":\"The theme of \\\"cyber intelligence\\\" is relevant in the text. This is because the text discusses the use of generative adversarial networks to automate the training of electromagnetic-based anomaly detection systems for legacy industrial control systems and Industrial Internet of Things. This automation process aims to enhance the protection of these systems from intrusion, which is a key aspect of cyber intelligence. Additionally, the mention of reducing manual labor and operational costs further emphasizes the importance of utilizing cyber intelligence techniques in this context.\",\"242\":\"None\",\"243\":\"None\",\"244\":\"None\",\"245\":\"None\",\"246\":\"None\",\"247\":\"None\",\"248\":\"None\",\"249\":\"None\",\"250\":\"None\",\"251\":\"None\",\"252\":\"None\",\"253\":\"The theme of \\\"cyber intelligence\\\" is relevant in the given text. The Resilient Attack Interceptor for Intelligent Devices approach focuses on developing external monitoring methods to protect industrial internet of things (IoT) devices. This approach involves analyzing physical aspects and identifying abnormal functionality to detect potential attacks. This showcases the relevance of cyber intelligence as it emphasizes the need for surveillance and monitoring to safeguard IoT devices against cyber threats.\",\"254\":\"None\",\"255\":\"None\",\"256\":\"None\",\"257\":\"The theme of \\\"cyber intelligence\\\" is relevant in the text because it discusses the use of descriptive analytics to classify indicators of compromise based on organizational-centric intelligence data. It also mentions the verification of indicators by an analyst and the use of opinion and confidence values to filter and prioritize actions and investigations. All of these elements are related to the field of cyber intelligence.\",\"258\":\"None\",\"259\":\"None\",\"260\":\"None\",\"261\":\"None\",\"262\":\"None\",\"263\":\"None\",\"264\":\"None\",\"265\":\"None\",\"266\":\"None\",\"267\":\"None\",\"268\":\"None\",\"269\":\"None\",\"270\":\"None\",\"271\":\"None\",\"272\":\"None\",\"273\":\"None\",\"274\":\"None\",\"275\":\"None\",\"276\":\"None\",\"277\":\"None\",\"278\":\"None\",\"279\":\"The theme \\\"cyber intelligence\\\" is relevant in the text because it mentions the team's goal of training AI models on determining important attributes for cybersecurity in digital twins. This indicates that the team is focused on using artificial intelligence to enhance cybersecurity measures in the digital twin framework they are developing.\",\"280\":\"None\",\"281\":\"None\",\"282\":\"None\",\"283\":\"None\",\"284\":\"None\",\"285\":\"None\",\"286\":\"None\",\"287\":\"None\",\"288\":\"None\",\"289\":\"The theme \\\"cyber intelligence\\\" is relevant in the text above. This is because the project focuses on developing a framework for automated malware analysis using dynamic sandboxes. This indicates the use of technology and algorithms to gather intelligence on cyber threats and analyze malware samples. Additionally, the mention of machine learning and automated analysis further emphasizes the importance of cyber intelligence in this context.\",\"290\":\"None\",\"291\":\"None\",\"292\":\"None\",\"293\":\"None\",\"294\":\"None\",\"295\":\"None\",\"296\":\"None\",\"297\":\"The theme of \\\"cyber intelligence\\\" is relevant in the given text. The text mentions the use of an artificial intelligence-powered dashboard in the Operations Center of CISA (Cybersecurity and Infrastructure Security Agency). This dashboard utilizes real-time event data, historical cybersecurity information, and previous response activity to suggest appropriate actions and engagement strategies. This indicates the importance of cyber intelligence in understanding ongoing operational activities and making informed decisions related to potential impacts on national critical functions.\",\"298\":\"None\",\"299\":\"None\",\"300\":\"None\",\"301\":\"None\",\"302\":\"None\",\"303\":\"None\",\"304\":\"None\",\"305\":\"None\",\"306\":\"None\",\"307\":\"None\",\"308\":\"None\",\"309\":\"None\",\"310\":\"None\",\"311\":\"None\",\"312\":\"None\",\"313\":\"None\",\"314\":\"None\",\"315\":\"None\",\"316\":\"None\",\"317\":\"The theme \\\"cyber intelligence\\\" is relevant in the given text. It is evident from the mention of the SMART system on OpenNet, which integrates AI capabilities. These capabilities, such as entity extraction, sentiment analysis, keyword extraction, and historical data analysis, are all components of cyber intelligence. The system utilizes these capabilities to identify objects within cables, analyze sentiment, extract keywords, and provide recommendations. Therefore, the text demonstrates the relevance of \\\"cyber intelligence\\\" through the use of AI-enabled tasks in analyzing and processing cables.\",\"318\":\"None\",\"319\":\"None\",\"320\":\"None\",\"321\":\"None\",\"322\":\"None\",\"323\":\"The theme of \\\"cyber intelligence\\\" is not relevant in the given text. The text discusses the Complaint Lead Value Probability Threat Intake Processing System (TIPS) database, which employs artificial intelligence algorithms to identify and process actionable tips. While this system utilizes artificial intelligence, it does not specifically pertain to cyber intelligence. The system helps prioritize immediate threats and assists law enforcement in responding promptly, but it does not focus on cyber threats or cyber intelligence.\",\"324\":\"None\",\"325\":\"The theme of \\\"cyber intelligence\\\" is relevant in the given text. The text mentions the use of advanced automation tools like Machine Learning and Natural Language Processing, which are key components of cyber intelligence. These tools help vulnerability analysts process and aggregate data from different reporting channels, improving the accuracy and relevance of the information. Furthermore, the text highlights that Machine Learning techniques aid in aggregating information from databases like KEV and CVE for further analysis and presentation, which are essential aspects of cyber intelligence.\",\"326\":\"None\",\"327\":\"None\",\"328\":\"None\",\"329\":\"None\",\"330\":\"None\",\"331\":\"None\",\"332\":\"None\",\"333\":\"None\",\"334\":\"None\",\"335\":\"None\",\"336\":\"None\",\"337\":\"None\",\"338\":\"None\",\"339\":\"None\",\"340\":\"None\",\"341\":\"None\",\"342\":\"None\",\"343\":\"None\",\"344\":\"None\",\"345\":\"The theme of \\\"cyber intelligence\\\" is relevant in the given text. The text mentions that the Cybersecurity and Infrastructure Security Agency (CISA) utilizes advanced analytics and forensic specialists to investigate cyber events. These specialists employ artificial intelligence tools to analyze data and identify anomalies and potential threats more effectively. This demonstrates the application of cyber intelligence techniques and technologies to enhance cybersecurity measures and protect government departments, agencies, and other partners from cyber threats.\",\"346\":\"None\",\"347\":\"None\",\"348\":\"None\",\"349\":\"None\",\"350\":\"None\",\"351\":\"None\",\"352\":\"None\",\"353\":\"None\",\"354\":\"None\",\"355\":\"None\",\"356\":\"None\",\"357\":\"None\",\"358\":\"None\",\"359\":\"None\",\"360\":\"None\",\"361\":\"None\",\"362\":\"None\",\"363\":\"The theme \\\"cyber intelligence\\\" is relevant in the given text. The text discusses the development of a machine learning system that aims to detect 5G attacks, including zero-day attacks. This indicates a focus on utilizing intelligence and advanced technology to identify and counter potential cyber threats. The mention of using field programmable gate array based deep autoencoders demonstrates a sophisticated approach to address the vulnerability to zero-day attacks. Therefore, the theme of \\\"cyber intelligence\\\" is highly relevant in this text.\",\"364\":\"None\",\"365\":\"None\",\"366\":\"None\",\"367\":\"None\",\"368\":\"None\",\"369\":\"None\",\"370\":\"None\",\"371\":\"None\",\"372\":\"None\",\"373\":\"None\",\"374\":\"None\",\"375\":\"None\",\"376\":\"None\",\"377\":\"None\",\"378\":\"None\",\"379\":\"None\",\"380\":\"None\",\"381\":\"None\",\"382\":\"None\",\"383\":\"None\",\"384\":\"None\",\"385\":\"None\",\"386\":\"None\",\"387\":\"None\",\"388\":\"None\",\"389\":\"The theme of \\\"cyber intelligence\\\" is relevant in the given text. The text discusses improving the assessment of security in machine learning and artificial intelligence systems. It mentions activities such as reverse engineering, exploitation, risk assessment, and vulnerability remediation, all of which are related to cyber intelligence. Additionally, the goal of developing risk evaluation metrics to enhance cybersecurity practices further emphasizes the relevance of cyber intelligence in this research.\",\"390\":\"None\",\"391\":\"None\",\"392\":\"None\",\"393\":\"None\",\"394\":\"None\",\"395\":\"None\",\"396\":\"None\",\"397\":\"None\",\"398\":\"None\",\"399\":\"None\",\"400\":\"The theme \\\"cyber intelligence\\\" is relevant in the given text. The text discusses how Advanced Network Anomaly Alerting Threat hunting and Security Operations Center (SOC) analysts receive data from the National Cybersecurity Protection System's (NCPS) Einstein sensors. These analysts use a combination of manual and automated techniques, as well as mathematical and probabilistic models, to detect network attacks and anomalies. This demonstrates the use of intelligence and techniques in the field of cybersecurity to enhance detection and response capabilities.\",\"401\":\"None\",\"402\":\"None\",\"403\":\"None\",\"404\":\"None\",\"405\":\"None\",\"406\":\"None\",\"407\":\"None\",\"408\":\"None\",\"409\":\"None\",\"410\":\"None\",\"411\":\"None\",\"412\":\"None\",\"413\":\"None\",\"414\":\"None\",\"415\":\"None\",\"416\":\"None\",\"417\":\"None\",\"418\":\"None\",\"419\":\"None\",\"420\":\"None\",\"421\":\"None\",\"422\":\"None\",\"423\":\"None\",\"424\":\"None\",\"425\":\"None\",\"426\":\"None\",\"427\":\"None\",\"428\":\"None\",\"429\":\"None\",\"430\":\"None\",\"431\":\"None\",\"432\":\"None\",\"433\":\"None\",\"434\":\"None\",\"435\":\"None\",\"436\":\"None\",\"437\":\"None\",\"438\":\"None\",\"439\":\"None\",\"440\":\"None\",\"441\":\"None\",\"442\":\"None\",\"443\":\"None\",\"444\":\"None\",\"445\":\"None\",\"446\":\"None\",\"447\":\"None\",\"448\":\"None\",\"449\":\"None\",\"450\":\"None\",\"451\":\"None\",\"452\":\"None\",\"453\":\"None\",\"454\":\"None\"},\"security\":{\"0\":\"None\",\"1\":\"None\",\"2\":\"None\",\"3\":\"None\",\"4\":\"The theme of \\\"security\\\" is relevant in the text above. This is evident from the mention of the project being developed by the DHS (Department of Homeland Security) and its specific division, HSI (Homeland Security Investigations) Innovation Lab. The project aims to scan and populate information from barcodes into text fields on the RAVEn GO's Encounter Card, which suggests a focus on secure data collection and management. Additionally, the text mentions that the project supports ICE's (Immigration and Customs Enforcement) mission to enforce and investigate violations of U.S. laws, indicating a connection to security and public safety. The reference to the DHS\\/ICE\\/PIA-055 Privacy Impact Assessment further emphasizes the security aspect, suggesting that privacy and data protection are being considered.\",\"5\":\"None\",\"6\":\"The theme of \\\"security\\\" is relevant in the text because the Retailer Receipt Analysis aims to detect and visualize fraud patterns on retailer invoices and receipts. By automating the manual process of reviewing FNS receipts and invoices, the analysis system helps ensure the accuracy of detecting fraudulent activities. This can provide a sense of security to the organization by minimizing the risk of financial losses due to fraudulent transactions.\",\"7\":\"None\",\"8\":\"None\",\"9\":\"None\",\"10\":\"The theme \\\"security\\\" is not directly relevant in the given text. The text primarily discusses the functionality and purpose of the Chatbot - Voice CMS\\/OSFLO, which is an automated phone response system aimed at providing general information about badging and assisting the CMS Badging Help Desk. While the text does not explicitly mention security, it indirectly implies that the Chatbot helps in streamlining the help desk's tasks, which could potentially contribute to overall security by allowing personnel to focus on more complex issues faced by employees and contractors. However, this connection is not explicitly stated in the text.\",\"11\":\"None\",\"12\":\"The theme of \\\"security\\\" is not relevant in this text. The text primarily focuses on the Global Engagement Center's Technology Testbed, Makor Analytics' involvement, and the pilot's objective of providing additional information through sentiment analysis. None of these elements directly relate to security.\",\"13\":\"None\",\"14\":\"None. The text does not contain any information or context related to the theme of \\\"security.\\\" It primarily provides information about the Coast Train dataset, including the type of images and data it contains, as well as its size and scope.\",\"15\":\"None\",\"16\":\"The theme of \\\"security\\\" is not relevant in the given text. The text primarily discusses the functionality and availability of the Sentiment Analysis - Surveys system, focusing on statistical analysis, Natural Language Processing (NLP), and the analysis of employee satisfaction surveys. It does not mention or imply anything related to security measures or concerns.\",\"17\":\"None\",\"18\":\"The theme of \\\"security\\\" is relevant in the given text. The text discusses developing methods and technologies to enhance cybersecurity in industrial control systems (ICS) networks. The goal is to defend these networks and enable cybersecurity analysts to detect compromise before any harm can occur. The use of machine learning to identify unknown protocols and analyzing captured communication signals indicates a focus on enhancing the security of the ICS networks. Hence, the theme of security is clearly relevant in this text.\",\"19\":\"None\",\"20\":\"None\",\"21\":\"None\",\"22\":\"None\",\"23\":\"None\",\"24\":\"None\",\"25\":\"None\",\"26\":\"None\",\"27\":\"The theme \\\"security\\\" is relevant in the text because it discusses how integrated technologies and analytics can enhance maritime detection. By using machine-assisted and AI-enhanced detection and tracking, the text suggests that it can improve the detection of illicit vessels. This is important for security purposes, especially in areas with high volumes of legitimate trade and recreational water vessel traffic. Additionally, the use of AI algorithms and sharing of detections of Items of Interest (IoI) can aid in tracking and maintaining these IoIs across multiple sensors, further emphasizing the importance of security in the context of maritime detection.\",\"28\":\"None\",\"29\":\"None\",\"30\":\"The theme of \\\"security\\\" is not relevant in this text. The text primarily discusses the functionality and potential uses of the Predicted to Naturalize model, which enables the prediction of eligibility for naturalization and provides current addresses of Legal Permanent Residents. It emphasizes the practical applications of the model, such as sending correspondence to USCIS (United States Citizenship and Immigration Services) customers about their resident status and informing others about potential benefits. The text does not address security concerns or implications.\",\"31\":\"The theme of \\\"security\\\" is relevant in the given text. The text discusses Crisis Campaign Cable Analytics, which utilizes optical character recognition and natural language processing on Department cables. This implies that the organization is concerned about the security of its communication and data. By analyzing the cables, they aim to identify gaps and trends in crisis training to enhance post preparedness for crisis events. This suggests that security measures are being taken to ensure the organization is adequately prepared for potential crises.\",\"32\":\"None\",\"33\":\"None\",\"34\":\"None\",\"35\":\"None\",\"36\":\"None\",\"37\":\"None\",\"38\":\"None\",\"39\":\"None\",\"40\":\"None\",\"41\":\"None\",\"42\":\"None\",\"43\":\"The theme of \\\"security\\\" is relevant in the given text. The Identity Match Option (IMO) is a process used by USCIS (U.S. Citizenship and Immigration Services) to ensure the security of immigration systems. By combining data from various systems, the IMO aims to determine a single identity for each applicant or beneficiary, which helps in analyzing immigration histories, detecting fraud, and resolving data quality issues. This process helps in maintaining the security of the immigration system by ensuring accurate and reliable information about individuals.\",\"44\":\"None\",\"45\":\"None\",\"46\":\"None\",\"47\":\"None\",\"48\":\"The theme \\\"security\\\" is relevant in the given text. The text discusses how the use of technology, such as Artificial Intelligence and mobile device cameras, is employed in the CBP One app to detect proof of life or \\\"Liveness Detection.\\\" This technology serves the purpose of reducing fraudulent activity by ensuring that the submitted data is from the actual person in front of the camera. By implementing security measures like Liveness Detection, the app aims to provide a secure and reliable platform for verifying the identity of individuals.\",\"49\":\"The theme of security is relevant in the given text. The text discusses the use of AI Curated Synthetic Data to improve anomaly detection in complex environments, specifically in the field of detecting narcotics and contraband in vehicles and cargo. The generation of artificial data, such as synthetic X-ray scan images and virtual 3D assets, helps in developing algorithms that can enhance security measures by accurately identifying potential threats.\",\"50\":\"The theme of \\\"security\\\" is relevant in the given text. Mobile Device Analytics (MDA) is specifically designed to assist investigators in analyzing large volumes of data extracted from mobile devices. By using MDA, the efficiency of agents in identifying relevant evidence and criminal networks would be enhanced, which directly relates to the security aspect of law enforcement. Additionally, the project's involvement in developing machine learning for object detection in photos and videos can also contribute to security measures, as it can aid in identifying and apprehending potential threats or evidence related to criminal activities. Therefore, the concept of security is pertinent in this context.\",\"51\":\"None\",\"52\":\"The theme of \\\"security\\\" is relevant in the given text. This is evident from phrases such as \\\"trusted source,\\\" \\\"accurate matching of records,\\\" \\\"maintaining high confidence and trust,\\\" and \\\"handling fuzzy matches and variations in data quality.\\\" These aspects emphasize the importance of maintaining the security and reliability of biographical and biometric information for immigration history and status. The use of machine learning and the A-Number Management model further indicates the need for ensuring security in handling sensitive data. Therefore, the theme of security is relevant in this text.\",\"53\":\"None\",\"54\":\"None\",\"55\":\"None\",\"56\":\"None\",\"57\":\"The theme of \\\"security\\\" is not relevant in the given text. The text focuses on the City Pairs Program Ticket Forecast and Scenario Analysis Tools, which use air travel purchase data to generate predictions for air travel purchases. The text does not discuss any aspects related to security, such as protecting data, preventing unauthorized access, or ensuring the safety of travelers. Therefore, the theme of security does not apply to this text.\",\"58\":\"None\",\"59\":\"The theme of \\\"security\\\" is relevant in the text above. The text discusses the Priority Score Model, which is a system used within the Fraud Prevention System (FPS). The purpose of this system is to rank providers based on program integrity guidelines, which implies ensuring the security of the healthcare system by preventing fraud. The system utilizes inputs such as Medicare Claims data, Targeted Probe and Educate (TPE) Data, and Jurisdiction information to determine the ranking of providers. This emphasis on ranking and utilizing various data sources highlights the importance of security measures in safeguarding against fraudulent activities within the healthcare system.\",\"60\":\"The theme of \\\"security\\\" is not explicitly mentioned in the provided text. The text primarily focuses on the General Services Administration's efforts to enhance their document workflow platform by implementing intelligent data capture and extraction techniques. While the text does not directly address security, it indirectly implies that the GSA is aiming to improve the security of their data transfer processes by efficiently transferring important data to appropriate processes, workflows, or decision engines. Despite the indirect implication, the theme of security is not a central focus of the text.\",\"61\":\"None\",\"62\":\"None\",\"63\":\"None\",\"64\":\"The theme \\\"security\\\" is relevant in the text above. The mention of \\\"customization and automation of agency applications for greater connectivity and security\\\" indicates that the Integrated Digital Environment aims to enhance the security of agency applications. This implies that security is an important consideration in the system's design and implementation.\",\"65\":\"None\",\"66\":\"None\",\"67\":\"None\",\"68\":\"None\",\"69\":\"The theme of \\\"security\\\" is relevant in the given text. This is because the text discusses the SSI Redetermination Model, which utilizes machine learning to identify cases of supplemental security income that may have significant overpayments. By flagging these cases for review by technicians, the system aims to ensure the security of the financial eligibility process and prevent potential fraudulent activities or errors that could compromise the security of the supplemental security income program.\",\"70\":\"The theme of \\\"security\\\" is not relevant in the given text. The text discusses the USDA's development of a natural language processing model to analyze procurement descriptions and determine the likelihood of an award being IT-related and requiring an Acquisition Approval Request (AAR). It focuses on the calculation of probabilities and the analysis of text, but it does not directly mention or address security. Therefore, the theme of \\\"security\\\" is None in this text.\",\"71\":\"None\",\"72\":\"None\",\"73\":\"None\",\"74\":\"None\",\"75\":\"None\",\"76\":\"None\",\"77\":\"None\",\"78\":\"None\",\"79\":\"The theme \\\"security\\\" is relevant in the text as it discusses the development of a machine learning-based system that aims to enhance security in the fifth generation (5G) cellular network. The system's goal is to detect attacks, which is essential for ensuring the safety and reliability of mission-critical applications such as automated vehicles, drones, connected health, and emergency response operations that depend on the 5G network.\",\"80\":\"None\",\"81\":\"None\",\"82\":\"None\",\"83\":\"The theme of \\\"security\\\" is relevant in the given text. The text discusses the use of AI in the Cyber Threat Intelligence Feed Correlation to enhance the quality of externally shared information. This implies that the AI algorithm is being used to improve the security of the shared information by quickly correlating information from multiple feeds. Additionally, it mentions the development of customized algorithms for continuous monitoring of threat actors' tactics, techniques, and procedures (TTPs), which further emphasizes the importance of security in identifying and mitigating potential cyber threats.\",\"84\":\"None\",\"85\":\"The theme of \\\"security\\\" is relevant in the given text. The Autonomous Maritime Awareness system is designed to detect, identify, and track objects of interest in a maritime environment. This system aims to enhance security by utilizing surveillance towers, ocean data solutions, unmanned autonomous surface vehicles (ASV), and AI. The low-cost surveillance towers equipped with radars and cameras, along with the ruggedized ASVs, help to monitor and safeguard maritime areas. The AI\\/ML technology employed in the system enables autonomous detection and tracking of objects, allowing for potential interdictions or intelligence collection. Therefore, the theme of security is relevant in this text as it highlights the use of advanced technology to enhance maritime security.\",\"86\":\"The theme of \\\"security\\\" is not directly relevant in the given text. The text primarily focuses on the development of a model to classify and route Service Desk tickets, aiming to automate the current manual process. While the text does not specifically mention security concerns or measures, it is possible to argue that the development of such a model indirectly relates to security. By automating the process, it may reduce the likelihood of human error or intentional mishandling of tickets, which can enhance the overall security and efficiency of the system. However, since the text does not explicitly discuss security, it can be considered as a minor or indirect aspect in this context.\",\"87\":\"None\",\"88\":\"None\",\"89\":\"None\",\"90\":\"The theme of \\\"security\\\" is relevant in the given text. It is evident as the text mentions the use of statistical models to forecast future outcomes, including the occurrence of violent events. By analyzing data, these models aim to provide a sense of security by predicting potential risks and allowing preventative measures to be taken. Additionally, the mention of applying these models to analyze tweets further emphasizes the relevance of security as it implies monitoring and predicting potential threats or incidents for public safety.\",\"91\":\"None\",\"92\":\"None\",\"93\":\"The theme of \\\"security\\\" is relevant in the given text. The discussion revolves around an application that scans documents to identify attorney\\/client privileged information. This implies that the text is concerned with protecting sensitive and confidential information from unauthorized access or disclosure. The application's purpose is to ensure the security of attorney\\/client privileged information by using keyword input provided by the system operator to perform the scanning task. Therefore, the theme of \\\"security\\\" is directly applicable in this context.\",\"94\":\"None\",\"95\":\"None\",\"96\":\"None\",\"97\":\"None\",\"98\":\"None\",\"99\":\"None\",\"100\":\"None\",\"101\":\"None\",\"102\":\"None\",\"103\":\"None\",\"104\":\"The theme of \\\"security\\\" is relevant in the given text. The Consolidated Screening List (CSL) is a tool that combines multiple export screening lists from different government departments. The purpose of these screening lists is to ensure the security of export transactions by identifying entities that may pose a risk to national security or have restrictions on exporting certain goods or technologies. The CSL allows users to perform a fuzzy name search, which helps in identifying entities even if the exact spelling of their name is not known. This feature aids in enhancing security measures by enabling users to find entities that may have translated their names into English from non-Latin alphabet languages, ensuring comprehensive screening and minimizing potential security threats.\",\"105\":\"None\",\"106\":\"None\",\"107\":\"None\",\"108\":\"None\",\"109\":\"None\",\"110\":\"None\",\"111\":\"None\",\"112\":\"The theme of \\\"security\\\" is relevant in the given text. It is evident from the mention of using machine learning algorithms to improve the detection of invasive and quarantine significant pests at the port of entry. The use of these algorithms and predictive models aims to enhance the security measures by effectively identifying and preventing the entry of such pests, thereby safeguarding the ecosystem and agricultural industry.\",\"113\":\"None\",\"114\":\"None\",\"115\":\"None\",\"116\":\"None\",\"117\":\"The theme of \\\"security\\\" is relevant in the given text. The text mentions the importance of identifying wells with sustained casing pressure (SCP) quickly to prevent safety issues and accidents on well platforms. This highlights the need for ensuring the security and stability of the platforms to prevent any potential harm or accidents.\",\"118\":\"None\",\"119\":\"The theme of \\\"security\\\" is relevant in the text. The Video Surveillance System (VSS) mentioned in the text is designed to enhance security by collecting, managing, and presenting video from multiple sources. It includes components like cameras, network switches, and routers which are essential for monitoring and ensuring the security of a particular area or premises. Additionally, the system's advanced features for tracking targets and selecting cameras further contribute to enhancing security measures.\",\"120\":\"None\",\"121\":\"None\",\"122\":\"None\",\"123\":\"The theme of \\\"security\\\" is relevant in the text. The text discusses how Project Vikela aims to prevent the smuggling of rhino horn by using artificial intelligence and advanced technology. This implies a focus on ensuring the security of airports and preventing illegal activities related to the smuggling of wildlife products.\",\"124\":\"The theme of \\\"security\\\" is relevant in the given text. This is because the Email Analytics application deals with analyzing email data, which often contains sensitive and personal information. The mention of classifying spam messages indicates the need to ensure the security of the users' email accounts by identifying and filtering potentially harmful or malicious messages. Additionally, the extraction of information about names, organizations, and locations suggests the importance of protecting users' privacy and data security. Furthermore, the inclusion of AI and machine translation capabilities highlights the need for secure handling and processing of the data to prevent unauthorized access or misuse. Therefore, the theme of \\\"security\\\" is relevant in this context.\",\"125\":\"None\",\"126\":\"None\",\"127\":\"None\",\"128\":\"The theme of security is relevant in the text because it discusses the role of security analysts in Security Operations Centers who are responsible for detecting and correlating potential cyber attacks. The text also mentions the use of automated tooling and mathematically and probabilistically based models to refine alerts and detect anomalies, which are all measures taken to enhance security.\",\"129\":\"The theme of \\\"security\\\" is relevant in the given text. The text mentions that HSI uses Artificial Intelligence to identify purposeful misidentification, which implies that it is concerned with ensuring the security of data and information. Additionally, it states that the services provided by HSI, such as normalizing addresses and validating phone numbers, are part of the Repository for Analytics in a Virtualized Environment (RAVEn), which supports ICE's mission to enforce and investigate violations of U.S. laws. This suggests that the services provided by HSI are aimed at enhancing security measures in law enforcement and investigations.\",\"130\":\"None\",\"131\":\"None\",\"132\":\"The theme of \\\"security\\\" is relevant in this text. The text mentions that CMS is using a Security Data Lake to modernize its pipelines and data tooling, which will enhance Agency security. The goal is to build a modern data platform that will allow for machine learning model development in the future, implying that security measures will need to be implemented to protect the data and ensure its integrity.\",\"133\":\"None\",\"134\":\"None\",\"135\":\"None\",\"136\":\"None\",\"137\":\"None\",\"138\":\"None\",\"139\":\"None\",\"140\":\"The theme of \\\"security\\\" is relevant in the text because the Duplicate Identification Process (DIP) helps ensure the security of cases by efficiently identifying and marking duplicate cases. By reducing the time spent on reviewing cases for hearings, DIP contributes to maintaining the security and integrity of the Social Security Administration's policies and processes.\",\"141\":\"None\",\"142\":\"None\",\"143\":\"None\",\"144\":\"None\",\"145\":\"None\",\"146\":\"None\",\"147\":\"None\",\"148\":\"None\",\"149\":\"None\",\"150\":\"None\",\"151\":\"None\",\"152\":\"None\",\"153\":\"The theme of \\\"security\\\" is relevant in the given text. The Village Monitoring System program, which utilizes AI and machine learning, is designed to analyze satellite imagery for security purposes. By using the near-infrared band, the program can identify anomalies or unusual patterns that may indicate potential security threats. Therefore, the text demonstrates the relevance of the theme \\\"security\\\" in relation to the monitoring system's capabilities.\",\"154\":\"None\",\"155\":\"None\",\"156\":\"None\",\"157\":\"None\",\"158\":\"None\",\"159\":\"None\",\"160\":\"The theme of \\\"security\\\" is relevant in the text as it discusses how malware reverse engineering is crucial for CISA's cyber defense mission. It highlights the use of advanced engineering, formal methods, and deep learning techniques to improve cyber threat intelligence. The text also emphasizes the need for scalable, automated tools to disrupt sophisticated adversaries' malware development lifecycle. Additionally, it mentions the importance of understanding deployment environments and other capabilities to enhance security.\",\"161\":\"None\",\"162\":\"None\",\"163\":\"None\",\"164\":\"None\",\"165\":\"None\",\"166\":\"The theme \\\"security\\\" is relevant in the text above. The text mentions that the project aims to develop a simulation framework that uses learning-based algorithms to detect and respond to component contingencies caused by extreme events like cyber-attacks. This indicates that the project is focused on enhancing the security of integrated energy systems by being prepared for potential cyber-attacks and other extreme events.\",\"167\":\"The theme of \\\"security\\\" is relevant in the given text. The text mentions the use of the anomalous iClaim predictive model, which is a machine learning model used to identify high-risk iClaims. This model is designed to enhance security by identifying potentially fraudulent or risky claims. The mention of sending these claims for further review before taking any action indicates that the aim is to ensure the security and accuracy of the claims processing system.\",\"168\":\"None\",\"169\":\"None\",\"170\":\"The theme of \\\"security\\\" is relevant in the given text because it discusses the development of AI Security and Robustness Frameworks, processes, and testing tools. These tools are designed to govern the acquisition, development, deployment, and maintenance of AI technologies, with the aim of ensuring the trustworthy, robust, and secure operation of AI systems. This indicates that the text is focused on the topic of security in relation to AI technologies.\",\"171\":\"None\",\"172\":\"None\",\"173\":\"None\",\"174\":\"The theme of \\\"security\\\" is relevant in the text above. This is because the research aims to develop a digital twin of a centrifugal contactor system in the nuclear fuel cycle, which is a critical component of nuclear energy production. The digital twin will receive data from sensors and use machine learning to analyze the data for anomalies, failures, and trends. This analysis is crucial for ensuring the security and safety of the nuclear fuel cycle, as it helps in identifying any potential security breaches, failures, or abnormal behavior in the system. Furthermore, the involvement of a team of nuclear safeguards experts indicates the focus on security measures and ensuring the safe operation of the system.\",\"175\":\"None\",\"176\":\"None\",\"177\":\"None\",\"178\":\"The theme \\\"security\\\" is relevant in the text. This is because Splunk, being an IT system monitoring software, plays a crucial role in enhancing the security of IT infrastructure systems and endpoints. By collecting and analyzing system logs, Splunk helps to identify potential security breaches, monitor for unusual activities, and conduct audits to ensure the security of the IT systems.\",\"179\":\"None\",\"180\":\"None\",\"181\":\"None\",\"182\":\"None\",\"183\":\"The theme of \\\"security\\\" is relevant in the given text. The text discusses the use of millimeter wave beam directionality and autonomous beam scheduling to support secure spectrum sharing for 5G. It emphasizes the importance of ensuring optimal performance for base stations and highlights the benefits of using autonomous beam scheduling algorithms for secure communication in mission critical communications, emergency response operations, and critical infrastructure. This demonstrates the relevance of the theme of \\\"security\\\" in the text.\",\"184\":\"None\",\"185\":\"None\",\"186\":\"The theme of \\\"security\\\" is relevant in the given text. The use of geospatial imagery and annotation through Synthetic Aperture Radar (SAR) satellites, along with AI technologies like machine vision and object detection, plays a crucial role in ensuring security. This technology aids in identifying airframes, military vehicles, and marine vessels, which can be important for national security and defense purposes. It also helps in detecting changes for disaster response missions, which ultimately contribute to the safety and security of affected areas. Thus, the text highlights the relevance of security in the context of geospatial imagery and AI technologies.\",\"187\":\"None\",\"188\":\"The theme of \\\"security\\\" is relevant in the text above. The text mentions the Facial Recognition Service, which is utilized by HSI agents and analysts to identify individuals involved in crimes such as child exploitation, human rights violations, and war crimes. This service is part of the DHS HSI Innovation Lab project known as RAVEn, which supports ICE's mission to enforce and investigate violations of U.S. laws. The use of this facial recognition technology and analytical tools helps enhance security by aiding in the identification of criminals and analyzing criminal patterns.\",\"189\":\"The theme of \\\"security\\\" is not directly relevant in the given text. The text focuses on the concept of topic modeling, which is a tool used for organizing and summarizing text data. It does not specifically mention or discuss security-related aspects. Therefore, the theme of security is not relevant in this context.\",\"190\":\"None\",\"191\":\"None\",\"192\":\"None\",\"193\":\"None\",\"194\":\"None\",\"195\":\"None\",\"196\":\"The theme \\\"security\\\" is relevant in the text above. The text discusses the Deepfake Detector, a deep learning model designed to identify deepfakes. Deepfakes pose a security concern as they involve the creation of synthetic faces that can be used for malicious purposes, such as spreading misinformation or impersonating individuals. The development of tools like the Deepfake Detector addresses the need for security measures to combat the potential harm caused by deepfakes.\",\"197\":\"None\",\"198\":\"None\",\"199\":\"None\",\"200\":\"None\",\"201\":\"The theme of \\\"security\\\" is relevant in the text because it discusses translating industrial control system features into a machine-readable format for use with automated cyber tools. This implies a focus on securing these systems from cyber threats. The text also mentions examining current and evolving standards for usability with diverse grid architectures, which suggests a concern for ensuring the security of these systems. Furthermore, the text mentions prioritizing future research steps for automated threat response and improved cyber incident consequence models, indicating a focus on enhancing security measures. Lastly, the text discusses enhancing national capabilities for sharing actionable threat intelligence at machine speed, which is directly related to improving security measures.\",\"202\":\"None\",\"203\":\"The theme of \\\"security\\\" is relevant in the given text. The text discusses the use case of the Line Anomaly Recommender, which aims to evaluate compliance risk and detect abnormal tax returns and line-item values. By using advanced deep learning techniques, this model enhances the understanding of IRS LB&I reviewers in identifying anomalies. This is important in terms of security as it helps to detect potential fraudulent or non-compliant activities and ensures the security of the tax system.\",\"204\":\"None\",\"205\":\"None\",\"206\":\"None\",\"207\":\"None\",\"208\":\"None\",\"209\":\"None\",\"210\":\"The theme of \\\"security\\\" is relevant in the given text. The text discusses the use of computer vision techniques to process satellite imagery, specifically for analyzing critical infrastructure and interdependency data. This technology is aimed at enhancing national critical infrastructure security and defense capabilities. Therefore, the text focuses on how the use of advanced computer vision techniques can contribute to improving security in terms of protecting critical infrastructure.\",\"211\":\"None\",\"212\":\"None\",\"213\":\"None\",\"214\":\"None\",\"215\":\"None\",\"216\":\"None\",\"217\":\"The theme of \\\"security\\\" is relevant in the text because it discusses the Cyber Sentry program, which is designed to monitor critical infrastructure networks. It utilizes advanced anomaly detection and machine learning to analyze cyber-physical data from IT and OT networks, aiming to ensure the security of these systems. Additionally, the Critical Infrastructure Anomaly Alerting model aids threat hunting analysts by providing AI-assisted processing of the information, further emphasizing the focus on security.\",\"218\":\"None\",\"219\":\"None\",\"220\":\"None\",\"221\":\"None\",\"222\":\"The theme of \\\"security\\\" is relevant in the text because it discusses the development of machine learning methodologies to assess the resilience of integrated energy systems and their vulnerabilities to threats. This implies that the goal of the project is to enhance the security of energy systems by understanding and mitigating potential risks and vulnerabilities.\",\"223\":\"None\",\"224\":\"None\",\"225\":\"None\",\"226\":\"None\",\"227\":\"None\",\"228\":\"None\",\"229\":\"The theme of \\\"security\\\" is relevant in the text because it discusses the use of advanced automation tools in cyber incident handling. These tools, which leverage Machine Learning and Natural Language Processing, help process and filter data from various threat intelligence and cyber incident channels. By doing so, they enhance the accuracy and relevance of the data presented to human analysts and decision-makers, ultimately improving the security measures taken to address cyber incidents.\",\"230\":\"None\",\"231\":\"None\",\"232\":\"None\",\"233\":\"None\",\"234\":\"None\",\"235\":\"None\",\"236\":\"The theme of \\\"security\\\" is relevant in the given text. The Conflict Observatory program utilizes AI and machine learning to analyze satellite imagery and document war crimes and abuses in Ukraine. By conducting automated damage assessments of various buildings, including critical infrastructure, hospitals, schools, and crop storage facilities, the program aims to ensure the security of these important structures.\",\"237\":\"The theme of \\\"security\\\" is relevant in the text. The project aims to improve probabilistic risk assessment by using a support vector machine and PRA software to automatically detect vulnerabilities in system design. By identifying these vulnerabilities, the project aims to enhance the security of the system by addressing previously unknown issues. This approach also reduces the need for training data that would typically only be available after system failures occur, thereby reducing the potential for security breaches and minimizing human error and associated costs.\",\"238\":\"The theme of \\\"security\\\" is relevant in the text above. The Person-Centric Identity Services (PCIS) is mentioned as a trusted source of biographical and biometric information for individuals' immigration history. The use of a de-duplication model and machine learning to identify and match records with high accuracy emphasizes the importance of ensuring the security and integrity of the data being collected and used by PCIS. The mention of gathering an individual's immigration history efficiently without the need for extensive research across multiple systems also implies a focus on maintaining the security and privacy of the information.\",\"239\":\"The theme of \\\"security\\\" is relevant in the given text. The Media Early Warning System (MEWS) is designed to ensure the security of the information shared on social media platforms. By detecting alterations in images and videos, the system aims to identify any potentially harmful narratives or trends. This emphasis on security is crucial as it enables timely monitoring and addressing of malign narratives, ultimately working towards the goal of maintaining a safe and secure online environment.\",\"240\":\"None\",\"241\":\"The theme of \\\"security\\\" is relevant in this text. The use of generative adversarial networks to automate the training of electromagnetic-based anomaly detection systems highlights the need for security in legacy industrial control systems devices and Industrial Internet of Things. The text emphasizes that this automation aims to reduce manual labor and operational costs associated with protecting these systems from intrusion, indicating the importance of maintaining security measures.\",\"242\":\"None\",\"243\":\"The theme of \\\"security\\\" is not relevant in the text above. The text primarily focuses on prioritizing alerts produced by the Fraud Prevention System based on forecasted time. It discusses the inputs and outputs of this prioritization process but does not directly address the concept of security.\",\"244\":\"None\",\"245\":\"None\",\"246\":\"None\",\"247\":\"The theme \\\"security\\\" is relevant in the text because it mentions that the Chatbot is designed to help the Security team. By automating email responses to general physical security questions, the Chatbot ensures that accurate and consistent information is provided to employees and contractors. This helps in maintaining the security of the organization by efficiently addressing common security concerns.\",\"248\":\"None\",\"249\":\"None\",\"250\":\"None\",\"251\":\"None\",\"252\":\"The theme of \\\"security\\\" is relevant in the text because it discusses the use of AI technology for validating official documents. By detecting mismatched addresses and garbled text in letters sent to benefits recipients, the technology ensures the security and accuracy of important information.\",\"253\":\"The theme of \\\"security\\\" is relevant in the given text. The text discusses the development of external monitoring methods to safeguard industrial internet of things devices. The aim is to ensure the security of these devices by analyzing physical aspects and detecting any abnormal functionality that might indicate a potential attack. This indicates a focus on ensuring the security and protection of the intelligent devices from potential threats.\",\"254\":\"None\",\"255\":\"None\",\"256\":\"None\",\"257\":\"The theme of \\\"security\\\" is relevant in the text because it discusses how AIS Automated Scoring & Feedback (AS&F) uses descriptive analytics to classify indicators of compromise (IOCs) based on organizational-centric intelligence data. This implies that the system is used for security purposes to identify potential threats or compromises within an organization's network. It also mentions the need for verification by an analyst and the importance of filtering and prioritizing actions and investigations, which are all related to maintaining the security of the organization's systems and data.\",\"258\":\"None\",\"259\":\"None\",\"260\":\"The theme \\\"security\\\" is relevant in the text above. The text mentions that A\\/LM plans to develop AI\\/ML models to detect potential fraud or malfeasance in their Integrated Logistics Management System (ILMS). This indicates that the company is concerned about the security of their system and wants to enhance existing risk analytics in order to ensure the security and integrity of their supply chain functions such as Asset Management, Procure-to-Pay, and Fleet Management.\",\"261\":\"None\",\"262\":\"None\",\"263\":\"None\",\"264\":\"None\",\"265\":\"None\",\"266\":\"The theme of \\\"security\\\" is not relevant in this text. The text primarily focuses on the description of a deep neural network called DeepCNet and its ability to identify and classify various features related to railroad tracks. It also mentions the network's use in \\\"change detection\\\" applications to detect any changes in the track's status or between different inspections based on geolocation. Although the network's capabilities may have implications for safety and maintenance of the tracks, the text does not directly address the theme of security.\",\"267\":\"None\",\"268\":\"None\",\"269\":\"None\",\"270\":\"None\",\"271\":\"None\",\"272\":\"The theme of \\\"security\\\" is relevant in the given text. The Department of Homeland Security (DHS) is using Text Analytics for Survey Responses (TASR) to analyze and extract important topics\\/themes from open-ended survey responses. This indicates that the DHS is concerned about the security and well-being of its employees by actively seeking their feedback and addressing their concerns. The extracted topics\\/themes are then utilized by DHS Leadership to improve employee satisfaction and meet their basic needs, which further emphasizes the importance of ensuring a secure and stable work environment for the employees.\",\"273\":\"None\",\"274\":\"The theme of \\\"security\\\" is relevant in the given text. The use of machine learning to predict veterans' suicidal thoughts after leaving the military highlights the concern for their overall well-being and mental health. By collecting data through a web-based survey, the aim is to identify potential risks and provide necessary support, ensuring the security and safety of veterans as they transition into civilian life.\",\"275\":\"None\",\"276\":\"None\",\"277\":\"None\",\"278\":\"The theme of \\\"security\\\" is not relevant in the given text. The text primarily discusses the process of auto tagging and its benefits in terms of efficiency and categorization of content. It does not touch upon any aspect related to security or the protection of data or information.\",\"279\":\"The theme of \\\"security\\\" is relevant in the text. The text mentions that the team aims to train AI models on determining important attributes for cybersecurity in digital twins. This shows that the team is concerned about the security aspect of digital twins and wants to ensure that they are protected from potential threats.\",\"280\":\"None\",\"281\":\"None\",\"282\":\"None\",\"283\":\"None\",\"284\":\"None\",\"285\":\"None\",\"286\":\"The theme of \\\"security\\\" is relevant in the text. The use of the Solicitation Review Tool (SRT) and the application of machine learning algorithms aim to ensure the security of Information and Communications Technology (ICT) solicitations. The SRT analyzes the solicitations to determine if they contain compliance language, which suggests that security measures are being taken into account. Additionally, the validation process by agencies and the monthly random manual reviews conducted by GSA further emphasize the importance of security in the context of solicitation reviews.\",\"287\":\"The theme of \\\"security\\\" is relevant in the text above. The text mentions that the Level 1 surveys obtained from BSEE are used to assess safety concerns related to the condition of well platforms. The purpose of these surveys is to ensure the security and safety of the platforms. Additionally, the text suggests that an automated screening system could be implemented to identify areas with excessive corrosion, which would in turn improve the security of the platforms by addressing potential safety hazards more efficiently.\",\"288\":\"None\",\"289\":\"The theme of \\\"security\\\" is relevant in the text. The text discusses the development of a framework for automated malware analysis using dynamic sandboxes. This indicates a focus on securing computer systems from malware threats. Additionally, the framework aims to provide capabilities for analyzing industrial control system malware, sharing threat information, and enabling further analysis through machine learning. All these objectives are related to enhancing security measures against malware attacks.\",\"290\":\"None\",\"291\":\"None\",\"292\":\"None\",\"293\":\"None\",\"294\":\"None\",\"295\":\"None\",\"296\":\"None\",\"297\":\"The theme of \\\"security\\\" is relevant in the given text. The text mentions that the Operations Center in CISA (Cybersecurity and Infrastructure Security Agency) uses an artificial intelligence-powered dashboard to assist duty officers and analysts in understanding ongoing operational activities. This indicates that the main focus is on ensuring the security of operational activities. Additionally, the AI system mentioned in the text combines real-time event data, historical cybersecurity information, and previous response activity to suggest appropriate actions and engagement strategies. This further emphasizes the importance of security in dealing with potential impacts to national critical functions.\",\"298\":\"None\",\"299\":\"None\",\"300\":\"None\",\"301\":\"None\",\"302\":\"None\",\"303\":\"None\",\"304\":\"None\",\"305\":\"None\",\"306\":\"The theme of \\\"security\\\" is relevant in the given text. The mention of the ICAD system using automated software called Matroid to analyze and annotate photographs taken by field imaging equipment implies that the system is concerned with ensuring the security of the surroundings. The software's ability to determine if the images contain human subjects and recognize objects, people, and events in any image or video stream is likely employed to enhance security measures. Additionally, the goal of expanding the software's capabilities to include vehicles and subjects with long-arm rifles suggests a further emphasis on security.\",\"307\":\"None\",\"308\":\"None\",\"309\":\"The theme of \\\"security\\\" is not directly relevant in the given text. The text primarily focuses on the use of Predictive Intelligence (PI) in the Quality Service Center (QSC) to assign incidents based on their short descriptions. It mentions the training of the solution with incident data every 3-6 months, but it does not specifically address security concerns or measures related to the handling of incidents. Therefore, the theme of \\\"security\\\" is None in this text.\",\"310\":\"None\",\"311\":\"None\",\"312\":\"None\",\"313\":\"None\",\"314\":\"None\",\"315\":\"None\",\"316\":\"None\",\"317\":\"The theme of \\\"security\\\" is not relevant in the given text. This text primarily discusses the capabilities of the SMART system on OpenNet, which involves tasks such as entity extraction, sentiment analysis, keyword extraction, and historical data analysis. While these capabilities may have implications for information management and communication, there is no direct mention of security measures or concerns in this specific text.\",\"318\":\"The theme of \\\"security\\\" is not directly relevant in the given text. The text mainly focuses on the development of an AI-based recommender system that detects potential non-compliance issues, aiming to enhance the efficiency and scalability of training returns selection and field work processes. While the text does not directly mention security, it indirectly implies the importance of security measures in identifying and addressing non-compliance issues to ensure a secure and compliant environment. However, the text does not provide specific details or examples related to security measures or concerns.\",\"319\":\"The theme of \\\"security\\\" is not relevant in the given text. The text mainly focuses on the capabilities and functions of the virtual agent named SAM, which utilizes manual learning and natural language processing to understand customer needs and provide appropriate responses. There is no mention or indication of any security-related aspects in the text.\",\"320\":\"None\",\"321\":\"None\",\"322\":\"The theme of \\\"security\\\" is relevant in the text because it mentions the use of neural networks and AI technologies to identify and detect no-changes in digital imagery for the NRI program. This indicates that advanced technologies are being employed to ensure the security and protection of national resources. These technologies help in analyzing and monitoring the resources, which contributes to maintaining a sense of security in relation to the national resources.\",\"323\":\"The theme of \\\"security\\\" is relevant in the text above. The text describes how the Complaint Lead Value Probability Threat Intake Processing System (TIPS) database uses artificial intelligence algorithms to efficiently identify and process actionable tips. This system helps prioritize immediate threats, allowing FBI field offices and law enforcement to respond promptly to the most serious threats. The mention of prioritizing tips with the highest algorithm score for human review emphasizes the importance of security in addressing potential threats.\",\"324\":\"None\",\"325\":\"The theme of \\\"security\\\" is relevant in the text because it discusses the use of advanced automation tools, such as Machine Learning and Natural Language Processing, to process and aggregate data for vulnerability analysts. These tools help improve the accuracy and relevance of filtered information, which is essential in the field of security. Additionally, the mention of Machine Learning techniques aiding in aggregating information from databases like KEV and CVE highlights the importance of security in analyzing and presenting information for decision-making.\",\"326\":\"None\",\"327\":\"None\",\"328\":\"None\",\"329\":\"The theme of \\\"security\\\" is not directly relevant in the text. The text primarily focuses on ILMS creating an automated support desk assistant to improve customer interactions and reduce the workload of support desk agents. It emphasizes streamlining operations and minimizing costs. However, it does not mention any specific security measures or concerns related to the system. Therefore, the theme of security is not present in this text.\",\"330\":\"None\",\"331\":\"None\",\"332\":\"None\",\"333\":\"None\",\"334\":\"The theme of \\\"security\\\" is relevant in the text above. The text discusses an AI system that focuses on detecting and tracking illicit cross-border traffic in remote locations. This system aims to enhance security by using IoT sensor kits, motion image\\/video systems, and AI algorithms to detect vehicles and determine their direction. The system also captures high-resolution images and processes them using AI models for object classification and re-identification. Overall, the text emphasizes the importance of security in detecting and monitoring potential threats.\",\"335\":\"The theme of \\\"security\\\" is not directly relevant in the given text. The text primarily discusses the features and benefits of RelativityOne, a document review platform that aims to streamline the process of reviewing and producing large volumes of documents in legal contexts. While security is an important aspect of any document review platform, the text does not mention or emphasize it explicitly. Therefore, the relevance of the theme \\\"security\\\" in this text is None.\",\"336\":\"None\",\"337\":\"None\",\"338\":\"The theme of \\\"security\\\" is relevant in the given text. \\n\\nThe text mentions that Conflict Forecasting CSO\\/AA is working on creating forecasting models to predict conflict outcomes such as interstate war, mass mobilization, and mass killings. This indicates a focus on anticipating and understanding potential security threats and conflicts. The use of open-source data on political, social, and economic factors suggests an analysis of various factors that can impact security. Additionally, the utilization of statistical AI techniques like machine learning and clustering methods implies an effort to enhance security forecasting capabilities. Therefore, the theme of \\\"security\\\" is relevant in this text.\",\"339\":\"None\",\"340\":\"None\",\"341\":\"The theme \\\"security\\\" is relevant in the text above. The text discusses the Rapid Authority to Operate (ATO) System, which uses natural language processing (NLP) to analyze system security plans. It specifically mentions that the system helps identify commonly used technology components in Federal Information Security Management Act (FISMA) systems. This indicates a focus on ensuring the security of the systems used by the Centers for Medicare and Medicaid Services (CMS). The system helps identify similar approaches to solving control areas within Acceptable Risk Safeguards (ARS) and streamlines the generation of system security plans for new systems. This emphasis on security throughout the text makes the theme \\\"security\\\" relevant.\",\"342\":\"None\",\"343\":\"None\",\"344\":\"None\",\"345\":\"The theme of \\\"security\\\" is relevant in the given text. The text mentions the Cybersecurity and Infrastructure Security Agency (CISA), which is an organization specifically focused on security. It highlights the agency's use of advanced analytics and forensic specialists to investigate cyber events in government departments and agencies. The use of artificial intelligence tools is also mentioned, which helps in analyzing data and detecting anomalies and potential threats more efficiently. This demonstrates the importance of security measures and technologies in combating cyber threats and ensuring the safety of government departments, agencies, and partners.\",\"346\":\"None\",\"347\":\"None\",\"348\":\"None\",\"349\":\"None\",\"350\":\"In the given text, the theme of \\\"security\\\" is not directly relevant. The text primarily focuses on the Expenditure Classification Autocoder, a machine learning model used for classifying and categorizing expenses. It does not mention any aspects related to security, such as protecting sensitive data, ensuring secure transactions, or safeguarding against potential threats. Therefore, the theme of \\\"security\\\" is not applicable in this text.\",\"351\":\"None\",\"352\":\"None\",\"353\":\"None\",\"354\":\"None\",\"355\":\"None\",\"356\":\"None\",\"357\":\"None\",\"358\":\"None\",\"359\":\"The theme of \\\"security\\\" is not relevant in this text. The text primarily focuses on the development of software called Video Computer Aided Detection (VCAD) that allows users to create and share vision detectors. It mentions the software's ability to recognize objects, people, and events in images or videos, provide reports and alert notifications, and integrate with other applications. However, there is no explicit mention of security or any related aspects in the text.\",\"360\":\"None\",\"361\":\"None\",\"362\":\"The theme of \\\"security\\\" is not directly relevant in the given text. The text talks about the use of third-party global trade data and AI\\/ML models to enhance investigations and support software's knowledge graph and user interface. While the text discusses data management and analysis, it does not explicitly mention security measures or concerns. None.\",\"363\":\"The theme of \\\"security\\\" is relevant in the text above. The text discusses the development of a machine learning system that focuses on detecting 5G attacks, specifically zero-day attacks. Zero-day attacks refer to vulnerabilities that are exploited before they are known or have been patched, making them a significant security concern. The use of field programmable gate array based deep autoencoders indicates the emphasis on addressing these vulnerabilities and enhancing security measures.\",\"364\":\"None\",\"365\":\"The theme of \\\"security\\\" is not directly relevant in the given text. The text primarily focuses on explaining the main idea and functionality of CALI, an automated machine learning tool used for evaluating vendor proposals. It mentions the processing and analysis of documents, as well as the training of CALI with sample data from the EULAs under the Multiple Award Schedule program. However, it does not provide any information or discussion about the security aspects of CALI or how it ensures data security during the Source Selection process. Therefore, the theme of \\\"security\\\" is not addressed in the text.\",\"366\":\"None\",\"367\":\"None\",\"368\":\"None\",\"369\":\"None\",\"370\":\"None\",\"371\":\"None\",\"372\":\"The theme of \\\"security\\\" is not directly relevant in the given text. The text primarily discusses the use of an AI retrieval system for trademark design coding and image search, focusing on its purpose and expected functionality. It does not mention any specific security concerns or measures related to the system. Therefore, the theme of \\\"security\\\" is not applicable in this context.\",\"373\":\"None\",\"374\":\"None\",\"375\":\"None\",\"376\":\"None\",\"377\":\"None\",\"378\":\"The theme of \\\"security\\\" is not directly relevant in the given text. The text primarily discusses the development and deployment of an AI chatbot for HRSA EHBs grantees, its features, and integration with existing systems. While security measures might be implied or assumed in the chatbot's integration with EHBs application UI and Salesforce, the text does not explicitly address security aspects or considerations. Therefore, the relevance of the theme \\\"security\\\" in this text is None.\",\"379\":\"The theme of \\\"security\\\" is relevant in the given text. The text mentions that the MARS program is working on developing a safety case for reducing separation standards between PBN routes in terminal airspace. By reducing separation standards, the program aims to deconflict airports in high-demand areas, which can enhance the security of air travel. Additionally, the text talks about the need to identify rare events where aircraft fail to navigate procedures correctly, which is crucial for building collision risk models. This emphasis on identifying and addressing potential incidents further highlights the relevance of the theme of \\\"security\\\" in the text.\",\"380\":\"None\",\"381\":\"None\",\"382\":\"None\",\"383\":\"None\",\"384\":\"None\",\"385\":\"The theme of \\\"security\\\" is relevant in the text because the use of predictive analytics and the Autonomous Track Geometry Measurement System (ATGMS) helps ensure the security and safety of railway tracks. By analyzing and predicting track locations of concern, the system helps identify potential issues before they lead to failures or accidents. This information is then used to generate an inspection report that aids in maintenance and setting safety limits, thus enhancing the overall security of the railway system.\",\"386\":\"None\",\"387\":\"The theme of \\\"security\\\" is not relevant in the given text. The text primarily discusses the introduction of a chatbot to streamline customer experience and automate answering frequently asked questions. It highlights the benefits of reducing the need for live chat agents and allocating resources to other customer service initiatives. However, it does not touch upon any aspects related to security.\",\"388\":\"None\",\"389\":\"The theme of \\\"security\\\" is relevant in the provided text. The text discusses a research goal to enhance the assessment of security in machine learning and artificial intelligence systems. It specifically mentions activities like reverse engineering, exploitation, risk assessment, and vulnerability remediation, which are all related to identifying and addressing security weaknesses in these systems. The text emphasizes the need to bridge gaps in understanding and develop risk evaluation metrics to improve cybersecurity practices in the field of AI.\",\"390\":\"None\",\"391\":\"None\",\"392\":\"None\",\"393\":\"None\",\"394\":\"None\",\"395\":\"None\",\"396\":\"None\",\"397\":\"The theme \\\"security\\\" is relevant in the text. The text introduces the Rep Payee Misuse Model, which is a machine learning model designed to predict the likelihood of representative payees misusing resources. By identifying cases that require further examination, the model aims to prevent the misuse of funds. This demonstrates a focus on ensuring the security and proper utilization of resources.\",\"398\":\"The theme of \\\"security\\\" is relevant in the text above. The use of artificial intelligence in the I-485 Family Matching system is aimed at improving the reliability of matching family members with their underlying I-485 petitions. By leveraging AI, the system is able to identify and group I-485s filed by family members more accurately, which can contribute to faster and more efficient processing. The emphasis on reliability and accuracy in matching and processing these petitions highlights the importance of ensuring the security of the immigration process.\",\"399\":\"None\",\"400\":\"The theme of \\\"security\\\" is relevant in the given text. The text discusses Advanced Network Anomaly Alerting, Threat hunting, and Security Operations Center (SOC) analysts who receive data from the National Cybersecurity Protection System's (NCPS) Einstein sensors. These analysts use manual and automated techniques to detect network attacks and refine their alerts, aiming to ensure timely and accurate detection of anomalies. This highlights the importance of security in protecting networks and systems from potential threats.\",\"401\":\"None\",\"402\":\"None\",\"403\":\"None\",\"404\":\"None\",\"405\":\"None\",\"406\":\"None\",\"407\":\"The theme \\\"security\\\" is relevant in the text above. The text discusses a project that focuses on using machine learning and artificial intelligence algorithms to detect false data injection in physical processes. The aim of the project is to enhance the security of these processes by developing an advanced library that can detect and prevent malicious tampering. Therefore, security is a central concern in this context.\",\"408\":\"None\",\"409\":\"None\",\"410\":\"The theme \\\"security\\\" is not relevant in the given text. The text primarily focuses on the implementation of a chatbot assistant by the Department of Labor to provide information and support to employees. There is no mention of any security concerns or measures related to the chatbot or the intranet websites.\",\"411\":\"The theme of \\\"security\\\" is not directly relevant in the given text. The text focuses on the utilization of machine learning to forecast the retention schedule for records and integrating it into a records management application. While security may indirectly play a role in the implementation and protection of the records management application, it is not explicitly mentioned or discussed in the text. Therefore, the relevance of the theme \\\"security\\\" is None in this context.\",\"412\":\"None\",\"413\":\"None\",\"414\":\"None\",\"415\":\"None\",\"416\":\"None\",\"417\":\"None\",\"418\":\"The theme \\\"security\\\" is relevant in the text above. It is emphasized that inspectors can utilize Hololens AI technology to visually inspect high and unsafe areas without jeopardizing their safety. By using this technology, inspectors can assess these areas from a secure location, which enhances their security and minimizes potential risks or dangers they may face while physically inspecting such locations.\",\"419\":\"The theme of \\\"security\\\" is not relevant in the given text. The text primarily focuses on the capabilities of the Autonomous Aerostat Aerostat, which includes launching and recovering aerostats based on weather conditions and eliminating the need for on-site staff. While these capabilities may have indirect implications for security (e.g., reducing human presence in potentially risky situations), the text does not directly address security concerns or discuss any specific security measures.\",\"420\":\"None\",\"421\":\"None\",\"422\":\"None\",\"423\":\"The theme of \\\"security\\\" is relevant in the text as it discusses the use of the Automated PII Detection and Human Review Process. This process aims to detect potential personally identifiable information (PII) in submissions, which is a security concern. The system ensures compliance with privacy requirements by flagging PII, reviewing it, and redacting it if necessary. The emphasis on analytics, natural language processing, and learning from feedback also indicates a focus on maintaining security and protecting sensitive information.\",\"424\":\"The theme \\\"security\\\" is relevant in the given text because it discusses the Autonomous Surveillance Towers that are equipped with artificial intelligence technology. These towers are designed to detect, identify, and track items of interest without the need for a dedicated operator. By constantly scanning the surroundings and alerting the user, the towers enhance security by providing near real-time photos and tracking objects autonomously. Additionally, the system being easily deployable and relocatable allows for flexible security measures in different locations.\",\"425\":\"None\",\"426\":\"The theme of \\\"security\\\" is not relevant in the given text. This text primarily discusses the Land Use Plan Document and Data Mining and Analysis R&D project, which focuses on analyzing unstructured planning documents to identify patterns and conflicts in resource management planning rules. The purpose of the project is to uncover information that can aid in identifying proposed action locations that may require exclusion, restrictions, or stipulations. While this project deals with data analysis and resource management, it does not directly address the concept of \\\"security.\",\"427\":\"None\",\"428\":\"None\",\"429\":\"The theme \\\"security\\\" is not relevant in the given text. The text discusses the Text Similarity capability of GEC A&R, which identifies and groups similar texts based on cosine similarity. Although this capability may have implications for data analysis and information management, it does not directly relate to the concept of security.\",\"430\":\"None\",\"431\":\"The theme of \\\"security\\\" is not directly relevant in the given text. The text primarily discusses the functionality and benefits of the Grants Analytics Portal, which is a tool that utilizes AI to provide efficient access to grants data for HHS OIG staff. Although the text mentions the ability to identify potential anomalies in grantees, it does not explicitly discuss the security measures in place to protect the data or prevent unauthorized access. Therefore, the theme of \\\"security\\\" is not relevant in this context.\",\"432\":\"None\",\"433\":\"The theme of \\\"security\\\" is relevant in the text because it discusses the use of an Artificial Intelligence solution to address the issue of spam and marketing emails in civil rights complaints email channels. By automatically classifying and removing these unwanted emails, the solution aims to enhance the security of the email channels by ensuring that only legitimate and relevant emails are received.\",\"434\":\"None\",\"435\":\"None\",\"436\":\"None\",\"437\":\"None\",\"438\":\"The theme of \\\"security\\\" is not directly mentioned in the text. The text primarily discusses the AVS International office's need to comply with ICAO Standards and Recommended Practices (SARPs) and the use of the Regulatory Compliance Mapping Tool (RCMT) to process documents and establish matches between SARPs and FAA text. The focus is on compliance and document processing rather than security. Therefore, the theme of \\\"security\\\" is not relevant in this text.\",\"439\":\"None\",\"440\":\"None\",\"441\":\"The theme of \\\"security\\\" is not directly relevant in the given text. The text primarily focuses on how the company plans to utilize transactional data and user interactions to create customized experiences and improve efficiency. While security may indirectly play a role in ensuring the protection of user data during the process, it is not explicitly mentioned or emphasized.\",\"442\":\"None\",\"443\":\"None\",\"444\":\"The theme of \\\"security\\\" is relevant in the text. It is mentioned that the technology service called Sealr utilizes blockchain encryption and artificial intelligence to secure and detect tampering of photographs taken on smartphones. This highlights the importance of ensuring the security of sensitive information and data related to the delivery of foreign assistance in conflict-affected areas. Additionally, the use of Sealr as a tool for remote monitoring in dangerous or inaccessible areas further emphasizes the need for security in such situations.\",\"445\":\"None\",\"446\":\"None\",\"447\":\"None\",\"448\":\"None\",\"449\":\"None\",\"450\":\"None\",\"451\":\"The theme \\\"security\\\" is relevant in the given text. The DEA's Special Testing and Research Laboratory utilizes AI and machine learning techniques to classify the geographic origin of samples in their Heroin and Cocaine signature programs. By using statistical analysis tools to automatically detect anomalies and low confidence results, the laboratory ensures the security of their classification process by minimizing errors and inaccuracies. This emphasis on security is crucial in maintaining the integrity of the classification system and the overall goal of effectively combating drug trafficking.\",\"452\":\"None\",\"453\":\"None\",\"454\":\"None\"},\"environmental\":{\"0\":\"None\",\"1\":\"None\",\"2\":\"None\",\"3\":\"None\",\"4\":\"None\",\"5\":\"None\",\"6\":\"None\",\"7\":\"None\",\"8\":\"None. The text does not mention anything related to the environment or any environmental issues. It focuses on the use of remote sensing and modeling techniques to improve earthquake damage assessment and prediction abilities.\",\"9\":\"None\",\"10\":\"None\",\"11\":\"None\",\"12\":\"None\",\"13\":\"None\",\"14\":\"The theme \\\"environmental\\\" is relevant in the given text. The text mentions that the dataset includes orthomosaic and satellite images of coastal, estuarine, and wetland environments. It also mentions that the dataset contains over 1.2 billion labeled pixels, representing more than 3.6 million hectares. This indicates that the text is discussing a collection of data related to various environmental settings, emphasizing the relevance of the environmental theme.\",\"15\":\"None\",\"16\":\"None\",\"17\":\"The theme \\\"environmental\\\" is relevant in the text above. This is because the project focuses on predicting and forecasting daily hydrologic drought in the Colorado River Basin. Hydrologic droughts have direct implications on the environment, as they can impact water availability, ecosystem health, and overall environmental balance. Additionally, the project involves using gridded meteorologic forcing data, which is related to weather patterns and climate, both of which are key components of the environment. The cooperation with CHS (possibly referring to a government agency or organization with an environmental focus) and the utilization of HPC systems from the USGS further emphasize the relevance of the environmental theme in this text.\",\"18\":\"None\",\"19\":\"None\",\"20\":\"None\",\"21\":\"None\",\"22\":\"The theme \\\"environmental\\\" is not relevant in the given text. The text primarily discusses the Coastal Change Analysis Program (C-CAP)'s use of geographic object-based image analysis, machine learning algorithms, and convolutional neural networks (CNN) for land cover classification and data development. It does not directly address environmental concerns or the impact on the environment.\",\"23\":\"None\",\"24\":\"None\",\"25\":\"None\",\"26\":\"None\",\"27\":\"None\",\"28\":\"None\",\"29\":\"None\",\"30\":\"None\",\"31\":\"None\",\"32\":\"The theme \\\"environmental\\\" is relevant in the text above. The text discusses the Water Mission Area Drought Prediction Project, which focuses on predicting daily hydrologic drought. This implies a concern for the environment and the impact of drought on water resources. Additionally, the project aims to use machine learning models calibrated on streamflow and meteorological data, indicating a scientific approach to understanding and managing environmental conditions. Overall, the text highlights the project's focus on environmental factors and their role in predicting and managing drought.\",\"33\":\"None. The text does not mention anything related to the environment or environmental issues. It focuses on the features and functionalities of the RMRS Raster Utility, which is a .NET library for data acquisition, raster sampling, statistical and spatial modeling, and incorporates machine learning techniques.\",\"34\":\"None\",\"35\":\"The theme \\\"environmental\\\" is relevant in the text above. The text discusses how robotic microscopes and machine learning algorithms are being used to track and monitor phytoplankton. Phytoplankton are a vital part of marine food webs and can be affected by changes in the ocean. By deploying these technologies, scientists can assess the changes in phytoplankton communities in relation to ocean and climate variability. This highlights the importance of understanding and monitoring the environment and its impact on marine ecosystems.\",\"36\":\"None\",\"37\":\"The theme \\\"environmental\\\" is not relevant in the given text. The text primarily focuses on improving the detection and classification process of ice seals in aerial imagery, reducing false positive rates, and minimizing the need for post-survey review. While the project may indirectly contribute to environmental conservation by potentially reducing human interference in seal habitats, the text itself does not directly address or emphasize environmental concerns. Therefore, the relevance to the theme \\\"environmental\\\" is None.\",\"38\":\"The theme \\\"environmental\\\" is not relevant in the given text. The text primarily focuses on the improvement of the standard technique for measuring thermal diffusivity using a modified experimental setup and a machine learning tool. There is no mention or discussion about environmental factors or their impact in this context.\",\"39\":\"The theme \\\"environmental\\\" is relevant in the text because the project aims to estimate the amount of water flowing in small, unmonitored stream networks. By doing so, they are collecting data that can contribute to understanding and monitoring the environment. Additionally, the project aims to create a web-based platform that allows easy access to climate data, which is also related to the environment. Lastly, users can contribute data to the database, which can further enhance the understanding of the environmental factors affecting water flow.\",\"40\":\"None\",\"41\":\"The theme \\\"environmental\\\" is relevant in the text because it discusses the forecasting of water temperature in the Delaware River Basin. Water temperature is an important environmental factor that can impact various aspects of the ecosystem, including aquatic life, water quality, and overall ecosystem health. The researchers' approach to forecasting water temperature in real-time can help in monitoring and managing environmental conditions in the Delaware River Basin, making it relevant to the environmental theme.\",\"42\":\"None\",\"43\":\"None\",\"44\":\"The theme \\\"environmental\\\" is not relevant in the given text. The text primarily discusses NASA SERVIR's project of enhancing urban vulnerability assessment in major population centers using satellite imagery and artificial intelligence. The focus is on mapping informal settlements and developing replicable methods for future use. While the text does not specifically mention the environment or any environmental concerns, it may indirectly contribute to environmental awareness by providing valuable data for urban planning and resource management in these population centers. However, the direct relevance to the theme \\\"environmental\\\" is limited in this context.\",\"45\":\"None\",\"46\":\"None\",\"47\":\"None\",\"48\":\"None\",\"49\":\"None\",\"50\":\"None\",\"51\":\"None\",\"52\":\"None\",\"53\":\"None\",\"54\":\"None\",\"55\":\"None\",\"56\":\"None\",\"57\":\"None\",\"58\":\"The theme \\\"environmental\\\" is not relevant in the given text. This is because the text primarily discusses the Ecosystem Management Decision Support System (EMDS), which is a spatial decision support system used within ArcGIS and QGIS. It focuses on the technical aspects of the system, such as creating applications tailored to specific needs and utilizing various AI engines. There is no mention or discussion of environmental issues, conservation, or any other topic related to the environment.\",\"59\":\"None\",\"60\":\"None\",\"61\":\"None\",\"62\":\"None\",\"63\":\"None. The text does not mention anything related to the environment or environmental issues. It primarily discusses the improvement and development of a nowcasting model for predicting severe weather events, along with the funding and proposal for its operational update.\",\"64\":\"None\",\"65\":\"None\",\"66\":\"None\",\"67\":\"None\",\"68\":\"None\",\"69\":\"None\",\"70\":\"None\",\"71\":\"None\",\"72\":\"None\",\"73\":\"None. \\nThe text does not provide any information or context related to the environment or environmental issues. It focuses on describing a machine learning product and its capabilities in predicting excessive rainfall.\",\"74\":\"None\",\"75\":\"The theme \\\"environmental\\\" is relevant in the text above. The text mentions that NOAA Coral Reef Watch uses remote sensing, modeling, and in situ data to help prepare for and respond to coral reef ecosystem stressors caused by climate change and warming oceans. They provide early warnings and outlooks of stressful environmental conditions at targeted reef locations worldwide. Additionally, their products focus on sea surface temperature and incorporate other variables such as light and ocean color, which are environmental factors. Therefore, the theme \\\"environmental\\\" is relevant in this text.\",\"76\":\"None\",\"77\":\"The theme \\\"environmental\\\" is not relevant in the given text. The text focuses on the utilization of AI tools, machine learning, and natural language processing to analyze publicly-funded data and evidence in serving science and society. It discusses the goal of democratizing access to this information and making it more widely available. There is no mention or connection to environmental issues or concerns in the text.\",\"78\":\"None\",\"79\":\"None\",\"80\":\"None\",\"81\":\"None\",\"82\":\"None\",\"83\":\"None\",\"84\":\"The theme \\\"environmental\\\" is relevant in the text above. The text discusses the use of machine learning and object-based image classification techniques to identify buildings, building loss, and defensible space in wildland-urban interface areas before and after a wildfire. This application is aimed at mapping wildfire damage and assessing the effectiveness of defensible space measures, which directly relates to environmental concerns and the impact of wildfires on the surrounding environment.\",\"85\":\"The theme \\\"environmental\\\" is relevant in the text above because it mentions the use of low-cost surveillance towers equipped with radars and cameras, as well as ruggedized autonomous surface vehicles (ASVs) that are powered by wind, solar, or onboard engines. This indicates that the system is designed to minimize its environmental impact by utilizing renewable energy sources rather than relying solely on fossil fuels.\",\"86\":\"None\",\"87\":\"None\",\"88\":\"None\",\"89\":\"None\",\"90\":\"None\",\"91\":\"None\",\"92\":\"The theme \\\"environmental\\\" is relevant in the text because it discusses the long-term impacts of land-use and land-cover dynamics on surface water quality. It also mentions the effects of climate change on water quality and availability. The study aims to analyze these environmental factors using satellite data and artificial intelligence methods. Additionally, the study intends to develop empirical models for estimating water quality and mapping a water quality index using in-situ measurements and satellite imagery.\",\"93\":\"None\",\"94\":\"None\",\"95\":\"The theme \\\"environmental\\\" is relevant in the text above. The text discusses a model that utilizes natural language processing techniques to classify NIFA funded projects as either climate change related or not. Climate change is an environmental issue, and the model uses text fields such as project titles, non-technical summaries, objectives, and keywords to determine if a project is related to climate change. Therefore, the theme of \\\"environmental\\\" is relevant in this context.\",\"96\":\"None\",\"97\":\"None\",\"98\":\"None\",\"99\":\"None\",\"100\":\"The theme \\\"environmental\\\" is relevant in the text above. The text specifically mentions aquatic environments and the need to identify and locate aquatic weeds. This demonstrates an awareness of the impact of these weeds on the environment and the importance of addressing them in order to maintain a healthy aquatic ecosystem.\",\"101\":\"None\",\"102\":\"The theme \\\"environmental\\\" is not relevant in the given text. The text focuses on the development and testing of a hybrid statistical-dynamical prediction system for climate variability predictions. While climate variability is indirectly related to the environment, the text does not directly discuss environmental issues or the impact of climate on the environment.\",\"103\":\"None\",\"104\":\"None\",\"105\":\"The theme \\\"environmental\\\" is relevant in the given text. The text discusses VIAME, an open-source software toolkit specifically designed for the analysis of imagery in the marine environment. The purpose of VIAME is to aid users in automatically annotating imagery using deep-learning algorithms. Additionally, the text mentions that VIAME is available for free to NOAA (National Oceanic and Atmospheric Administration) users and is supported by the NOAA Fisheries Office of Science and Technology. This indicates its relevance to the environmental field, specifically in terms of marine conservation and research.\",\"106\":\"None\",\"107\":\"None\",\"108\":\"None\",\"109\":\"None\",\"110\":\"None\",\"111\":\"The theme \\\"environmental\\\" is not relevant in this text. The text focuses on the development of a next-generation prototype for generating water supply forecasts and the use of AI and data-science technologies to improve accuracy. While water management is important for environmental sustainability, the text does not specifically discuss environmental issues or concerns.\",\"112\":\"The theme \\\"environmental\\\" is not relevant in the text. None. This is because the text focuses on the use of machine learning algorithms for predicting and improving the detection of pests at the port of entry, without any direct mention or connection to environmental concerns or impacts.\",\"113\":\"None\",\"114\":\"None\",\"115\":\"None\",\"116\":\"None\",\"117\":\"The theme \\\"environmental\\\" is not relevant in the given text. The text primarily focuses on the identification and prevention of safety issues and accidents on well platforms caused by sustained casing pressure (SCP). There is no mention or connection to environmental concerns or issues related to the natural surroundings or ecosystems.\",\"118\":\"None\",\"119\":\"None\",\"120\":\"None\",\"121\":\"The theme \\\"environmental\\\" is not relevant in the given text. This text primarily discusses the technical details and production of the GOES-16 Solar Ultraviolet Imager (SUVI) and its data products. It does not directly address or discuss environmental issues or concerns.\",\"122\":\"The theme \\\"environmental\\\" is relevant in the given text. The study aims to connect data on the flow of the Delaware River with models of trout population dynamics, changes in fish catch, and the economic benefits of recreational fishing. This implies that the study is focusing on the ecological aspects of the river and its impact on the trout population. Additionally, the study mentions the use of observational data and literature estimates, which further reinforces the environmental theme by relying on existing information related to the river's ecosystem.\",\"123\":\"The theme \\\"environmental\\\" is relevant in the text above. This is because the text discusses the use of artificial intelligence to detect illegal rhino horn in airplane luggage X-Ray scanners. The main goal of this project is to prevent the smuggling of rhino horn, which is an environmental concern. Rhinos are endangered species, and the illegal trade of their horns contributes to their decline. Therefore, by utilizing advanced technology to detect and prevent the smuggling of rhino horn, the project aims to protect the environment and conserve the rhino population.\",\"124\":\"None\",\"125\":\"None\",\"126\":\"None\",\"127\":\"None\",\"128\":\"None\",\"129\":\"None\",\"130\":\"The theme \\\"environmental\\\" is relevant in the text because the Landscape Change Monitoring System (LCMS) is a data system designed by the USDA Forest Service to monitor changes in vegetation canopy cover, land cover, and land use. This implies that the system is focused on monitoring and analyzing environmental changes, specifically in relation to vegetation and land.\",\"131\":\"None\",\"132\":\"None\",\"133\":\"The theme \\\"environmental\\\" is not directly relevant in the given text. The text primarily focuses on the technical aspects of the Cropland Data Layer (CDL) and its accuracy in classifying the type of crops or activities in specific areas using satellite sensors and machine learning algorithms. It does not discuss the environmental impact or implications of this data layer. Hence, the relevance of the environmental theme in this text is None.\",\"134\":\"None\",\"135\":\"The theme \\\"environmental\\\" is relevant in the text provided. The text discusses the work of the Seabird Studies Team, who conducted aerial surveys to study marine birds and mammals in the ocean off central and southern California. This indicates a focus on the environment and the impact of human activities on marine life. Additionally, the team used machine learning techniques to process the large volume of images, showcasing the use of technology to study and understand the environment. The mention of generating maps of species distribution and abundance to inform planning for offshore wind energy development further emphasizes the environmental theme, as it highlights the consideration of environmental factors in the development of renewable energy sources.\",\"136\":\"None\",\"137\":\"None\",\"138\":\"None\",\"139\":\"None\",\"140\":\"None\",\"141\":\"None\",\"142\":\"The theme \\\"environmental\\\" is relevant in the text above. The project focuses on studying the distribution and ecology of green sea turtles in southern California. It aims to understand the population size, residency patterns, and foraging habits of the turtles. By engaging with local photographers to collect underwater images and using facial recognition software to identify individual turtles, researchers can gather information about these turtles' interactions with their environment.\",\"143\":\"None\",\"144\":\"The theme \\\"environmental\\\" is relevant in the given text. The text discusses the investigation of replacing unstructured wave models in the Great Lakes with two AI models, namely a Recurrent Neural Network (RNN) and a boosted ensemble decision tree. The purpose of these models is to improve the accuracy and efficiency of predicting and modeling waves in Lake Erie. By utilizing these AI models, researchers aim to enhance the understanding of wave patterns and behaviors in the lake, which directly relates to the environmental aspect of studying and monitoring the Great Lakes ecosystem.\",\"145\":\"None\",\"146\":\"None\",\"147\":\"None\",\"148\":\"The theme \\\"environmental\\\" is not relevant in the text above. The text specifically mentions the Fisheries Electronic Monitoring Library (FEML), which is a centralized database for storing electronic monitoring data related to marine life. While this database is important for monitoring marine life and fisheries, it does not directly address or discuss environmental issues or concerns. Thus, the theme \\\"environmental\\\" is not applicable in this context.\",\"149\":\"None\",\"150\":\"None\",\"151\":\"The theme \\\"environmental\\\" is relevant in the text above. The project focuses on using AI to automate the detection and classification of wildlife from aerial imagery. By developing and training algorithms to identify and categorize wildlife, the project aims to contribute to environmental conservation efforts. Additionally, the use of databases to store annotated data and image metadata suggests a commitment to preserving and organizing information related to the environment.\",\"152\":\"The theme \\\"environmental\\\" is relevant in the text above. The text discusses the VOLCAT system, which utilizes AI-powered satellite applications to detect volcanic ash, a hazardous material. Volcanic ash poses a significant risk to aviation, highlighting the environmental impact of volcanic eruptions. The goal of the project is to enhance the VOLCAT products to meet new International Civil Aviation Organization requirements, which emphasizes the importance of environmental safety in the aviation industry.\",\"153\":\"None. The given text does not mention anything about the environment or environmental issues. It focuses on the use of AI and machine learning in the Village Monitoring System program to analyze satellite imagery for detecting anomalies or unusual patterns.\",\"154\":\"The theme \\\"environmental\\\" is relevant in the given text. The text discusses how machine learning models are being utilized to map and monitor forest mortality and defoliation across the United States. This indicates that the focus is on the environment and the impact on forests. The use of machine learning models in this context highlights the importance of technology and data analysis in understanding and managing environmental issues.\",\"155\":\"None\",\"156\":\"None\",\"157\":\"None\",\"158\":\"The theme \\\"environmental\\\" is relevant in the given text. The text discusses how the EPA's Office of Compliance and the University of Chicago collaborated to develop a proof-of-concept that aimed to enhance the enforcement of environmental regulations through facility inspections. The use of predictive analytics in this initiative resulted in a 47% improvement in identifying violations of the Resource Conservation and Recovery Act, which is an environmental regulation. Therefore, the text directly relates to the theme of environmental issues and regulations.\",\"159\":\"The theme \\\"environmental\\\" is relevant in the text above. The text discusses a study that aims to map benthic algae along the Buffalo National River in northern Arkansas. Benthic algae are a significant component of river ecosystems and can have an impact on the overall health and environmental conditions of the river. The study focuses on using orthophotos and multispectral images to collect data and develop a classification algorithm to distinguish between different levels of algal density. This research is important for understanding and monitoring the environmental conditions of the river and the potential impact of algal growth.\",\"160\":\"None\",\"161\":\"None\",\"162\":\"None. The text does not mention or discuss anything related to the environment or environmental issues. It focuses on the use of artificial intelligence and machine learning in analyzing photogrammetric data obtained from unmanned aerial systems for better decision making, but does not address environmental concerns or the impact on the environment.\",\"163\":\"The theme \\\"environmental\\\" is not relevant in the given text. The text primarily focuses on the detection of pre-symptomatic citrus trees infected with Huanglongbing (HLB) through the use of multispectral and thermal imagery. While this topic is related to agriculture and plant health, it does not directly address environmental aspects such as ecosystems, conservation, or sustainability.\",\"164\":\"The theme \\\"environmental\\\" is relevant in the text above. This is because the text discusses the development of a system to predict flood flow metrics for stream reaches based on watershed characteristics and long-term meteorological data. Floods are natural disasters that can have a significant impact on the environment, causing damage to ecosystems, vegetation, and wildlife habitats. By predicting flood flow metrics, this system aims to better understand and manage the environmental impacts of floods. Additionally, the mention of catchments, which are areas where water is collected, implies a focus on the natural environment and the need to consider the environmental characteristics of these areas when predicting flood flow metrics. Therefore, the theme \\\"environmental\\\" is relevant in this text.\",\"165\":\"None\",\"166\":\"The theme \\\"environmental\\\" is not relevant in the given text. This text focuses on developing a simulation framework that combines physics models with grid monitoring data to make real-time decisions for integrated energy systems operation. It primarily discusses the use of learning-based algorithms to detect and respond to component contingencies caused by extreme events like cyber-attacks or extreme weather. There is no direct mention or discussion of environmental concerns or impacts in the text.\",\"167\":\"None\",\"168\":\"None\",\"169\":\"None\",\"170\":\"None\",\"171\":\"None\",\"172\":\"None\",\"173\":\"The theme \\\"environmental\\\" is not relevant in the given text. The text primarily discusses the development and expansion of deep learning algorithms for automating the identification of right whales in photos. It mentions the use of these algorithms on the Flukebook platform and the submission of a paper about the system for review at Mammalian Biology. However, it does not directly address any environmental aspects or issues related to the right whales or their habitat.\",\"174\":\"None\",\"175\":\"None\",\"176\":\"None\",\"177\":\"None. The text does not mention anything about the environment or any environmental issues.\",\"178\":\"None\",\"179\":\"The theme \\\"environmental\\\" is not relevant in the given text. This text primarily discusses the development of a multi-task deep learning model and the use of meteorological variables to predict streamflow and stream water temperature. There is no mention or connection to environmental issues or concerns.\",\"180\":\"None\",\"181\":\"The theme \\\"environmental\\\" is not relevant in the given text. The text primarily discusses the NAL Automated indexing Cogito software, which utilizes artificial intelligence to annotate journal articles. It mentions the National Ag Library Thesaurus concept space and various databases related to agriculture. While these databases may contain articles related to the environment, the text itself does not provide any information or context specifically regarding the environmental theme. Therefore, the relevance of the environmental theme is None.\",\"182\":\"The theme \\\"environmental\\\" is relevant in the given text. The development of an AI system to identify individual fish and detect diseases from images has potential implications for the environment. If successful, this system could replace traditional methods used for estimating fish abundance and movement, which could lead to more efficient and sustainable fisheries management practices. By reducing costs for fisheries managers, there is a possibility of minimizing the negative impact on the environment caused by traditional methods. Furthermore, the ability to assess fish health status and trends through disease detection from images could contribute to better understanding and monitoring of the environmental health of fish populations.\",\"183\":\"None\",\"184\":\"None\",\"185\":\"The theme \\\"environmental\\\" is not relevant in the given text. This text is focused on the development of a deep reinforcement learning approach for managing distributed or tightly coupled multi-agent systems in energy systems. It discusses the utilization of deep neural networks for system representation, modeling, and learning. There is no mention of environmental factors or concerns in this text.\",\"186\":\"The theme \\\"environmental\\\" is not relevant in the given text. The text primarily focuses on the use of geospatial imagery, annotation, and AI technology for various purposes such as identifying airframes, military vehicles, marine vessels, and detecting changes for disaster response missions. While the technology described can have implications for environmental monitoring or assessing the impact of disasters on the environment, the text does not specifically address or discuss environmental concerns or issues.\",\"187\":\"None\",\"188\":\"None\",\"189\":\"None\",\"190\":\"None\",\"191\":\"The theme \\\"environmental\\\" is not relevant in the given text. The text primarily focuses on the importance of AI-based automation of acoustic detection of marine mammals for adapting mitigation measures in response to climate change. Although the text mentions the acoustic repertoire of Alaska region marine mammals, it does not discuss any specific environmental issues or concerns related to the environment.\",\"192\":\"None. The text does not mention anything related to the environment or any environmental issues. It focuses on the ARS Project Mapping NLP tool and its purpose of enhancing collaboration and coordination among research programs.\",\"193\":\"None\",\"194\":\"The theme \\\"environmental\\\" is not relevant in the given text. None of the ideas mentioned in the text directly relate to the environment or any environmental issues. The text mainly focuses on the development of a model for predicting dissolved oxygen concentrations in stream locations using meteorological inputs and static catchment attributes. The use of Python, R, TensorFlow, and Snakemake are mentioned as the tools and technologies being used for this work.\",\"195\":\"The theme \\\"environmental\\\" is not relevant in the given text. The text primarily focuses on the project's objective of classifying walrus haulout camera trap images using codes developed for wildlife underpass camera trap image classification. It discusses the system's ability to determine the probability of an image containing walruses and human disturbances such as boats and aircraft. The text mentions the training, validation, and testing datasets used to train and evaluate the models, as well as the use of a convolutional neural network (CNN) approach based on TensorFlow and performed on the USGS Tallgrass supercomputer. However, there is no direct mention or relevance to the broader environmental context or concerns. Therefore, the answer is None.\",\"196\":\"None\",\"197\":\"None\",\"198\":\"The theme \\\"environmental\\\" is relevant in this text because it mentions the use of automated machine learning tools to study environmental processes affecting marine mammal density and distribution. Additionally, the project aims to analyze long-term recordings from passive acoustic moored instruments in the Gulf of Mexico, further emphasizing its focus on the environmental aspect.\",\"199\":\"The theme \\\"environmental\\\" is relevant in the text because it discusses the monitoring of the endangered western Steller sea lion population in Alaska. By conducting aerial surveys, the NOAA Fisheries Alaska Fisheries Science Center's Marine Mammal Laboratory collects data on the sea lion population, which is crucial for understanding the species and ecosystem. This information is then used to inform sustainable fishery management decisions, highlighting the connection between the environment and the need for responsible resource management.\",\"200\":\"None\",\"201\":\"None\",\"202\":\"None\",\"203\":\"None\",\"204\":\"None\",\"205\":\"None\",\"206\":\"None\",\"207\":\"None\",\"208\":\"The theme \\\"environmental\\\" is not relevant in the given text. The text primarily focuses on the project's goals and techniques related to developing an image library, using machine learning and deep learning, and processing imagery. However, it does not mention any specific environmental concerns or implications.\",\"209\":\"The theme \\\"environmental\\\" is relevant in the text above because it discusses the use of high throughput phenotyping techniques to monitor the health of citrus orchards. By assessing the overall well-being of citrus trees, it implies a concern for the environment and the sustainability of the orchard.\",\"210\":\"None\",\"211\":\"None\",\"212\":\"None\",\"213\":\"None\",\"214\":\"None\",\"215\":\"The theme \\\"environmental\\\" is not relevant in the text. The text primarily focuses on the application of machine learning to predict ground shaking during earthquakes, the usage of seismic data from different areas, and the transition to a cloud computing platform. There is no mention or connection to the environment or environmental concerns.\",\"216\":\"None. The text does not mention anything related to the environment or environmental issues. It focuses on the development of neural network radiations for forecasting systems.\",\"217\":\"None\",\"218\":\"None. The text does not mention anything related to the environment or environmental issues. It focuses on streamflow forecasting technologies and a prize competition, which are not directly relevant to the theme of environmental.\",\"219\":\"The theme \\\"environmental\\\" is not relevant in the given text. The text primarily discusses the Land Change Analysis Tool (LCAT) and its process of creating land cover maps using machine learning and aerial\\/satellite imagery. It does not touch upon any environmental aspects or address any concerns related to the environment. Therefore, the answer is None.\",\"220\":\"None. The text does not mention anything related to the environment or environmental issues. It focuses on the use of machine learning techniques for predicting precipitation and temperature, specifically for drought outlooks in the United States.\",\"221\":\"The theme \\\"environmental\\\" is not directly relevant in this text. The text focuses on the use of photogrammetric products, drones, and other devices to analyze and map cracks on Reclamation facilities. It mentions implementing a standardized protocol and utilizing machine learning and AI to make informed decisions about Reclamation assets. While the project may have indirect environmental implications, such as potentially reducing the need for physical access to facilities and improving efficiency, the text does not specifically address environmental concerns or impacts.\",\"222\":\"None\",\"223\":\"None\",\"224\":\"None\",\"225\":\"None\",\"226\":\"None\",\"227\":\"None\",\"228\":\"None\",\"229\":\"None\",\"230\":\"None\",\"231\":\"None\",\"232\":\"None.\\n\\nThe text does not discuss the theme of \\\"environmental\\\" and does not provide any information or context related to the environment or environmental issues. The text primarily focuses on the development and training of a deep learning model for predicting lake water temperatures, as well as the software used for modeling.\",\"233\":\"None\",\"234\":\"None\",\"235\":\"The theme \\\"environmental\\\" is relevant in the text above. The text discusses the importance of understanding changes in sub-surface drainage and their effects on streamflow and water quality. This implies a concern for the environment and the potential impact of these changes. Additionally, the use of satellite imagery and geospatial analysis techniques highlights the relevance of environmental monitoring and the use of technology for assessing environmental factors.\",\"236\":\"None\",\"237\":\"None\",\"238\":\"None\",\"239\":\"None\",\"240\":\"None\",\"241\":\"None\",\"242\":\"The theme \\\"environmental\\\" is relevant in the given text. This is because the text discusses the EcoCast, which is an operational tool that focuses on modeling the distribution of swordfish and bycatch species in the California Current. By utilizing boosted regression trees, this tool aims to reduce bycatch and support sustainable fisheries. The mention of sustainable fisheries and reducing bycatch indicates a focus on environmental conservation and management.\",\"243\":\"None\",\"244\":\"The theme \\\"environmental\\\" is not relevant in the given text. The text primarily focuses on the automated detection of hazardous low clouds for the purpose of ensuring safe and efficient transportation. While satellite imagery and machine learning are mentioned, there is no direct connection or discussion about the impact on the environment or environmental concerns. Therefore, the theme \\\"environmental\\\" is not applicable in this context.\",\"245\":\"None\",\"246\":\"None\",\"247\":\"None\",\"248\":\"None\",\"249\":\"None\",\"250\":\"The theme \\\"environmental\\\" is not relevant in the given text. The text focuses on the use of machine learning software to analyze camera images of a wind sock to determine surface wind speed and direction in remote areas. While this information is related to weather and the environment, the text does not specifically address any environmental issues, concerns, or impacts. Therefore, the theme \\\"environmental\\\" is None in this case.\",\"251\":\"None\",\"252\":\"None\",\"253\":\"None\",\"254\":\"The theme \\\"environmental\\\" is relevant in the given text. The text discusses how NASA SERVIR is using artificial intelligence to predict harmful algae blooms in Lake Atitl\\u00e1n, Guatemala. Algae blooms can have detrimental effects on the environment, as they can deplete oxygen levels in the water and harm aquatic life. By utilizing machine learning and data from Earth observations and weather models, NASA SERVIR is able to provide daily forecasts of these harmful algal blooms. This information is then used by Lake Authorities to inform their Harmful Algal Blooms Alert System, which helps in taking appropriate measures to mitigate the environmental impact of the blooms. The support of National Geographic and Microsoft also highlights the importance of addressing environmental concerns in this project. Therefore, the theme \\\"environmental\\\" is highly relevant in the given text.\",\"255\":\"None\",\"256\":\"The theme of \\\"environmental\\\" is relevant in this text. The text discusses the use of a neural network to differentiate between exposed bare rock and soil covered areas in land cover classification. This distinction is important for understanding the environmental composition of an area. The researchers aim to accurately map soil vs. rock-covered areas, which has implications for various environmental applications such as landslide hazard mapping and calculating water fluxes.\",\"257\":\"None\",\"258\":\"The theme \\\"environmental\\\" is relevant in the text because it discusses the prediction and estimation of intake rates for a large number of chemicals. This implies that the study is focused on understanding the potential exposure of these chemicals in the environment and its impact on human intake. Additionally, the mention of identifying chemicals with potentially high intake rates highlights the importance of studying and assessing the environmental presence and impact of these substances.\",\"259\":\"The theme \\\"environmental\\\" is relevant in the given text. The text mentions that the CLT knowledge database aims to support the increasing use of mass timber, which benefits forest health. This implies that the use of cross-laminated timber (CLT) as an alternative to traditional timber can have positive environmental impacts. By promoting the use of CLT, the text suggests an emphasis on sustainable and environmentally friendly practices in the construction industry.\",\"260\":\"None\",\"261\":\"None\",\"262\":\"The theme \\\"environmental\\\" is relevant in the given text. This is because the text discusses the development of a system that will aid in population research of walruses. Population research is a crucial component of environmental studies as it helps monitor and understand the impact of human activities on wildlife and ecosystems. By using advanced technology like convolutional neural networks and drones, the system aims to accurately detect and count individual walruses in their natural environment. Consequently, this research contributes to the broader understanding of the environmental health and conservation of walruses in Alaska.\",\"263\":\"The theme \\\"environmental\\\" is not relevant in the given text. The text primarily discusses the research methodology of using artificial neural networks to identify surface water in different areas. It mentions training the neural networks with annotated hydrography data, various types of remotely sensed data, and surface flow models. Additionally, it states that the researchers are utilizing open-source tools in a high-performance computing environment. While the research may have potential implications for environmental studies or applications, the text itself does not directly address or emphasize environmental issues.\",\"264\":\"None\",\"265\":\"None\",\"266\":\"None\",\"267\":\"None\",\"268\":\"None\",\"269\":\"None\",\"270\":\"None\",\"271\":\"The theme \\\"environmental\\\" is relevant in the text because it discusses the use of machine learning and high-resolution remote sensing data to enhance the mapping of wetlands and floodplains. This mapping is important for managing protected species and making informed decisions in operations and planning, which directly relates to the environmental aspect of resource management and conservation.\",\"272\":\"None\",\"273\":\"The theme \\\"environmental\\\" is relevant in the given text because it talks about the use of machine learning to analyze a large amount of data related to soils and ecological state. The analysis of this data is an important aspect of understanding and studying the environment, its conditions, and how it is changing. Therefore, the text highlights the relevance of the environmental theme.\",\"274\":\"None\",\"275\":\"The theme \\\"environmental\\\" is relevant in the text above because it mentions that NASA SERVIR's GEOGloWS ECMWF Streamflow Service (GESS) uses Earth Observations (EO) to create a system that forecasts flow on every river worldwide. This indicates that the text is discussing the use of technology and data to understand and manage water resources, which is directly related to the environmental theme.\",\"276\":\"None\",\"277\":\"None\",\"278\":\"None\",\"279\":\"None\",\"280\":\"None\",\"281\":\"The theme \\\"environmental\\\" is relevant in the text above. The text mentions that the National Landcover database (NLCD) uses artificial intelligence and machine learning to generate landcover data for all 50 states. This data is then used to estimate wildlife habitat, urban runoff, population growth, and other related factors. These factors are directly related to the environment and indicate the importance of understanding and managing the impact of human activities on the environment. Therefore, the text highlights the relevance of the environmental theme.\",\"282\":\"None\",\"283\":\"The theme \\\"environmental\\\" is not relevant in the given text. The text focuses on developing expertise and resources for Explainable AI in WMA PUMP Projects, with the goal of predicting stream temperature, discharge, dissolved oxygen, and other characteristics. While these predictions may have implications for the environment, the text does not specifically address environmental issues or concerns. Therefore, the theme \\\"environmental\\\" is None in this context.\",\"284\":\"None\",\"285\":\"None\",\"286\":\"None\",\"287\":\"The theme \\\"environmental\\\" is not directly relevant in the given text. The text primarily discusses the condition of well platforms, safety concerns, and report processing time. It does not mention any specific environmental factors or considerations related to the environment. Therefore, the relevance of the environmental theme in this text is None.\",\"288\":\"None\",\"289\":\"None\",\"290\":\"None\",\"291\":\"None\",\"292\":\"None\",\"293\":\"None\",\"294\":\"None\",\"295\":\"None\",\"296\":\"None\",\"297\":\"None\",\"298\":\"The theme \\\"environmental\\\" is not relevant in the given text. The text primarily focuses on the development of a system to identify individual mountain lions using facial images and its potential use for researchers to mark and estimate the population of mountain lions. While this information is related to wildlife conservation and research, it does not directly address any specific environmental concerns or issues. Therefore, the theme \\\"environmental\\\" is not applicable to this text.\",\"299\":\"None\",\"300\":\"The theme \\\"environmental\\\" is not relevant in the given text. This is because the text mainly focuses on the efforts of researchers to detect and identify branded Steller sea lions from remote camera images in the western Aleutian Islands. While this topic may have implications for wildlife conservation or ecological research, it does not directly address the broader environmental issues or concerns.\",\"301\":\"None. The text does not mention anything related to the environment or environmental issues. It primarily discusses a system called The Fouling Identification Neural Network (FINN) that uses supervised learning to predict and detect sensor fouling at USGS stream gages.\",\"302\":\"The theme \\\"environmental\\\" is relevant in the given text. The text discusses the Fish and Climate Change Database (FiCli), which specifically focuses on the impact of climate change on inland fishes globally. This directly addresses the environmental aspect of how climate change affects aquatic ecosystems and fish populations. Additionally, the creators of the database aim to automate parts of the review process to make it more efficient, which aligns with the broader goal of addressing environmental issues by providing up-to-date and well-maintained information on climate change impacts.\",\"303\":\"The theme \\\"environmental\\\" is not directly relevant in the given text. The text primarily focuses on the efforts of Reclamation in conducting prize competitions to develop data-driven methods for predicting temperature and precipitation in the western US. It mentions collaborating with the Scripps Institute of Oceanography to refine and pilot the most promising methods. The emphasis is on improving sub-seasonal forecasts to have a significant impact on water management outcomes. Overall, the text does not explicitly address environmental concerns or issues.\",\"304\":\"The theme \\\"environmental\\\" is relevant in the given text. The text describes how passive acoustic analysis, a machine learning technique, is being utilized to detect and classify the signals emitted by beluga whales in Cook Inlet, AK. The purpose of this analysis is to gain an understanding of various aspects related to the whales' habitat, including seasonal distribution and impact of human disturbance. This indicates a clear focus on environmental factors and how they affect the beluga whales. Additionally, the project aims to expand its analysis to include other cetacean species and anthropogenic noise, further emphasizing the environmental theme.\",\"305\":\"None\",\"306\":\"None\",\"307\":\"None\",\"308\":\"None. The text does not mention anything related to the environment or any environmental issues. It focuses on the use of deep learning computer vision algorithms to analyze particle size grading of crushed aggregate, which is unrelated to the theme of the environment.\",\"309\":\"None\",\"310\":\"The theme \\\"environmental\\\" is not relevant in the given text. The text primarily focuses on the USGS National Earthquake Information Center using deep learning to enhance their earthquake monitoring system. It discusses how AI models were trained to analyze waveform data and improve automatic earthquake detection and characterization. Although the text mentions Python, Keras, and Tensorflow as the tools used for development, it does not provide any information or context related to the environment or environmental concerns. Therefore, the theme \\\"environmental\\\" is not relevant in this text.\",\"311\":\"None\",\"312\":\"The theme \\\"environmental\\\" is relevant in the text because it mentions courses that focus on geospatial and remote sensing, which are techniques used to study and monitor the environment. The topics covered, such as change detection and utilizing Collect Earth Online, are specifically related to environmental monitoring and analysis.\",\"313\":\"None. \\n\\nThe text does not mention anything related to the environment or environmental factors. It focuses on the development of ground-motion models and the inclusion of certain explanatory variables for predicting peak ground acceleration and peak ground velocity.\",\"314\":\"The theme \\\"environmental\\\" is relevant in the text above. The text discusses the development of a machine learning model to predict the location of the salt front in the Delaware River Estuary. By using data on river discharge, tidal forcings, and meteorological data, the researchers aim to understand and analyze the environmental factors affecting the movement of the salt front. This demonstrates the focus on the environment and the impact of various natural factors on the estuary's dynamics.\",\"315\":\"None\",\"316\":\"None\",\"317\":\"None\",\"318\":\"None\",\"319\":\"None\",\"320\":\"None\",\"321\":\"None\",\"322\":\"The theme \\\"environmental\\\" is not directly relevant in the given text. The text discusses the use of neural networks and AI technologies in identifying and detecting no-changes in digital imagery for the NRI program. While the NRI program may indirectly relate to environmental resources, the main focus of the text is on the use of advanced technologies for analysis and monitoring, rather than the environment itself. Therefore, the relevance to the environmental theme is minimal.\",\"323\":\"None\",\"324\":\"The theme \\\"environmental\\\" is relevant in the text because it discusses the identification and classification of clutter obstructed radio frequency propagation paths caused by vegetation, buildings, and other structures. This indicates a focus on understanding and analyzing the impact of the environment on radio signal loss. Additionally, the use of lidar data to train the convolutional neural network (CNN) further emphasizes the relevance of the environmental theme, as lidar technology is commonly used for environmental mapping and analysis.\",\"325\":\"None\",\"326\":\"The theme \\\"environmental\\\" is not directly relevant in the given text. The text primarily discusses a study that proposes a method called meta-transfer learning to predict water temperature dynamics in unmonitored lakes. The focus is on different model types and their performance in transferring knowledge for making predictions in unobserved lakes. The text does not provide any specific information or discussion about the environmental implications or impacts of the study or its findings.\",\"327\":\"None\",\"328\":\"The theme \\\"environmental\\\" is not relevant in the given text. None. The text primarily discusses FathomNet, a platform that provides training data for machine learning algorithms to analyze visual data. It mentions the use of interns and college class curriculums to annotate and localize imagery from NOAA videos, which aids in training their algorithms. However, the text does not address any specific environmental aspects or concerns.\",\"329\":\"None\",\"330\":\"None\",\"331\":\"None. The text does not discuss or mention anything related to the environment or environmental issues. It focuses on the use of an artificial intelligence system to support rulemaking processes, specifically in analyzing and categorizing comments on proposed rules.\",\"332\":\"None\",\"333\":\"None\",\"334\":\"None\",\"335\":\"None\",\"336\":\"None\",\"337\":\"None\",\"338\":\"None\",\"339\":\"The theme \\\"environmental\\\" is not directly relevant in the given text. The text primarily focuses on the use of deep learning tools to extract and recognize terrain features, rather than discussing the environment or environmental issues. Therefore, None.\",\"340\":\"The theme \\\"environmental\\\" is not relevant in the given text. The text primarily focuses on the development of a multi-sensor data science system for analyzing solvent extraction processes in order to improve target metals recovery, identify process faults, account for special nuclear material, and make real-time decisions. There is no mention of any environmental factors or concerns related to the system or the processes being analyzed.\",\"341\":\"None\",\"342\":\"None\",\"343\":\"None\",\"344\":\"The theme \\\"environmental\\\" is not relevant in the given text. This text primarily focuses on the Offshore Precipitation Capability (OPC) and how it uses various data sources and machine learning techniques to improve the accuracy of identifying and predicting precipitation. It does not mention any direct connection to the environment or environmental issues.\",\"345\":\"None\",\"346\":\"The theme \\\"environmental\\\" is relevant in the text because it discusses the development of a system to predict specific conductance in inland stream reaches. Specific conductance is an important environmental parameter that measures the ability of water to conduct an electrical current, which can provide insight into water quality and environmental health. The system will utilize watershed characteristics, land use, and meteorological data, all of which are environmental factors, to make predictions. Additionally, the mention of the USGS Tallgrass supercomputer indicates the involvement of technological advancements in the field of environmental research. Overall, the text highlights the importance of understanding and monitoring the environmental conditions of stream reaches in the Delaware River Basin.\",\"347\":\"None\",\"348\":\"None\",\"349\":\"None\",\"350\":\"None\",\"351\":\"None\",\"352\":\"The theme \\\"environmental\\\" is not relevant in the given text. This text focuses on the development of a system for detecting and mapping host plants and generating maps using street view images. While the system may have potential environmental applications, the text does not directly discuss any environmental concerns or implications.\",\"353\":\"None\",\"354\":\"None\",\"355\":\"None. The text provided does not mention or discuss anything related to the environment or environmental issues.\",\"356\":\"The theme \\\"environmental\\\" is relevant in the given text. The text discusses a project that aims to predict the thickness of the regolith layer in the Delaware River Basin. Understanding the thickness of the regolith layer is crucial for groundwater and hydrologic modeling, which are important aspects of environmental science. By utilizing data collected from private well drillers and training a Random Forest model, the researchers hope to create a data product that can support these environmental modeling efforts.\",\"357\":\"The theme \\\"environmental\\\" is relevant in the given text as it discusses the use of high-frequency satellite images to estimate water depth in river channels. This application is important in understanding and monitoring the environmental conditions of river ecosystems. Additionally, the text mentions the use of field measurements of water depth from different rivers as training data, indicating a focus on understanding and analyzing the environmental characteristics of these water bodies.\",\"358\":\"None\",\"359\":\"None\",\"360\":\"The theme \\\"environmental\\\" is relevant in the given text. The text mentions that a system is being developed to predict lake water temperature. This indicates that the focus is on understanding and studying the environment, specifically the temperature of the lakes. Additionally, the text mentions the use of meteorological data, which further emphasizes the environmental aspect of the topic. The development of models using Python packages such as PyTorch on the USGS Tallgrass supercomputer also suggests the application of advanced technology to monitor and analyze environmental conditions.\",\"361\":\"The theme \\\"environmental\\\" is not relevant in the given text. The text mainly describes a machine learning product that predicts excessive rainfall based on atmospheric variables. While the prediction of excessive rainfall is indirectly related to the environment, the text does not provide any specific information or discussion about the broader environmental impact or concerns. Therefore, the theme \\\"environmental\\\" is not applicable in this context.\",\"362\":\"None\",\"363\":\"None\",\"364\":\"The theme \\\"environmental\\\" is not directly relevant in the given text. The text primarily focuses on discussing a model that classifies waterfowl behavior using GPS relocations and potentially habitat data. While the study of waterfowl behavior does have an indirect connection to the environment, the text does not specifically address any environmental issues or concerns. Therefore, the relevance of the environmental theme in this text is None.\",\"365\":\"None\",\"366\":\"None\",\"367\":\"None. The text does not mention anything related to the environment or environmental issues. It focuses on the use of VIAME for automated identification of reef fish and the creation of models for the SEAMAP Reef Fish Video survey.\",\"368\":\"None\",\"369\":\"None\",\"370\":\"None\",\"371\":\"None\",\"372\":\"None\",\"373\":\"None\",\"374\":\"None. The text does not mention anything related to the environment or environmental issues. It focuses on the use of Natural Language Processing (NLP) tools for regulatory comment analysis and the benefits it provides for government agencies.\",\"375\":\"None\",\"376\":\"None\",\"377\":\"None\",\"378\":\"None\",\"379\":\"None\",\"380\":\"The theme \\\"environmental\\\" is relevant in the text because it discusses the use of a large dataset to predict stream habitat conditions in the Chesapeake Bay Watershed. This implies a focus on the natural environment and the impact of human activities on it. The project aims to assess and predict the physical habitat condition of the stream reaches, highlighting the environmental aspect of the study. Additionally, the mention of updating the model quickly with new data suggests a continuous monitoring and evaluation of the environmental conditions in the region.\",\"381\":\"None\",\"382\":\"The theme \\\"environmental\\\" is relevant in the given text. The text discusses the use of species distribution models for fluvial fish species in the United States. These models utilize landscape data and anthropogenic impacts to predict the presence or absence of each species in stream segments. This indicates a focus on understanding and analyzing the environmental factors that influence the distribution of these fish species.\",\"383\":\"None\",\"384\":\"None\",\"385\":\"None\",\"386\":\"The theme \\\"environmental\\\" is relevant in the text above. The collaboration between USGS, USFWS, and the University of Michigan is developing a machine learning model to analyze fish movement in restored coastal wetlands. By accurately identifying, tracking, and quantifying fish movement, the model will provide valuable information for wetland managers and researchers in estimating fish habitat use and supporting the restoration of coastal wetland habitats. This demonstrates a focus on environmental conservation and the importance of understanding and managing the ecosystem in coastal wetlands.\",\"387\":\"None\",\"388\":\"None. The text is not relevant to the theme \\\"environmental\\\" as it focuses on the use of Artificial Neural Networks to enhance the accuracy of weather forecasts, rather than addressing environmental concerns or issues.\",\"389\":\"None\",\"390\":\"None\",\"391\":\"None\",\"392\":\"None\",\"393\":\"None. The text does not mention anything related to the environment or environmental issues. It focuses on the development of a multispectral aerial imaging payload for the purpose of analyzing and assessing arctic mammals.\",\"394\":\"None\",\"395\":\"None\",\"396\":\"The theme \\\"environmental\\\" is relevant in the given text. The researchers are using machine learning and modeling techniques to predict water temperature in the Delaware River Basin. This prediction is significant in understanding and managing the environmental conditions of the river. They trained their model using a process-based model that predicts stream flow and temperature, which further emphasizes the environmental aspect of their research.\",\"397\":\"None\",\"398\":\"None\",\"399\":\"The theme \\\"environmental\\\" is relevant in the text above. The text mentions the TreeMap 2016 model, which is used to match forest plot data to a grid and provide a detailed representation of forests in the United States. This indicates that the text is discussing the environment and specifically forests. Furthermore, the text states that the model is being used in sectors such as fuel treatment planning and estimating carbon resources, both of which are directly related to environmental concerns. Additionally, the model incorporates predictor variables such as forest cover, height, topography, and disturbance history, which are all environmental factors associated with forests. Thus, the theme \\\"environmental\\\" is relevant in this text.\",\"400\":\"None\",\"401\":\"The theme of \\\"environmental\\\" is not directly relevant in the given text. The text focuses on establishing a social innovation lab for a machine vision program to address agricultural problems faced by farmers in Morogoro, Tanzania. While the project aims to improve agricultural practices and crop performance, it does not specifically address environmental concerns or the impact on the environment. Therefore, the theme of \\\"environmental\\\" is not relevant in this text.\",\"402\":\"The theme \\\"environmental\\\" is relevant in the given text. The text discusses the use of wildlife camera trap images and AI systems to classify different taxonomic classes based on the species present in each image. This application is significant for environmental purposes as it can aid in wildlife monitoring and conservation efforts. By accurately classifying these images, it can provide valuable data for analyzing and understanding the biodiversity and populations of various species. Additionally, the mention of training the system on the USGS Tallgrass supercomputer highlights the involvement of scientific research and technological advancements in the environmental field.\",\"403\":\"None\",\"404\":\"None\",\"405\":\"The theme \\\"environmental\\\" is relevant in the text above. The text discusses the RISE project, which aims to create a camera system for the USGS Water Mission Area's streamgage monitoring network. By capturing images and videos, the system will be able to generate time-series data of surface water levels. This is relevant to the environment as it will provide crucial information for monitoring and managing water resources, which is important for understanding and addressing environmental concerns such as water scarcity, flooding, and ecosystem health.\",\"406\":\"None\",\"407\":\"None\",\"408\":\"None. The text does not mention anything related to the environment or environmental issues.\",\"409\":\"None\",\"410\":\"None\",\"411\":\"None\",\"412\":\"None\",\"413\":\"None\",\"414\":\"The theme \\\"environmental\\\" is not relevant in the given text. The text primarily focuses on the use of deep learning approaches and machine learning methods to analyze earthquake data in Puerto Rico. It does not discuss any specific environmental factors or their impact on the earthquakes. Therefore, the text is not relevant to the theme \\\"environmental.\",\"415\":\"None\",\"416\":\"The theme \\\"environmental\\\" is not relevant in the given text. This text is primarily discussing the use of machine learning models, specifically LSTM and CNN, to forecast ONI values in the tropical Pacific. It does not directly address any environmental aspects or issues.\",\"417\":\"None\",\"418\":\"None\",\"419\":\"None\",\"420\":\"The theme \\\"environmental\\\" is relevant in the text because it mentions the utilization of environmental data to predict conservation benefits at the field level. This indicates that the project takes into consideration the impact on the environment and aims to assess the positive effects of conservation efforts on the environment.\",\"421\":\"None\",\"422\":\"The theme \\\"environmental\\\" is not relevant in the given text. The text primarily focuses on the USGS Amphibian and Reptile Monitoring Initiative (ARMI) and their efforts to reverse amphibian population declines by providing scientific information to managers. While the text mentions the use of acoustic monitoring of amphibian vocalizations and the development of convolutional neural networks (CNNs) to classify species vocalizations, there is no direct connection to the environment or environmental issues. Therefore, the theme \\\"environmental\\\" is None in this text.\",\"423\":\"None\",\"424\":\"None\",\"425\":\"None\",\"426\":\"The theme \\\"environmental\\\" is relevant in the text. The Land Use Plan Document and Data Mining and Analysis R&D project focuses on resource management planning rules, which directly relates to environmental concerns. By analyzing unstructured planning documents, the project aims to uncover patterns and conflicts that might have an impact on the environment. The project's outputs assist in identifying proposed action locations that might require exclusion, restrictions, or stipulations to ensure environmental protection.\",\"427\":\"The theme \\\"environmental\\\" is relevant in the text because it discusses the prediction of daily average stream temperature in the Delaware River Basin. Stream temperature is an important environmental factor that can impact the ecosystem and the organisms living in the water. Additionally, the text mentions the influence of groundwater on stream temperature, highlighting the interconnectedness of different environmental elements.\",\"428\":\"None\",\"429\":\"None\",\"430\":\"None\",\"431\":\"None\",\"432\":\"None\",\"433\":\"None\",\"434\":\"None\",\"435\":\"None\",\"436\":\"The theme \\\"environmental\\\" is not relevant in the given text. The text primarily focuses on the use of technology and data analysis to assess convective weather information for aircraft flying over the ocean and remote areas. It mentions the use of weather satellite data, lightning data, weather prediction models, and artificial intelligence to identify areas of thunderstorm activity and cloud top heights. While the text discusses the use of data to enhance accuracy, it does not mention any direct connection to environmental concerns or the impact on the environment.\",\"437\":\"None\",\"438\":\"None\",\"439\":\"The theme \\\"environmental\\\" is relevant in the text above because it discusses the prediction of stream temperature in the Delaware River Basin. Stream temperature is an important environmental factor as it affects the health and viability of aquatic ecosystems. The study specifically focuses on understanding the limitations of deep learning models in accurately predicting stream temperature under changing climate and precipitation conditions, which further emphasizes the environmental theme.\",\"440\":\"None\",\"441\":\"None\",\"442\":\"None\",\"443\":\"None\",\"444\":\"None\",\"445\":\"None\",\"446\":\"None\",\"447\":\"None\",\"448\":\"None\",\"449\":\"The theme \\\"environmental\\\" is relevant in the text because it mentions the development of Neural Network training software for the new generation of NCEP (National Centers for Environmental Prediction) models. The goal is to optimize the NCEP EMC (Environmental Modeling Center) Training and Validation System to effectively handle the high spatial resolution model data generated by these new operational models. This indicates that the text is discussing advancements and improvements in environmental modeling and prediction systems.\",\"450\":\"The theme \\\"environmental\\\" is relevant in the text as it focuses on the impact of human-driven environmental changes on global inland fisheries. The researchers analyze a large amount of literature to understand how these changes affect the fisheries and aim to develop a risk index to assess the level of stressors they face. This highlights the connection between the environment and the well-being of the fisheries, making the theme of \\\"environmental\\\" significant in the text.\",\"451\":\"None\",\"452\":\"None. The given text does not mention or discuss anything related to the environment or environmental issues. It primarily focuses on the PROSPER modeling framework and the tools and resources used to develop it.\",\"453\":\"None\",\"454\":\"None\"},\"customer service or engagement\":{\"0\":\"None\",\"1\":\"None\",\"2\":\"None\",\"3\":\"None\",\"4\":\"None\",\"5\":\"None\",\"6\":\"None\",\"7\":\"None\",\"8\":\"None\",\"9\":\"None\",\"10\":\"The theme of customer service or engagement is not relevant in the given text. The text simply describes the functionality and purpose of a chatbot phone response system, which assists the CMS Badging Help Desk by providing general information about badging. There is no mention or discussion of customer service or engagement in this context.\",\"11\":\"None\",\"12\":\"None\",\"13\":\"None\",\"14\":\"None\",\"15\":\"None\",\"16\":\"None\",\"17\":\"None\",\"18\":\"None\",\"19\":\"None\",\"20\":\"None\",\"21\":\"None\",\"22\":\"None\",\"23\":\"The theme of customer service is relevant in the text because it discusses the Service Desk Virtual Agent, Curie, which is a chatbot designed to enhance the customer service experience for employees seeking IT support. It utilizes machine learning to offer predictive responses during chats and provides relevant information from knowledge-based articles, thereby improving customer engagement and satisfaction.\",\"24\":\"None\",\"25\":\"None\",\"26\":\"The theme of customer service or engagement is relevant in the text. The website chatbot assistant is designed to provide basic information and guidance, which indicates that it aims to engage with users and provide them with the necessary support. The chatbot's purpose is to assist users by answering their questions and addressing their concerns, demonstrating a clear focus on customer service.\",\"27\":\"None\",\"28\":\"None\",\"29\":\"None\",\"30\":\"The theme of customer service or engagement is relevant in the text because it mentions that the Predicted to Naturalize model can be used to send correspondence to USCIS customers regarding their resident status. This implies that the model is designed to engage with customers and provide them with information and updates about their legal status.\",\"31\":\"None\",\"32\":\"None\",\"33\":\"None\",\"34\":\"None\",\"35\":\"None\",\"36\":\"None\",\"37\":\"None\",\"38\":\"None\",\"39\":\"None\",\"40\":\"None\",\"41\":\"None\",\"42\":\"None\",\"43\":\"None\",\"44\":\"None\",\"45\":\"None\",\"46\":\"None\",\"47\":\"None\",\"48\":\"None\",\"49\":\"None\",\"50\":\"None\",\"51\":\"None\",\"52\":\"None\",\"53\":\"None\",\"54\":\"None\",\"55\":\"None\",\"56\":\"None\",\"57\":\"None\",\"58\":\"None\",\"59\":\"None\",\"60\":\"None\",\"61\":\"None\",\"62\":\"None\",\"63\":\"None\",\"64\":\"None\",\"65\":\"None\",\"66\":\"None\",\"67\":\"None\",\"68\":\"None\",\"69\":\"None\",\"70\":\"None\",\"71\":\"None\",\"72\":\"None\",\"73\":\"None\",\"74\":\"None\",\"75\":\"None\",\"76\":\"None\",\"77\":\"None\",\"78\":\"None\",\"79\":\"None\",\"80\":\"None\",\"81\":\"None\",\"82\":\"None\",\"83\":\"None\",\"84\":\"None\",\"85\":\"None\",\"86\":\"The theme of customer service or engagement is not directly relevant in the given text. The text primarily discusses the development of a model to classify and automatically route Service Desk tickets to the appropriate team. While this process improvement may indirectly impact customer service by potentially enhancing response times and efficiency, the text does not directly address customer interactions, satisfaction, or engagement. Therefore, the relevance to customer service or engagement is None.\",\"87\":\"None\",\"88\":\"None\",\"89\":\"None\",\"90\":\"None\",\"91\":\"None\",\"92\":\"None\",\"93\":\"None\",\"94\":\"The theme of customer service or engagement is not directly relevant in the given text. The text focuses on explaining how Azure Chatbot is being utilized to automate and enhance user responses on the MBDA website using AI, machine learning, and natural language processing. While customer service is indirectly related to the use of the chatbot, the text does not provide any specific information about customer interactions, feedback, or engagement. Therefore, the relevance of the theme \\\"customer service or engagement\\\" is minimal or none in this particular text.\",\"95\":\"None\",\"96\":\"None\",\"97\":\"None\",\"98\":\"None\",\"99\":\"None\",\"100\":\"None\",\"101\":\"None\",\"102\":\"None\",\"103\":\"None\",\"104\":\"None\",\"105\":\"None\",\"106\":\"None\",\"107\":\"None\",\"108\":\"None\",\"109\":\"None\",\"110\":\"None\",\"111\":\"None\",\"112\":\"None\",\"113\":\"None\",\"114\":\"None\",\"115\":\"None\",\"116\":\"None\",\"117\":\"None\",\"118\":\"None\",\"119\":\"None\",\"120\":\"The theme of \\\"customer service or engagement\\\" is relevant in the given text. IRM's BMP Systems is planning to integrate ServiceNow's Virtual Agent into their applications. This AI-powered chatbot will facilitate support and data requests for users. By implementing this chatbot, BMP Systems aims to enhance customer service by providing a virtual assistant that can assist users with their inquiries and requests. Therefore, customer service and engagement are central to their decision to integrate ServiceNow's Virtual Agent.\",\"121\":\"None\",\"122\":\"None\",\"123\":\"None\",\"124\":\"None\",\"125\":\"None. The text does not mention or address customer service or engagement. It primarily discusses the system of Intelligent Ticket Routing and the technologies and tools used for its implementation.\",\"126\":\"None\",\"127\":\"None\",\"128\":\"None\",\"129\":\"None\",\"130\":\"None\",\"131\":\"None\",\"132\":\"None\",\"133\":\"None\",\"134\":\"None\",\"135\":\"None\",\"136\":\"None\",\"137\":\"None\",\"138\":\"None\",\"139\":\"None\",\"140\":\"None\",\"141\":\"None\",\"142\":\"None\",\"143\":\"None\",\"144\":\"None\",\"145\":\"None\",\"146\":\"None\",\"147\":\"None\",\"148\":\"None\",\"149\":\"None\",\"150\":\"The theme of customer service or engagement is not relevant in this text. This is because the text is describing the development of a virtual assistant chat bot by the National Institutes of Health (NIH) to help users find grant-related information. While the chat bot may provide assistance, there is no mention of customer service or engagement with users. Therefore, the theme is not applicable in this context.\",\"151\":\"None\",\"152\":\"None\",\"153\":\"None\",\"154\":\"None\",\"155\":\"The theme \\\"customer service or engagement\\\" is relevant in the text above. The integration of the NLU model into the Automated Collections IVR (ACI) menu aims to enhance customer service by analyzing customer speech input and determining their intent. This will guide the taxpayer to the appropriate call path, ensuring a more personalized and efficient customer experience.\",\"156\":\"None\",\"157\":\"None\",\"158\":\"None\",\"159\":\"None\",\"160\":\"None\",\"161\":\"None\",\"162\":\"None\",\"163\":\"None\",\"164\":\"None\",\"165\":\"None\",\"166\":\"None\",\"167\":\"None\",\"168\":\"None\",\"169\":\"None\",\"170\":\"None\",\"171\":\"None\",\"172\":\"The theme of customer service or engagement is not directly relevant in the given text. The text focuses on developing a machine learning model to predict the approval of I-539 applications. While the project's goal is to improve the efficiency of the approval process, there is no mention of customer service or engagement in relation to the applicants. Therefore, None.\",\"173\":\"None\",\"174\":\"None\",\"175\":\"None\",\"176\":\"None\",\"177\":\"None\",\"178\":\"None\",\"179\":\"None\",\"180\":\"None\",\"181\":\"None\",\"182\":\"None\",\"183\":\"None\",\"184\":\"None\",\"185\":\"None\",\"186\":\"None\",\"187\":\"None\",\"188\":\"None\",\"189\":\"None\",\"190\":\"None\",\"191\":\"None\",\"192\":\"None\",\"193\":\"None\",\"194\":\"None\",\"195\":\"None\",\"196\":\"None\",\"197\":\"None\",\"198\":\"None\",\"199\":\"None\",\"200\":\"None\",\"201\":\"None\",\"202\":\"The theme \\\"customer service or engagement\\\" is relevant in the given text. The integration of the Natural Language Understanding (NLU) model into the eGain intent engine is aimed at improving customer service and engagement. By analyzing customer typed text input and matching it to a specific intent, the system can provide the relevant knowledge article in response, effectively addressing customer queries and enhancing their overall experience.\",\"203\":\"None\",\"204\":\"None\",\"205\":\"None\",\"206\":\"None\",\"207\":\"None\",\"208\":\"None\",\"209\":\"None\",\"210\":\"None\",\"211\":\"None\",\"212\":\"The theme \\\"customer service or engagement\\\" is not relevant in the given text. This text primarily focuses on the development of production systems, GPATools and GPAIX, for testing messages at a large scale across different foreign sub-audiences. It discusses the goal of determining the most effective way to reach and engage with specific target audiences, but it does not directly mention customer service or engagement in relation to these systems. Thus, the text is not relevant to the theme.\",\"213\":\"None\",\"214\":\"None\",\"215\":\"None\",\"216\":\"None\",\"217\":\"None\",\"218\":\"None\",\"219\":\"None\",\"220\":\"None\",\"221\":\"None\",\"222\":\"None\",\"223\":\"None\",\"224\":\"None\",\"225\":\"None\",\"226\":\"None\",\"227\":\"None\",\"228\":\"The theme of \\\"customer service or engagement\\\" is relevant in the given text. This is evident from the fact that Aidan FSA, a virtual assistant, is designed to provide information and answer commonly asked questions about financial aid. By doing so, Aidan assists over 2.6 million customers and processes more than 11 million user messages. This demonstrates the engagement between Aidan and its customers, highlighting the importance of customer service in this context.\",\"229\":\"None\",\"230\":\"None\",\"231\":\"None\",\"232\":\"None\",\"233\":\"None\",\"234\":\"None\",\"235\":\"None\",\"236\":\"None\",\"237\":\"None\",\"238\":\"None\",\"239\":\"None\",\"240\":\"None\",\"241\":\"None\",\"242\":\"None\",\"243\":\"None\",\"244\":\"None\",\"245\":\"None\",\"246\":\"None\",\"247\":\"The theme of customer service or engagement is not relevant in the given text. Although the text mentions a Chatbot being designed to automate email responses to physical security questions, it does not directly address any aspect of customer service or engagement. The focus of the text is on assisting the Security team and allowing the help desk team to handle complex issues.\",\"248\":\"None\",\"249\":\"None\",\"250\":\"None\",\"251\":\"None\",\"252\":\"None\",\"253\":\"None\",\"254\":\"None\",\"255\":\"None\",\"256\":\"None\",\"257\":\"None\",\"258\":\"None\",\"259\":\"None\",\"260\":\"None\",\"261\":\"None\",\"262\":\"None\",\"263\":\"None\",\"264\":\"None\",\"265\":\"None\",\"266\":\"None\",\"267\":\"None\",\"268\":\"None\",\"269\":\"None\",\"270\":\"The theme of customer service or engagement is relevant in the given text. The text talks about a chatbot being an interactive interface that can understand and respond to queries in real time using natural language processing. This implies that the chatbot is designed to engage with customers and provide them with the necessary assistance or information they require. The chatbot's ability to understand plain language and provide appropriate responses further emphasizes its role in customer service and engagement.\",\"271\":\"None\",\"272\":\"The theme of customer service or engagement is not directly relevant in the given text. The text discusses the use of Text Analytics for Survey Responses (TASR) by the DHS OCHCO to analyze and extract topics\\/themes from open-ended survey responses. These results are then utilized by DHS Leadership to enhance employee satisfaction and meet their basic needs. The focus here is on employee satisfaction and meeting their needs rather than customer service or engagement.\",\"273\":\"None\",\"274\":\"None\",\"275\":\"The theme of customer service or engagement is not relevant in the given text. The text primarily focuses on the technical aspects of NASA SERVIR's GEOGloWS ECMWF Streamflow Service (GESS) and how it utilizes machine learning techniques and Earth Observations (EO) to forecast flow on every river worldwide. It does not mention any customer service or engagement aspects.\",\"276\":\"None\",\"277\":\"None\",\"278\":\"None\",\"279\":\"None\",\"280\":\"None\",\"281\":\"None\",\"282\":\"None\",\"283\":\"None\",\"284\":\"None\",\"285\":\"None\",\"286\":\"None\",\"287\":\"None\",\"288\":\"None\",\"289\":\"None\",\"290\":\"None\",\"291\":\"None\",\"292\":\"None\",\"293\":\"The theme of customer service or engagement is not directly relevant in the given text. The text primarily focuses on describing a remote tool powered by AI called CuraPatient that allows patients to manage their health conditions without visiting a healthcare provider. Although the tool provides various features such as health tracking, program enrollment, insurance management, and appointment scheduling, the text does not mention anything about customer service or engagement with users. Therefore, the theme is None in this context.\",\"294\":\"The theme of customer service or engagement is not relevant in the given text. This is because the text primarily discusses the development of a new search algorithm called Best Match in PubMed to enhance retrieval performance and user experience. It does not specifically mention any interaction or engagement with customers or users of PubMed.\",\"295\":\"None\",\"296\":\"None\",\"297\":\"The theme \\\"customer service or engagement\\\" is not relevant in the given text. This is because the text discusses the use of an artificial intelligence-powered dashboard in the Operations Center of CISA to assist duty officers and analysts in understanding ongoing operational activities. It focuses more on the utilization of AI technology to suggest appropriate actions and engagement strategies with government entities and critical infrastructure owners based on potential impacts to national critical functions, rather than customer service or engagement.\",\"298\":\"None\",\"299\":\"None\",\"300\":\"None\",\"301\":\"None\",\"302\":\"None\",\"303\":\"None\",\"304\":\"None\",\"305\":\"None\",\"306\":\"None\",\"307\":\"None\",\"308\":\"None\",\"309\":\"The theme \\\"customer service or engagement\\\" is not relevant in the given text. This text primarily focuses on the technical aspect of using Predictive Intelligence (PI) in the Quality Service Center (QSC) to assign incidents. It does not mention anything about customer service or engagement.\",\"310\":\"None\",\"311\":\"None\",\"312\":\"None\",\"313\":\"None\",\"314\":\"None\",\"315\":\"None\",\"316\":\"None\",\"317\":\"None\",\"318\":\"None\",\"319\":\"The theme of customer service or engagement is not directly mentioned in the given text. The text primarily focuses on describing the virtual agent, SAM, and its capabilities in understanding customer needs and providing appropriate responses using manual learning and natural language processing. However, it does not discuss any specific interactions or engagement with customers, nor does it address the concept of customer service. Therefore, the text is not relevant to the theme of customer service or engagement.\",\"320\":\"None\",\"321\":\"None\",\"322\":\"None\",\"323\":\"None\",\"324\":\"None\",\"325\":\"None\",\"326\":\"None\",\"327\":\"None\",\"328\":\"None\",\"329\":\"The theme of customer service or engagement is relevant in the given text. The text mentions that ILMS has created an automated support desk assistant using ServiceNow Virtual Agent. This indicates that ILMS is focusing on improving customer service by making interactions with the support desk easier for customers. The aim is to streamline support desk operations and minimize costs, which indirectly relates to providing better customer service by resolving simple issues efficiently.\",\"330\":\"None\",\"331\":\"None\",\"332\":\"None\",\"333\":\"None\",\"334\":\"None\",\"335\":\"None\",\"336\":\"None\",\"337\":\"None\",\"338\":\"None\",\"339\":\"None\",\"340\":\"None\",\"341\":\"None\",\"342\":\"None\",\"343\":\"None\",\"344\":\"None\",\"345\":\"None\",\"346\":\"None\",\"347\":\"None\",\"348\":\"None\",\"349\":\"None\",\"350\":\"None\",\"351\":\"None\",\"352\":\"None\",\"353\":\"None\",\"354\":\"None\",\"355\":\"None\",\"356\":\"None\",\"357\":\"None\",\"358\":\"None\",\"359\":\"None\",\"360\":\"None\",\"361\":\"None\",\"362\":\"None\",\"363\":\"None\",\"364\":\"None\",\"365\":\"None\",\"366\":\"None\",\"367\":\"None\",\"368\":\"None\",\"369\":\"None\",\"370\":\"None\",\"371\":\"The theme of \\\"customer service or engagement\\\" is relevant in the given text. This is evident from the mention of implementing a chatbot pilot on trade.gov. The chatbot is designed to assist clients by providing answers to frequently asked questions, locating information, suggesting events and services. This demonstrates an effort to engage with customers and provide them with a better customer service experience. The chatbot's ability to scan content libraries and input from staff to provide relevant answers and suggestions based on the client's persona further enhances customer engagement.\",\"372\":\"None\",\"373\":\"None\",\"374\":\"None\",\"375\":\"The theme of \\\"customer service or engagement\\\" is relevant in the text because it mentions plans to automate customer service inbox monitoring. This indicates that the organization is prioritizing customer service by developing a bot to handle customer inquiries and ensure timely responses.\",\"376\":\"None\",\"377\":\"None\",\"378\":\"The theme of \\\"customer service or engagement\\\" is relevant in the given text. The development and deployment of an AI chatbot for HRSA EHBs grantees indicates a focus on improving customer service and engagement. The chatbot allows grantees to communicate using natural conversational expressions, providing a more interactive and engaging experience. Additionally, the integration with existing EHBs application UI and Salesforce for automated ticket creation suggests a streamlined and efficient customer service process. The mention of the chatbot's ability to improve its responses over time further emphasizes the commitment to continuously enhancing customer service and engagement.\",\"379\":\"None\",\"380\":\"None\",\"381\":\"None\",\"382\":\"None\",\"383\":\"None\",\"384\":\"None\",\"385\":\"None\",\"386\":\"None\",\"387\":\"The theme of \\\"customer service or engagement\\\" is relevant in the text. It discusses the introduction of a chatbot that aims to streamline customer experience and automate answering commonly asked questions. This initiative demonstrates an effort to improve customer service by providing quicker and more efficient responses to customer inquiries. Additionally, it mentions that customers still have the option to connect with a live agent if they prefer, which shows a commitment to customer engagement and personalization.\",\"388\":\"None\",\"389\":\"None\",\"390\":\"None\",\"391\":\"None\",\"392\":\"None\",\"393\":\"None\",\"394\":\"None\",\"395\":\"None\",\"396\":\"None\",\"397\":\"None\",\"398\":\"None\",\"399\":\"None\",\"400\":\"None\",\"401\":\"None\",\"402\":\"None\",\"403\":\"None\",\"404\":\"None\",\"405\":\"None\",\"406\":\"None\",\"407\":\"None\",\"408\":\"None\",\"409\":\"None\",\"410\":\"The theme of customer service or engagement is relevant in the given text. The implementation of a chatbot assistant by the Department of Labor shows their focus on improving customer service and engagement with their employees. By providing a chatbot that can answer common procurement questions and specific contract inquiries, the department aims to assist their employees in finding information quickly and efficiently. This initiative reflects their commitment to enhancing customer service and engagement within their organization.\",\"411\":\"None\",\"412\":\"None\",\"413\":\"None\",\"414\":\"None\",\"415\":\"None\",\"416\":\"None\",\"417\":\"None\",\"418\":\"None\",\"419\":\"None\",\"420\":\"None\",\"421\":\"None\",\"422\":\"None\",\"423\":\"None\",\"424\":\"None\",\"425\":\"None\",\"426\":\"None\",\"427\":\"None\",\"428\":\"None\",\"429\":\"None\",\"430\":\"None\",\"431\":\"None\",\"432\":\"None\",\"433\":\"None. The text does not mention anything related to customer service or engagement. It focuses on the use of an AI solution to address the issue of spam and marketing emails in civil rights complaints email channels.\",\"434\":\"None\",\"435\":\"None\",\"436\":\"None\",\"437\":\"None\",\"438\":\"None\",\"439\":\"None\",\"440\":\"None\",\"441\":\"The theme of customer service or engagement is relevant in the text. The company A\\/LM plans to utilize transactional data and planned transactions to create customized user experiences and analytics. This indicates that they are focused on understanding and meeting the specific needs of their users. They aim to gather valuable insights from real system actions and clicks, which suggests they are committed to improving user interactions. By simplifying user interactions and reducing the time taken to complete daily tasks, they are likely aiming to enhance customer satisfaction and engagement.\",\"442\":\"None\",\"443\":\"None\",\"444\":\"None\",\"445\":\"None\",\"446\":\"None. The text does not mention customer service or engagement. It mainly discusses how USAGov collects qualitative data from different sources and classifies it by topic to identify areas in need of product updates or enhancements.\",\"447\":\"None\",\"448\":\"None\",\"449\":\"None\",\"450\":\"None\",\"451\":\"None\",\"452\":\"None\",\"453\":\"The theme of customer service or engagement is not directly relevant in the text. The text primarily focuses on the automatic analysis of recorded calls in order to evaluate the content and quality of the calls, with the aim of improving the efficiency and effectiveness of the service provided by Benefits Advisors. While the analysis of calls indirectly relates to customer service by aiming to enhance the quality of service provided, the theme of customer service or engagement is not explicitly addressed.\",\"454\":\"None\"},\"power systems\":{\"0\":\"None\",\"1\":\"None\",\"2\":\"None\",\"3\":\"None\",\"4\":\"None\",\"5\":\"None\",\"6\":\"None\",\"7\":\"None\",\"8\":\"None\",\"9\":\"None\",\"10\":\"None\",\"11\":\"None\",\"12\":\"None\",\"13\":\"None\",\"14\":\"None\",\"15\":\"None\",\"16\":\"None\",\"17\":\"None\",\"18\":\"The theme of \\\"power systems\\\" is not relevant in the given text. This text is focused on the development of methods and technologies to enhance the cybersecurity of industrial control systems (ICS) networks. It does not mention power systems or any connection to them. Therefore, the theme of \\\"power systems\\\" is not applicable in this context.\",\"19\":\"None\",\"20\":\"None\",\"21\":\"The theme of \\\"power systems\\\" is relevant in the given text. The text specifically discusses the use of deep learning technology and voltage sensors to diagnose and predict failure in solid-state ceramic membrane reactors. It mentions collecting data on current and impedance during operation, which are key parameters in power systems. Additionally, the utilization of artificial intelligence to analyze the data and anticipate reactor failure also falls under the theme of power systems, as it involves the use of advanced technology to manage and optimize the performance of power systems.\",\"22\":\"None\",\"23\":\"None\",\"24\":\"None\",\"25\":\"None\",\"26\":\"None\",\"27\":\"None\",\"28\":\"None\",\"29\":\"None\",\"30\":\"None\",\"31\":\"None\",\"32\":\"None\",\"33\":\"None\",\"34\":\"None\",\"35\":\"None\",\"36\":\"None\",\"37\":\"None\",\"38\":\"None\",\"39\":\"None\",\"40\":\"None\",\"41\":\"None\",\"42\":\"None\",\"43\":\"None\",\"44\":\"None\",\"45\":\"None\",\"46\":\"None\",\"47\":\"The theme of \\\"power systems\\\" is relevant in the text because the project is focused on using artificial intelligence technology to expedite the development of nuclear fuel. The analysis of microstructural image and thermal conductivity data from UZr fuel, the creation of a dataset, and the training of machine learning and deep learning models all contribute to understanding the relationships between various factors in fuel properties. This understanding is crucial for improving power systems and optimizing the efficiency and effectiveness of nuclear fuel.\",\"48\":\"None\",\"49\":\"None\",\"50\":\"None\",\"51\":\"None\",\"52\":\"None\",\"53\":\"None\",\"54\":\"None\",\"55\":\"None\",\"56\":\"None\",\"57\":\"None\",\"58\":\"None\",\"59\":\"None\",\"60\":\"None\",\"61\":\"None\",\"62\":\"None\",\"63\":\"None\",\"64\":\"None\",\"65\":\"None\",\"66\":\"None\",\"67\":\"None\",\"68\":\"None\",\"69\":\"None\",\"70\":\"None\",\"71\":\"None\",\"72\":\"None\",\"73\":\"None\",\"74\":\"The theme \\\"power systems\\\" is relevant in the text because it specifically discusses the application of big data, artificial intelligence, and machine learning to analyze phasor measurement unit (PMU) data. This demonstrates a focus on improving grid operation and management, which is a fundamental aspect of power systems.\",\"75\":\"None\",\"76\":\"The theme \\\"power systems\\\" is relevant in the given text. The text discusses the use of big data, AI, and machine learning technology to analyze PMU (Phasor Measurement Unit) data for the purpose of enhancing grid operation and management. This indicates that the text is focused on power systems and the application of advanced technologies to improve their efficiency and reliability.\",\"77\":\"None\",\"78\":\"None\",\"79\":\"None\",\"80\":\"None\",\"81\":\"None\",\"82\":\"None\",\"83\":\"None\",\"84\":\"None\",\"85\":\"The theme of \\\"power systems\\\" is relevant in the text. This is because the text mentions that the surveillance towers are equipped with radars and cameras, and the autonomous surface vehicles (ASVs) are powered by wind, solar, or onboard engines. These power systems are crucial for the operation of the surveillance towers and ASVs in detecting, identifying, and tracking objects of interest in a maritime environment.\",\"86\":\"None\",\"87\":\"None\",\"88\":\"None\",\"89\":\"The theme \\\"power systems\\\" is relevant in the text as it discusses the use of machine learning methods to estimate load composition data and motor protection profiles in different climate regions. It also mentions the application of a deep learning algorithm to calibrate the parameters of the WECC composite load model. These concepts are directly related to power systems and the use of advanced algorithms in analyzing and optimizing them.\",\"90\":\"None\",\"91\":\"None\",\"92\":\"None\",\"93\":\"None\",\"94\":\"None\",\"95\":\"None\",\"96\":\"None\",\"97\":\"None\",\"98\":\"None\",\"99\":\"None\",\"100\":\"None\",\"101\":\"None\",\"102\":\"None\",\"103\":\"The theme of \\\"power systems\\\" is not relevant in the given text. The text focuses on improving the analysis of DC ramp test data from rotating machines using machine learning and AI tools. It does not directly discuss or pertain to power systems.\",\"104\":\"None\",\"105\":\"None\",\"106\":\"None\",\"107\":\"None\",\"108\":\"None\",\"109\":\"None\",\"110\":\"The theme of \\\"power systems\\\" is not relevant in the given text. The text primarily discusses the development of a tool that combines various models, algorithms, and equipment to accelerate the discovery, development, and deployment of nuclear fuels. The focus is on describing thermal properties and their relationship to temperature and irradiation. While nuclear fuels can be used in power systems, the text does not directly address power systems themselves. Therefore, the theme of \\\"power systems\\\" is not relevant in this context.\",\"111\":\"None\",\"112\":\"None\",\"113\":\"The theme of \\\"power systems\\\" is relevant in the text provided. The text discusses the use of big data, artificial intelligence, and machine learning technology to improve grid operation and management. This implies that the focus is on enhancing the power systems and their efficiency through the utilization of advanced technologies. Therefore, the theme of power systems is directly addressed in the text.\",\"114\":\"None\",\"115\":\"None\",\"116\":\"None\",\"117\":\"None\",\"118\":\"None\",\"119\":\"None\",\"120\":\"None\",\"121\":\"None\",\"122\":\"None\",\"123\":\"None\",\"124\":\"None\",\"125\":\"None\",\"126\":\"None\",\"127\":\"None\",\"128\":\"None\",\"129\":\"None\",\"130\":\"None\",\"131\":\"None\",\"132\":\"None\",\"133\":\"None\",\"134\":\"None\",\"135\":\"None\",\"136\":\"None\",\"137\":\"None\",\"138\":\"None\",\"139\":\"None\",\"140\":\"None\",\"141\":\"None\",\"142\":\"None\",\"143\":\"None\",\"144\":\"None\",\"145\":\"None\",\"146\":\"None\",\"147\":\"None\",\"148\":\"None\",\"149\":\"The theme \\\"power systems\\\" is relevant in the text because it discusses the use of artificial intelligence and Monte Carlo algorithms to improve computational simulations for estimating low failure probabilities in advanced reactor technologies. This implies that the text is addressing the power system of advanced reactor technologies and how the project aims to enhance its efficiency and reliability.\",\"150\":\"None\",\"151\":\"None\",\"152\":\"None\",\"153\":\"None\",\"154\":\"None\",\"155\":\"None\",\"156\":\"None\",\"157\":\"None\",\"158\":\"None\",\"159\":\"None\",\"160\":\"None\",\"161\":\"None\",\"162\":\"None\",\"163\":\"None\",\"164\":\"None\",\"165\":\"None\",\"166\":\"The theme of \\\"power systems\\\" is relevant in this text. The text discusses the development of a simulation framework that combines physics models with grid monitoring data for integrated energy systems operation. It mentions the use of learning-based algorithms to detect and respond to component contingencies caused by extreme events like cyber-attacks or extreme weather. This indicates a focus on power systems and their management in the context of potential disruptions or challenges.\",\"167\":\"None\",\"168\":\"None\",\"169\":\"None\",\"170\":\"None\",\"171\":\"The theme \\\"power systems\\\" is relevant in the given text. The text specifically mentions the use of big data, artificial intelligence, and machine learning technology to analyze phasor measurement unit data. This indicates a focus on the power grid and its operation and management. The use of these technologies suggests an exploration of power systems and their optimization. Therefore, the theme of \\\"power systems\\\" is directly relevant in this text.\",\"172\":\"None\",\"173\":\"None\",\"174\":\"The theme of \\\"power systems\\\" is not relevant in this text. The text focuses on developing a digital twin of a centrifugal contactor system in the nuclear fuel cycle, analyzing data for anomalies, failures, and trends using machine learning and data analysis techniques. It mentions the use of advanced artificial intelligence and the guidance of a team of nuclear safeguards experts. However, it does not directly address power systems or their functioning.\",\"175\":\"None\",\"176\":\"None\",\"177\":\"None\",\"178\":\"None\",\"179\":\"None\",\"180\":\"None\",\"181\":\"None\",\"182\":\"None\",\"183\":\"None\",\"184\":\"None\",\"185\":\"The theme \\\"power systems\\\" is relevant in the given text because it discusses the development of a deep reinforcement learning approach to manage distributed or tightly coupled multi-agent systems in energy systems. This implies that the text is focused on how power systems can be effectively controlled and optimized using advanced technologies like deep neural networks and complex optimization algorithms.\",\"186\":\"None\",\"187\":\"None\",\"188\":\"None\",\"189\":\"None\",\"190\":\"None\",\"191\":\"None\",\"192\":\"None\",\"193\":\"None\",\"194\":\"None\",\"195\":\"None\",\"196\":\"None\",\"197\":\"None\",\"198\":\"None\",\"199\":\"None\",\"200\":\"None\",\"201\":\"The theme \\\"power systems\\\" is relevant in the given text. The text discusses the development of a framework and process to translate industrial control system features into a machine-readable format. This indicates that the project is focused on power systems and their automation. The research also examines current and evolving standards for usability with diverse grid architectures, further emphasizing the relevance to power systems. The project aims to improve cyber incident consequence models, which suggests a focus on the consequences and impacts of cyber threats on power systems. Lastly, the project aims to enhance national capabilities for sharing actionable threat intelligence at machine speed, which is directly related to power systems as they are critical infrastructure that requires efficient threat intelligence sharing for effective protection.\",\"202\":\"None\",\"203\":\"None\",\"204\":\"The theme of \\\"power systems\\\" is relevant in the given text. The text discusses the use of big data, AI, and machine learning on PMU data (Phasor Measurement Unit data) to enhance power system resilience. It highlights the goal of improving existing knowledge, discovering new insights, and developing tools for better grid operation and management. This demonstrates the relevance of the theme \\\"power systems\\\" as the text directly addresses the use of power systems and the technologies associated with it.\",\"205\":\"None\",\"206\":\"None\",\"207\":\"None\",\"208\":\"None\",\"209\":\"None\",\"210\":\"The theme of \\\"power systems\\\" is relevant in the given text. The text discusses the use of computer vision techniques for processing satellite imagery to analyze critical infrastructure and interdependency data. This implies that the focus is on the power systems within critical infrastructure, which are essential for national security and defense capabilities.\",\"211\":\"None\",\"212\":\"None\",\"213\":\"None\",\"214\":\"None\",\"215\":\"None\",\"216\":\"None\",\"217\":\"The theme of \\\"power systems\\\" is relevant in the given text because it discusses the Cyber Sentry program, which is designed to monitor critical infrastructure networks. These networks often include power systems such as Industrial Control Systems (ICS) and Supervisory Control and Data Acquisition (SCADA) systems. The program uses advanced anomaly detection and machine learning to analyze cyber-physical data from both IT and OT networks, which can include power system data. Additionally, the Critical Infrastructure Anomaly Alerting model mentioned in the text assists threat hunting analysts by providing AI-assisted processing of this information, further emphasizing the relevance of power systems in the context of the text.\",\"218\":\"None\",\"219\":\"None\",\"220\":\"None\",\"221\":\"None\",\"222\":\"The theme of \\\"power systems\\\" is relevant in the given text. The text discusses the project's objective of developing machine learning techniques to evaluate the resilience and vulnerabilities of integrated energy systems. It specifically mentions assessing the impact of microreactors and distributed energy resources on the reliability and resiliency of energy systems. This directly relates to the theme of power systems as it focuses on understanding and improving the functioning of energy systems.\",\"223\":\"None\",\"224\":\"None\",\"225\":\"None\",\"226\":\"None\",\"227\":\"None\",\"228\":\"None\",\"229\":\"None\",\"230\":\"None\",\"231\":\"The theme of \\\"power systems\\\" is relevant in the given text. The text discusses the use of big data, artificial intelligence, and machine learning technology on PMU (Phasor Measurement Unit) data. PMUs are devices used in power systems to measure and monitor electrical waveforms, which are crucial for grid operation and management. By applying these advanced technologies to PMU data, the text aims to enhance the understanding of power systems, improve their operation, and discover new insights for better grid management.\",\"232\":\"None\",\"233\":\"None\",\"234\":\"None\",\"235\":\"None\",\"236\":\"None\",\"237\":\"None\",\"238\":\"None\",\"239\":\"None\",\"240\":\"The theme of \\\"power systems\\\" is relevant in the given text. The text discusses the development and validation of scalable models for achieving autonomous operation of microreactors. Microreactors are part of power systems as they generate power. The text also mentions the analysis of the risk of cascading failures when deploying emerging reactors in a full feeder microgrid, which further emphasizes the relevance of power systems.\",\"241\":\"The theme \\\"power systems\\\" is relevant in the text above. This is because the research project focuses on using generative adversarial networks to automate the training of electromagnetic-based anomaly detection systems for legacy industrial control systems devices and Industrial Internet of Things. This implies the involvement of power systems in the industrial control systems and the need to protect them from intrusion. The use of power systems is essential for the functioning of these control systems, and automating their training helps reduce manual labor and operational costs.\",\"242\":\"None\",\"243\":\"None\",\"244\":\"None\",\"245\":\"The theme of \\\"power systems\\\" is relevant in the given text. The text discusses the Grid Resilience and Intelligence Platform (GRIP), which utilizes artificial intelligence (AI) to analyze utility data and predict the potential impacts on the power grid caused by major storms. This highlights the importance of understanding and managing power systems in the face of extreme weather events.\",\"246\":\"None\",\"247\":\"None\",\"248\":\"None\",\"249\":\"None\",\"250\":\"None\",\"251\":\"The theme of \\\"power systems\\\" is relevant in the given text. It discusses the use of big data, AI, and machine learning technology in analyzing PMU (Phasor Measurement Unit) data for enhancing grid operation and management. This implies that the text pertains to the power systems domain, specifically focusing on improving grid management through the utilization of advanced technologies and data analysis.\",\"252\":\"None\",\"253\":\"None\",\"254\":\"None\",\"255\":\"None\",\"256\":\"None\",\"257\":\"None\",\"258\":\"None\",\"259\":\"None\",\"260\":\"None\",\"261\":\"None\",\"262\":\"None\",\"263\":\"None\",\"264\":\"None\",\"265\":\"None\",\"266\":\"None\",\"267\":\"None\",\"268\":\"None\",\"269\":\"None\",\"270\":\"None\",\"271\":\"None\",\"272\":\"None\",\"273\":\"None\",\"274\":\"None\",\"275\":\"None\",\"276\":\"None\",\"277\":\"None\",\"278\":\"None\",\"279\":\"None\",\"280\":\"None\",\"281\":\"None\",\"282\":\"None\",\"283\":\"None\",\"284\":\"None\",\"285\":\"None\",\"286\":\"None\",\"287\":\"None\",\"288\":\"None\",\"289\":\"The theme \\\"power systems\\\" is not relevant in the given text. The text primarily focuses on developing a framework for automated malware analysis using dynamic sandboxes and does not directly address power systems.\",\"290\":\"None\",\"291\":\"The theme of \\\"power systems\\\" is not relevant in the given text. The text focuses on the efficient use of limited experimental data, developing sparse data reconstruction methods, determining sensor requirements, and leveraging sparse sensing and sparse learning for prediction, diagnostics, and prognostics capabilities. These ideas do not directly relate to power systems, but rather to the use of data and modeling techniques in nuclear digital twin technology.\",\"292\":\"None\",\"293\":\"None\",\"294\":\"None\",\"295\":\"None\",\"296\":\"None\",\"297\":\"None\",\"298\":\"None\",\"299\":\"None\",\"300\":\"None\",\"301\":\"None\",\"302\":\"None\",\"303\":\"None\",\"304\":\"None\",\"305\":\"None\",\"306\":\"None\",\"307\":\"None\",\"308\":\"None\",\"309\":\"None\",\"310\":\"None\",\"311\":\"None\",\"312\":\"None\",\"313\":\"None\",\"314\":\"None\",\"315\":\"None\",\"316\":\"None\",\"317\":\"None\",\"318\":\"None\",\"319\":\"None\",\"320\":\"None\",\"321\":\"None\",\"322\":\"None\",\"323\":\"None\",\"324\":\"None\",\"325\":\"None\",\"326\":\"None\",\"327\":\"None\",\"328\":\"None\",\"329\":\"None\",\"330\":\"None\",\"331\":\"None\",\"332\":\"None\",\"333\":\"None\",\"334\":\"None\",\"335\":\"None\",\"336\":\"None\",\"337\":\"None\",\"338\":\"None\",\"339\":\"None\",\"340\":\"None\",\"341\":\"None\",\"342\":\"None\",\"343\":\"None\",\"344\":\"None\",\"345\":\"None\",\"346\":\"None\",\"347\":\"None\",\"348\":\"None\",\"349\":\"None\",\"350\":\"None\",\"351\":\"None\",\"352\":\"None\",\"353\":\"None\",\"354\":\"None\",\"355\":\"None\",\"356\":\"None\",\"357\":\"None\",\"358\":\"None\",\"359\":\"None\",\"360\":\"None\",\"361\":\"None\",\"362\":\"None\",\"363\":\"None\",\"364\":\"None\",\"365\":\"None\",\"366\":\"None\",\"367\":\"None\",\"368\":\"None\",\"369\":\"None\",\"370\":\"None\",\"371\":\"None\",\"372\":\"None\",\"373\":\"None\",\"374\":\"None\",\"375\":\"None\",\"376\":\"None\",\"377\":\"None\",\"378\":\"None\",\"379\":\"None\",\"380\":\"None\",\"381\":\"None\",\"382\":\"None\",\"383\":\"None\",\"384\":\"None\",\"385\":\"None\",\"386\":\"None\",\"387\":\"None\",\"388\":\"None\",\"389\":\"None\",\"390\":\"None\",\"391\":\"None\",\"392\":\"The theme of \\\"power systems\\\" is relevant in the given text. The text discusses the limitations of typical contingency analysis for power utilities and introduces a new approach using a machine learning framework and resilience-chaos plots. This new method aims to improve the analysis of power systems by reducing computational expense and accurately discovering n-2 contingencies by 50%. Therefore, the text directly relates to the theme of power systems and their analysis.\",\"393\":\"None\",\"394\":\"None\",\"395\":\"None\",\"396\":\"None\",\"397\":\"None\",\"398\":\"None\",\"399\":\"None\",\"400\":\"None\",\"401\":\"None\",\"402\":\"None\",\"403\":\"None\",\"404\":\"None\",\"405\":\"None\",\"406\":\"None\",\"407\":\"The theme \\\"power systems\\\" is not relevant in the given text. The text focuses on the project's objectives, which involve researching and implementing machine learning and artificial intelligence algorithms for signal decomposition and detecting false data injection in physical processes. It also mentions developing an advanced library for improved detection of malicious tampering. While the text does mention physical processes, it does not specifically relate to power systems.\",\"408\":\"None\",\"409\":\"None\",\"410\":\"None\",\"411\":\"None\",\"412\":\"None\",\"413\":\"None\",\"414\":\"None\",\"415\":\"None\",\"416\":\"None\",\"417\":\"None\",\"418\":\"None\",\"419\":\"None\",\"420\":\"None\",\"421\":\"None\",\"422\":\"None\",\"423\":\"None\",\"424\":\"The theme of \\\"power systems\\\" is relevant in the text because it mentions that the Autonomous Surveillance Towers are solar-powered with battery backup. This indicates that the towers rely on a power system to operate and function effectively.\",\"425\":\"None\",\"426\":\"None\",\"427\":\"None\",\"428\":\"The theme \\\"power systems\\\" is relevant in the text because it discusses using big data, artificial intelligence, and machine learning to analyze phasor measurement unit data for grid operation and management. This indicates a focus on improving the efficiency and effectiveness of power systems.\",\"429\":\"None\",\"430\":\"None\",\"431\":\"None\",\"432\":\"None\",\"433\":\"None\",\"434\":\"None\",\"435\":\"None\",\"436\":\"None\",\"437\":\"None\",\"438\":\"None\",\"439\":\"None\",\"440\":\"None\",\"441\":\"None\",\"442\":\"None\",\"443\":\"None\",\"444\":\"None\",\"445\":\"None\",\"446\":\"None\",\"447\":\"None\",\"448\":\"None\",\"449\":\"None\",\"450\":\"None\",\"451\":\"None\",\"452\":\"None\",\"453\":\"None\",\"454\":\"None\"},\"infrastructure\":{\"0\":\"None\",\"1\":\"None\",\"2\":\"None\",\"3\":\"None\",\"4\":\"The theme \\\"infrastructure\\\" is not relevant in the given text. This text primarily discusses a project developed by the DHS HSI Innovation Lab \\/ RAVEn, which involves barcode scanning and data population. It mentions supporting ICE's mission, analyzing trends and criminal patterns, and refers to a privacy impact assessment. However, it does not provide any information or discussion related to infrastructure.\",\"5\":\"None\",\"6\":\"The theme \\\"infrastructure\\\" is not relevant in the given text. The text primarily focuses on the use of artificial intelligence and automation in the process of reviewing receipts and invoices. It does not mention or discuss any specific infrastructure requirements or considerations.\",\"7\":\"None\",\"8\":\"The theme of \\\"infrastructure\\\" is not directly relevant in this text. The focus of the text is on the breakthrough in assessing and modeling ground failure and loss caused by earthquakes using remote sensing and ground truth observations. While this advancement is important for predicting and mitigating damage to infrastructure, the text itself does not specifically discuss infrastructure or its implications. Therefore, the theme of \\\"infrastructure\\\" is None in this text.\",\"9\":\"None\",\"10\":\"The theme \\\"infrastructure\\\" is not relevant in this text. The text describes a chatbot system that is designed to assist the CMS Badging Help Desk by providing general information and tackling simpler issues. While the text mentions automation and phone response system, it does not provide any information or context related to the broader infrastructure. Hence, the theme \\\"infrastructure\\\" is None in this text.\",\"11\":\"None\",\"12\":\"The theme of \\\"infrastructure\\\" is not relevant in this text. This text primarily discusses the Global Engagement Center's Technology Testbed and the involvement of Makor Analytics in analyzing survey responses using their behavioral analytics technology. It does not mention or discuss any aspect of physical infrastructure or its relevance.\",\"13\":\"None\",\"14\":\"None. The text does not mention anything related to infrastructure. It focuses on describing a dataset of images and label masks of coastal, estuarine, and wetland environments.\",\"15\":\"None\",\"16\":\"None\",\"17\":\"The theme \\\"infrastructure\\\" is relevant in the text. It is mentioned that the project is being developed on AWS (Amazon Web Services) and in cooperation with CHS (presumably an organization or company), indicating the use of technological infrastructure for the development and testing of machine learning models. Additionally, the USGS HPC systems (High-Performance Computing systems) are being utilized, which further emphasizes the importance of infrastructure in the project.\",\"18\":\"The theme \\\"infrastructure\\\" is relevant in the text because it discusses the development of methods and technologies to defend industrial control systems (ICS) networks. Industrial control systems are a critical part of infrastructure, as they manage and control various processes in industries such as manufacturing, energy, and transportation. The research aims to enhance the cybersecurity of these systems, which are essential components of a country's infrastructure. Additionally, the mention of creating a prototype device suggests the development of physical infrastructure to support the implementation of cybersecurity measures in ICS networks. Therefore, the theme of \\\"infrastructure\\\" is relevant in this text.\",\"19\":\"None\",\"20\":\"The theme of \\\"infrastructure\\\" is not directly relevant in the given text. The text is discussing a machine-learning algorithm called ProbSR, which predicts the probability of roads being subfreezing. While this algorithm could indirectly impact infrastructure, as freezing roads can affect transportation and road conditions, the text itself does not delve into any infrastructure-related aspects. Therefore, the relevance of the theme \\\"infrastructure\\\" is None in this text.\",\"21\":\"The theme of \\\"infrastructure\\\" is not directly relevant in the given text. The text primarily focuses on the use of deep learning technology and internal voltage sensors to diagnose and predict failure in solid-state ceramic membrane reactors. It discusses data collection on current and impedance and the utilization of artificial intelligence to analyze the data for anticipating reactor failure. The text does not contain any specific information related to infrastructure such as the physical systems or structures supporting the reactors. Therefore, the theme of \\\"infrastructure\\\" is not relevant in this context.\",\"22\":\"The theme of \\\"infrastructure\\\" is not relevant in the given text. The text primarily discusses the Coastal Change Analysis Program (C-CAP) and the techniques they have been using for classifying coastal land cover. It mentions the transition from using Classification and Regression Trees to a convolutional neural network approach for deriving the impervious surface component of their land cover products. However, there is no mention or discussion of infrastructure in the text.\",\"23\":\"None\",\"24\":\"None\",\"25\":\"None\",\"26\":\"None\",\"27\":\"None\",\"28\":\"None\",\"29\":\"None\",\"30\":\"None\",\"31\":\"None\",\"32\":\"The theme \\\"infrastructure\\\" is relevant in the text above. This is because the Water Mission Area Drought Prediction Project mentions the utilization of USGS HPC systems for model development and running. HPC systems refer to High-Performance Computing systems, which are a part of the infrastructure necessary for carrying out the project efficiently.\",\"33\":\"None\",\"34\":\"None\",\"35\":\"None\",\"36\":\"The theme \\\"infrastructure\\\" is not relevant in the given text. The text primarily discusses the use of Apptio, a software tool, for invoicing bureaus, creating cost models, and predicting future values. It does not directly address or discuss any physical or technical infrastructure.\",\"37\":\"None\",\"38\":\"None\",\"39\":\"None\",\"40\":\"None\",\"41\":\"None\",\"42\":\"None\",\"43\":\"None\",\"44\":\"The theme of \\\"infrastructure\\\" is relevant in the given text. This is because the text discusses NASA SERVIR's project, which aims to enhance urban vulnerability assessment in major population centers. The project focuses on developing techniques to utilize satellite imagery and artificial intelligence to map informal settlements. This indicates a focus on the physical structures and systems that make up the infrastructure of urban areas. By creating replicable methods for future use, the project aims to improve the infrastructure of informal settlements and enhance urban resilience.\",\"45\":\"None\",\"46\":\"None\",\"47\":\"The theme of \\\"infrastructure\\\" is not relevant in the given text. The text focuses on the use of artificial intelligence technology to expedite the development of nuclear fuel through the analysis of microstructural image and thermal conductivity data. There is no mention or discussion of infrastructure-related aspects such as physical structures, systems, or networks. Therefore, the relevance of the theme \\\"infrastructure\\\" is None in this text.\",\"48\":\"None\",\"49\":\"The theme of \\\"infrastructure\\\" is not relevant in the given text. The text primarily focuses on the AI Curated Synthetic Data technology and its application in the field of anomaly detection in complex environments. It discusses the generation of artificial data for computer vision, specifically in the context of detecting narcotics and contraband in vehicles and cargo. There is no mention or connection to infrastructure, such as physical structures, systems, or networks that support the functioning of the technology or its implementation.\",\"50\":\"None\",\"51\":\"None\",\"52\":\"None\",\"53\":\"None\",\"54\":\"None\",\"55\":\"None\",\"56\":\"None\",\"57\":\"In the given text, the theme of \\\"infrastructure\\\" is not directly relevant. The text primarily discusses the City Pairs Program Ticket Forecast and Scenario Analysis Tools, which utilize segment-level City Pair Program air travel purchase data to predict air travel purchases in the current and upcoming fiscal year. It mentions different levels at which these forecasts are provided, such as DOD vs Civilian, Agency, and Region. Infrastructure, which refers to the physical and organizational structures needed for the operation of a society or organization, is not directly addressed in this text. None.\",\"58\":\"None\",\"59\":\"None\",\"60\":\"The theme \\\"infrastructure\\\" is relevant in the given text. The text mentions that the General Services Administration (GSA) is working on improving their document workflow platform. This implies that they are focusing on enhancing the infrastructure of their system to make it more accurate and scalable. By implementing intelligent data capture and extraction techniques, they aim to efficiently transfer important data from PDF files to the appropriate processes, workflows, or decision engines. This indicates a direct connection to infrastructure improvement within their document management system.\",\"61\":\"None\",\"62\":\"None\",\"63\":\"None\",\"64\":\"None\",\"65\":\"None\",\"66\":\"None\",\"67\":\"None\",\"68\":\"None\",\"69\":\"None\",\"70\":\"None\",\"71\":\"None\",\"72\":\"None\",\"73\":\"None\",\"74\":\"The theme of \\\"infrastructure\\\" is not directly relevant in the given text. The text mainly focuses on the application of big data, artificial intelligence, and machine learning to analyze PMU data for enhancing grid operation and management. It does not specifically address the topic of infrastructure, such as physical structures or systems, that support the functioning of the grid. Therefore, the relevance of the theme \\\"infrastructure\\\" in this text is None.\",\"75\":\"None\",\"76\":\"The theme \\\"infrastructure\\\" is relevant in the text because it talks about utilizing technology (big data, AI, and machine learning) to analyze PMU data for enhancing grid operation and management. This implies that there is a focus on improving the infrastructure of the power grid system by using advanced technologies and tools.\",\"77\":\"None\",\"78\":\"None\",\"79\":\"The theme \\\"infrastructure\\\" is relevant in the given text. This is because the text discusses the development of a machine learning-based system to detect attacks in the fifth generation (5G) cellular network. The 5G network is an example of infrastructure, as it refers to the underlying communication network that supports various technologies and applications like automated vehicles, drones, connected health, and emergency response operations. The focus on enhancing security for these mission-critical applications highlights the importance of a robust and reliable infrastructure, like the 5G network, to ensure their smooth functioning.\",\"80\":\"None\",\"81\":\"None\",\"82\":\"None\",\"83\":\"None\",\"84\":\"The theme \\\"infrastructure\\\" is relevant in the text above. The study focuses on using machine learning and object-based image classification techniques to identify buildings and building loss in wildland-urban interface areas before and after a wildfire. This implies that the study is concerned with the assessment of the impact of wildfires on infrastructure, specifically buildings. Additionally, the study aims to evaluate the effectiveness of defensible space measures, which are a form of infrastructure designed to protect buildings and surrounding areas from wildfires. Therefore, the theme of infrastructure is relevant in this context.\",\"85\":\"The theme of \\\"infrastructure\\\" is relevant in the text above. It highlights the various components and systems that make up the Autonomous Maritime Awareness system. These include surveillance towers, ocean data solutions, unmanned autonomous surface vehicles (ASV), and AI. The text also mentions that the surveillance towers are equipped with radars and cameras, and the ASVs are powered by wind, solar, or onboard engines. This emphasis on the physical structures and technologies used to detect, identify, and track objects in the maritime environment demonstrates the relevance of infrastructure in the text.\",\"86\":\"The theme of \\\"infrastructure\\\" is not directly relevant in the given text. The text mainly discusses the development of a model to classify and route Service Desk tickets, which pertains to automation and streamlining of processes. Infrastructure, on the other hand, typically refers to the underlying physical or organizational systems and facilities that support and enable operations. Since the text does not mention any explicit reference to infrastructure, the theme is not relevant in this context.\",\"87\":\"None\",\"88\":\"None\",\"89\":\"The theme of \\\"infrastructure\\\" is relevant in the text. This is because the text discusses the use of machine learning methods and deep learning algorithms to estimate load composition data and motor protection profiles for different climate regions in the Western US. These methods and algorithms are used to calibrate the parameters of the Western Electricity Coordinating Council (WECC) composite load model. The WECC composite load model is an important component of the infrastructure in the electricity system as it helps in understanding and predicting load responses.\",\"90\":\"None\",\"91\":\"None\",\"92\":\"The theme of \\\"infrastructure\\\" is not directly relevant in the given text. The text primarily focuses on analyzing the long-term impacts of land-use and land-cover dynamics on surface water quality in Botswana's Limpopo River Basin. It discusses the use of satellite data and artificial intelligence methods to determine the relationships between various factors and their effects on water quality and availability. Although the text mentions the development of empirical models for estimating water quality and mapping a water quality index, it does not specifically address infrastructure-related aspects such as the construction or maintenance of physical structures. Hence, the theme of \\\"infrastructure\\\" is not relevant in this text.\",\"93\":\"None\",\"94\":\"None\",\"95\":\"None\",\"96\":\"None\",\"97\":\"None\",\"98\":\"None\",\"99\":\"None\",\"100\":\"None\",\"101\":\"None\",\"102\":\"None\",\"103\":\"The theme of \\\"infrastructure\\\" is not directly relevant in the given text. The text primarily discusses the project's objective of improving the analysis of DC ramp test data from rotating machines by utilizing machine learning and AI tools. While this project may require certain infrastructure for the implementation and deployment of the computer software, the text does not focus on or provide any specific details regarding the infrastructure aspect.\",\"104\":\"None\",\"105\":\"None\",\"106\":\"None\",\"107\":\"None\",\"108\":\"The theme of \\\"infrastructure\\\" is not relevant in the given text. The text primarily discusses a system called the Surface Report Classifier (SCM\\/Auto-Class) that categorizes surface incident reports based on event type and severity. It does not provide any information or context related to infrastructure.\",\"109\":\"None\",\"110\":\"The theme of infrastructure is not directly relevant in the given text. The text primarily discusses the development of a tool that combines various models, algorithms, and equipment to accelerate the discovery, development, and deployment of nuclear fuels. It focuses on describing thermal properties related to temperature and irradiation. While the development of such a tool may require some infrastructure to support the research and testing processes, the text itself does not provide specific information or details about infrastructure. Hence, the relevance of the theme \\\"infrastructure\\\" is none in this text.\",\"111\":\"The theme \\\"infrastructure\\\" is not directly relevant in the given text. The text primarily focuses on the development of a next-generation prototype called the multi-model machine-learning metasystem (M4) by the USDA Natural Resources Conservation Service. This prototype aims to improve the accuracy of water supply forecasts and provide geophysical explanations for its results. While the text mentions water management in the western US, it does not specifically discuss or address any infrastructure-related aspects. Therefore, the theme \\\"infrastructure\\\" is not relevant in this context.\",\"112\":\"The theme of infrastructure is not directly relevant in the given text. The text focuses on the use of machine learning algorithms to predict and improve the detection of pests at the port of entry. It does not discuss or mention any infrastructure-related aspects such as physical structures, systems, or networks. Therefore, the relevance of the theme \\\"infrastructure\\\" is None in this text.\",\"113\":\"The theme of \\\"infrastructure\\\" is relevant in the given text. The text discusses the use of technology and tools, such as big data, artificial intelligence, and machine learning, to improve grid operation and management. This implies that the focus is on enhancing the infrastructure of the electrical grid by utilizing advanced technologies and tools for real-time monitoring.\",\"114\":\"None\",\"115\":\"None\",\"116\":\"None\",\"117\":\"The theme of \\\"infrastructure\\\" is relevant in the given text. The text discusses the importance of identifying wells with sustained casing pressure (SCP) in well platforms. SCP is typically caused by issues in the infrastructure, such as leaking cement sheaths, defects in tube connections, downhole accessories, or seals. This implies that the integrity and reliability of the infrastructure, including the cement sheaths and tube connections, are essential for preventing safety issues and accidents on the platforms.\",\"118\":\"None\",\"119\":\"The theme of \\\"infrastructure\\\" is relevant in the text provided. The text describes the Video Surveillance System (VSS), which is a comprehensive system consisting of various components such as cameras, network switches, and routers. This infrastructure is necessary for the functioning of the VSS, enabling it to collect, manage, and present video from multiple sources efficiently. Additionally, the mention of advanced features for tracking targets and selecting cameras indicates the importance of a robust infrastructure to support these capabilities.\",\"120\":\"None\",\"121\":\"None\",\"122\":\"The theme of \\\"infrastructure\\\" is not relevant in the given text. The text primarily focuses on the goal of connecting data on the flow of the Delaware River with models of trout population dynamics, changes in fish catch, and the economic benefits of recreational fishing. It mentions developing trout population models using observational data, literature estimates, and existing models, but it does not mention or discuss any infrastructure-related aspects. Therefore, the relevance of the theme \\\"infrastructure\\\" is None.\",\"123\":\"None\",\"124\":\"None\",\"125\":\"The theme of infrastructure is relevant in the given text because it mentions the various technologies and tools that are utilized in the system of Intelligent Ticket Routing. These technologies and tools, such as Python, JupyterHub, scikit-learn, GitLab, Flask, Gunicorn, Nginx, and ERMS, form the infrastructure of the system. They are the foundational components that enable the automation and routing of BMC Remedy tickets to the appropriate work groups. Therefore, the text highlights the importance of infrastructure in the development and operation of the system.\",\"126\":\"None\",\"127\":\"None\",\"128\":\"None\",\"129\":\"None\",\"130\":\"The theme of infrastructure is not directly relevant in the given text. The text primarily focuses on the Landscape Change Monitoring System (LCMS), which is a data system developed by the USDA Forest Service. The LCMS utilizes remote sensing to track and analyze changes in vegetation canopy cover, land cover, and land use. It employs a supervised classification process to identify areas of vegetation gain, loss, and changes in land cover and use. While the LCMS itself may rely on the underlying infrastructure of remote sensing technology and data systems, the text does not explicitly discuss infrastructure as a central theme. Therefore, the relevance of the theme \\\"infrastructure\\\" in this text is None.\",\"131\":\"None\",\"132\":\"None\",\"133\":\"The theme of \\\"infrastructure\\\" is not relevant in the given text. The text primarily discusses the Cropland Data Layer (CDL), which is a machine learning algorithm used to classify the type of crop or activity in each pixel on the ground. It mentions the training of the algorithm on USDA's Farm Services Agency data and its accuracy for commodities like corn and soybeans. However, it does not discuss or address any aspect of infrastructure.\",\"134\":\"None\",\"135\":\"None\",\"136\":\"None\",\"137\":\"None\",\"138\":\"None\",\"139\":\"None\",\"140\":\"None\",\"141\":\"None\",\"142\":\"None\",\"143\":\"None\",\"144\":\"The theme \\\"infrastructure\\\" is not directly relevant in the given text. The text primarily focuses on discussing the investigation of replacing unstructured wave models in the Great Lakes with AI models. It does not specifically address any aspects related to physical infrastructure or the development, maintenance, or improvement of infrastructure. Therefore, the relevance of the theme \\\"infrastructure\\\" in this text is None.\",\"145\":\"None\",\"146\":\"None\",\"147\":\"None\",\"148\":\"None\",\"149\":\"The theme of \\\"infrastructure\\\" is not directly relevant in the given text. The text focuses on the use of artificial intelligence and Monte Carlo algorithms to improve the efficiency and reliability of computational simulations for estimating low failure probabilities in advanced reactor technologies. It talks about reducing the number of finite element evaluations to enable the nuclear engineering community to conduct probabilistic failure analyses and uncertainty quantification studies more efficiently in the design and optimization of these technologies. While the text discusses the improvement and optimization of computational simulations, it does not directly address the physical infrastructure or the development or maintenance of any physical infrastructure. Therefore, the theme of \\\"infrastructure\\\" is not relevant in this text.\",\"150\":\"None\",\"151\":\"None\",\"152\":\"The theme of \\\"infrastructure\\\" is relevant in the given text. The text mentions the \\\"NESDIS Common Cloud Framework,\\\" which indicates the existence of a technological infrastructure that supports the VOLCAT project. The goal of transitioning the VOLCAT products to this framework implies the importance of having a robust and efficient infrastructure in place to meet the new requirements set by the International Civil Aviation Organization.\",\"153\":\"The theme of \\\"infrastructure\\\" is not relevant in the given text. The text primarily discusses the Village Monitoring System program, which utilizes AI and machine learning to analyze satellite imagery. It mentions the program's capability to detect anomalies or unusual patterns by focusing on the near-infrared band. However, it does not directly address or discuss any aspects related to infrastructure. Therefore, the relevance of the theme \\\"infrastructure\\\" is None in this context.\",\"154\":\"None\",\"155\":\"None\",\"156\":\"None\",\"157\":\"None\",\"158\":\"None\",\"159\":\"None\",\"160\":\"The theme of \\\"infrastructure\\\" is not directly relevant in the text. The text primarily focuses on the importance of malware reverse engineering and the use of advanced techniques and tools for cyber threat intelligence. It does not specifically discuss or address infrastructure-related aspects such as physical or digital infrastructure. Therefore, the relevance of the theme \\\"infrastructure\\\" in this text is None.\",\"161\":\"None\",\"162\":\"The theme of \\\"infrastructure\\\" is relevant in the given text. The text discusses how artificial intelligence and machine learning can be utilized to improve the analysis of high-resolution photogrammetric data obtained from unmanned aerial systems. This analysis can aid in providing detailed information about Reclamation's assets, which is crucial for better-informed decision making regarding infrastructure.\",\"163\":\"None\",\"164\":\"The theme \\\"infrastructure\\\" is relevant in the text because it mentions the use of the USGS Tallgrass supercomputer to build the models. The mention of the supercomputer highlights the importance of having a reliable and powerful infrastructure in place to handle the computational requirements of the project.\",\"165\":\"None\",\"166\":\"The theme of \\\"infrastructure\\\" is relevant in the text because it refers to the development of a simulation framework that aims to make real-time decisions for integrated energy systems (IES) operation. This suggests that the project is focused on improving and optimizing the infrastructure of energy systems by using high-fidelity physics models and grid monitoring data. The framework will also help in detecting and responding to component contingencies caused by extreme events, such as cyber-attacks or extreme weather, which further emphasizes the relevance of infrastructure in ensuring the smooth operation of energy systems.\",\"167\":\"None\",\"168\":\"None\",\"169\":\"None\",\"170\":\"None\",\"171\":\"The theme \\\"infrastructure\\\" is relevant in the text because it discusses the use of technology (big data, artificial intelligence, and machine learning) to analyze phasor measurement unit data. This technology is used to improve grid operation and management, which is a crucial aspect of infrastructure.\",\"172\":\"None\",\"173\":\"None\",\"174\":\"The theme of \\\"infrastructure\\\" is not directly relevant in the given text. The text primarily focuses on the development of a digital twin for a centrifugal contactor system in the nuclear fuel cycle, utilizing sensors, machine learning, and data analysis techniques. Although the text mentions the involvement of a team of nuclear safeguards experts, it does not explicitly discuss the infrastructure required to support the research or the development of the digital twin. Therefore, the theme of \\\"infrastructure\\\" is not relevant to this text.\",\"175\":\"None\",\"176\":\"None\",\"177\":\"None\",\"178\":\"The theme \\\"infrastructure\\\" is relevant in the given text. The text describes how Splunk, an IT system monitoring software, collects and analyzes system logs from various IT infrastructure systems and endpoints. This implies that infrastructure, which refers to the underlying physical and organizational structures that support a system, is an integral part of Splunk's functioning. Therefore, the theme of infrastructure is relevant in this context.\",\"179\":\"None\",\"180\":\"None\",\"181\":\"None\",\"182\":\"None\",\"183\":\"The theme of \\\"infrastructure\\\" is relevant in the given text. This is because the text discusses the use of millimeter wave beam directionality and autonomous beam scheduling to support secure spectrum sharing for 5G. These technologies aim to ensure optimal performance for base stations, which are a crucial part of the infrastructure required for wireless communication. Additionally, the text mentions that the autonomous beam scheduling algorithms developed through measurements and predictive analytics will benefit mission-critical communications, emergency response operations, and secure communication for critical infrastructure. Therefore, the text clearly highlights the significance of infrastructure in the context of 5G communication.\",\"184\":\"None\",\"185\":\"The theme \\\"infrastructure\\\" is not directly relevant in the given text. The text primarily focuses on the development of a deep reinforcement learning approach for managing multi-agent systems in energy systems. It discusses the utilization of deep neural networks for system representation, modeling, and learning. While the text mentions optimization of nonlinear systems over various timescales, it does not specifically address infrastructure in terms of physical structures or systems. Therefore, the theme \\\"infrastructure\\\" is None in this context.\",\"186\":\"None\",\"187\":\"None\",\"188\":\"None\",\"189\":\"None\",\"190\":\"None\",\"191\":\"None\",\"192\":\"None\",\"193\":\"None\",\"194\":\"None\",\"195\":\"None\",\"196\":\"None\",\"197\":\"None\",\"198\":\"None\",\"199\":\"None\",\"200\":\"None\",\"201\":\"The theme of \\\"infrastructure\\\" is relevant in the text because it discusses the development of a framework and process to translate industrial control system features into a machine-readable format. This indicates a focus on the infrastructure required for automated cyber tools to function effectively. The text also mentions the examination of current and evolving standards for usability with diverse grid architectures, which further emphasizes the importance of infrastructure in the context of cyber tools. Additionally, the project aims to enhance national capabilities for sharing actionable threat intelligence at machine speed, which also involves infrastructure considerations related to communication networks and information sharing systems.\",\"202\":\"None\",\"203\":\"None\",\"204\":\"The theme of \\\"infrastructure\\\" is not directly relevant in the given text. The text primarily focuses on the use of big data, AI, and machine learning to enhance power system resilience and improve grid operation and management. While infrastructure is an essential component of power systems, the text does not explicitly discuss the planning, development, or maintenance of physical infrastructure such as power plants, transmission lines, or substations. Therefore, the theme of infrastructure is not directly addressed in the text.\",\"205\":\"The theme \\\"infrastructure\\\" is relevant in the text because it discusses how predictive maintenance can impact infrastructure items. It mentions specific tools and technologies like einblick, mysql, python, linux, and tableau that are used in the process, implying that these tools contribute to the infrastructure necessary for conducting predictive maintenance. Thus, the text directly relates to the theme of infrastructure.\",\"206\":\"None\",\"207\":\"None. The text does not mention or discuss infrastructure in any way. It focuses on the use of machine learning to develop a ground motion model and its effectiveness in utilizing synthetic data.\",\"208\":\"None\",\"209\":\"None\",\"210\":\"The theme of \\\"infrastructure\\\" is relevant in the text above. The text discusses the use of computer vision techniques for processing satellite imagery to analyze critical infrastructure and interdependency data. It highlights how these techniques, when combined with functional taxonomic approach and unique geo-spatial and dependency datasets, can improve national critical infrastructure security and defense capabilities. Therefore, the text directly addresses the relevance of infrastructure in the context of computer vision and satellite imagery analysis.\",\"211\":\"None\",\"212\":\"None\",\"213\":\"None\",\"214\":\"None\",\"215\":\"The theme \\\"infrastructure\\\" is relevant in the text. The text mentions the plan to transition from running the machine learning codes on a desktop to a cloud computing platform like AWS. This transition is a change in infrastructure, highlighting the relevance of the theme in the text.\",\"216\":\"None. The text does not mention or discuss anything related to infrastructure. It focuses on the development and success of neural network radiations for forecasting systems.\",\"217\":\"The theme of \\\"infrastructure\\\" is relevant in the given text. The text specifically mentions the monitoring of critical infrastructure networks, which indicates a focus on the infrastructure. The Cyber Sentry program is designed to analyze cyber-physical data from IT and OT networks, including ICS\\/SCADA, which are crucial components of infrastructure systems. Additionally, the text mentions the Critical Infrastructure Anomaly Alerting model, which further emphasizes the relevance of infrastructure in the context of cybersecurity.\",\"218\":\"The theme \\\"infrastructure\\\" is not relevant in the given text. The text mainly discusses the evaluation of streamflow forecasting technologies and the success of a specific company in providing accurate forecasts. There is no mention or discussion of infrastructure or its relevance.\",\"219\":\"The theme of infrastructure is relevant in the given text. The text mentions several components of infrastructure that are involved in the process of creating detailed land cover maps. \\n\\nFirstly, it mentions the use of a web application to generate training data. This implies the presence of a digital infrastructure, such as servers and networks, that enable the functioning of the web application.\\n\\nSecondly, the text states that the data is processed using a large docker cluster. This highlights the importance of the computing infrastructure required to process the data efficiently. The docker cluster likely includes multiple interconnected servers or virtual machines working together to handle the computational workload.\\n\\nLastly, the results are made publicly available through an image service. This indicates the existence of an infrastructure that allows for the storage, retrieval, and dissemination of the land cover maps to the public.\\n\\nTherefore, infrastructure plays a crucial role in the overall process described in the text.\",\"220\":\"None\",\"221\":\"The theme of \\\"infrastructure\\\" is relevant in the text because it discusses the use of photogrammetric products, drones, and other devices to analyze and map cracks on Reclamation facilities. This indicates that there is a focus on improving the infrastructure of these facilities by utilizing modern technology and methods. The implementation of a standardized protocol and the use of machine learning and AI also suggest an effort to enhance the infrastructure management and decision-making process related to Reclamation assets. Therefore, the theme of infrastructure is directly applicable in this text.\",\"222\":\"The theme of \\\"infrastructure\\\" is relevant in the given text. The text discusses the development of machine learning methodologies to assess the resilience of integrated energy systems. This implies a focus on the infrastructure of energy systems and how it can withstand threats and vulnerabilities. Additionally, the text mentions the impact of microreactors and distributed energy resources on the reliability and resiliency of energy systems, which further emphasizes the importance of infrastructure in the context of energy systems.\",\"223\":\"None\",\"224\":\"None\",\"225\":\"The theme of \\\"infrastructure\\\" is not directly relevant in the given text. The text primarily focuses on the COVID-19 Pandemic Vulnerability Index Dashboard, which is a tool for assessing disease risk profiles in different counties of the United States. It does not specifically discuss or touch upon the topic of infrastructure. Therefore, the text is not relevant to the theme of infrastructure.\",\"226\":\"None\",\"227\":\"None\",\"228\":\"None\",\"229\":\"None\",\"230\":\"None\",\"231\":\"The theme \\\"infrastructure\\\" is relevant in the given text. The text discusses using big data, artificial intelligence, and machine learning technology on PMU data to enhance grid operation and management. This implies a focus on the electrical grid infrastructure and finding ways to improve its efficiency and effectiveness.\",\"232\":\"None\",\"233\":\"None\",\"234\":\"None\",\"235\":\"The theme of \\\"infrastructure\\\" is not directly relevant in the given text. The text primarily focuses on the importance of understanding changes in sub-surface drainage and analyzing their effects on streamflow and water quality. It mentions the method proposed, which involves using satellite imagery and a combination of python scripting and Jupyter notebook for creating a geospatial layer. While the text indirectly references the use of technology and tools for data analysis, it does not specifically address the broader concept of infrastructure.\",\"236\":\"The theme \\\"infrastructure\\\" is relevant in the text because the Conflict Observatory program uses AI and machine learning to analyze satellite imagery and conduct automated damage assessments of various buildings, including critical infrastructure. This means that the program focuses on assessing the damage to infrastructure such as hospitals, schools, and crop storage facilities, which is crucial in understanding the impact of war crimes and abuses in Ukraine.\",\"237\":\"None\",\"238\":\"None\",\"239\":\"None\",\"240\":\"The theme of \\\"infrastructure\\\" is relevant in the text because it discusses the development and validation of scalable models for achieving autonomous operation of microreactors. This implies the need for a well-designed infrastructure that can support the functioning of these microreactors. The mention of a \\\"full feeder microgrid\\\" further suggests the importance of infrastructure in deploying and managing emerging reactors.\",\"241\":\"The theme of infrastructure is relevant in the given text. The text discusses the use of generative adversarial networks to automate the training of anomaly detection systems for legacy industrial control systems devices and Industrial Internet of Things. By automating the training process, the text suggests that it would reduce the manual labor and operational costs associated with protecting legacy control systems from intrusion. This implies a focus on improving the infrastructure of industrial control systems and Industrial Internet of Things by implementing more efficient and cost-effective methods for protecting them.\",\"242\":\"None\",\"243\":\"None\",\"244\":\"None\",\"245\":\"The theme \\\"infrastructure\\\" is relevant in the given text. The text discusses the Grid Resilience and Intelligence Platform (GRIP), which utilizes artificial intelligence (AI) to analyze utility data and predict the potential impacts of major storms on the power grid. This demonstrates the relevance of infrastructure as the focus is on the power grid's resilience and ability to withstand extreme weather events.\",\"246\":\"None\",\"247\":\"None\",\"248\":\"None\",\"249\":\"None\",\"250\":\"The theme of infrastructure is not directly relevant in the given text. The text discusses the use of machine learning software to analyze camera images of a wind sock in remote areas. It highlights the AI capability's success in accurately determining surface wind speed and direction, providing crucial weather information in inaccessible locations. While the text does mention remote areas and inaccessible locations, it does not focus on the infrastructure required to support this technology or the development of necessary infrastructure. Therefore, the theme of infrastructure is not relevant in this context.\",\"251\":\"The theme of \\\"infrastructure\\\" is relevant in the given text. It discusses the use of big data, AI, and machine learning technology to enhance grid operation and management. This indicates a focus on improving the infrastructure of the grid system by utilizing advanced technologies and developing tools for better management.\",\"252\":\"None\",\"253\":\"None\",\"254\":\"None\",\"255\":\"None\",\"256\":\"The theme of \\\"infrastructure\\\" is not relevant in this text. The text primarily focuses on the use of a neural network for land cover classification and its application in mapping soil vs. rock-covered areas for different purposes such as landslide hazard mapping and water flux calculations. There is no direct mention or connection to infrastructure development, maintenance, or related issues.\",\"257\":\"None\",\"258\":\"None\",\"259\":\"The theme \\\"infrastructure\\\" is not relevant in the given text. The text primarily discusses the CLT knowledge database, an information system that collects and organizes information about cross-laminated timber (CLT). It mentions the use of data aggregator bots to search the internet for relevant CLT information and the cataloging of over 3,600 publications on various aspects of CLT. It also highlights the database's goal of fostering collaboration among stakeholders and supporting the increased use of mass timber for the benefit of forest health. However, it does not directly address or discuss infrastructure in any significant manner.\",\"260\":\"The theme of \\\"infrastructure\\\" is relevant in the text. The text discusses A\\/LM's plan to develop AI\\/ML models to detect potential fraud or malfeasance in their Integrated Logistics Management System (ILMS). This indicates that A\\/LM aims to strengthen their infrastructure by implementing advanced technologies to improve risk analytics in key supply chain functions such as Asset Management, Procure-to-Pay, and Fleet Management. This shows the relevance of the theme of infrastructure in the text.\",\"261\":\"None\",\"262\":\"None\",\"263\":\"None\",\"264\":\"None\",\"265\":\"None\",\"266\":\"The theme of \\\"infrastructure\\\" is relevant in the given text because it discusses the use of a deep neural network, DeepCNet, for identifying and classifying features related to railroad tracks. This technology is utilized for \\\"change detection\\\" applications, where it can identify any changes in the track's status or between different inspections based on geolocation. This application demonstrates the relevance of infrastructure as it pertains to the maintenance and monitoring of railroad tracks.\",\"267\":\"None\",\"268\":\"None\",\"269\":\"None\",\"270\":\"None\",\"271\":\"The theme of infrastructure is not directly relevant in the given text. The text primarily discusses the investigation of using advancements in machine learning to enhance the mapping of wetlands and floodplains. It focuses on the potential applications of these improved mappings in managing protected species and decision-making in operations and planning. While infrastructure could indirectly be involved in the decision-making process or management of protected species, it is not explicitly mentioned or discussed in the text. Therefore, the theme of infrastructure is not relevant in this text.\",\"272\":\"The theme \\\"infrastructure\\\" is not relevant in the given text. The text primarily discusses the use of Text Analytics for Survey Responses (TASR) by the DHS OCHCO to analyze and extract important topics\\/themes from survey responses. It further mentions how the results are used by DHS Leadership to improve employee satisfaction and meet their basic needs. However, there is no direct mention or connection to infrastructure in the text.\",\"273\":\"None\",\"274\":\"None\",\"275\":\"None\",\"276\":\"None\",\"277\":\"None\",\"278\":\"None\",\"279\":\"None\",\"280\":\"None\",\"281\":\"The theme of \\\"infrastructure\\\" is not directly relevant in the given text. The text primarily discusses the National Landcover database (NLCD) and its use of artificial intelligence and machine learning to generate landcover data for various purposes. While the NLCD and its data may indirectly contribute to urban planning and development, the text does not provide specific information about the physical infrastructure involved in this process. Therefore, the theme of \\\"infrastructure\\\" is not directly addressed in the text.\",\"282\":\"None\",\"283\":\"None\",\"284\":\"None\",\"285\":\"None\",\"286\":\"The theme of \\\"infrastructure\\\" is not relevant in the given text. The text primarily discusses the Solicitation Review Tool (SRT) and its use of machine learning algorithms to analyze ICT solicitations for compliance language. It mentions the validation process by agencies and the monthly random manual reviews conducted by GSA. However, there is no direct connection to infrastructure.\",\"287\":\"The theme of \\\"infrastructure\\\" is relevant in the text provided. The text discusses the condition of well platforms and the need for assessing safety concerns. It states that reports are used to determine if additional audits are needed. The mention of an automated screening system that can identify areas with excessive corrosion highlights the importance of having a well-maintained infrastructure to ensure safety and efficiency.\",\"288\":\"None\",\"289\":\"The theme of \\\"infrastructure\\\" is relevant in the text. The text mentions the development of a framework for automated malware analysis using dynamic sandboxes. This framework is designed to provide capabilities for analyzing industrial control system malware and sharing threat information. By creating this infrastructure, the goal is to enable further analysis through machine learning and facilitate timely and automated analysis of malware samples. Hence, the text demonstrates the relevance of the theme \\\"infrastructure\\\" as it pertains to the development of a framework for automated malware analysis.\",\"290\":\"None\",\"291\":\"The theme of \\\"infrastructure\\\" is not directly relevant in the given text. The text primarily focuses on the efficient use of limited experimental data, developing sparse data reconstruction methods, and leveraging sparse sensing and learning for prediction, diagnostics, and prognostics capabilities in the context of nuclear digital twins (NDTs). It does not discuss the physical infrastructure or the development, maintenance, or improvement of any specific infrastructure systems. Therefore, the theme \\\"infrastructure\\\" is not applicable here.\",\"292\":\"None\",\"293\":\"None\",\"294\":\"None\",\"295\":\"None\",\"296\":\"None\",\"297\":\"The theme \\\"infrastructure\\\" is relevant in the given text. It mentions the Operations Center in CISA (Cybersecurity and Infrastructure Security Agency) which utilizes an artificial intelligence-powered dashboard. This dashboard assists duty officers and analysts in understanding ongoing operational activities, particularly in the context of critical infrastructure. The AI system combines real-time event data, historical cybersecurity information, and previous response activity to suggest appropriate actions and engagement strategies with government entities and critical infrastructure owners. The focus on critical infrastructure and its potential impacts on national critical functions highlights the relevance of the theme \\\"infrastructure\\\" in this text.\",\"298\":\"None\",\"299\":\"None\",\"300\":\"None\",\"301\":\"The theme of \\\"infrastructure\\\" is relevant in the text because it mentions the use of Amazon Web Services (AWS) as the platform for the Fouling Identification Neural Network (FINN) system. AWS is an important part of the infrastructure that enables the system to operate in real-time and provide predictions every 30 minutes. Additionally, the text mentions the USGS AQUARIUS database, which is likely part of the overall infrastructure supporting the system.\",\"302\":\"None\",\"303\":\"The theme of \\\"infrastructure\\\" is not directly relevant in the given text. The text primarily focuses on the efforts of Reclamation and its collaboration with the Scripps Institute of Oceanography to develop data-driven methods for predicting temperature and precipitation. It mentions the improvement of sub-seasonal forecasts and its significant impact on water management outcomes. However, there is no specific mention or discussion of infrastructure in the text.\",\"304\":\"None\",\"305\":\"None\",\"306\":\"None\",\"307\":\"None\",\"308\":\"The theme of \\\"infrastructure\\\" is not directly relevant in the given text. The text mainly focuses on the description of a system that utilizes deep learning computer vision algorithms to analyze the particle size grading of crushed aggregate and generate a ballast fouling index. It does not discuss or address any aspects of infrastructure such as buildings, transportation networks, or basic physical structures.\",\"309\":\"None\",\"310\":\"The theme \\\"infrastructure\\\" is relevant in the text above. This is because the USGS National Earthquake Information Center has utilized deep learning and AI technology to enhance their earthquake monitoring system. This advancement in infrastructure allows for improved automatic earthquake detection and characterization. Additionally, the models were developed using programming languages and libraries such as Python, Keras, and Tensorflow, which are part of the technological infrastructure used in this context.\",\"311\":\"None\",\"312\":\"None\",\"313\":\"The theme of \\\"infrastructure\\\" is not relevant in the given text. The text primarily discusses the development of ground-motion models using a gradient boosting method and the identification of four explanatory variables (M, Rjb, VS30, and Ztor) for predicting peak ground acceleration (PGA) and peak ground velocity (PGV). The focus is on the methodology and variables used in the research, rather than infrastructure.\",\"314\":\"The theme of \\\"infrastructure\\\" is relevant in the given text. The researchers are developing a machine learning model to predict the location of the salt front in the Delaware River Estuary. To build this model, they are using various data sources such as river discharge, tidal forcings, and meteorological data. Additionally, they are comparing their model with a process-based hydrodynamic model called COAWST. Furthermore, they mention that the model is being built using tools from pyTorch, which is a software library for machine learning. All these elements, including the data sources, comparison with another model, and the use of specific tools, highlight the relevance of infrastructure in this context.\",\"315\":\"None\",\"316\":\"None\",\"317\":\"None\",\"318\":\"The theme of \\\"infrastructure\\\" is relevant in the text because it mentions the development of an AI-based recommender system that improves the efficiency and scalability of training returns selection and field work processes. This implies that the system enhances the existing infrastructure by providing a more advanced and effective solution for detecting potential non-compliance issues.\",\"319\":\"None\",\"320\":\"None\",\"321\":\"None\",\"322\":\"None\",\"323\":\"None\",\"324\":\"The theme of infrastructure is not directly relevant in the given text. The text primarily focuses on the Institute for Telecommunication Sciences (ITS) using AI and a convolutional neural network (CNN) to identify and classify clutter obstructed radio frequency propagation paths. It mentions the use of lidar data and radio frequency propagation measurements to train the CNN and predict clutter classification labels. However, it does not discuss or mention anything specific about infrastructure such as the construction, maintenance, or development of physical structures or systems. Hence, the theme of infrastructure is not relevant in this text.\",\"325\":\"None\",\"326\":\"None\",\"327\":\"None\",\"328\":\"None\",\"329\":\"The theme of \\\"infrastructure\\\" is relevant in the given text. The text mentions the use of ServiceNow Virtual Agent by ILMS to create an automated support desk assistant. This implies the implementation of a technological infrastructure that supports the virtual agent system. The use of this infrastructure is intended to streamline support desk operations and minimize costs.\",\"330\":\"None\",\"331\":\"The theme of \\\"infrastructure\\\" is not relevant in this text. The text primarily discusses the use of an artificial intelligence system called ChatGPT to support the rulemaking processes of PHMSA. It mentions how ChatGPT will analyze comments on proposed rules, provide summaries, and identify duplicate comments to improve efficiency and scalability in handling public scrutiny or interest. However, it does not directly address infrastructure.\",\"332\":\"None\",\"333\":\"None\",\"334\":\"The theme of \\\"infrastructure\\\" is relevant in the given text. The text discusses the use of IoT sensor kits, high-resolution cameras, and AI models to create a system for detecting and tracking illicit cross-border traffic. This indicates the presence of a physical infrastructure comprising of sensors, cameras, and AI technology that is being utilized to enhance situational awareness.\",\"335\":\"None\",\"336\":\"None\",\"337\":\"The theme of \\\"infrastructure\\\" is not directly relevant in the given text. The text mainly focuses on the need for automated delay detection using voice processing in air traffic control. It discusses the limitations of the current reporting system and proposes the use of voice detection to improve the detection of certain delay events. While the text does mention the need for accurate tracking and accounting for delays in air traffic control, it does not delve into the broader theme of infrastructure that encompasses the physical structures and systems supporting the aviation industry. Hence, the relevance of the theme \\\"infrastructure\\\" is None in this text.\",\"338\":\"None\",\"339\":\"None\",\"340\":\"None\",\"341\":\"The theme \\\"infrastructure\\\" is relevant in the given text. The text discusses the Rapid Authority to Operate (ATO) System, which utilizes natural language processing (NLP) to analyze system security plans and identify commonly used technology components in Federal Information Security Management Act (FISMA) systems. This system helps the Centers for Medicare and Medicaid Services (CMS) in identifying similar approaches to solving control areas within the Acceptable Risk Safeguards (ARS) and streamlining the generation of system security plans for new systems. The infrastructure here refers to the technological and security infrastructure utilized by the ATO System to analyze and streamline the generation of system security plans.\",\"342\":\"None\",\"343\":\"None\",\"344\":\"The theme \\\"infrastructure\\\" is not directly relevant in the given text. The text primarily discusses the Offshore Precipitation Capability (OPC), which is a technological system that utilizes various data sources and machine learning techniques to improve the identification and prediction of precipitation areas. While the text mentions the use of satellite data, it does not provide any information about the infrastructure or physical systems involved in the implementation of OPC. Therefore, the theme \\\"infrastructure\\\" is not relevant in this context.\",\"345\":\"The theme of \\\"infrastructure\\\" is relevant in the given text. It is evident through the mention of the Cybersecurity and Infrastructure Security Agency (CISA), which highlights the importance of having robust infrastructure in place to ensure cybersecurity. The text further emphasizes the use of advanced analytics, forensic specialists, and artificial intelligence tools, all of which require a strong technological infrastructure to operate effectively.\",\"346\":\"The theme of \\\"infrastructure\\\" is relevant in the given text. It is mentioned that the system for predicting specific conductance in inland stream reaches in the Delaware River Basin will be built using pyTorch on the USGS Tallgrass supercomputer. This indicates that the infrastructure, which includes the computer hardware and software, is an essential component in developing and implementing the predictive model.\",\"347\":\"None\",\"348\":\"None\",\"349\":\"None\",\"350\":\"None\",\"351\":\"None\",\"352\":\"None\",\"353\":\"None\",\"354\":\"None\",\"355\":\"None\",\"356\":\"The theme \\\"infrastructure\\\" is not directly relevant in the provided text. The text primarily focuses on predicting the thickness of the regolith layer in the Delaware River Basin using data collected from private well drillers. It mentions the use of a Random Forest model to create a data product that can support groundwater and hydrologic modeling. While infrastructure, in a broader sense, may play a role in the collection and management of the data, it is not explicitly discussed or emphasized in the text.\",\"357\":\"None\",\"358\":\"None\",\"359\":\"None\",\"360\":\"The theme \\\"infrastructure\\\" is relevant in the given text. The text mentions the development of a system to predict lake water temperature. This implies the need for a well-established infrastructure to support the process. It mentions the utilization of Python packages such as PyTorch, which requires a robust computational infrastructure like the USGS Tallgrass supercomputer. Additionally, the mention of collecting and utilizing lake temperature observations and meteorological data suggests the importance of a data infrastructure to store, process, and analyze the information. Therefore, the theme of infrastructure is relevant in this text.\",\"361\":\"In the given text, the theme of \\\"infrastructure\\\" is not relevant. The text primarily discusses a machine learning product called First Guess Excessive Rainfall Outlook, which is designed to predict excessive rainfall based on atmospheric variables. While infrastructure might play a role in collecting the atmospheric data and disseminating the rainfall outlook, the text itself does not directly address infrastructure. Hence, the relevance of the theme \\\"infrastructure\\\" is None in this text.\",\"362\":\"None\",\"363\":\"None\",\"364\":\"None\",\"365\":\"None\",\"366\":\"None\",\"367\":\"None\",\"368\":\"The theme \\\"infrastructure\\\" is not relevant in the given text. This text primarily focuses on the use of Artificial Neural Networks (ANNs) to enhance earthquake ground-motion models. It discusses the data and programming tools used to build the model, but it does not touch upon infrastructure-related topics such as transportation systems, communication networks, or urban development. Therefore, the relevance of the theme \\\"infrastructure\\\" is None in this text.\",\"369\":\"None\",\"370\":\"The theme of \\\"infrastructure\\\" is relevant in the given text. The development of a web app by the IRS to predict when procurement requests will become signed contracts highlights the importance of a technological infrastructure. This infrastructure, in the form of a machine learning model, plays a crucial role in providing valuable insights for the IRS and other federal agencies. The app's predictive capabilities help streamline the process of signing contracts, which ultimately impacts the allocation of significant government funds amounting to $600 billion.\",\"371\":\"None\",\"372\":\"None\",\"373\":\"None\",\"374\":\"The theme of \\\"infrastructure\\\" is not directly relevant in the given text. The text discusses the use of Natural Language Processing (NLP) as a tool to assist in the regulatory comment analysis process. It highlights how these tools can help reviewers identify comment topics and themes, group similar comments together, and streamline the comment processing, thereby providing efficiency and cost savings for government agencies. However, the text does not specifically address infrastructure in terms of physical structures or systems.\",\"375\":\"None\",\"376\":\"None\",\"377\":\"None\",\"378\":\"None\",\"379\":\"The theme \\\"infrastructure\\\" is relevant in the given text. The text mentions the MARS program, which is working on developing a safety case for reducing separation standards between PBN (Performance-Based Navigation) routes in terminal airspace. This implies that the program is focusing on improving the infrastructure of the airspace by implementing more efficient separation standards. Additionally, the text talks about the need to build collision risk models, which is an integral part of infrastructure planning and management in the aviation industry. Thus, the theme of infrastructure is relevant in this text.\",\"380\":\"None\",\"381\":\"None\",\"382\":\"None. The text does not mention infrastructure or any related concepts, so the theme of \\\"infrastructure\\\" is not relevant in this text.\",\"383\":\"None\",\"384\":\"None\",\"385\":\"The theme \\\"infrastructure\\\" is relevant in the text because it discusses the development of predictive analytics using Autonomous Track Geometry Measurement System (ATGMS) data to analyze and predict track locations of concern. This process helps with maintenance and safety limits, which are crucial aspects of infrastructure management.\",\"386\":\"The theme \\\"infrastructure\\\" is not relevant in the given text. None. The text focuses on the development of a machine learning model and its application in analyzing fish movement in restored coastal wetlands. It does not mention or discuss any infrastructure-related aspects.\",\"387\":\"None\",\"388\":\"None\",\"389\":\"None\",\"390\":\"None\",\"391\":\"None\",\"392\":\"The theme of \\\"infrastructure\\\" is relevant in the given text. The text discusses the limitations of typical contingency analysis for power utilities, which refers to the examination of potential failures or disruptions in the infrastructure of power systems. It then introduces a new approach that utilizes a machine learning framework and resilience-chaos plots, which can improve the analysis of infrastructure vulnerabilities. This new method reduces computational expense and enhances the ability to accurately discover n-2 contingencies, which are issues or failures involving multiple components of the power system's infrastructure. Therefore, the theme of infrastructure is directly addressed in the text.\",\"393\":\"None\",\"394\":\"None\",\"395\":\"None\",\"396\":\"None\",\"397\":\"None\",\"398\":\"None\",\"399\":\"None\",\"400\":\"None\",\"401\":\"In this text, the theme of \\\"infrastructure\\\" is not directly mentioned. The focus of the text is on the establishment of a social innovation lab for a machine vision program in Morogoro, Tanzania, to address agricultural problems faced by farmers in the region. The text discusses the development of experts who can use machine vision to solve various agricultural problems. While infrastructure may play a role in the establishment of the lab, it is not explicitly discussed or emphasized in the text. Therefore, the theme of \\\"infrastructure\\\" is not relevant in this context.\",\"402\":\"None\",\"403\":\"None\",\"404\":\"None\",\"405\":\"The theme of \\\"infrastructure\\\" is relevant in the given text. The text discusses the RISE project, which aims to integrate a camera system into the USGS Water Mission Area's streamgage monitoring network. This integration requires the development of physical infrastructure to install the camera system at various locations within the network. Additionally, the use of AI\\/ML modeling techniques to generate time-series data from the camera images also involves the development of computational infrastructure to process and analyze the data. Therefore, the theme of \\\"infrastructure\\\" is relevant in the context of this text.\",\"406\":\"None\",\"407\":\"The theme of \\\"infrastructure\\\" is not directly relevant in the given text. The text primarily focuses on the project's aim to research and implement machine learning and artificial intelligence algorithms for detecting false data injection in physical processes. It also mentions the development of an advanced library for improved detection of malicious tampering. Although infrastructure may indirectly play a role in supporting the implementation and development of these algorithms and libraries, it is not explicitly mentioned in the text. Therefore, the relevance of the theme \\\"infrastructure\\\" in this text is None.\",\"408\":\"The theme of \\\"infrastructure\\\" is relevant in the text above. This is because the researchers are developing a cloud-native software architecture to apply the machine learning model in real-time using Amazon Web Services (AWS). This infrastructure is crucial for the effective and efficient implementation of the model and the improvement of the earthquake catalog.\",\"409\":\"None\",\"410\":\"The theme of infrastructure is relevant in the given text because it discusses the implementation of a chatbot assistant on the Department of Labor's intranet websites. This implementation is a part of the organization's infrastructure development to improve the efficiency and accessibility of information for its employees.\",\"411\":\"None\",\"412\":\"None\",\"413\":\"None\",\"414\":\"None. The text does not mention or discuss infrastructure. It focuses on the use of deep learning approaches to analyze earthquake sequences and understand fault systems and triggering mechanisms.\",\"415\":\"None\",\"416\":\"None\",\"417\":\"None\",\"418\":\"The theme of \\\"infrastructure\\\" is not directly relevant in the given text. The passage focuses on the use of Hololens AI technology for inspectors to visually inspect high and unsafe areas without risking their safety. While the text discusses the use of technology and its benefits, it does not specifically address the concept of infrastructure. Therefore, the relevance of the theme \\\"infrastructure\\\" in this text is None.\",\"419\":\"None\",\"420\":\"None\",\"421\":\"None\",\"422\":\"The theme of infrastructure is relevant in the given text. Specifically, the text mentions the use of the USGS Tallgrass supercomputer for training the convolutional neural networks (CNNs). This demonstrates the importance of having a robust and efficient infrastructure, such as a powerful computer system, to support the development and implementation of technology-based solutions like the CNNs.\",\"423\":\"None\",\"424\":\"The theme of \\\"infrastructure\\\" is relevant in the given text because it describes the features and capabilities of the Autonomous Surveillance Towers. The text highlights how these towers are easily deployable and can be relocated quickly, indicating the importance of having a flexible and adaptable infrastructure to support their operation. Furthermore, the mention of the towers being solar-powered with battery backup emphasizes the need for a reliable and sustainable infrastructure to ensure the continuous functioning of the surveillance system. Additionally, the text mentions the hybrid command and control capability accessible through various devices, which implies the presence of a robust infrastructure to enable seamless communication and coordination between the towers and the user interface.\",\"425\":\"None\",\"426\":\"The theme of \\\"infrastructure\\\" is not directly relevant in the given text. This text primarily focuses on the Land Use Plan Document and Data Mining and Analysis R&D project, which aims to analyze unstructured planning documents to uncover patterns and conflicts in resource management planning rules. The output of this project helps identify proposed action locations that require exclusion, restrictions, or stipulations based on the conflicts found in the planning documents. While infrastructure may indirectly play a role in resource management planning, it is not explicitly mentioned or discussed in the given text. Therefore, the theme of \\\"infrastructure\\\" is not relevant in this context.\",\"427\":\"None\",\"428\":\"The theme of \\\"infrastructure\\\" is relevant in the given text. The text discusses using big data, artificial intelligence, and machine learning to analyze phasor measurement unit data for grid operation and management. This implies that the focus is on improving the efficiency of the grid infrastructure through the utilization of advanced technologies and data analysis techniques.\",\"429\":\"None\",\"430\":\"None\",\"431\":\"None\",\"432\":\"None\",\"433\":\"None\",\"434\":\"None\",\"435\":\"None\",\"436\":\"None\",\"437\":\"None\",\"438\":\"The theme \\\"infrastructure\\\" is relevant in the given text because it discusses the need for the AVS International office to comply with ICAO Standards and Recommended Practices (SARPs). To achieve compliance, the office requires an infrastructure in the form of the Regulatory Compliance Mapping Tool (RCMT). This tool processes thousands of pages of documents through Natural Language Processing (NLP) to extract the meaning of the text and uses a recommender system to establish matches between the SARPs and FAA text. The RCMT serves as an infrastructure to organize and manage the compliance evidence, making it easier for the office to comply with the ICAO standards.\",\"439\":\"None\",\"440\":\"None\",\"441\":\"The theme of \\\"infrastructure\\\" is not directly relevant in the given text. This text focuses on the company A\\/LM's plans to utilize transactional data and analyze real system actions and clicks to create customized user experiences and analytics. It mentions reducing the time taken to complete daily tasks, which implies improving efficiency. While infrastructure can play a role in supporting these goals, the text does not provide any specific information or details about the infrastructure being used or how it relates to the company's plans. Therefore, the theme of \\\"infrastructure\\\" is not directly addressed in this text.\",\"442\":\"None\",\"443\":\"None\",\"444\":\"None\",\"445\":\"None\",\"446\":\"None\",\"447\":\"None\",\"448\":\"None\",\"449\":\"None\",\"450\":\"None\",\"451\":\"None\",\"452\":\"None\",\"453\":\"None\",\"454\":\"None\"},\"fraud\":{\"0\":\"None\",\"1\":\"None\",\"2\":\"None\",\"3\":\"None\",\"4\":\"None\",\"5\":\"None\",\"6\":\"The theme of \\\"fraud\\\" is relevant in the text because it explicitly mentions the detection of fraud patterns on retailer invoices and receipts. The text suggests that the Retailer Receipt Analysis is designed to automate the process of reviewing receipts and invoices to detect any fraudulent activities. Therefore, the theme of fraud is directly addressed in the text.\",\"7\":\"None\",\"8\":\"None\",\"9\":\"None\",\"10\":\"None\",\"11\":\"None\",\"12\":\"None\",\"13\":\"None\",\"14\":\"None\",\"15\":\"None\",\"16\":\"None\",\"17\":\"None\",\"18\":\"None\",\"19\":\"None\",\"20\":\"None\",\"21\":\"None\",\"22\":\"None\",\"23\":\"None\",\"24\":\"None\",\"25\":\"None\",\"26\":\"None\",\"27\":\"None\",\"28\":\"None\",\"29\":\"None\",\"30\":\"None\",\"31\":\"None\",\"32\":\"None\",\"33\":\"None\",\"34\":\"None\",\"35\":\"None\",\"36\":\"None\",\"37\":\"None\",\"38\":\"None\",\"39\":\"None\",\"40\":\"None\",\"41\":\"None\",\"42\":\"None\",\"43\":\"The theme of \\\"fraud\\\" is relevant in the given text because it mentions that the Identity Match Option (IMO) process is used by USCIS (United States Citizenship and Immigration Services) for fraud detection. By combining data from multiple systems, the IMO process helps analyze and identify potential instances of fraud in immigration histories. Therefore, fraud detection is an important aspect of the text.\",\"44\":\"None\",\"45\":\"None\",\"46\":\"None\",\"47\":\"None\",\"48\":\"The theme of fraud is relevant in the given text. The text highlights the use of technology, such as Artificial Intelligence and mobile device cameras, for \\\"Liveness Detection\\\" in the CBP One app. This technology aims to detect proof of life and ensure that the submitted data is from the real person in front of the camera. By emphasizing the importance of this technology in reducing fraudulent activity, the text establishes the theme of fraud and its prevention.\",\"49\":\"None\",\"50\":\"None. The text does not mention or imply any form of fraud. It primarily discusses the use of Mobile Device Analytics (MDA) in aiding investigators to analyze data from mobile devices, improving efficiency, identifying evidence, and detecting objects in photos and videos.\",\"51\":\"None\",\"52\":\"None\",\"53\":\"None\",\"54\":\"None\",\"55\":\"None\",\"56\":\"The theme of \\\"fraud\\\" is not relevant in this text. The text is discussing the NRP Redesign, which aims to improve the efficiency of compliance baselines, tax gap estimation, improper payments reporting, workload identification and selection models, and policy analysis. It mentions that the system inputs depend on existing NRP data that must meet a certain level of precision and quality. However, there is no mention or relevance to fraud in this context.\",\"57\":\"None\",\"58\":\"None\",\"59\":\"The theme of \\\"fraud\\\" is relevant in the text because it mentions the \\\"Fraud Prevention System (FPS)\\\" and the use of the \\\"Priority Score Model\\\" to rank providers within the system. This implies that the text is discussing measures taken to prevent and detect fraudulent activities within the healthcare system.\",\"60\":\"None\",\"61\":\"None\",\"62\":\"None\",\"63\":\"None\",\"64\":\"None\",\"65\":\"None\",\"66\":\"None\",\"67\":\"None\",\"68\":\"None\",\"69\":\"The theme of \\\"fraud\\\" is relevant in the given text. The text mentions the utilization of machine learning in the SSI Redetermination Model to identify cases of supplemental security income that have significant overpayments due to alterations in financial eligibility. These alterations could potentially be fraudulent activities where individuals manipulate their financial information to receive more benefits than they are entitled to. Therefore, the text highlights the relevance of the theme of \\\"fraud\\\" in identifying such cases and flagging them for further review by technicians.\",\"70\":\"None\",\"71\":\"None\",\"72\":\"None\",\"73\":\"None\",\"74\":\"None\",\"75\":\"None\",\"76\":\"None\",\"77\":\"None\",\"78\":\"None\",\"79\":\"None\",\"80\":\"None\",\"81\":\"None\",\"82\":\"None\",\"83\":\"None\",\"84\":\"None\",\"85\":\"None\",\"86\":\"None\",\"87\":\"None\",\"88\":\"None\",\"89\":\"None\",\"90\":\"None\",\"91\":\"None\",\"92\":\"None\",\"93\":\"None\",\"94\":\"None\",\"95\":\"None\",\"96\":\"None\",\"97\":\"None\",\"98\":\"None\",\"99\":\"None\",\"100\":\"None\",\"101\":\"None\",\"102\":\"None\",\"103\":\"None\",\"104\":\"None\",\"105\":\"None\",\"106\":\"None\",\"107\":\"None\",\"108\":\"None\",\"109\":\"None\",\"110\":\"None\",\"111\":\"None\",\"112\":\"None\",\"113\":\"None\",\"114\":\"None\",\"115\":\"None\",\"116\":\"None\",\"117\":\"None\",\"118\":\"None\",\"119\":\"None\",\"120\":\"None\",\"121\":\"None\",\"122\":\"None\",\"123\":\"None\",\"124\":\"None\",\"125\":\"None\",\"126\":\"None\",\"127\":\"None\",\"128\":\"None\",\"129\":\"None\",\"130\":\"None\",\"131\":\"None\",\"132\":\"None\",\"133\":\"None\",\"134\":\"None\",\"135\":\"None\",\"136\":\"None\",\"137\":\"None\",\"138\":\"None\",\"139\":\"None\",\"140\":\"None\",\"141\":\"None\",\"142\":\"None\",\"143\":\"None\",\"144\":\"None\",\"145\":\"None\",\"146\":\"None\",\"147\":\"None\",\"148\":\"None\",\"149\":\"None\",\"150\":\"None\",\"151\":\"None\",\"152\":\"None\",\"153\":\"None\",\"154\":\"None\",\"155\":\"None\",\"156\":\"None\",\"157\":\"None\",\"158\":\"None\",\"159\":\"None\",\"160\":\"None\",\"161\":\"None\",\"162\":\"None\",\"163\":\"None\",\"164\":\"None\",\"165\":\"None\",\"166\":\"None\",\"167\":\"None. The theme of \\\"fraud\\\" is not relevant in this text. The text mainly discusses the use of a predictive model to identify high-risk iClaims and the subsequent review process. There is no mention or indication of fraudulent activities or deceptive behavior.\",\"168\":\"None\",\"169\":\"None\",\"170\":\"None\",\"171\":\"None\",\"172\":\"None\",\"173\":\"None\",\"174\":\"None\",\"175\":\"None\",\"176\":\"None\",\"177\":\"None\",\"178\":\"None\",\"179\":\"None\",\"180\":\"None\",\"181\":\"None\",\"182\":\"None\",\"183\":\"None\",\"184\":\"None\",\"185\":\"None\",\"186\":\"None\",\"187\":\"None\",\"188\":\"None\",\"189\":\"None\",\"190\":\"None\",\"191\":\"None\",\"192\":\"None\",\"193\":\"None\",\"194\":\"None\",\"195\":\"None\",\"196\":\"None\",\"197\":\"None\",\"198\":\"None\",\"199\":\"None\",\"200\":\"None\",\"201\":\"None\",\"202\":\"None\",\"203\":\"The theme of \\\"fraud\\\" is relevant in the given text. This is evident from phrases such as \\\"evaluate compliance risk,\\\" \\\"detect abnormal tax returns,\\\" and \\\"identifying anomalies.\\\" These indicate the intention to uncover fraudulent activities related to tax returns and line-item values. The text suggests that the recommender system model is designed to identify and flag potential instances of fraud or non-compliance with tax regulations, ultimately assisting the IRS LB&I reviewers in their efforts to combat fraud.\",\"204\":\"None\",\"205\":\"None\",\"206\":\"None\",\"207\":\"None\",\"208\":\"None\",\"209\":\"None\",\"210\":\"None\",\"211\":\"None\",\"212\":\"None\",\"213\":\"None\",\"214\":\"None\",\"215\":\"None\",\"216\":\"None\",\"217\":\"None\",\"218\":\"None\",\"219\":\"None\",\"220\":\"None\",\"221\":\"None\",\"222\":\"None\",\"223\":\"None\",\"224\":\"None\",\"225\":\"None\",\"226\":\"None\",\"227\":\"None\",\"228\":\"None\",\"229\":\"None\",\"230\":\"None\",\"231\":\"None\",\"232\":\"None\",\"233\":\"None\",\"234\":\"None\",\"235\":\"None\",\"236\":\"None\",\"237\":\"None\",\"238\":\"None\",\"239\":\"None\",\"240\":\"None\",\"241\":\"None\",\"242\":\"None\",\"243\":\"The theme of \\\"fraud\\\" is relevant in this text. The text specifically mentions the \\\"Fraud Prevention System\\\" and prioritizing alerts related to fraud. It also mentions that the inputs for this prioritization include Medicare Claims data, which suggests that the system is designed to detect and prevent fraud in healthcare claims. Therefore, the theme of fraud is relevant in this text.\",\"244\":\"None\",\"245\":\"None\",\"246\":\"None\",\"247\":\"None\",\"248\":\"None\",\"249\":\"None\",\"250\":\"None\",\"251\":\"None\",\"252\":\"The theme of \\\"fraud\\\" is relevant in the text because it discusses the use of AI technology to detect mismatched addresses and garbled text in letters sent to benefits recipients. This implies that there may be attempts to deceive or manipulate the system by providing false or altered information, which relates to the concept of fraud. The technology mentioned aims to identify and prevent such fraudulent activities by validating official documents.\",\"253\":\"None\",\"254\":\"None\",\"255\":\"None\",\"256\":\"None\",\"257\":\"None\",\"258\":\"None\",\"259\":\"None\",\"260\":\"The theme of \\\"fraud\\\" is relevant in the given text. The text mentions that A\\/LM plans to develop AI\\/ML models to detect potential fraud or malfeasance in their Integrated Logistics Management System (ILMS). This indicates that the company recognizes the importance of identifying and preventing fraudulent activities within their supply chain functions, such as Asset Management, Procure-to-Pay, and Fleet Management. By enhancing existing risk analytics, A\\/LM aims to address the issue of fraud and malfeasance, highlighting the relevance of the theme in the text.\",\"261\":\"None\",\"262\":\"None\",\"263\":\"None\",\"264\":\"None\",\"265\":\"None\",\"266\":\"None\",\"267\":\"None\",\"268\":\"None\",\"269\":\"None\",\"270\":\"None\",\"271\":\"None\",\"272\":\"None\",\"273\":\"None\",\"274\":\"None\",\"275\":\"None\",\"276\":\"None\",\"277\":\"None\",\"278\":\"None\",\"279\":\"None\",\"280\":\"None\",\"281\":\"None\",\"282\":\"None\",\"283\":\"None\",\"284\":\"None\",\"285\":\"None\",\"286\":\"None\",\"287\":\"None\",\"288\":\"None\",\"289\":\"None\",\"290\":\"None\",\"291\":\"None\",\"292\":\"None\",\"293\":\"None\",\"294\":\"None\",\"295\":\"None\",\"296\":\"None\",\"297\":\"None\",\"298\":\"None\",\"299\":\"None\",\"300\":\"None\",\"301\":\"None\",\"302\":\"None\",\"303\":\"None\",\"304\":\"None\",\"305\":\"The theme of fraud is relevant in the given text. It is mentioned that the IT modernization product, IMAGEN, will leverage machine learning technologies to support fraud prevention initiatives. This indicates that the product is designed to improve efficiency and consistency in disability determinations and decisions while also aiming to prevent fraud.\",\"306\":\"None\",\"307\":\"None\",\"308\":\"None\",\"309\":\"None\",\"310\":\"None\",\"311\":\"None\",\"312\":\"None\",\"313\":\"None\",\"314\":\"None\",\"315\":\"None\",\"316\":\"None\",\"317\":\"None\",\"318\":\"None\",\"319\":\"None\",\"320\":\"None\",\"321\":\"None\",\"322\":\"None\",\"323\":\"None\",\"324\":\"None\",\"325\":\"None\",\"326\":\"None\",\"327\":\"None\",\"328\":\"None\",\"329\":\"None\",\"330\":\"None\",\"331\":\"None\",\"332\":\"None\",\"333\":\"None\",\"334\":\"None\",\"335\":\"None\",\"336\":\"None\",\"337\":\"None\",\"338\":\"None\",\"339\":\"None\",\"340\":\"None\",\"341\":\"None\",\"342\":\"None\",\"343\":\"None\",\"344\":\"None\",\"345\":\"None\",\"346\":\"None\",\"347\":\"None\",\"348\":\"None\",\"349\":\"None\",\"350\":\"None\",\"351\":\"None\",\"352\":\"None\",\"353\":\"None\",\"354\":\"None\",\"355\":\"None\",\"356\":\"None\",\"357\":\"None\",\"358\":\"None\",\"359\":\"None\",\"360\":\"None\",\"361\":\"None\",\"362\":\"None. The text does not mention or discuss any fraudulent activities or deceptive behavior. It focuses on the use of third-party global trade data, AI\\/ML models, and software functions to enhance investigations and analyze trade flows and associated risks.\",\"363\":\"None\",\"364\":\"None\",\"365\":\"None\",\"366\":\"None\",\"367\":\"None\",\"368\":\"None\",\"369\":\"None. \\n\\nThe theme of \\\"fraud\\\" is not relevant in the text provided. The text discusses the use of a machine learning model to analyze partnership data and assess the risk of potential non-compliance. While non-compliance may involve legal or regulatory issues, it does not necessarily imply fraudulent activities.\",\"370\":\"None\",\"371\":\"None\",\"372\":\"None\",\"373\":\"None\",\"374\":\"None\",\"375\":\"None\",\"376\":\"None\",\"377\":\"None\",\"378\":\"None\",\"379\":\"None\",\"380\":\"None\",\"381\":\"None\",\"382\":\"None\",\"383\":\"None\",\"384\":\"None\",\"385\":\"None\",\"386\":\"None\",\"387\":\"None\",\"388\":\"None\",\"389\":\"None\",\"390\":\"None\",\"391\":\"None. The text does not mention anything related to fraud.\",\"392\":\"None\",\"393\":\"None\",\"394\":\"None\",\"395\":\"None\",\"396\":\"None\",\"397\":\"None. The theme of \\\"fraud\\\" is not relevant in the given text. The text discusses a machine learning model called the Rep Payee Misuse Model, which is designed to predict the likelihood of representative payees misusing resources. It aims to identify cases that may require further examination to prevent the misuse of funds. However, the text does not indicate any instances of actual fraud or fraudulent activities.\",\"398\":\"None\",\"399\":\"None\",\"400\":\"None\",\"401\":\"None\",\"402\":\"None\",\"403\":\"None\",\"404\":\"None\",\"405\":\"None\",\"406\":\"None\",\"407\":\"The theme of \\\"fraud\\\" is relevant in the given text. The text discusses a project that focuses on using machine learning and artificial intelligence algorithms to detect false data injection in physical processes. This implies that the project is aiming to identify and uncover instances of fraudulent activities where data is being manipulated or tampered with malicious intent. Therefore, the theme of fraud is directly connected to the project's goals and objectives.\",\"408\":\"None\",\"409\":\"None\",\"410\":\"None\",\"411\":\"None\",\"412\":\"None\",\"413\":\"None\",\"414\":\"None\",\"415\":\"None\",\"416\":\"None\",\"417\":\"None\",\"418\":\"None\",\"419\":\"None\",\"420\":\"None\",\"421\":\"None\",\"422\":\"None\",\"423\":\"None\",\"424\":\"None\",\"425\":\"None\",\"426\":\"None\",\"427\":\"None\",\"428\":\"None\",\"429\":\"None\",\"430\":\"None\",\"431\":\"The theme of \\\"fraud\\\" is not relevant in the given text. The text discusses a tool called Grants Analytics Portal, which utilizes AI to help HHS OIG staff access grants data efficiently. The purpose of the tool is to assist in finding relevant findings, comparing data, identifying trends, and assessing potential anomalies in grantees. While the text mentions anomalies, it does not specifically refer to fraud. Therefore, the theme of fraud is not relevant in this context.\",\"432\":\"None\",\"433\":\"None. The theme of fraud is not relevant in this text. The text discusses the use of AI to address the issue of spam and marketing emails in civil rights complaints email channels, but it does not mention any fraudulent activity.\",\"434\":\"None\",\"435\":\"None\",\"436\":\"None\",\"437\":\"None\",\"438\":\"None\",\"439\":\"None\",\"440\":\"None\",\"441\":\"None\",\"442\":\"None\",\"443\":\"None\",\"444\":\"The theme of \\\"fraud\\\" is not relevant in this text. The text discusses the use of a technology service called Sealr to verify the delivery of foreign assistance in conflict-affected areas. While the use of blockchain encryption and artificial intelligence helps secure and detect tampering of photographs, there is no mention of fraud or deceitful practices.\",\"445\":\"None\",\"446\":\"None\",\"447\":\"None\",\"448\":\"None\",\"449\":\"None\",\"450\":\"None\",\"451\":\"None\",\"452\":\"None\",\"453\":\"None\",\"454\":\"None\"}}",
  "executive_summary": "AI is utilized in a wide range of projects to improve efficiency, accuracy, and decision-making across different industries and sectors. These projects involve using AI for tasks such as identifying incorrect subsidies, predicting disease progression, enhancing treatment, detecting suicidal thoughts, optimizing hospital performance, analyzing claim submission patterns, tracking mental health, mapping wildfire damage, classifying marine species, defending industrial control systems, improving document workflow, enhancing customer service experiences, predicting eligibility for naturalization, analyzing data for various applications, and automating manual processes to detect fraud patterns. Overall, AI is being applied to address diverse challenges and improve outcomes across multiple domains."
}